{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a26ad83",
   "metadata": {},
   "source": [
    "# Competition 3: Team 21\n",
    "\n",
    "112062649 王俊皓\n",
    "\n",
    "112062650 廖士傑\n",
    "\n",
    "##  Reverse Image Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "414f827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project settings\n",
    "# enc / gen / dis: True means using a more complex setting, False means using a setting that is closer to template\n",
    "# enc_do_batchnorm: encoder will perform batch normalization to make the text encoding more variant\n",
    "# dis_backbone: the type of backbone in discriminator, can be 'resnet', 'vgg', 'simple'\n",
    "# delete_checkpoint: deletes all checkpoint files before training\n",
    "\n",
    "class experimental_settings:\n",
    "    def __init__(self,\n",
    "                 enc=True,\n",
    "                 enc_do_batchnorm=False,\n",
    "                 gen=True,\n",
    "                 dis=True,\n",
    "                 dis_backbone='simple',\n",
    "                 delete_checkpoint=False):\n",
    "        self.enc = enc\n",
    "        self.gen = gen\n",
    "        self.dis = dis\n",
    "        self.dis_backbone = dis_backbone\n",
    "        self.enc_do_batchnorm = enc_do_batchnorm\n",
    "        self.delete_checkpoint = delete_checkpoint # not implemented yet\n",
    "        \n",
    "        # ============================ #\n",
    "        # automatic\n",
    "        # ============================ #\n",
    "        \n",
    "        self.caption_type = 'sentence' if self.enc else 'id'\n",
    "\n",
    "\n",
    "expSettings = experimental_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32322ac2",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "15576cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "import re\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd7b646",
   "metadata": {},
   "source": [
    "GPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "d992c613",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a71f7c6",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "58104ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 5427 vocabularies in total\n",
      "Word to id mapping, for example: flower -> 1\n",
      "Id to word mapping, for example: 1 -> flower\n",
      "Tokens: <PAD>: 5427; <RARE>: 5428\n"
     ]
    }
   ],
   "source": [
    "dictionary_path = './dictionary'\n",
    "vocab = np.load(dictionary_path + '/vocab.npy')\n",
    "print('there are {} vocabularies in total'.format(len(vocab)))\n",
    "\n",
    "word2Id_dict = dict(np.load(dictionary_path + '/word2Id.npy'))\n",
    "id2word_dict = dict(np.load(dictionary_path + '/id2Word.npy'))\n",
    "print('Word to id mapping, for example: %s -> %s' % ('flower', word2Id_dict['flower']))\n",
    "print('Id to word mapping, for example: %s -> %s' % ('1', id2word_dict['1']))\n",
    "print('Tokens: <PAD>: %s; <RARE>: %s' % (word2Id_dict['<PAD>'], word2Id_dict['<RARE>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "3bf3f5d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the flower shown has yellow anther red pistil and bright red petals.\n",
      "['9', '1', '82', '5', '11', '70', '20', '31', '3', '29', '20', '2', '5427', '5427', '5427', '5427', '5427', '5427', '5427', '5427']\n"
     ]
    }
   ],
   "source": [
    "def sent2IdList(line, MAX_SEQ_LENGTH=20):\n",
    "    MAX_SEQ_LIMIT = MAX_SEQ_LENGTH\n",
    "    padding = 0\n",
    "    \n",
    "    # data preprocessing, remove all puntuation in the texts\n",
    "    prep_line = re.sub('[%s]' % re.escape(string.punctuation), ' ', line.rstrip())\n",
    "    prep_line = prep_line.replace('-', ' ')\n",
    "    prep_line = prep_line.replace('-', ' ')\n",
    "    prep_line = prep_line.replace('  ', ' ')\n",
    "    prep_line = prep_line.replace('.', '')\n",
    "    tokens = prep_line.split(' ')\n",
    "    tokens = [\n",
    "        tokens[i] for i in range(len(tokens))\n",
    "        if tokens[i] != ' ' and tokens[i] != ''\n",
    "    ]\n",
    "    l = len(tokens)\n",
    "    padding = MAX_SEQ_LIMIT - l\n",
    "    \n",
    "    # make sure length of each text is equal to MAX_SEQ_LENGTH, and replace the less common word with <RARE> token\n",
    "    for i in range(padding):\n",
    "        tokens.append('<PAD>')\n",
    "    line = [\n",
    "        word2Id_dict[tokens[k]]\n",
    "        if tokens[k] in word2Id_dict else word2Id_dict['<RARE>']\n",
    "        for k in range(len(tokens))\n",
    "    ]\n",
    "\n",
    "    return line\n",
    "\n",
    "text = \"the flower shown has yellow anther red pistil and bright red petals.\"\n",
    "print(text)\n",
    "print(sent2IdList(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "d14b0e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9', '1', '82', '5', '11', '70', '20', '31', '3', '29', '20', '2', '5427', '5427', '5427', '5427', '5427', '5427', '5427', '5427']\n",
      "tf.Tensor(b'the flower shown has yellow anther red pistil and bright red petals <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def id2Sent(ids):\n",
    "    return \" \".join([id2word_dict[idx] for idx in ids]).strip()\n",
    "\n",
    "#def batch_id2Sent(batch_ids):\n",
    "    #return [id2Sent(ids) for ids in batch_ids]\n",
    "    \n",
    "def batch_id2Sent(batch_ids):\n",
    "    def process_single(ids):\n",
    "        # Convert a single tensor of IDs to a sentence\n",
    "        ids = ids.numpy()  # Convert Tensor to NumPy\n",
    "        sentence = \" \".join([id2word_dict.get(idx, \"<UNK>\") for idx in ids])  # Handle unknown IDs\n",
    "        return sentence\n",
    "\n",
    "    # Use tf.py_function to apply Python function inside the TensorFlow graph\n",
    "    sentences = tf.map_fn(\n",
    "        lambda ids: tf.py_function(process_single, [ids], tf.string),\n",
    "        batch_ids,\n",
    "        fn_output_signature=tf.string\n",
    "    )\n",
    "    return sentences\n",
    "\n",
    "\n",
    "print(sent2IdList(text))\n",
    "print(id2Sent(sent2IdList(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "23133915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7370 image in training data\n"
     ]
    }
   ],
   "source": [
    "data_path = './dataset'\n",
    "text2ImgData = pd.read_pickle(data_path + '/text2ImgData.pkl')\n",
    "num_training_sample = len(text2ImgData)\n",
    "n_images_train = num_training_sample\n",
    "print('There are %d image in training data' % (n_images_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "d2c49264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption2string(cap):\n",
    "    output = []\n",
    "    for sen in cap:\n",
    "        s = \" \".join([id2word_dict[idx] for idx in sen]).strip()\n",
    "        output.append(s.split(' <PAD>')[0])\n",
    "    return output\n",
    "\n",
    "# adding caption as strings\n",
    "text2ImgData['Captions_string'] = text2ImgData['Captions'].apply(caption2string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "cdf9314c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Captions</th>\n",
       "      <th>ImagePath</th>\n",
       "      <th>Captions_string</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>[[9, 2, 17, 9, 1, 6, 14, 13, 18, 3, 41, 8, 11,...</td>\n",
       "      <td>./102flowers/image_06734.jpg</td>\n",
       "      <td>[the petals of the flower are pink in color an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6736</th>\n",
       "      <td>[[4, 1, 5, 12, 2, 3, 11, 31, 28, 68, 106, 132,...</td>\n",
       "      <td>./102flowers/image_06736.jpg</td>\n",
       "      <td>[this flower has white petals and yellow pisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6737</th>\n",
       "      <td>[[9, 2, 27, 4, 1, 6, 14, 7, 12, 19, 5427, 5427...</td>\n",
       "      <td>./102flowers/image_06737.jpg</td>\n",
       "      <td>[the petals on this flower are pink with white...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6738</th>\n",
       "      <td>[[9, 1, 5, 8, 54, 16, 38, 7, 12, 116, 325, 3, ...</td>\n",
       "      <td>./102flowers/image_06738.jpg</td>\n",
       "      <td>[the flower has a smooth purple petal with whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>[[4, 12, 1, 5, 29, 11, 19, 7, 26, 70, 5427, 54...</td>\n",
       "      <td>./102flowers/image_06739.jpg</td>\n",
       "      <td>[this white flower has bright yellow stamen wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Captions  \\\n",
       "ID                                                        \n",
       "6734  [[9, 2, 17, 9, 1, 6, 14, 13, 18, 3, 41, 8, 11,...   \n",
       "6736  [[4, 1, 5, 12, 2, 3, 11, 31, 28, 68, 106, 132,...   \n",
       "6737  [[9, 2, 27, 4, 1, 6, 14, 7, 12, 19, 5427, 5427...   \n",
       "6738  [[9, 1, 5, 8, 54, 16, 38, 7, 12, 116, 325, 3, ...   \n",
       "6739  [[4, 12, 1, 5, 29, 11, 19, 7, 26, 70, 5427, 54...   \n",
       "\n",
       "                         ImagePath  \\\n",
       "ID                                   \n",
       "6734  ./102flowers/image_06734.jpg   \n",
       "6736  ./102flowers/image_06736.jpg   \n",
       "6737  ./102flowers/image_06737.jpg   \n",
       "6738  ./102flowers/image_06738.jpg   \n",
       "6739  ./102flowers/image_06739.jpg   \n",
       "\n",
       "                                        Captions_string  \n",
       "ID                                                       \n",
       "6734  [the petals of the flower are pink in color an...  \n",
       "6736  [this flower has white petals and yellow pisti...  \n",
       "6737  [the petals on this flower are pink with white...  \n",
       "6738  [the flower has a smooth purple petal with whi...  \n",
       "6739  [this white flower has bright yellow stamen wi...  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2ImgData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f4a6b09d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the petals of the flower are pink in color and have a yellow center',\n",
       "  'this flower is pink and white in color with petals that are multi colored',\n",
       "  'the purple petals have shades of white with white anther and filament',\n",
       "  'this flower has large pink petals and a white stigma in the center',\n",
       "  'this flower has petals that are pink and has a yellow stamen',\n",
       "  'a flower with short and wide petals that is light purple',\n",
       "  'this flower has small pink petals with a yellow center',\n",
       "  'this flower has large rounded pink petals with curved edges and purple veins',\n",
       "  'this flower has purple petals as well as a white stamen']]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2ImgData['Captions_string'][:1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d5efa616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this competition, you have to generate image in size 64x64x3\n",
    "IMAGE_SIZE = 64\n",
    "IMAGE_HEIGHT = IMAGE_SIZE\n",
    "IMAGE_WIDTH = IMAGE_SIZE\n",
    "IMAGE_CHANNEL = 3\n",
    "\n",
    "def training_data_generator(caption, image_path, caption_type='id'):\n",
    "    # load in the image according to image path\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize(img, size=[IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    img.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL])\n",
    "    if caption_type == 'id':\n",
    "        caption = tf.cast(caption, tf.int32)\n",
    "    elif caption_type == 'sentence':\n",
    "        caption = tf.convert_to_tensor(caption, dtype=tf.string)\n",
    "\n",
    "    return img, caption\n",
    "\n",
    "def dataset_generator(filenames, batch_size, data_generator, caption_type='id'):\n",
    "    # load the training data into two NumPy arrays\n",
    "    if filenames != None:\n",
    "        df = pd.read_pickle(filenames)\n",
    "    else:\n",
    "        df = text2ImgData\n",
    "    \n",
    "    if caption_type == 'id':\n",
    "        captions = df['Captions'].values\n",
    "    elif caption_type == 'sentence':\n",
    "        captions = df['Captions_string'].values\n",
    "    else:\n",
    "        raise ValueError('for dataset_generator, caption_type= should be \\'id\\' or \\'sentence\\'.')\n",
    "        \n",
    "    caption = []\n",
    "    # each image has 1 to 10 corresponding captions\n",
    "    # we choose one of them randomly for training\n",
    "    \n",
    "    # ============================================ #\n",
    "    # TODO: augmentation\n",
    "    # idea 1 (difficulty: easy)\n",
    "    #     training data has multiple captions, right now it picks a random one.\n",
    "    #     we can make it so that every caption is an entry and multiple captions link to the same image.\n",
    "    # idea 2 (difficulty: medium)\n",
    "    #     after text embedding, use the average of 2 caption embeddings to generate a new caption.\n",
    "    #     the data does not need to have an image tied to it, it just have the label 0 (fake image).\n",
    "    # ============================================ #\n",
    "    for i in range(len(captions)):\n",
    "        caption.append(random.choice(captions[i]))\n",
    "    caption = np.asarray(caption)\n",
    "    \n",
    "    if caption_type == 'id':\n",
    "        caption = caption.astype(np.int)\n",
    "        \n",
    "    image_path = df['ImagePath'].values\n",
    "    \n",
    "    # assume that each row of `features` corresponds to the same row as `labels`.\n",
    "    assert caption.shape[0] == image_path.shape[0]\n",
    "    \n",
    "    datagen_func = lambda cap, img: data_generator(cap, img, caption_type=caption_type)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((caption, image_path))\n",
    "    dataset = dataset.map(datagen_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(len(caption)).batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "710669ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "dataset = dataset_generator(\n",
    "    #data_path + '/text2ImgData.pkl',\n",
    "    None,\n",
    "    BATCH_SIZE, \n",
    "    training_data_generator, \n",
    "    caption_type=expSettings.caption_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "d9640f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (64, 64, 64, 3)\n",
      "Caption shape: (64,)\n"
     ]
    }
   ],
   "source": [
    "# dataset testing ground\n",
    "for img, cap in dataset.take(1):\n",
    "    print(\"Image shape:\", img.numpy().shape)\n",
    "    print(\"Caption shape:\", cap.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "4e941524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2DTranspose, Conv2D, BatchNormalization, LeakyReLU, Dense, Dropout\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "\n",
    "# custom layers\n",
    "class flattened_dense(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    a dense layer that is made compatible with convolution layers\n",
    "    by flattening the input first and followed by a dense layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels=64, kernel_initializer=\"glorot_uniform\"):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense = tf.keras.layers.Dense(channels, kernel_initializer=kernel_initializer)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        fl = self.flatten(inputs)\n",
    "        return self.dense(fl)\n",
    "    \n",
    "class conv_block(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    a convolution layer with batch normalization and leaky relu activation\n",
    "    \"\"\"\n",
    "    def __init__(self, filters=128, kernel_size=1, strides=1, kernel_initializer=HeNormal()):\n",
    "        super().__init__()\n",
    "        self.conv = Conv2D(filters=filters,\n",
    "                           kernel_size = (kernel_size, kernel_size),\n",
    "                           strides=(strides, strides),\n",
    "                           padding='same',\n",
    "                           kernel_initializer=kernel_initializer)\n",
    "        self.bn = BatchNormalization()\n",
    "        self.activation = LeakyReLU(alpha=0.1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.activation(self.bn(self.conv(inputs)))\n",
    "    \n",
    "class deconv_block(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    a deconvolution layer with batch normalization and leaky relu activation\n",
    "    \"\"\"\n",
    "    def __init__(self, filters=128, kernel_size=4, strides=2, kernel_initializer='glorot_uniform'):\n",
    "        super().__init__()\n",
    "        self.deconv = Conv2DTranspose(filters=filters,\n",
    "                                    kernel_size = (kernel_size, kernel_size),\n",
    "                                    strides=(strides, strides),\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=kernel_initializer)\n",
    "        self.bn = BatchNormalization()\n",
    "        self.activation = LeakyReLU(alpha=0.1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.activation(self.bn(self.deconv(inputs)))\n",
    "    \n",
    "class dense_block(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    a dense layer with batch normalization and leaky relu activation\n",
    "    \"\"\"\n",
    "    def __init__(self, filters=128, kernel_initializer='glorot_uniform'):\n",
    "        super().__init__()\n",
    "        self.d = Dense(filters, kernel_initializer=kernel_initializer)\n",
    "        self.bn = BatchNormalization()\n",
    "        self.activation = LeakyReLU(alpha=0.1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        outputs = self.d(inputs)\n",
    "        outputs = self.bn(outputs)\n",
    "        return self.activation(outputs)\n",
    "\n",
    "class noise_layer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    a layer that adds noise\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0, stddev=0.01):\n",
    "        super().__init__()\n",
    "        self.m = mean\n",
    "        self.s = stddev\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        noise = tf.random.normal(list(inputs.shape), self.m, self.s)\n",
    "        outputs = inputs + noise\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "7b79a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "class TextEncoder(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Encode text (a caption) into hidden representation\n",
    "    input: text, which is a list of ids\n",
    "    output: embedding, or hidden representation of input text in dimension of RNN_HIDDEN_SIZE\n",
    "    \"\"\"\n",
    "    def __init__(self, hparas, experimental=False, do_batchnorm=False):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.exp=experimental\n",
    "        self.do_batchnorm = do_batchnorm\n",
    "        self.hparas = hparas\n",
    "        self.batch_size = self.hparas['BATCH_SIZE']\n",
    "        \n",
    "        # embedding with tensorflow API\n",
    "        self.embedding = layers.Embedding(self.hparas['VOCAB_SIZE'], self.hparas['EMBED_DIM'])\n",
    "        # RNN, here we use GRU cell, another common RNN cell similar to LSTM\n",
    "        self.gru = layers.GRU(self.hparas['RNN_HIDDEN_SIZE'],\n",
    "                              return_sequences=True,\n",
    "                              return_state=True,\n",
    "                              recurrent_initializer='glorot_uniform')\n",
    "        if self.exp:\n",
    "            self.embed = hub.load('./checkpoints/universal_sentence_encoder')\n",
    "    \n",
    "    def call(self, text, hidden):\n",
    "        if self.exp:\n",
    "            with tf.device('/CPU:0'): # TODO if you find a way to use GPU, go for it.\n",
    "                output_last = self.embed(text)\n",
    "                \n",
    "            state = hidden # not updating state for compatibility reasons\n",
    "            \n",
    "        else:\n",
    "            text = self.embedding(text)\n",
    "            output, state = self.gru(text, initial_state = hidden)\n",
    "            output_last = output[:, -1, :]\n",
    "        \n",
    "        # normalization in-batch\n",
    "        if self.do_batchnorm:\n",
    "            mean = tf.reduce_mean(output_last, axis=0, keepdims=True)  # Mean across the batch\n",
    "            std = tf.math.reduce_std(output_last, axis=0, keepdims=True)  # Std across the batch\n",
    "            normalized = (output_last - mean) / (std + 1e-6)  # Avoid division by zero\n",
    "        else:\n",
    "            normalized = output_last\n",
    "        \n",
    "        return normalized, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.hparas['BATCH_SIZE'], self.hparas['RNN_HIDDEN_SIZE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "e7dcc746",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Generate fake image based on given text(hidden representation) and noise z\n",
    "    input: text and noise\n",
    "    output: fake image with size 64*64*3\n",
    "    \"\"\"\n",
    "    def __init__(self, hparas, experimental=False):\n",
    "        super(Generator, self).__init__()\n",
    "        self.exp = experimental\n",
    "        self.hparas = hparas\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.d1 = tf.keras.layers.Dense(self.hparas['DENSE_DIM'], kernel_initializer=\"glorot_uniform\")\n",
    "        self.d2 = tf.keras.layers.Dense(64*64*3, kernel_initializer=\"glorot_uniform\")\n",
    "        if self.exp:\n",
    "            self.deconv_depth = int(math.log(IMAGE_SIZE, 2)) - 1\n",
    "            self.starter = dense_block(filters=2*2*512)\n",
    "            self.deconv = [\n",
    "                deconv_block(filters=512, kernel_initializer=HeNormal()),\n",
    "                #conv_block(filters=512, kernel_size=1, strides=1),\n",
    "                deconv_block(filters=256, kernel_initializer=HeNormal()),\n",
    "                #conv_block(filters=256, kernel_size=1, strides=1),\n",
    "                #Dropout(0.2),\n",
    "                deconv_block(filters=128, kernel_initializer=HeNormal()),\n",
    "                #conv_block(filters=128, kernel_size=1, strides=1),\n",
    "                #Dropout(0.2),\n",
    "                #noise_layer(),\n",
    "                deconv_block(filters=64, kernel_initializer=HeNormal()),\n",
    "                #conv_block(filters=64, kernel_size=1, strides=1),\n",
    "                deconv_block(filters=32, kernel_initializer=HeNormal()),\n",
    "                #noise_layer(),\n",
    "                conv_block(filters=32, kernel_size=1, strides=1)\n",
    "            ]\n",
    "            self.headf = conv_block(filters=3, kernel_size=1, strides=1)\n",
    "            \n",
    "    def call(self, text, noise_z, debug_output=False, training=False):\n",
    "        # deconvolution\n",
    "        if self.exp:\n",
    "            noisy_text = tf.concat([text, noise_z], axis=1) * 10 # amplify the input a bit, they seem fairly close to 0.\n",
    "            img = self.starter(noisy_text)\n",
    "            \n",
    "            img = tf.reshape(img, [-1, 2, 2, 512])\n",
    "            debug = []\n",
    "            for layer in self.deconv:\n",
    "                if isinstance(layer, tf.keras.layers.Dropout) and training:\n",
    "                    continue\n",
    "                debug.append(img)\n",
    "                img = layer(img)\n",
    "\n",
    "            img = self.headf(img)\n",
    "            logits = tf.reshape(img, [-1, IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "            output = tf.nn.tanh(logits)\n",
    "        \n",
    "        # concatenate input text and random noise\n",
    "        else:\n",
    "            text = self.flatten(text)\n",
    "            text = self.d1(text)\n",
    "            text = tf.nn.leaky_relu(text)\n",
    "            text_concat = tf.concat([noise_z, text], axis=1)\n",
    "            text_concat = self.d2(text_concat)\n",
    "        \n",
    "            logits = tf.reshape(text_concat, [-1, 64, 64, 3])\n",
    "            output = tf.nn.tanh(logits)\n",
    "            debug_output = output\n",
    "        \n",
    "        if debug_output:\n",
    "            return logits, output, debug\n",
    "        else:\n",
    "            return logits, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "a78cfb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50, VGG16\n",
    "\n",
    "class Discriminator(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Differentiate the real and fake image\n",
    "    input: image and corresponding text\n",
    "    output: labels, the real image should be 1, while the fake should be 0\n",
    "    \"\"\"\n",
    "    def __init__(self, hparas, experimental=False, backbone='simple'):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.exp = experimental\n",
    "        self.bbtype = backbone\n",
    "        self.hparas = hparas\n",
    "        if self.exp:\n",
    "            if self.bbtype == 'resnet':\n",
    "                self.resnet_base = ResNet50(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), weights='imagenet', include_top=False)\n",
    "                for layer in self.resnet_base.layers:\n",
    "                    layer.trainable = False\n",
    "            elif self.bbtype == 'vgg':\n",
    "                self.vgg_base = VGG16(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), weights='imagenet', include_top=False)\n",
    "                for layer in self.vgg_base.layers:\n",
    "                    layer.trainable = False\n",
    "            elif self.bbtype == 'simple':\n",
    "                self.conv = [\n",
    "                    conv_block(filters=512, kernel_size=3, strides=2),\n",
    "                    #conv_block(filters=512, kernel_size=3, strides=1),\n",
    "                    conv_block(filters=512, kernel_size=1, strides=1),\n",
    "                    Dropout(0.5),\n",
    "                    conv_block(filters=256, kernel_size=3, strides=2),\n",
    "                    #conv_block(filters=256, kernel_size=3, strides=1),\n",
    "                    conv_block(filters=256, kernel_size=1, strides=1),\n",
    "                    Dropout(0.5),\n",
    "                    conv_block(filters=128, kernel_size=3, strides=2),\n",
    "                    #conv_block(filters=128, kernel_size=3, strides=1),\n",
    "                    conv_block(filters=128, kernel_size=1, strides=1),\n",
    "                    conv_block(filters=64, kernel_size=3, strides=2),\n",
    "                    #conv_block(filters=64, kernel_size=3, strides=1),\n",
    "                    conv_block(filters=64, kernel_size=1, strides=1)\n",
    "                ]\n",
    "                # more simple one\n",
    "                #self.conv1 = conv_block(filters=256, kernel_size=3, strides=1)\n",
    "                #self.conv2 = conv_block(filters=64, kernel_size=3, strides=1)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.d_text = tf.keras.layers.Dense(self.hparas['DENSE_DIM'])\n",
    "        self.d_img = tf.keras.layers.Dense(self.hparas['DENSE_DIM'])\n",
    "        self.d = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, img, text, training=False):\n",
    "        text = self.flatten(text)\n",
    "        text = self.d_text(text)\n",
    "        text = tf.nn.leaky_relu(text)\n",
    "        \n",
    "        if self.exp:\n",
    "            if self.bbtype == 'resnet':\n",
    "                img = self.resnet_base(img)\n",
    "            elif self.bbtype == 'vgg':\n",
    "                img = self.vgg_base(img)\n",
    "            elif self.bbtype == 'simple':\n",
    "                for layer in self.conv: # see init for spec\n",
    "                    if isinstance(layer, Dropout) and training:\n",
    "                        continue\n",
    "                    img = layer(img)\n",
    "        img = self.flatten(img)\n",
    "        img = self.d_img(img)\n",
    "        img = tf.nn.leaky_relu(img)\n",
    "        \n",
    "        # concatenate image with paired text\n",
    "        img_text = tf.concat([text, img], axis=1)\n",
    "        \n",
    "        logits = self.d(img_text)\n",
    "        output = tf.nn.sigmoid(logits)\n",
    "        \n",
    "        return logits, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fac84cb",
   "metadata": {},
   "source": [
    "Parameters and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "46263c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparas = {\n",
    "    'MAX_SEQ_LENGTH': 20,                     # maximum sequence length\n",
    "    'EMBED_DIM': 256,                         # word embedding dimension\n",
    "    'VOCAB_SIZE': len(word2Id_dict),          # size of dictionary of captions\n",
    "    'RNN_HIDDEN_SIZE': 128,                   # number of RNN neurons\n",
    "    'Z_DIM': 512,                             # random noise z dimension\n",
    "    'DENSE_DIM': 128,                         # number of neurons in dense layer\n",
    "    'IMAGE_SIZE': [64, 64, 3],                # render image size\n",
    "    'BATCH_SIZE': 64,\n",
    "    'LR_GEN': 1e-4,\n",
    "    'LR_DIS': 1e-5,\n",
    "    'LR_DECAY': 0.5,                          # unused\n",
    "    'BETA_1': 0.5,\n",
    "    'N_EPOCH': 1000,                            # number of epoch for demo\n",
    "    'N_SAMPLE': num_training_sample,          # size of training data\n",
    "    'CHECKPOINTS_DIR': './checkpoints/demo',  # checkpoint path\n",
    "    'PRINT_FREQ': 1                           # printing frequency of loss\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a3d61caf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_encoder = TextEncoder(hparas, \n",
    "                           experimental=expSettings.enc,\n",
    "                           do_batchnorm=expSettings.enc_do_batchnorm)\n",
    "\n",
    "generator = Generator(hparas,\n",
    "                      experimental=expSettings.gen)\n",
    "\n",
    "discriminator = Discriminator(hparas,\n",
    "                              experimental=expSettings.dis,\n",
    "                              backbone=expSettings.dis_backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "90824abe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (64, 64, 64, 3)\n",
      "Caption shape: (64,)\n",
      "Caption embed shape: (64, 512)\n"
     ]
    }
   ],
   "source": [
    "# test text encoder\n",
    "for img, cap in dataset.take(1):\n",
    "    print(\"Image shape:\", img.numpy().shape)\n",
    "    print(\"Caption shape:\", cap.shape)\n",
    "    with tf.device('/CPU:0'):\n",
    "        output, _ = text_encoder(cap, text_encoder.initialize_hidden_state())\n",
    "        print(\"Caption embed shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "220a1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3a45f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.nn import sigmoid_cross_entropy_with_logits\n",
    "\n",
    "def discriminator_loss(real_logits, fake_logits):\n",
    "    # output value of real image should be 1\n",
    "    real_loss = sigmoid_cross_entropy_with_logits(tf.ones_like(real_logits), real_logits)\n",
    "    # output value of fake image should be 0\n",
    "    fake_loss = sigmoid_cross_entropy_with_logits(tf.zeros_like(fake_logits), fake_logits)\n",
    "    total_loss = tf.reduce_mean(real_loss) + tf.reduce_mean(fake_loss)\n",
    "                                 \n",
    "    return total_loss\n",
    "def generator_loss(fake_output):\n",
    "    # output value of fake image should be 0\n",
    "    return tf.reduce_mean(sigmoid_cross_entropy_with_logits(tf.ones_like(fake_output), fake_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "21f720d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use seperated optimizers for training generator and discriminator\n",
    "generator_optimizer = tf.keras.optimizers.Adam(hparas['LR_GEN'], clipvalue=0.1)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(hparas['LR_DIS'], clipvalue=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "24d5f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "if expSettings.delete_checkpoint:\n",
    "    for f in os.listdir(hparas['CHECKPOINTS_DIR']):\n",
    "        file_path = os.path.join(hparas['CHECKPOINTS_DIR'], f)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "\n",
    "# one benefit of tf.train.Checkpoint() API is we can save everything seperately\n",
    "checkpoint_dir = hparas['CHECKPOINTS_DIR']\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 text_encoder=text_encoder,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "ckptManager = tf.train.CheckpointManager(\n",
    "    checkpoint, directory=hparas['CHECKPOINTS_DIR'], max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b35f60e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_image, caption, hidden, imshow=False):\n",
    "    # random noise for generator\n",
    "    noise = tf.random.normal(shape=[hparas['BATCH_SIZE'], hparas['Z_DIM']], mean=0.0, stddev=0.1)\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        text_embed, hidden = text_encoder(caption, hidden)\n",
    "        _, fake_image = generator(text_embed, noise, training=True)\n",
    "        if imshow:\n",
    "            plt.imshow(fake_image[0])\n",
    "\n",
    "        real_logits, real_output = discriminator(real_image, text_embed, training=True)\n",
    "        fake_logits, fake_output = discriminator(fake_image, text_embed, training=True)\n",
    "\n",
    "        g_loss = generator_loss(fake_logits)\n",
    "        d_loss = discriminator_loss(real_logits, fake_logits)\n",
    "\n",
    "    grad_g = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    grad_d = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(grad_g, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(grad_d, discriminator.trainable_variables))\n",
    "    \n",
    "    return g_loss, d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "c25ce5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(caption, noise, hidden):\n",
    "    text_embed, hidden = text_encoder(caption, hidden)\n",
    "    _, fake_image = generator(text_embed, noise)\n",
    "    return fake_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf5d5af",
   "metadata": {},
   "source": [
    "Sample Debugging (unused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d68c0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1], 3))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
    "    return img\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    # getting the pixel values between [0, 1] to save it\n",
    "    return plt.imsave(path, merge(images, size)*0.5 + 0.5)\n",
    "\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(images, size, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "09b260b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_generator(caption, batch_size, caption_type='id'):\n",
    "    if caption_type == 'sentence':\n",
    "        caption = caption2string(caption)\n",
    "    caption = np.asarray(caption)\n",
    "    if caption_type == 'id':\n",
    "        caption = caption.astype(np.int)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(caption)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e086c8df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ni = int(np.ceil(np.sqrt(hparas['BATCH_SIZE'])))\n",
    "sample_size = hparas['BATCH_SIZE']\n",
    "sample_seed = np.random.normal(loc=0.0, scale=1.0, size=(sample_size, hparas['Z_DIM'])).astype(np.float32)\n",
    "sample_sentence = [\"the flower shown has yellow anther red pistil and bright red petals.\"] * int(sample_size/ni) + \\\n",
    "                  [\"this flower has petals that are yellow, white and purple and has dark lines\"] * int(sample_size/ni) + \\\n",
    "                  [\"the petals on this flower are white with a yellow center\"] * int(sample_size/ni) + \\\n",
    "                  [\"this flower has a lot of small round pink petals.\"] * int(sample_size/ni) + \\\n",
    "                  [\"this flower is orange in color, and has petals that are ruffled and rounded.\"] * int(sample_size/ni) + \\\n",
    "                  [\"the flower has yellow petals and the center of it is brown.\"] * int(sample_size/ni) + \\\n",
    "                  [\"this flower has petals that are blue and white.\"] * int(sample_size/ni) +\\\n",
    "                  [\"these white flowers have petals that start off white in color and end in a white towards the tips.\"] * int(sample_size/ni)\n",
    "\n",
    "for i, sent in enumerate(sample_sentence):\n",
    "    sample_sentence[i] = sent2IdList(sent)\n",
    "sample_sentence = sample_generator(sample_sentence, hparas['BATCH_SIZE'], caption_type=expSettings.caption_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "2946f2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption shape: (64,)\n",
      "Caption embeddings: tf.Tensor(\n",
      "[[-0.01346336  0.06881763 -0.05529514 ... -0.01518281 -0.00633275\n",
      "   0.01500697]\n",
      " [-0.01346336  0.06881763 -0.05529514 ... -0.01518281 -0.00633275\n",
      "   0.01500697]\n",
      " [-0.01346336  0.06881763 -0.05529514 ... -0.01518281 -0.00633275\n",
      "   0.01500697]\n",
      " ...\n",
      " [-0.00790838  0.06233827  0.01107207 ... -0.02398296 -0.03450323\n",
      "  -0.00868433]\n",
      " [-0.00790838  0.06233827  0.01107207 ... -0.02398296 -0.03450323\n",
      "  -0.00868433]\n",
      " [-0.00790838  0.06233827  0.01107207 ... -0.02398296 -0.03450323\n",
      "  -0.00868433]], shape=(64, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# test the sample dataset\n",
    "for cap in sample_sentence.take(1):\n",
    "    print(\"Caption shape:\", cap.numpy().shape)\n",
    "    emb, _ = text_encoder(cap, text_encoder.initialize_hidden_state())\n",
    "    print(\"Caption embeddings:\", emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "c4af2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('samples/demo'):\n",
    "    os.makedirs('samples/demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd34dfd3",
   "metadata": {},
   "source": [
    "Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "620661c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    # hidden state of RNN\n",
    "    hidden = text_encoder.initialize_hidden_state()\n",
    "    steps_per_epoch = int(hparas['N_SAMPLE']/hparas['BATCH_SIZE'])\n",
    "    \n",
    "    lowest_gen_loss = 1e10\n",
    "    \n",
    "    for epoch in range(hparas['N_EPOCH']):\n",
    "        g_total_loss = 0\n",
    "        d_total_loss = 0\n",
    "        batchid = 0\n",
    "        start = time.time()\n",
    "        imshow = False\n",
    "        \n",
    "        for image, caption in dataset:\n",
    "            batchid += 1\n",
    "            g_loss, d_loss = train_step(image, caption, hidden, imshow=imshow)\n",
    "            imshow = False\n",
    "            g_total_loss += g_loss\n",
    "            d_total_loss += d_loss\n",
    "        \n",
    "        time_tuple = time.localtime()\n",
    "        time_string = time.strftime(\"%m/%d/%Y, %H:%M:%S\", time_tuple)\n",
    "            \n",
    "        print(\"Epoch {}, gen_loss: {:.4f}, disc_loss: {:.4f}\".format(epoch+1,\n",
    "                                                                     g_total_loss/steps_per_epoch,\n",
    "                                                                     d_total_loss/steps_per_epoch))\n",
    "        print('Time for epoch {} is {:.4f} sec'.format(epoch+1, time.time()-start))\n",
    "        \n",
    "        # save the model if lower gen loss is achieved\n",
    "        if g_total_loss < lowest_gen_loss:\n",
    "            lowest_gen_loss = g_total_loss\n",
    "            ckptManager.save()\n",
    "            print('new lowest. saving model.')\n",
    "        elif g_total_loss < 3 * lowest_gen_loss:\n",
    "            ckptManager.save()\n",
    "            print('within save threshold. saving model.')\n",
    "        else:\n",
    "            lowest_gen_loss *= 1.02\n",
    "            \n",
    "        print('======================================')\n",
    "        \n",
    "        # visualization\n",
    "        if (epoch + 1) % hparas['PRINT_FREQ'] == 0:\n",
    "            for caption in sample_sentence:\n",
    "                fake_image = test_step(caption, sample_seed, hidden)\n",
    "            save_images(fake_image,\n",
    "                        [ni, ni],\n",
    "                        'samples/demo/train_{:02d}.jpg'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "6c752c76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_20241101\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, gen_loss: 0.1284, disc_loss: 3.3784\n",
      "Time for epoch 1 is 27.7097 sec\n",
      "new lowest. saving model.\n",
      "======================================\n",
      "Epoch 2, gen_loss: 0.0845, disc_loss: 3.4380\n",
      "Time for epoch 2 is 21.2816 sec\n",
      "new lowest. saving model.\n",
      "======================================\n",
      "Epoch 3, gen_loss: 0.0875, disc_loss: 3.3005\n",
      "Time for epoch 3 is 20.9237 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 4, gen_loss: 0.1053, disc_loss: 3.0467\n",
      "Time for epoch 4 is 20.5971 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 5, gen_loss: 0.1471, disc_loss: 2.6813\n",
      "Time for epoch 5 is 20.7887 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 6, gen_loss: 0.2270, disc_loss: 2.2334\n",
      "Time for epoch 6 is 20.8328 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 7, gen_loss: 0.3566, disc_loss: 1.8722\n",
      "Time for epoch 7 is 20.9663 sec\n",
      "======================================\n",
      "Epoch 8, gen_loss: 0.7347, disc_loss: 1.2040\n",
      "Time for epoch 8 is 20.7251 sec\n",
      "======================================\n",
      "Epoch 9, gen_loss: 1.1386, disc_loss: 0.6872\n",
      "Time for epoch 9 is 20.3112 sec\n",
      "======================================\n",
      "Epoch 10, gen_loss: 1.6893, disc_loss: 0.4304\n",
      "Time for epoch 10 is 21.1583 sec\n",
      "======================================\n",
      "Epoch 11, gen_loss: 2.0646, disc_loss: 0.2913\n",
      "Time for epoch 11 is 20.6199 sec\n",
      "======================================\n",
      "Epoch 12, gen_loss: 2.6437, disc_loss: 0.1910\n",
      "Time for epoch 12 is 21.1049 sec\n",
      "======================================\n",
      "Epoch 13, gen_loss: 2.7781, disc_loss: 0.1536\n",
      "Time for epoch 13 is 20.7634 sec\n",
      "======================================\n",
      "Epoch 14, gen_loss: 3.1241, disc_loss: 0.1200\n",
      "Time for epoch 14 is 21.4964 sec\n",
      "======================================\n",
      "Epoch 15, gen_loss: 2.6345, disc_loss: 0.1475\n",
      "Time for epoch 15 is 20.9009 sec\n",
      "======================================\n",
      "Epoch 16, gen_loss: 2.8680, disc_loss: 0.1229\n",
      "Time for epoch 16 is 21.2840 sec\n",
      "======================================\n",
      "Epoch 17, gen_loss: 3.0930, disc_loss: 0.1147\n",
      "Time for epoch 17 is 21.4376 sec\n",
      "======================================\n",
      "Epoch 18, gen_loss: 3.3457, disc_loss: 0.1244\n",
      "Time for epoch 18 is 20.6623 sec\n",
      "======================================\n",
      "Epoch 19, gen_loss: 3.1507, disc_loss: 0.2166\n",
      "Time for epoch 19 is 21.3861 sec\n",
      "======================================\n",
      "Epoch 20, gen_loss: 2.4837, disc_loss: 0.7837\n",
      "Time for epoch 20 is 21.0433 sec\n",
      "======================================\n",
      "Epoch 21, gen_loss: 2.2878, disc_loss: 0.6185\n",
      "Time for epoch 21 is 21.5150 sec\n",
      "======================================\n",
      "Epoch 22, gen_loss: 1.7710, disc_loss: 0.6674\n",
      "Time for epoch 22 is 20.4882 sec\n",
      "======================================\n",
      "Epoch 23, gen_loss: 1.7316, disc_loss: 0.5757\n",
      "Time for epoch 23 is 20.6262 sec\n",
      "======================================\n",
      "Epoch 24, gen_loss: 1.8300, disc_loss: 0.4637\n",
      "Time for epoch 24 is 21.3268 sec\n",
      "======================================\n",
      "Epoch 25, gen_loss: 1.9577, disc_loss: 0.3865\n",
      "Time for epoch 25 is 20.6660 sec\n",
      "======================================\n",
      "Epoch 26, gen_loss: 2.1059, disc_loss: 0.3292\n",
      "Time for epoch 26 is 20.7662 sec\n",
      "======================================\n",
      "Epoch 27, gen_loss: 1.9844, disc_loss: 0.4118\n",
      "Time for epoch 27 is 20.7910 sec\n",
      "======================================\n",
      "Epoch 28, gen_loss: 1.6710, disc_loss: 0.6009\n",
      "Time for epoch 28 is 21.2310 sec\n",
      "======================================\n",
      "Epoch 29, gen_loss: 1.6569, disc_loss: 0.5541\n",
      "Time for epoch 29 is 20.5632 sec\n",
      "======================================\n",
      "Epoch 30, gen_loss: 1.4778, disc_loss: 0.7227\n",
      "Time for epoch 30 is 20.8621 sec\n",
      "======================================\n",
      "Epoch 31, gen_loss: 1.4084, disc_loss: 0.7277\n",
      "Time for epoch 31 is 20.5610 sec\n",
      "======================================\n",
      "Epoch 32, gen_loss: 1.6229, disc_loss: 0.5192\n",
      "Time for epoch 32 is 21.6587 sec\n",
      "======================================\n",
      "Epoch 33, gen_loss: 1.5083, disc_loss: 0.6693\n",
      "Time for epoch 33 is 20.6810 sec\n",
      "======================================\n",
      "Epoch 34, gen_loss: 1.4864, disc_loss: 0.7502\n",
      "Time for epoch 34 is 20.8654 sec\n",
      "======================================\n",
      "Epoch 35, gen_loss: 1.7731, disc_loss: 0.4735\n",
      "Time for epoch 35 is 21.0792 sec\n",
      "======================================\n",
      "Epoch 36, gen_loss: 1.6772, disc_loss: 0.4579\n",
      "Time for epoch 36 is 20.9024 sec\n",
      "======================================\n",
      "Epoch 37, gen_loss: 1.5884, disc_loss: 0.6719\n",
      "Time for epoch 37 is 21.3136 sec\n",
      "======================================\n",
      "Epoch 38, gen_loss: 1.6769, disc_loss: 0.5368\n",
      "Time for epoch 38 is 21.5001 sec\n",
      "======================================\n",
      "Epoch 39, gen_loss: 1.7768, disc_loss: 0.4527\n",
      "Time for epoch 39 is 20.6424 sec\n",
      "======================================\n",
      "Epoch 40, gen_loss: 1.9642, disc_loss: 0.3888\n",
      "Time for epoch 40 is 21.5077 sec\n",
      "======================================\n",
      "Epoch 41, gen_loss: 2.3324, disc_loss: 0.2524\n",
      "Time for epoch 41 is 20.9094 sec\n",
      "======================================\n",
      "Epoch 42, gen_loss: 2.0936, disc_loss: 0.2917\n",
      "Time for epoch 42 is 21.2858 sec\n",
      "======================================\n",
      "Epoch 43, gen_loss: 2.3995, disc_loss: 0.1948\n",
      "Time for epoch 43 is 20.6979 sec\n",
      "======================================\n",
      "Epoch 44, gen_loss: 2.1476, disc_loss: 0.3184\n",
      "Time for epoch 44 is 20.8443 sec\n",
      "======================================\n",
      "Epoch 45, gen_loss: 2.2729, disc_loss: 0.2559\n",
      "Time for epoch 45 is 21.3855 sec\n",
      "======================================\n",
      "Epoch 46, gen_loss: 1.9261, disc_loss: 0.3716\n",
      "Time for epoch 46 is 21.7590 sec\n",
      "======================================\n",
      "Epoch 47, gen_loss: 2.2840, disc_loss: 0.2631\n",
      "Time for epoch 47 is 20.9052 sec\n",
      "======================================\n",
      "Epoch 48, gen_loss: 2.2772, disc_loss: 0.2220\n",
      "Time for epoch 48 is 20.8033 sec\n",
      "======================================\n",
      "Epoch 49, gen_loss: 2.5576, disc_loss: 0.2026\n",
      "Time for epoch 49 is 21.1988 sec\n",
      "======================================\n",
      "Epoch 50, gen_loss: 2.9576, disc_loss: 0.1440\n",
      "Time for epoch 50 is 20.4697 sec\n",
      "======================================\n",
      "Epoch 51, gen_loss: 3.1010, disc_loss: 0.1144\n",
      "Time for epoch 51 is 21.6192 sec\n",
      "======================================\n",
      "Epoch 52, gen_loss: 3.3190, disc_loss: 0.0916\n",
      "Time for epoch 52 is 20.4865 sec\n",
      "======================================\n",
      "Epoch 53, gen_loss: 2.7923, disc_loss: 0.2048\n",
      "Time for epoch 53 is 21.7291 sec\n",
      "======================================\n",
      "Epoch 54, gen_loss: 2.1185, disc_loss: 0.3219\n",
      "Time for epoch 54 is 20.4850 sec\n",
      "======================================\n",
      "Epoch 55, gen_loss: 2.6458, disc_loss: 0.1917\n",
      "Time for epoch 55 is 20.8787 sec\n",
      "======================================\n",
      "Epoch 56, gen_loss: 3.2059, disc_loss: 0.0881\n",
      "Time for epoch 56 is 20.9140 sec\n",
      "======================================\n",
      "Epoch 57, gen_loss: 3.5190, disc_loss: 0.0829\n",
      "Time for epoch 57 is 20.4052 sec\n",
      "======================================\n",
      "Epoch 58, gen_loss: 3.7545, disc_loss: 0.0544\n",
      "Time for epoch 58 is 20.6730 sec\n",
      "======================================\n",
      "Epoch 59, gen_loss: 3.5135, disc_loss: 0.0797\n",
      "Time for epoch 59 is 21.0443 sec\n",
      "======================================\n",
      "Epoch 60, gen_loss: 3.9726, disc_loss: 0.0511\n",
      "Time for epoch 60 is 20.5814 sec\n",
      "======================================\n",
      "Epoch 61, gen_loss: 4.1217, disc_loss: 0.0468\n",
      "Time for epoch 61 is 21.1755 sec\n",
      "======================================\n",
      "Epoch 62, gen_loss: 4.3400, disc_loss: 0.0353\n",
      "Time for epoch 62 is 20.7268 sec\n",
      "======================================\n",
      "Epoch 63, gen_loss: 3.8959, disc_loss: 0.0568\n",
      "Time for epoch 63 is 20.5361 sec\n",
      "======================================\n",
      "Epoch 64, gen_loss: 3.8528, disc_loss: 0.0482\n",
      "Time for epoch 64 is 20.4983 sec\n",
      "======================================\n",
      "Epoch 65, gen_loss: 4.1875, disc_loss: 0.0375\n",
      "Time for epoch 65 is 20.7569 sec\n",
      "======================================\n",
      "Epoch 66, gen_loss: 3.7947, disc_loss: 0.0698\n",
      "Time for epoch 66 is 20.6223 sec\n",
      "======================================\n",
      "Epoch 67, gen_loss: 3.8951, disc_loss: 0.0576\n",
      "Time for epoch 67 is 20.6299 sec\n",
      "======================================\n",
      "Epoch 68, gen_loss: 4.2186, disc_loss: 0.0406\n",
      "Time for epoch 68 is 20.8671 sec\n",
      "======================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69, gen_loss: 4.6061, disc_loss: 0.0265\n",
      "Time for epoch 69 is 20.5390 sec\n",
      "======================================\n",
      "Epoch 70, gen_loss: 4.8323, disc_loss: 0.0204\n",
      "Time for epoch 70 is 20.9139 sec\n",
      "======================================\n",
      "Epoch 71, gen_loss: 4.9794, disc_loss: 0.0170\n",
      "Time for epoch 71 is 20.6760 sec\n",
      "======================================\n",
      "Epoch 72, gen_loss: 5.6523, disc_loss: 0.0092\n",
      "Time for epoch 72 is 21.3417 sec\n",
      "======================================\n",
      "Epoch 73, gen_loss: 5.9206, disc_loss: 0.0066\n",
      "Time for epoch 73 is 20.4680 sec\n",
      "======================================\n",
      "Epoch 74, gen_loss: 5.7473, disc_loss: 0.0071\n",
      "Time for epoch 74 is 20.6460 sec\n",
      "======================================\n",
      "Epoch 75, gen_loss: 5.6143, disc_loss: 0.0083\n",
      "Time for epoch 75 is 20.8871 sec\n",
      "======================================\n",
      "Epoch 76, gen_loss: 5.8806, disc_loss: 0.0070\n",
      "Time for epoch 76 is 20.9470 sec\n",
      "======================================\n",
      "Epoch 77, gen_loss: 6.0536, disc_loss: 0.0057\n",
      "Time for epoch 77 is 20.4525 sec\n",
      "======================================\n",
      "Epoch 78, gen_loss: 6.0497, disc_loss: 0.0053\n",
      "Time for epoch 78 is 21.1631 sec\n",
      "======================================\n",
      "Epoch 79, gen_loss: 5.8313, disc_loss: 0.0064\n",
      "Time for epoch 79 is 20.8635 sec\n",
      "======================================\n",
      "Epoch 80, gen_loss: 5.9285, disc_loss: 0.0059\n",
      "Time for epoch 80 is 20.4034 sec\n",
      "======================================\n",
      "Epoch 81, gen_loss: 5.1887, disc_loss: 0.0125\n",
      "Time for epoch 81 is 21.0212 sec\n",
      "======================================\n",
      "Epoch 82, gen_loss: 5.9063, disc_loss: 0.0061\n",
      "Time for epoch 82 is 21.5014 sec\n",
      "======================================\n",
      "Epoch 83, gen_loss: 6.0025, disc_loss: 0.0059\n",
      "Time for epoch 83 is 20.5803 sec\n",
      "======================================\n",
      "Epoch 84, gen_loss: 5.6397, disc_loss: 0.0130\n",
      "Time for epoch 84 is 20.8267 sec\n",
      "======================================\n",
      "Epoch 85, gen_loss: 5.6568, disc_loss: 0.0079\n",
      "Time for epoch 85 is 20.9159 sec\n",
      "======================================\n",
      "Epoch 86, gen_loss: 5.4917, disc_loss: 0.0107\n",
      "Time for epoch 86 is 20.7432 sec\n",
      "======================================\n",
      "Epoch 87, gen_loss: 5.6701, disc_loss: 0.0081\n",
      "Time for epoch 87 is 21.3811 sec\n",
      "======================================\n",
      "Epoch 88, gen_loss: 5.8525, disc_loss: 0.0113\n",
      "Time for epoch 88 is 20.6619 sec\n",
      "======================================\n",
      "Epoch 89, gen_loss: 6.6047, disc_loss: 0.0044\n",
      "Time for epoch 89 is 20.5245 sec\n",
      "======================================\n",
      "Epoch 90, gen_loss: 6.2185, disc_loss: 0.0055\n",
      "Time for epoch 90 is 20.4984 sec\n",
      "======================================\n",
      "Epoch 91, gen_loss: 6.6396, disc_loss: 0.0040\n",
      "Time for epoch 91 is 21.1636 sec\n",
      "======================================\n",
      "Epoch 92, gen_loss: 7.0504, disc_loss: 0.0021\n",
      "Time for epoch 92 is 20.9121 sec\n",
      "======================================\n",
      "Epoch 93, gen_loss: 5.7683, disc_loss: 0.1736\n",
      "Time for epoch 93 is 20.7433 sec\n",
      "======================================\n",
      "Epoch 94, gen_loss: 1.9585, disc_loss: 0.5638\n",
      "Time for epoch 94 is 20.7221 sec\n",
      "======================================\n",
      "Epoch 95, gen_loss: 1.5418, disc_loss: 0.7185\n",
      "Time for epoch 95 is 20.8381 sec\n",
      "======================================\n",
      "Epoch 96, gen_loss: 1.3620, disc_loss: 0.9460\n",
      "Time for epoch 96 is 20.9215 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 97, gen_loss: 1.7617, disc_loss: 0.4943\n",
      "Time for epoch 97 is 20.8089 sec\n",
      "======================================\n",
      "Epoch 98, gen_loss: 2.1463, disc_loss: 0.3475\n",
      "Time for epoch 98 is 20.8912 sec\n",
      "======================================\n",
      "Epoch 99, gen_loss: 1.9506, disc_loss: 0.4421\n",
      "Time for epoch 99 is 20.5942 sec\n",
      "======================================\n",
      "Epoch 100, gen_loss: 1.7120, disc_loss: 0.6096\n",
      "Time for epoch 100 is 20.8764 sec\n",
      "======================================\n",
      "Epoch 101, gen_loss: 1.8478, disc_loss: 0.4807\n",
      "Time for epoch 101 is 21.2168 sec\n",
      "======================================\n",
      "Epoch 102, gen_loss: 1.9196, disc_loss: 0.4429\n",
      "Time for epoch 102 is 20.7358 sec\n",
      "======================================\n",
      "Epoch 103, gen_loss: 1.7779, disc_loss: 0.5467\n",
      "Time for epoch 103 is 21.0507 sec\n",
      "======================================\n",
      "Epoch 104, gen_loss: 1.8975, disc_loss: 0.4575\n",
      "Time for epoch 104 is 20.8659 sec\n",
      "======================================\n",
      "Epoch 105, gen_loss: 2.0009, disc_loss: 0.4747\n",
      "Time for epoch 105 is 20.4765 sec\n",
      "======================================\n",
      "Epoch 106, gen_loss: 2.4227, disc_loss: 0.2868\n",
      "Time for epoch 106 is 21.9460 sec\n",
      "======================================\n",
      "Epoch 107, gen_loss: 2.7329, disc_loss: 0.1739\n",
      "Time for epoch 107 is 20.6981 sec\n",
      "======================================\n",
      "Epoch 108, gen_loss: 3.0175, disc_loss: 0.1464\n",
      "Time for epoch 108 is 21.0864 sec\n",
      "======================================\n",
      "Epoch 109, gen_loss: 2.1163, disc_loss: 0.5663\n",
      "Time for epoch 109 is 20.6430 sec\n",
      "======================================\n",
      "Epoch 110, gen_loss: 1.5326, disc_loss: 0.7319\n",
      "Time for epoch 110 is 20.8878 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 111, gen_loss: 1.6989, disc_loss: 0.6061\n",
      "Time for epoch 111 is 20.4556 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 112, gen_loss: 1.3231, disc_loss: 0.9131\n",
      "Time for epoch 112 is 21.2325 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 113, gen_loss: 1.4526, disc_loss: 0.8835\n",
      "Time for epoch 113 is 20.7188 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 114, gen_loss: 1.9471, disc_loss: 0.4590\n",
      "Time for epoch 114 is 20.7179 sec\n",
      "======================================\n",
      "Epoch 115, gen_loss: 2.4539, disc_loss: 0.3225\n",
      "Time for epoch 115 is 20.6749 sec\n",
      "======================================\n",
      "Epoch 116, gen_loss: 1.9612, disc_loss: 0.5298\n",
      "Time for epoch 116 is 20.7217 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 117, gen_loss: 2.2362, disc_loss: 0.3819\n",
      "Time for epoch 117 is 21.5650 sec\n",
      "======================================\n",
      "Epoch 118, gen_loss: 1.8675, disc_loss: 0.5237\n",
      "Time for epoch 118 is 20.9890 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 119, gen_loss: 2.2731, disc_loss: 0.3964\n",
      "Time for epoch 119 is 20.7513 sec\n",
      "======================================\n",
      "Epoch 120, gen_loss: 1.8169, disc_loss: 0.5737\n",
      "Time for epoch 120 is 20.6793 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 121, gen_loss: 2.0624, disc_loss: 0.4118\n",
      "Time for epoch 121 is 20.7049 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 122, gen_loss: 2.1151, disc_loss: 0.3723\n",
      "Time for epoch 122 is 21.4188 sec\n",
      "======================================\n",
      "Epoch 123, gen_loss: 2.0524, disc_loss: 0.4808\n",
      "Time for epoch 123 is 20.6409 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 124, gen_loss: 1.8833, disc_loss: 0.4718\n",
      "Time for epoch 124 is 21.0569 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 125, gen_loss: 2.1029, disc_loss: 0.3841\n",
      "Time for epoch 125 is 21.1818 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 126, gen_loss: 2.7358, disc_loss: 0.1829\n",
      "Time for epoch 126 is 20.9609 sec\n",
      "======================================\n",
      "Epoch 127, gen_loss: 2.5442, disc_loss: 0.3027\n",
      "Time for epoch 127 is 21.2428 sec\n",
      "======================================\n",
      "Epoch 128, gen_loss: 1.9361, disc_loss: 0.4597\n",
      "Time for epoch 128 is 20.9437 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 129, gen_loss: 1.4177, disc_loss: 0.9154\n",
      "Time for epoch 129 is 20.8854 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 130, gen_loss: 1.4277, disc_loss: 0.8516\n",
      "Time for epoch 130 is 21.2523 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 131, gen_loss: 1.4845, disc_loss: 0.8170\n",
      "Time for epoch 131 is 21.0579 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 132, gen_loss: 1.4823, disc_loss: 0.9506\n",
      "Time for epoch 132 is 20.9912 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133, gen_loss: 1.1335, disc_loss: 1.4498\n",
      "Time for epoch 133 is 21.1792 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 134, gen_loss: 1.4859, disc_loss: 0.9185\n",
      "Time for epoch 134 is 20.7825 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 135, gen_loss: 1.1529, disc_loss: 1.1007\n",
      "Time for epoch 135 is 21.0880 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 136, gen_loss: 1.1289, disc_loss: 1.1617\n",
      "Time for epoch 136 is 20.6531 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 137, gen_loss: 1.0073, disc_loss: 1.2800\n",
      "Time for epoch 137 is 21.2845 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 138, gen_loss: 1.1280, disc_loss: 1.1722\n",
      "Time for epoch 138 is 21.0310 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 139, gen_loss: 1.1426, disc_loss: 1.0851\n",
      "Time for epoch 139 is 21.0789 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 140, gen_loss: 1.2164, disc_loss: 0.9615\n",
      "Time for epoch 140 is 21.1192 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 141, gen_loss: 1.1551, disc_loss: 1.1099\n",
      "Time for epoch 141 is 21.5351 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 142, gen_loss: 1.2073, disc_loss: 1.0609\n",
      "Time for epoch 142 is 20.7435 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 143, gen_loss: 1.0738, disc_loss: 1.1322\n",
      "Time for epoch 143 is 21.3771 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 144, gen_loss: 1.4251, disc_loss: 0.7976\n",
      "Time for epoch 144 is 20.7600 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 145, gen_loss: 1.4451, disc_loss: 0.7824\n",
      "Time for epoch 145 is 20.9041 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 146, gen_loss: 1.1394, disc_loss: 1.0558\n",
      "Time for epoch 146 is 21.4139 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 147, gen_loss: 0.9652, disc_loss: 1.4028\n",
      "Time for epoch 147 is 20.7069 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 148, gen_loss: 1.0651, disc_loss: 1.1875\n",
      "Time for epoch 148 is 21.3123 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 149, gen_loss: 1.1844, disc_loss: 0.9484\n",
      "Time for epoch 149 is 20.9695 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 150, gen_loss: 0.9000, disc_loss: 1.5206\n",
      "Time for epoch 150 is 21.8249 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 151, gen_loss: 1.0040, disc_loss: 1.2744\n",
      "Time for epoch 151 is 20.8238 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 152, gen_loss: 1.4490, disc_loss: 0.7132\n",
      "Time for epoch 152 is 20.7047 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 153, gen_loss: 1.3600, disc_loss: 0.8018\n",
      "Time for epoch 153 is 21.3117 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 154, gen_loss: 1.5295, disc_loss: 0.7640\n",
      "Time for epoch 154 is 20.7241 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 155, gen_loss: 1.4849, disc_loss: 0.8668\n",
      "Time for epoch 155 is 20.7917 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 156, gen_loss: 1.2280, disc_loss: 0.9853\n",
      "Time for epoch 156 is 20.9058 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 157, gen_loss: 1.2410, disc_loss: 0.8890\n",
      "Time for epoch 157 is 20.5660 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 158, gen_loss: 1.1253, disc_loss: 1.0513\n",
      "Time for epoch 158 is 20.8440 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 159, gen_loss: 0.8789, disc_loss: 1.3813\n",
      "Time for epoch 159 is 20.6268 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 160, gen_loss: 0.8365, disc_loss: 1.4391\n",
      "Time for epoch 160 is 20.8231 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 161, gen_loss: 0.9989, disc_loss: 1.1867\n",
      "Time for epoch 161 is 20.6079 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 162, gen_loss: 1.0065, disc_loss: 1.1678\n",
      "Time for epoch 162 is 20.6848 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 163, gen_loss: 0.8895, disc_loss: 1.3330\n",
      "Time for epoch 163 is 20.9666 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 164, gen_loss: 0.9992, disc_loss: 1.1559\n",
      "Time for epoch 164 is 20.5603 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 165, gen_loss: 1.1725, disc_loss: 0.9115\n",
      "Time for epoch 165 is 20.5382 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 166, gen_loss: 0.9925, disc_loss: 1.1758\n",
      "Time for epoch 166 is 20.7461 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 167, gen_loss: 0.8498, disc_loss: 1.3855\n",
      "Time for epoch 167 is 20.7671 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 168, gen_loss: 0.9589, disc_loss: 1.2331\n",
      "Time for epoch 168 is 20.5712 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 169, gen_loss: 0.8258, disc_loss: 1.5023\n",
      "Time for epoch 169 is 21.0151 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 170, gen_loss: 0.8109, disc_loss: 1.4781\n",
      "Time for epoch 170 is 20.5667 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 171, gen_loss: 0.8613, disc_loss: 1.3924\n",
      "Time for epoch 171 is 20.8641 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 172, gen_loss: 0.8984, disc_loss: 1.3165\n",
      "Time for epoch 172 is 20.5885 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 173, gen_loss: 0.7769, disc_loss: 1.5285\n",
      "Time for epoch 173 is 20.8128 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 174, gen_loss: 0.7075, disc_loss: 1.6367\n",
      "Time for epoch 174 is 20.8461 sec\n",
      "new lowest. saving model.\n",
      "======================================\n",
      "Epoch 175, gen_loss: 0.7052, disc_loss: 1.5830\n",
      "Time for epoch 175 is 20.7902 sec\n",
      "new lowest. saving model.\n",
      "======================================\n",
      "Epoch 176, gen_loss: 0.6693, disc_loss: 1.6656\n",
      "Time for epoch 176 is 20.6600 sec\n",
      "new lowest. saving model.\n",
      "======================================\n",
      "Epoch 177, gen_loss: 0.7506, disc_loss: 1.4922\n",
      "Time for epoch 177 is 21.0889 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 178, gen_loss: 0.7552, disc_loss: 1.6574\n",
      "Time for epoch 178 is 21.4028 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 179, gen_loss: 0.7691, disc_loss: 1.4896\n",
      "Time for epoch 179 is 20.9699 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 180, gen_loss: 0.6643, disc_loss: 1.6779\n",
      "Time for epoch 180 is 20.9466 sec\n",
      "new lowest. saving model.\n",
      "======================================\n",
      "Epoch 181, gen_loss: 0.7719, disc_loss: 1.4371\n",
      "Time for epoch 181 is 20.5888 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 182, gen_loss: 0.8354, disc_loss: 1.3340\n",
      "Time for epoch 182 is 20.8369 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 183, gen_loss: 0.6599, disc_loss: 1.6230\n",
      "Time for epoch 183 is 20.7340 sec\n",
      "new lowest. saving model.\n",
      "======================================\n",
      "Epoch 184, gen_loss: 0.6367, disc_loss: 1.7492\n",
      "Time for epoch 184 is 20.8521 sec\n",
      "new lowest. saving model.\n",
      "======================================\n",
      "Epoch 185, gen_loss: 0.7142, disc_loss: 1.4908\n",
      "Time for epoch 185 is 20.6740 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186, gen_loss: 0.7560, disc_loss: 1.4722\n",
      "Time for epoch 186 is 20.8358 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 187, gen_loss: 0.7207, disc_loss: 1.5089\n",
      "Time for epoch 187 is 20.8620 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 188, gen_loss: 0.6877, disc_loss: 1.5495\n",
      "Time for epoch 188 is 20.6146 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 189, gen_loss: 0.6790, disc_loss: 1.5841\n",
      "Time for epoch 189 is 21.0043 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 190, gen_loss: 0.6668, disc_loss: 1.6028\n",
      "Time for epoch 190 is 20.6026 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 191, gen_loss: 0.6570, disc_loss: 1.5870\n",
      "Time for epoch 191 is 20.8110 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 192, gen_loss: 0.6648, disc_loss: 1.6545\n",
      "Time for epoch 192 is 20.3922 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 193, gen_loss: 0.7423, disc_loss: 1.4017\n",
      "Time for epoch 193 is 21.2582 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 194, gen_loss: 0.7420, disc_loss: 1.4985\n",
      "Time for epoch 194 is 20.5164 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 195, gen_loss: 0.7635, disc_loss: 1.5113\n",
      "Time for epoch 195 is 20.6035 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 196, gen_loss: 0.6814, disc_loss: 1.5017\n",
      "Time for epoch 196 is 21.7273 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 197, gen_loss: 0.6872, disc_loss: 1.4837\n",
      "Time for epoch 197 is 20.6240 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 198, gen_loss: 0.6725, disc_loss: 1.5106\n",
      "Time for epoch 198 is 20.8372 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 199, gen_loss: 0.6786, disc_loss: 1.4982\n",
      "Time for epoch 199 is 20.6163 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 200, gen_loss: 0.6710, disc_loss: 1.5363\n",
      "Time for epoch 200 is 20.5627 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 201, gen_loss: 0.6593, disc_loss: 1.5885\n",
      "Time for epoch 201 is 21.3580 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 202, gen_loss: 0.6164, disc_loss: 1.6099\n",
      "Time for epoch 202 is 20.6722 sec\n",
      "new lowest. saving model.\n",
      "======================================\n",
      "Epoch 203, gen_loss: 0.6448, disc_loss: 1.5707\n",
      "Time for epoch 203 is 20.5312 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 204, gen_loss: 0.6431, disc_loss: 1.5764\n",
      "Time for epoch 204 is 20.7692 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 205, gen_loss: 0.6159, disc_loss: 1.5821\n",
      "Time for epoch 205 is 21.1549 sec\n",
      "new lowest. saving model.\n",
      "======================================\n",
      "Epoch 206, gen_loss: 0.6122, disc_loss: 1.6100\n",
      "Time for epoch 206 is 20.8200 sec\n",
      "new lowest. saving model.\n",
      "======================================\n",
      "Epoch 207, gen_loss: 0.6224, disc_loss: 1.5610\n",
      "Time for epoch 207 is 21.3197 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 208, gen_loss: 0.6582, disc_loss: 1.4671\n",
      "Time for epoch 208 is 20.5643 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 209, gen_loss: 0.6523, disc_loss: 1.5151\n",
      "Time for epoch 209 is 20.7618 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 210, gen_loss: 0.6547, disc_loss: 1.5077\n",
      "Time for epoch 210 is 21.0905 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 211, gen_loss: 0.6308, disc_loss: 1.6175\n",
      "Time for epoch 211 is 20.9595 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 212, gen_loss: 0.6528, disc_loss: 1.4861\n",
      "Time for epoch 212 is 20.7916 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 213, gen_loss: 0.6607, disc_loss: 1.5044\n",
      "Time for epoch 213 is 20.6870 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 214, gen_loss: 0.6768, disc_loss: 1.4381\n",
      "Time for epoch 214 is 20.5410 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 215, gen_loss: 0.6539, disc_loss: 1.5368\n",
      "Time for epoch 215 is 20.9301 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 216, gen_loss: 0.6374, disc_loss: 1.4991\n",
      "Time for epoch 216 is 20.8788 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 217, gen_loss: 0.6878, disc_loss: 1.4228\n",
      "Time for epoch 217 is 21.1493 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 218, gen_loss: 0.6703, disc_loss: 1.5104\n",
      "Time for epoch 218 is 20.6856 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 219, gen_loss: 0.6511, disc_loss: 1.4670\n",
      "Time for epoch 219 is 20.7051 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 220, gen_loss: 0.6557, disc_loss: 1.4994\n",
      "Time for epoch 220 is 20.6729 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 221, gen_loss: 0.6585, disc_loss: 1.4924\n",
      "Time for epoch 221 is 21.2294 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 222, gen_loss: 0.6790, disc_loss: 1.4414\n",
      "Time for epoch 222 is 20.6519 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 223, gen_loss: 0.6694, disc_loss: 1.4435\n",
      "Time for epoch 223 is 20.3963 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 224, gen_loss: 0.6843, disc_loss: 1.4312\n",
      "Time for epoch 224 is 20.7119 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 225, gen_loss: 0.6996, disc_loss: 1.4356\n",
      "Time for epoch 225 is 20.8948 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 226, gen_loss: 0.6892, disc_loss: 1.4529\n",
      "Time for epoch 226 is 20.9683 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 227, gen_loss: 0.6511, disc_loss: 1.4684\n",
      "Time for epoch 227 is 21.1601 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 228, gen_loss: 0.6849, disc_loss: 1.4409\n",
      "Time for epoch 228 is 20.6105 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 229, gen_loss: 0.7086, disc_loss: 1.3652\n",
      "Time for epoch 229 is 20.6762 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 230, gen_loss: 0.6740, disc_loss: 1.4436\n",
      "Time for epoch 230 is 21.0674 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 231, gen_loss: 0.7094, disc_loss: 1.4011\n",
      "Time for epoch 231 is 21.3855 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 232, gen_loss: 0.6819, disc_loss: 1.4266\n",
      "Time for epoch 232 is 20.5020 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 233, gen_loss: 0.6917, disc_loss: 1.4100\n",
      "Time for epoch 233 is 20.8479 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 234, gen_loss: 0.7253, disc_loss: 1.3483\n",
      "Time for epoch 234 is 20.6258 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 235, gen_loss: 0.6423, disc_loss: 1.5085\n",
      "Time for epoch 235 is 21.1904 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 236, gen_loss: 0.7060, disc_loss: 1.4105\n",
      "Time for epoch 236 is 21.2138 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 237, gen_loss: 0.7170, disc_loss: 1.3735\n",
      "Time for epoch 237 is 20.6035 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 238, gen_loss: 0.7037, disc_loss: 1.4134\n",
      "Time for epoch 238 is 21.1164 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 239, gen_loss: 0.7094, disc_loss: 1.4324\n",
      "Time for epoch 239 is 20.6060 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 240, gen_loss: 0.7136, disc_loss: 1.3824\n",
      "Time for epoch 240 is 21.0482 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 241, gen_loss: 0.7452, disc_loss: 1.3237\n",
      "Time for epoch 241 is 21.1610 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 242, gen_loss: 0.7253, disc_loss: 1.3536\n",
      "Time for epoch 242 is 21.3688 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 243, gen_loss: 0.6924, disc_loss: 1.4206\n",
      "Time for epoch 243 is 20.8970 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 244, gen_loss: 0.7029, disc_loss: 1.4221\n",
      "Time for epoch 244 is 20.8799 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 245, gen_loss: 0.7284, disc_loss: 1.3574\n",
      "Time for epoch 245 is 20.6661 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 246, gen_loss: 0.6933, disc_loss: 1.4077\n",
      "Time for epoch 246 is 20.6609 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 247, gen_loss: 0.7615, disc_loss: 1.3218\n",
      "Time for epoch 247 is 20.9693 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 248, gen_loss: 0.7197, disc_loss: 1.4069\n",
      "Time for epoch 248 is 20.7267 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 249, gen_loss: 0.6634, disc_loss: 1.4278\n",
      "Time for epoch 249 is 20.5552 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 250, gen_loss: 0.7359, disc_loss: 1.3516\n",
      "Time for epoch 250 is 20.6950 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 251, gen_loss: 0.7231, disc_loss: 1.3428\n",
      "Time for epoch 251 is 20.6949 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 252, gen_loss: 0.6983, disc_loss: 1.4416\n",
      "Time for epoch 252 is 20.7172 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 253, gen_loss: 0.7203, disc_loss: 1.3764\n",
      "Time for epoch 253 is 21.2825 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 254, gen_loss: 0.7171, disc_loss: 1.3988\n",
      "Time for epoch 254 is 20.6852 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 255, gen_loss: 0.7249, disc_loss: 1.3774\n",
      "Time for epoch 255 is 21.4419 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 256, gen_loss: 0.6933, disc_loss: 1.4341\n",
      "Time for epoch 256 is 20.8458 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 257, gen_loss: 0.7594, disc_loss: 1.2830\n",
      "Time for epoch 257 is 20.8365 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 258, gen_loss: 0.7929, disc_loss: 1.3763\n",
      "Time for epoch 258 is 20.9325 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 259, gen_loss: 0.8222, disc_loss: 1.2206\n",
      "Time for epoch 259 is 20.6324 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 260, gen_loss: 0.9512, disc_loss: 1.0592\n",
      "Time for epoch 260 is 20.7359 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 261, gen_loss: 1.2320, disc_loss: 0.8171\n",
      "Time for epoch 261 is 20.8770 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 262, gen_loss: 1.1181, disc_loss: 1.0166\n",
      "Time for epoch 262 is 21.6057 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 263, gen_loss: 1.5240, disc_loss: 0.7193\n",
      "Time for epoch 263 is 20.8039 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 264, gen_loss: 1.3460, disc_loss: 0.8691\n",
      "Time for epoch 264 is 20.7536 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 265, gen_loss: 1.0138, disc_loss: 1.1041\n",
      "Time for epoch 265 is 20.8177 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 266, gen_loss: 1.1193, disc_loss: 0.9885\n",
      "Time for epoch 266 is 20.6056 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 267, gen_loss: 1.1561, disc_loss: 0.9846\n",
      "Time for epoch 267 is 20.8770 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 268, gen_loss: 1.1474, disc_loss: 1.0858\n",
      "Time for epoch 268 is 20.8005 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 269, gen_loss: 1.1547, disc_loss: 0.9837\n",
      "Time for epoch 269 is 21.2641 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 270, gen_loss: 1.2732, disc_loss: 0.9028\n",
      "Time for epoch 270 is 20.6650 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 271, gen_loss: 1.1405, disc_loss: 0.9244\n",
      "Time for epoch 271 is 20.5788 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 272, gen_loss: 0.9545, disc_loss: 1.1592\n",
      "Time for epoch 272 is 20.5779 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 273, gen_loss: 1.0934, disc_loss: 0.9826\n",
      "Time for epoch 273 is 20.9312 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 274, gen_loss: 1.2044, disc_loss: 0.9961\n",
      "Time for epoch 274 is 20.5841 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 275, gen_loss: 1.1518, disc_loss: 0.9800\n",
      "Time for epoch 275 is 20.4730 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 276, gen_loss: 1.0650, disc_loss: 1.0587\n",
      "Time for epoch 276 is 20.7631 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 277, gen_loss: 0.9404, disc_loss: 1.1542\n",
      "Time for epoch 277 is 20.6753 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 278, gen_loss: 1.0534, disc_loss: 1.0313\n",
      "Time for epoch 278 is 20.8052 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 279, gen_loss: 1.0141, disc_loss: 1.0742\n",
      "Time for epoch 279 is 20.6674 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 280, gen_loss: 0.8486, disc_loss: 1.2238\n",
      "Time for epoch 280 is 20.6619 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 281, gen_loss: 0.8806, disc_loss: 1.2990\n",
      "Time for epoch 281 is 20.8226 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 282, gen_loss: 0.9316, disc_loss: 1.2173\n",
      "Time for epoch 282 is 20.5139 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 283, gen_loss: 0.9069, disc_loss: 1.3019\n",
      "Time for epoch 283 is 20.6010 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 284, gen_loss: 0.9423, disc_loss: 1.1908\n",
      "Time for epoch 284 is 20.7361 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 285, gen_loss: 0.9673, disc_loss: 1.2008\n",
      "Time for epoch 285 is 20.4249 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 286, gen_loss: 0.9444, disc_loss: 1.2356\n",
      "Time for epoch 286 is 20.7690 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 287, gen_loss: 0.8725, disc_loss: 1.2142\n",
      "Time for epoch 287 is 20.7317 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 288, gen_loss: 1.0473, disc_loss: 1.1744\n",
      "Time for epoch 288 is 20.4666 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 289, gen_loss: 0.8375, disc_loss: 1.2421\n",
      "Time for epoch 289 is 20.4183 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 290, gen_loss: 0.8618, disc_loss: 1.2200\n",
      "Time for epoch 290 is 20.6665 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291, gen_loss: 0.8226, disc_loss: 1.3584\n",
      "Time for epoch 291 is 20.7830 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 292, gen_loss: 0.8316, disc_loss: 1.2835\n",
      "Time for epoch 292 is 20.8381 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 293, gen_loss: 0.8011, disc_loss: 1.3857\n",
      "Time for epoch 293 is 20.8906 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 294, gen_loss: 0.7860, disc_loss: 1.4022\n",
      "Time for epoch 294 is 20.3751 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 295, gen_loss: 0.8086, disc_loss: 1.3252\n",
      "Time for epoch 295 is 21.0043 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 296, gen_loss: 0.8512, disc_loss: 1.2489\n",
      "Time for epoch 296 is 20.4423 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 297, gen_loss: 0.7779, disc_loss: 1.3622\n",
      "Time for epoch 297 is 20.8457 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 298, gen_loss: 0.7876, disc_loss: 1.3320\n",
      "Time for epoch 298 is 20.4629 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 299, gen_loss: 0.7751, disc_loss: 1.3801\n",
      "Time for epoch 299 is 20.4101 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 300, gen_loss: 0.7337, disc_loss: 1.4443\n",
      "Time for epoch 300 is 21.4290 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 301, gen_loss: 0.7518, disc_loss: 1.3237\n",
      "Time for epoch 301 is 20.5701 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 302, gen_loss: 0.7338, disc_loss: 1.3862\n",
      "Time for epoch 302 is 20.6858 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 303, gen_loss: 0.6754, disc_loss: 1.5647\n",
      "Time for epoch 303 is 20.4910 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 304, gen_loss: 0.6921, disc_loss: 1.5083\n",
      "Time for epoch 304 is 20.5389 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 305, gen_loss: 0.7260, disc_loss: 1.4585\n",
      "Time for epoch 305 is 20.7002 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 306, gen_loss: 0.7081, disc_loss: 1.4365\n",
      "Time for epoch 306 is 20.5258 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 307, gen_loss: 0.6977, disc_loss: 1.4571\n",
      "Time for epoch 307 is 20.6289 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 308, gen_loss: 0.6879, disc_loss: 1.4898\n",
      "Time for epoch 308 is 20.3431 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 309, gen_loss: 0.6958, disc_loss: 1.4837\n",
      "Time for epoch 309 is 20.5569 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 310, gen_loss: 0.6742, disc_loss: 1.5038\n",
      "Time for epoch 310 is 20.4623 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 311, gen_loss: 0.6904, disc_loss: 1.5351\n",
      "Time for epoch 311 is 20.6902 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 312, gen_loss: 0.6944, disc_loss: 1.4463\n",
      "Time for epoch 312 is 20.6395 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 313, gen_loss: 0.7179, disc_loss: 1.4037\n",
      "Time for epoch 313 is 20.7973 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 314, gen_loss: 0.7114, disc_loss: 1.3870\n",
      "Time for epoch 314 is 20.4482 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 315, gen_loss: 0.7273, disc_loss: 1.3399\n",
      "Time for epoch 315 is 21.0525 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 316, gen_loss: 0.7357, disc_loss: 1.3680\n",
      "Time for epoch 316 is 20.8170 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 317, gen_loss: 0.7450, disc_loss: 1.3611\n",
      "Time for epoch 317 is 20.7841 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 318, gen_loss: 0.6899, disc_loss: 1.4872\n",
      "Time for epoch 318 is 20.9475 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 319, gen_loss: 0.6826, disc_loss: 1.4284\n",
      "Time for epoch 319 is 20.5712 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 320, gen_loss: 0.6823, disc_loss: 1.4331\n",
      "Time for epoch 320 is 21.1982 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 321, gen_loss: 0.7324, disc_loss: 1.3930\n",
      "Time for epoch 321 is 20.7039 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 322, gen_loss: 0.7089, disc_loss: 1.4030\n",
      "Time for epoch 322 is 20.7979 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 323, gen_loss: 0.7360, disc_loss: 1.3841\n",
      "Time for epoch 323 is 20.6298 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 324, gen_loss: 0.7501, disc_loss: 1.3142\n",
      "Time for epoch 324 is 20.5677 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 325, gen_loss: 0.7544, disc_loss: 1.3437\n",
      "Time for epoch 325 is 20.7400 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 326, gen_loss: 0.7281, disc_loss: 1.4134\n",
      "Time for epoch 326 is 20.5060 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 327, gen_loss: 0.7155, disc_loss: 1.4373\n",
      "Time for epoch 327 is 20.7546 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 328, gen_loss: 0.7358, disc_loss: 1.3157\n",
      "Time for epoch 328 is 20.5967 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 329, gen_loss: 0.7450, disc_loss: 1.3475\n",
      "Time for epoch 329 is 21.2091 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 330, gen_loss: 0.8042, disc_loss: 1.3339\n",
      "Time for epoch 330 is 20.7477 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 331, gen_loss: 0.8825, disc_loss: 1.1681\n",
      "Time for epoch 331 is 20.4359 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 332, gen_loss: 0.8873, disc_loss: 1.1671\n",
      "Time for epoch 332 is 20.8227 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 333, gen_loss: 0.9696, disc_loss: 1.1172\n",
      "Time for epoch 333 is 20.6558 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 334, gen_loss: 0.8970, disc_loss: 1.1970\n",
      "Time for epoch 334 is 20.6734 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 335, gen_loss: 0.8253, disc_loss: 1.2322\n",
      "Time for epoch 335 is 20.4459 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 336, gen_loss: 0.9203, disc_loss: 1.1774\n",
      "Time for epoch 336 is 20.4621 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 337, gen_loss: 0.9415, disc_loss: 1.1072\n",
      "Time for epoch 337 is 20.5210 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 338, gen_loss: 0.9248, disc_loss: 1.0678\n",
      "Time for epoch 338 is 20.5408 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 339, gen_loss: 0.9588, disc_loss: 1.1806\n",
      "Time for epoch 339 is 20.7240 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 340, gen_loss: 1.0542, disc_loss: 0.9904\n",
      "Time for epoch 340 is 20.7322 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 341, gen_loss: 0.8994, disc_loss: 1.1619\n",
      "Time for epoch 341 is 20.5870 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 342, gen_loss: 0.9750, disc_loss: 1.1576\n",
      "Time for epoch 342 is 20.5015 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 343, gen_loss: 0.9963, disc_loss: 1.0309\n",
      "Time for epoch 343 is 20.6160 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 344, gen_loss: 1.0426, disc_loss: 1.0442\n",
      "Time for epoch 344 is 20.6872 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 345, gen_loss: 1.0079, disc_loss: 1.0202\n",
      "Time for epoch 345 is 20.8093 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 346, gen_loss: 1.1644, disc_loss: 0.9672\n",
      "Time for epoch 346 is 20.5950 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 347, gen_loss: 0.9538, disc_loss: 1.1995\n",
      "Time for epoch 347 is 20.4738 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 348, gen_loss: 0.8948, disc_loss: 1.1243\n",
      "Time for epoch 348 is 20.5761 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 349, gen_loss: 1.0512, disc_loss: 1.0213\n",
      "Time for epoch 349 is 20.8516 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 350, gen_loss: 1.0759, disc_loss: 1.1133\n",
      "Time for epoch 350 is 20.6400 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 351, gen_loss: 1.1834, disc_loss: 0.8624\n",
      "Time for epoch 351 is 20.4670 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 352, gen_loss: 1.0525, disc_loss: 1.0964\n",
      "Time for epoch 352 is 20.8290 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 353, gen_loss: 0.9681, disc_loss: 1.1548\n",
      "Time for epoch 353 is 20.5657 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 354, gen_loss: 0.9389, disc_loss: 1.0663\n",
      "Time for epoch 354 is 20.6510 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 355, gen_loss: 1.1174, disc_loss: 1.0737\n",
      "Time for epoch 355 is 20.5270 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 356, gen_loss: 1.0223, disc_loss: 1.1152\n",
      "Time for epoch 356 is 20.7359 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 357, gen_loss: 1.1922, disc_loss: 0.8653\n",
      "Time for epoch 357 is 20.6168 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 358, gen_loss: 0.8784, disc_loss: 1.2078\n",
      "Time for epoch 358 is 20.5168 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 359, gen_loss: 0.9563, disc_loss: 1.1484\n",
      "Time for epoch 359 is 20.7124 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 360, gen_loss: 1.0006, disc_loss: 1.1442\n",
      "Time for epoch 360 is 20.8640 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 361, gen_loss: 1.0675, disc_loss: 0.9784\n",
      "Time for epoch 361 is 20.5825 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 362, gen_loss: 1.0898, disc_loss: 1.0286\n",
      "Time for epoch 362 is 20.5843 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 363, gen_loss: 1.0454, disc_loss: 1.0693\n",
      "Time for epoch 363 is 20.6500 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 364, gen_loss: 0.9669, disc_loss: 1.1672\n",
      "Time for epoch 364 is 20.6987 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 365, gen_loss: 0.9977, disc_loss: 1.0746\n",
      "Time for epoch 365 is 20.6692 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 366, gen_loss: 0.9380, disc_loss: 1.1539\n",
      "Time for epoch 366 is 20.5464 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 367, gen_loss: 0.9505, disc_loss: 1.1448\n",
      "Time for epoch 367 is 20.5722 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 368, gen_loss: 0.8451, disc_loss: 1.2624\n",
      "Time for epoch 368 is 20.7712 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 369, gen_loss: 0.7969, disc_loss: 1.5100\n",
      "Time for epoch 369 is 20.4911 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 370, gen_loss: 0.8305, disc_loss: 1.3465\n",
      "Time for epoch 370 is 20.8460 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 371, gen_loss: 0.7709, disc_loss: 1.4155\n",
      "Time for epoch 371 is 20.6131 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 372, gen_loss: 0.7537, disc_loss: 1.4091\n",
      "Time for epoch 372 is 20.8460 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 373, gen_loss: 0.7178, disc_loss: 1.4963\n",
      "Time for epoch 373 is 20.6248 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 374, gen_loss: 0.6829, disc_loss: 1.4741\n",
      "Time for epoch 374 is 20.4775 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 375, gen_loss: 0.7538, disc_loss: 1.3801\n",
      "Time for epoch 375 is 21.1162 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 376, gen_loss: 0.8544, disc_loss: 1.2460\n",
      "Time for epoch 376 is 20.6219 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 377, gen_loss: 0.7631, disc_loss: 1.4388\n",
      "Time for epoch 377 is 20.7641 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 378, gen_loss: 0.8301, disc_loss: 1.2556\n",
      "Time for epoch 378 is 20.6669 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 379, gen_loss: 0.8565, disc_loss: 1.2768\n",
      "Time for epoch 379 is 20.9578 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 380, gen_loss: 0.8331, disc_loss: 1.2185\n",
      "Time for epoch 380 is 20.6270 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 381, gen_loss: 0.8149, disc_loss: 1.3034\n",
      "Time for epoch 381 is 20.5227 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 382, gen_loss: 0.7582, disc_loss: 1.4049\n",
      "Time for epoch 382 is 20.7903 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 383, gen_loss: 0.7380, disc_loss: 1.3609\n",
      "Time for epoch 383 is 20.4810 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 384, gen_loss: 0.7790, disc_loss: 1.3348\n",
      "Time for epoch 384 is 20.5225 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 385, gen_loss: 0.7848, disc_loss: 1.3254\n",
      "Time for epoch 385 is 20.6148 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 386, gen_loss: 0.7871, disc_loss: 1.3687\n",
      "Time for epoch 386 is 20.8142 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 387, gen_loss: 0.8058, disc_loss: 1.3105\n",
      "Time for epoch 387 is 20.6261 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 388, gen_loss: 0.7103, disc_loss: 1.4857\n",
      "Time for epoch 388 is 20.6893 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 389, gen_loss: 0.6886, disc_loss: 1.5046\n",
      "Time for epoch 389 is 20.5922 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 390, gen_loss: 0.7377, disc_loss: 1.4915\n",
      "Time for epoch 390 is 20.5967 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 391, gen_loss: 0.7447, disc_loss: 1.4105\n",
      "Time for epoch 391 is 20.6700 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 392, gen_loss: 0.8903, disc_loss: 1.2107\n",
      "Time for epoch 392 is 20.7659 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 393, gen_loss: 0.7584, disc_loss: 1.3329\n",
      "Time for epoch 393 is 20.5029 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 394, gen_loss: 0.7707, disc_loss: 1.3717\n",
      "Time for epoch 394 is 20.6723 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 395, gen_loss: 0.8638, disc_loss: 1.1479\n",
      "Time for epoch 395 is 20.5308 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396, gen_loss: 0.8539, disc_loss: 1.2827\n",
      "Time for epoch 396 is 20.5377 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 397, gen_loss: 0.8964, disc_loss: 1.1872\n",
      "Time for epoch 397 is 20.5089 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 398, gen_loss: 0.8001, disc_loss: 1.3166\n",
      "Time for epoch 398 is 20.6294 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 399, gen_loss: 0.8418, disc_loss: 1.2668\n",
      "Time for epoch 399 is 20.6136 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 400, gen_loss: 0.7962, disc_loss: 1.2640\n",
      "Time for epoch 400 is 20.9253 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 401, gen_loss: 0.8525, disc_loss: 1.2578\n",
      "Time for epoch 401 is 20.5705 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 402, gen_loss: 0.7622, disc_loss: 1.4027\n",
      "Time for epoch 402 is 20.6204 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 403, gen_loss: 0.7139, disc_loss: 1.4332\n",
      "Time for epoch 403 is 20.6768 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 404, gen_loss: 0.7434, disc_loss: 1.4117\n",
      "Time for epoch 404 is 20.8573 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 405, gen_loss: 0.8299, disc_loss: 1.2641\n",
      "Time for epoch 405 is 20.5931 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 406, gen_loss: 0.8392, disc_loss: 1.3141\n",
      "Time for epoch 406 is 20.7394 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 407, gen_loss: 0.7469, disc_loss: 1.3931\n",
      "Time for epoch 407 is 20.5198 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 408, gen_loss: 0.7705, disc_loss: 1.4779\n",
      "Time for epoch 408 is 20.5579 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 409, gen_loss: 0.7897, disc_loss: 1.2686\n",
      "Time for epoch 409 is 20.6521 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 410, gen_loss: 0.8286, disc_loss: 1.2518\n",
      "Time for epoch 410 is 20.7537 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 411, gen_loss: 0.8934, disc_loss: 1.2047\n",
      "Time for epoch 411 is 20.5541 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 412, gen_loss: 0.8791, disc_loss: 1.1809\n",
      "Time for epoch 412 is 20.4600 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 413, gen_loss: 0.8380, disc_loss: 1.2885\n",
      "Time for epoch 413 is 20.5703 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 414, gen_loss: 0.9402, disc_loss: 1.1515\n",
      "Time for epoch 414 is 20.7544 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 415, gen_loss: 0.9458, disc_loss: 1.1229\n",
      "Time for epoch 415 is 20.5867 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 416, gen_loss: 0.8724, disc_loss: 1.1826\n",
      "Time for epoch 416 is 20.6396 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 417, gen_loss: 0.9054, disc_loss: 1.1464\n",
      "Time for epoch 417 is 20.5392 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 418, gen_loss: 0.9292, disc_loss: 1.1811\n",
      "Time for epoch 418 is 21.4177 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 419, gen_loss: 1.0178, disc_loss: 1.0328\n",
      "Time for epoch 419 is 20.5899 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 420, gen_loss: 0.8072, disc_loss: 1.2790\n",
      "Time for epoch 420 is 21.0877 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 421, gen_loss: 0.7738, disc_loss: 1.3381\n",
      "Time for epoch 421 is 20.5484 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 422, gen_loss: 0.8028, disc_loss: 1.3368\n",
      "Time for epoch 422 is 20.6289 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 423, gen_loss: 0.8476, disc_loss: 1.2188\n",
      "Time for epoch 423 is 20.9896 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 424, gen_loss: 0.8627, disc_loss: 1.2564\n",
      "Time for epoch 424 is 20.6836 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 425, gen_loss: 0.7709, disc_loss: 1.3032\n",
      "Time for epoch 425 is 20.5507 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 426, gen_loss: 0.7807, disc_loss: 1.3476\n",
      "Time for epoch 426 is 20.4462 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 427, gen_loss: 0.8801, disc_loss: 1.2227\n",
      "Time for epoch 427 is 20.4524 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 428, gen_loss: 0.8427, disc_loss: 1.2030\n",
      "Time for epoch 428 is 20.5770 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 429, gen_loss: 0.8207, disc_loss: 1.3584\n",
      "Time for epoch 429 is 20.8311 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 430, gen_loss: 0.8348, disc_loss: 1.3014\n",
      "Time for epoch 430 is 20.5922 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 431, gen_loss: 0.8411, disc_loss: 1.1860\n",
      "Time for epoch 431 is 20.6602 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 432, gen_loss: 0.8957, disc_loss: 1.2126\n",
      "Time for epoch 432 is 20.5260 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 433, gen_loss: 0.9611, disc_loss: 1.1309\n",
      "Time for epoch 433 is 20.4502 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 434, gen_loss: 1.0029, disc_loss: 1.0871\n",
      "Time for epoch 434 is 20.4570 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 435, gen_loss: 0.8154, disc_loss: 1.2919\n",
      "Time for epoch 435 is 20.6017 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 436, gen_loss: 0.9153, disc_loss: 1.1096\n",
      "Time for epoch 436 is 20.6555 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 437, gen_loss: 0.9544, disc_loss: 1.1007\n",
      "Time for epoch 437 is 20.5891 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 438, gen_loss: 0.7904, disc_loss: 1.3821\n",
      "Time for epoch 438 is 20.5284 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 439, gen_loss: 0.8197, disc_loss: 1.3725\n",
      "Time for epoch 439 is 20.5500 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 440, gen_loss: 0.8037, disc_loss: 1.3424\n",
      "Time for epoch 440 is 20.6172 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 441, gen_loss: 0.8017, disc_loss: 1.2900\n",
      "Time for epoch 441 is 20.5975 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 442, gen_loss: 0.8070, disc_loss: 1.3044\n",
      "Time for epoch 442 is 20.8416 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 443, gen_loss: 0.7898, disc_loss: 1.3411\n",
      "Time for epoch 443 is 20.7190 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 444, gen_loss: 0.7989, disc_loss: 1.3650\n",
      "Time for epoch 444 is 20.5781 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 445, gen_loss: 0.7927, disc_loss: 1.2065\n",
      "Time for epoch 445 is 20.7361 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 446, gen_loss: 0.7950, disc_loss: 1.4193\n",
      "Time for epoch 446 is 20.6149 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 447, gen_loss: 0.7424, disc_loss: 1.4060\n",
      "Time for epoch 447 is 20.5725 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 448, gen_loss: 0.8127, disc_loss: 1.3000\n",
      "Time for epoch 448 is 20.7071 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 449, gen_loss: 0.8057, disc_loss: 1.2523\n",
      "Time for epoch 449 is 20.6878 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 450, gen_loss: 0.7648, disc_loss: 1.3889\n",
      "Time for epoch 450 is 28.6299 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 451, gen_loss: 0.8545, disc_loss: 1.3392\n",
      "Time for epoch 451 is 20.5572 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 452, gen_loss: 0.8026, disc_loss: 1.2822\n",
      "Time for epoch 452 is 20.6200 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 453, gen_loss: 0.7807, disc_loss: 1.4106\n",
      "Time for epoch 453 is 20.8581 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 454, gen_loss: 0.7577, disc_loss: 1.3705\n",
      "Time for epoch 454 is 20.8143 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 455, gen_loss: 0.8177, disc_loss: 1.2804\n",
      "Time for epoch 455 is 20.4318 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 456, gen_loss: 0.8229, disc_loss: 1.3484\n",
      "Time for epoch 456 is 20.5941 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 457, gen_loss: 0.8116, disc_loss: 1.3496\n",
      "Time for epoch 457 is 20.9925 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 458, gen_loss: 0.7337, disc_loss: 1.3611\n",
      "Time for epoch 458 is 20.6261 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 459, gen_loss: 0.7974, disc_loss: 1.3142\n",
      "Time for epoch 459 is 20.7134 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 460, gen_loss: 0.7619, disc_loss: 1.3672\n",
      "Time for epoch 460 is 20.6663 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 461, gen_loss: 0.8411, disc_loss: 1.3121\n",
      "Time for epoch 461 is 20.7077 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 462, gen_loss: 0.8079, disc_loss: 1.2054\n",
      "Time for epoch 462 is 20.5161 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 463, gen_loss: 0.8373, disc_loss: 1.2715\n",
      "Time for epoch 463 is 20.4210 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 464, gen_loss: 0.8184, disc_loss: 1.2287\n",
      "Time for epoch 464 is 20.4940 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 465, gen_loss: 0.8534, disc_loss: 1.1858\n",
      "Time for epoch 465 is 20.8367 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 466, gen_loss: 0.7703, disc_loss: 1.4092\n",
      "Time for epoch 466 is 20.7222 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 467, gen_loss: 0.7711, disc_loss: 1.2949\n",
      "Time for epoch 467 is 20.9421 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 468, gen_loss: 0.8170, disc_loss: 1.2751\n",
      "Time for epoch 468 is 20.5566 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 469, gen_loss: 0.8362, disc_loss: 1.2865\n",
      "Time for epoch 469 is 20.5771 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 470, gen_loss: 0.8217, disc_loss: 1.2875\n",
      "Time for epoch 470 is 20.7899 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 471, gen_loss: 0.8703, disc_loss: 1.1824\n",
      "Time for epoch 471 is 20.6056 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 472, gen_loss: 0.8299, disc_loss: 1.2486\n",
      "Time for epoch 472 is 20.7153 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 473, gen_loss: 0.7927, disc_loss: 1.3635\n",
      "Time for epoch 473 is 20.6661 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 474, gen_loss: 0.7714, disc_loss: 1.4114\n",
      "Time for epoch 474 is 20.7377 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 475, gen_loss: 0.7760, disc_loss: 1.3771\n",
      "Time for epoch 475 is 20.7737 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 476, gen_loss: 0.8153, disc_loss: 1.2251\n",
      "Time for epoch 476 is 20.7867 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 477, gen_loss: 0.8236, disc_loss: 1.2446\n",
      "Time for epoch 477 is 20.5658 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 478, gen_loss: 0.8522, disc_loss: 1.3008\n",
      "Time for epoch 478 is 20.6650 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 479, gen_loss: 0.9927, disc_loss: 1.0271\n",
      "Time for epoch 479 is 20.5720 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 480, gen_loss: 0.8743, disc_loss: 1.1834\n",
      "Time for epoch 480 is 20.5279 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 481, gen_loss: 0.8884, disc_loss: 1.1838\n",
      "Time for epoch 481 is 20.4511 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 482, gen_loss: 0.8209, disc_loss: 1.3443\n",
      "Time for epoch 482 is 20.4761 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 483, gen_loss: 0.8563, disc_loss: 1.3137\n",
      "Time for epoch 483 is 20.8253 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 484, gen_loss: 0.9058, disc_loss: 1.1475\n",
      "Time for epoch 484 is 20.6848 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 485, gen_loss: 0.8540, disc_loss: 1.2103\n",
      "Time for epoch 485 is 20.6483 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 486, gen_loss: 0.7757, disc_loss: 1.4072\n",
      "Time for epoch 486 is 20.3570 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 487, gen_loss: 0.8430, disc_loss: 1.2657\n",
      "Time for epoch 487 is 20.6928 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 488, gen_loss: 0.8140, disc_loss: 1.2867\n",
      "Time for epoch 488 is 20.6146 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 489, gen_loss: 0.8569, disc_loss: 1.2434\n",
      "Time for epoch 489 is 20.6660 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 490, gen_loss: 0.8496, disc_loss: 1.3424\n",
      "Time for epoch 490 is 20.4447 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 491, gen_loss: 0.7719, disc_loss: 1.3162\n",
      "Time for epoch 491 is 20.5121 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 492, gen_loss: 0.8095, disc_loss: 1.2754\n",
      "Time for epoch 492 is 20.8815 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 493, gen_loss: 0.9412, disc_loss: 1.1567\n",
      "Time for epoch 493 is 20.4036 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 494, gen_loss: 0.9604, disc_loss: 1.1213\n",
      "Time for epoch 494 is 20.7511 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 495, gen_loss: 0.9106, disc_loss: 1.2227\n",
      "Time for epoch 495 is 20.4082 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 496, gen_loss: 0.7605, disc_loss: 1.3555\n",
      "Time for epoch 496 is 20.8216 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 497, gen_loss: 0.7931, disc_loss: 1.3606\n",
      "Time for epoch 497 is 20.5568 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 498, gen_loss: 0.8977, disc_loss: 1.2091\n",
      "Time for epoch 498 is 20.5858 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 499, gen_loss: 0.9103, disc_loss: 1.1704\n",
      "Time for epoch 499 is 20.6206 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 500, gen_loss: 0.9267, disc_loss: 1.1284\n",
      "Time for epoch 500 is 20.5100 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501, gen_loss: 0.8350, disc_loss: 1.2337\n",
      "Time for epoch 501 is 20.5761 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 502, gen_loss: 0.8078, disc_loss: 1.2829\n",
      "Time for epoch 502 is 20.3986 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 503, gen_loss: 0.9092, disc_loss: 1.1872\n",
      "Time for epoch 503 is 20.5459 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 504, gen_loss: 0.8282, disc_loss: 1.2192\n",
      "Time for epoch 504 is 20.5600 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 505, gen_loss: 0.9316, disc_loss: 1.2160\n",
      "Time for epoch 505 is 20.6988 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 506, gen_loss: 0.8465, disc_loss: 1.3166\n",
      "Time for epoch 506 is 20.4481 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 507, gen_loss: 0.8503, disc_loss: 1.2441\n",
      "Time for epoch 507 is 20.6326 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 508, gen_loss: 0.8587, disc_loss: 1.2769\n",
      "Time for epoch 508 is 20.5397 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 509, gen_loss: 0.8544, disc_loss: 1.3061\n",
      "Time for epoch 509 is 20.6458 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 510, gen_loss: 0.8664, disc_loss: 1.1707\n",
      "Time for epoch 510 is 20.8190 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 511, gen_loss: 0.8265, disc_loss: 1.3424\n",
      "Time for epoch 511 is 20.3929 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 512, gen_loss: 0.8307, disc_loss: 1.2756\n",
      "Time for epoch 512 is 20.6163 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 513, gen_loss: 0.8796, disc_loss: 1.1459\n",
      "Time for epoch 513 is 20.5287 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 514, gen_loss: 0.8913, disc_loss: 1.2473\n",
      "Time for epoch 514 is 20.5931 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 515, gen_loss: 0.8084, disc_loss: 1.3157\n",
      "Time for epoch 515 is 20.4596 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 516, gen_loss: 0.9045, disc_loss: 1.1924\n",
      "Time for epoch 516 is 20.4496 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 517, gen_loss: 0.8939, disc_loss: 1.2305\n",
      "Time for epoch 517 is 20.3836 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 518, gen_loss: 0.9589, disc_loss: 1.0915\n",
      "Time for epoch 518 is 20.4697 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 519, gen_loss: 0.9193, disc_loss: 1.1770\n",
      "Time for epoch 519 is 20.7100 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 520, gen_loss: 1.0216, disc_loss: 1.1282\n",
      "Time for epoch 520 is 20.3667 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 521, gen_loss: 1.0291, disc_loss: 0.9984\n",
      "Time for epoch 521 is 20.6696 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 522, gen_loss: 0.9792, disc_loss: 1.0474\n",
      "Time for epoch 522 is 20.7120 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 523, gen_loss: 0.9746, disc_loss: 1.1605\n",
      "Time for epoch 523 is 20.4487 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 524, gen_loss: 1.0146, disc_loss: 1.0627\n",
      "Time for epoch 524 is 20.3177 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 525, gen_loss: 1.0972, disc_loss: 1.0338\n",
      "Time for epoch 525 is 20.4642 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 526, gen_loss: 0.9610, disc_loss: 1.0932\n",
      "Time for epoch 526 is 20.8316 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 527, gen_loss: 1.0881, disc_loss: 1.0420\n",
      "Time for epoch 527 is 20.6022 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 528, gen_loss: 0.9979, disc_loss: 1.0336\n",
      "Time for epoch 528 is 20.4122 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 529, gen_loss: 0.8738, disc_loss: 1.2469\n",
      "Time for epoch 529 is 20.6246 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 530, gen_loss: 0.9794, disc_loss: 1.1231\n",
      "Time for epoch 530 is 20.6843 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 531, gen_loss: 0.9013, disc_loss: 1.2225\n",
      "Time for epoch 531 is 20.6147 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 532, gen_loss: 0.8459, disc_loss: 1.2792\n",
      "Time for epoch 532 is 20.4236 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 533, gen_loss: 0.9251, disc_loss: 1.2438\n",
      "Time for epoch 533 is 20.6951 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 534, gen_loss: 0.8452, disc_loss: 1.2983\n",
      "Time for epoch 534 is 20.6381 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 535, gen_loss: 0.9340, disc_loss: 1.2002\n",
      "Time for epoch 535 is 20.5781 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 536, gen_loss: 0.8531, disc_loss: 1.2339\n",
      "Time for epoch 536 is 20.6213 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 537, gen_loss: 0.9085, disc_loss: 1.1580\n",
      "Time for epoch 537 is 20.6823 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 538, gen_loss: 0.8864, disc_loss: 1.1832\n",
      "Time for epoch 538 is 20.5170 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 539, gen_loss: 0.8177, disc_loss: 1.3469\n",
      "Time for epoch 539 is 20.5539 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 540, gen_loss: 0.7849, disc_loss: 1.3664\n",
      "Time for epoch 540 is 20.5845 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 541, gen_loss: 0.8153, disc_loss: 1.4074\n",
      "Time for epoch 541 is 20.5808 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 542, gen_loss: 0.7960, disc_loss: 1.3633\n",
      "Time for epoch 542 is 20.5228 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 543, gen_loss: 0.8663, disc_loss: 1.2026\n",
      "Time for epoch 543 is 20.7354 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 544, gen_loss: 0.8652, disc_loss: 1.1958\n",
      "Time for epoch 544 is 20.5990 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 545, gen_loss: 0.8868, disc_loss: 1.2235\n",
      "Time for epoch 545 is 20.4818 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 546, gen_loss: 0.9645, disc_loss: 1.1265\n",
      "Time for epoch 546 is 20.7010 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 547, gen_loss: 0.8696, disc_loss: 1.2501\n",
      "Time for epoch 547 is 20.6861 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 548, gen_loss: 0.9319, disc_loss: 1.1752\n",
      "Time for epoch 548 is 20.8920 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 549, gen_loss: 0.8318, disc_loss: 1.3532\n",
      "Time for epoch 549 is 20.5290 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 550, gen_loss: 0.8814, disc_loss: 1.2137\n",
      "Time for epoch 550 is 20.4581 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 551, gen_loss: 0.9094, disc_loss: 1.1632\n",
      "Time for epoch 551 is 20.4689 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 552, gen_loss: 0.9888, disc_loss: 1.1557\n",
      "Time for epoch 552 is 20.5434 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 553, gen_loss: 1.0214, disc_loss: 1.0434\n",
      "Time for epoch 553 is 20.7102 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 554, gen_loss: 0.9261, disc_loss: 1.1082\n",
      "Time for epoch 554 is 20.5653 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 555, gen_loss: 0.9225, disc_loss: 1.1299\n",
      "Time for epoch 555 is 20.5638 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 556, gen_loss: 0.9549, disc_loss: 1.1846\n",
      "Time for epoch 556 is 20.7892 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 557, gen_loss: 0.7740, disc_loss: 1.4143\n",
      "Time for epoch 557 is 20.4740 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 558, gen_loss: 0.8896, disc_loss: 1.2166\n",
      "Time for epoch 558 is 20.5950 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 559, gen_loss: 0.8033, disc_loss: 1.3691\n",
      "Time for epoch 559 is 20.4994 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 560, gen_loss: 0.9048, disc_loss: 1.2088\n",
      "Time for epoch 560 is 20.6653 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 561, gen_loss: 0.8669, disc_loss: 1.3296\n",
      "Time for epoch 561 is 20.7014 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 562, gen_loss: 0.8695, disc_loss: 1.1646\n",
      "Time for epoch 562 is 20.5583 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 563, gen_loss: 0.9526, disc_loss: 1.1624\n",
      "Time for epoch 563 is 20.5989 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 564, gen_loss: 0.9843, disc_loss: 1.0862\n",
      "Time for epoch 564 is 20.3940 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 565, gen_loss: 0.9275, disc_loss: 1.2939\n",
      "Time for epoch 565 is 20.6801 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 566, gen_loss: 0.9579, disc_loss: 1.2029\n",
      "Time for epoch 566 is 20.5692 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 567, gen_loss: 1.0446, disc_loss: 1.0093\n",
      "Time for epoch 567 is 20.5609 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 568, gen_loss: 0.8510, disc_loss: 1.3162\n",
      "Time for epoch 568 is 20.6089 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 569, gen_loss: 0.8976, disc_loss: 1.2580\n",
      "Time for epoch 569 is 20.5180 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 570, gen_loss: 0.8280, disc_loss: 1.2837\n",
      "Time for epoch 570 is 20.5107 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 571, gen_loss: 0.7851, disc_loss: 1.3404\n",
      "Time for epoch 571 is 20.5821 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 572, gen_loss: 0.9229, disc_loss: 1.1593\n",
      "Time for epoch 572 is 20.5785 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 573, gen_loss: 0.9926, disc_loss: 1.0806\n",
      "Time for epoch 573 is 20.5599 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 574, gen_loss: 0.9813, disc_loss: 1.1388\n",
      "Time for epoch 574 is 20.8692 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 575, gen_loss: 1.0069, disc_loss: 1.0850\n",
      "Time for epoch 575 is 20.5037 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 576, gen_loss: 0.9262, disc_loss: 1.1796\n",
      "Time for epoch 576 is 20.8526 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 577, gen_loss: 1.0165, disc_loss: 1.1684\n",
      "Time for epoch 577 is 20.6799 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 578, gen_loss: 1.0563, disc_loss: 1.0579\n",
      "Time for epoch 578 is 20.4052 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 579, gen_loss: 1.1724, disc_loss: 0.8808\n",
      "Time for epoch 579 is 20.6811 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 580, gen_loss: 1.0362, disc_loss: 1.1598\n",
      "Time for epoch 580 is 20.4261 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 581, gen_loss: 0.8917, disc_loss: 1.2858\n",
      "Time for epoch 581 is 20.6991 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 582, gen_loss: 0.9673, disc_loss: 1.1408\n",
      "Time for epoch 582 is 20.4575 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 583, gen_loss: 1.0391, disc_loss: 1.0331\n",
      "Time for epoch 583 is 20.9251 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 584, gen_loss: 1.0549, disc_loss: 1.0163\n",
      "Time for epoch 584 is 20.7444 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 585, gen_loss: 1.1473, disc_loss: 0.9765\n",
      "Time for epoch 585 is 20.8688 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 586, gen_loss: 1.1389, disc_loss: 0.9160\n",
      "Time for epoch 586 is 20.4565 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 587, gen_loss: 1.0740, disc_loss: 1.0040\n",
      "Time for epoch 587 is 20.6945 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 588, gen_loss: 0.9865, disc_loss: 1.2406\n",
      "Time for epoch 588 is 20.5471 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 589, gen_loss: 1.0052, disc_loss: 1.0872\n",
      "Time for epoch 589 is 20.6501 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 590, gen_loss: 1.0219, disc_loss: 1.1497\n",
      "Time for epoch 590 is 20.6174 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 591, gen_loss: 1.1056, disc_loss: 0.9338\n",
      "Time for epoch 591 is 20.4262 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 592, gen_loss: 0.9629, disc_loss: 1.1477\n",
      "Time for epoch 592 is 20.5694 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 593, gen_loss: 1.0298, disc_loss: 1.0079\n",
      "Time for epoch 593 is 20.4822 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 594, gen_loss: 1.1104, disc_loss: 0.9575\n",
      "Time for epoch 594 is 20.9518 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 595, gen_loss: 1.0315, disc_loss: 1.1134\n",
      "Time for epoch 595 is 20.7429 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 596, gen_loss: 0.9876, disc_loss: 1.1633\n",
      "Time for epoch 596 is 20.6340 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 597, gen_loss: 0.8722, disc_loss: 1.2927\n",
      "Time for epoch 597 is 20.5634 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 598, gen_loss: 0.8958, disc_loss: 1.2266\n",
      "Time for epoch 598 is 20.5888 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 599, gen_loss: 1.1016, disc_loss: 0.9702\n",
      "Time for epoch 599 is 20.8444 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 600, gen_loss: 1.0109, disc_loss: 1.1246\n",
      "Time for epoch 600 is 20.4989 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 601, gen_loss: 1.0429, disc_loss: 1.0881\n",
      "Time for epoch 601 is 20.7109 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 602, gen_loss: 1.0864, disc_loss: 0.9998\n",
      "Time for epoch 602 is 20.5038 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 603, gen_loss: 0.8691, disc_loss: 1.3373\n",
      "Time for epoch 603 is 20.5004 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 604, gen_loss: 0.8722, disc_loss: 1.3218\n",
      "Time for epoch 604 is 20.9196 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 605, gen_loss: 0.9153, disc_loss: 1.2555\n",
      "Time for epoch 605 is 20.5297 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 606, gen_loss: 1.0626, disc_loss: 1.0280\n",
      "Time for epoch 606 is 20.6515 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 607, gen_loss: 1.0234, disc_loss: 1.0189\n",
      "Time for epoch 607 is 20.4289 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 608, gen_loss: 0.9691, disc_loss: 1.1445\n",
      "Time for epoch 608 is 20.9309 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 609, gen_loss: 0.9537, disc_loss: 1.2484\n",
      "Time for epoch 609 is 20.5219 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 610, gen_loss: 0.9710, disc_loss: 1.1035\n",
      "Time for epoch 610 is 20.5163 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 611, gen_loss: 0.9569, disc_loss: 1.1694\n",
      "Time for epoch 611 is 20.6980 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 612, gen_loss: 0.9932, disc_loss: 1.1075\n",
      "Time for epoch 612 is 20.4149 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 613, gen_loss: 0.9804, disc_loss: 1.1700\n",
      "Time for epoch 613 is 20.6701 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 614, gen_loss: 1.0430, disc_loss: 1.0256\n",
      "Time for epoch 614 is 20.4624 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 615, gen_loss: 1.0014, disc_loss: 1.1062\n",
      "Time for epoch 615 is 20.5952 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 616, gen_loss: 0.9829, disc_loss: 1.1971\n",
      "Time for epoch 616 is 20.9477 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 617, gen_loss: 0.9899, disc_loss: 1.0720\n",
      "Time for epoch 617 is 20.5810 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 618, gen_loss: 0.9625, disc_loss: 1.2621\n",
      "Time for epoch 618 is 20.6055 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 619, gen_loss: 0.9044, disc_loss: 1.1801\n",
      "Time for epoch 619 is 20.6482 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 620, gen_loss: 0.8858, disc_loss: 1.2090\n",
      "Time for epoch 620 is 20.7978 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 621, gen_loss: 0.8986, disc_loss: 1.2546\n",
      "Time for epoch 621 is 20.3554 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 622, gen_loss: 0.9585, disc_loss: 1.1893\n",
      "Time for epoch 622 is 20.6297 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 623, gen_loss: 0.8000, disc_loss: 1.4525\n",
      "Time for epoch 623 is 20.5049 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 624, gen_loss: 0.9209, disc_loss: 1.1341\n",
      "Time for epoch 624 is 20.6576 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 625, gen_loss: 0.8653, disc_loss: 1.3424\n",
      "Time for epoch 625 is 20.5999 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 626, gen_loss: 0.9010, disc_loss: 1.1653\n",
      "Time for epoch 626 is 20.5733 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 627, gen_loss: 0.9877, disc_loss: 1.0929\n",
      "Time for epoch 627 is 21.2516 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 628, gen_loss: 0.9919, disc_loss: 1.1537\n",
      "Time for epoch 628 is 20.5010 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 629, gen_loss: 0.9518, disc_loss: 1.1610\n",
      "Time for epoch 629 is 20.8068 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 630, gen_loss: 0.9873, disc_loss: 1.1483\n",
      "Time for epoch 630 is 20.6096 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 631, gen_loss: 0.9223, disc_loss: 1.2564\n",
      "Time for epoch 631 is 20.5738 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 632, gen_loss: 0.8837, disc_loss: 1.2383\n",
      "Time for epoch 632 is 20.6667 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 633, gen_loss: 0.8501, disc_loss: 1.2781\n",
      "Time for epoch 633 is 20.6860 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 634, gen_loss: 0.9625, disc_loss: 1.1043\n",
      "Time for epoch 634 is 20.3493 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 635, gen_loss: 0.8755, disc_loss: 1.2497\n",
      "Time for epoch 635 is 20.6507 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 636, gen_loss: 0.9414, disc_loss: 1.1462\n",
      "Time for epoch 636 is 20.5728 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 637, gen_loss: 0.8437, disc_loss: 1.3176\n",
      "Time for epoch 637 is 20.4928 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 638, gen_loss: 1.0291, disc_loss: 1.0922\n",
      "Time for epoch 638 is 20.4928 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 639, gen_loss: 0.9633, disc_loss: 1.1870\n",
      "Time for epoch 639 is 20.4249 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 640, gen_loss: 0.9156, disc_loss: 1.1712\n",
      "Time for epoch 640 is 21.1310 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 641, gen_loss: 0.9801, disc_loss: 1.1190\n",
      "Time for epoch 641 is 20.4950 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 642, gen_loss: 0.8835, disc_loss: 1.2707\n",
      "Time for epoch 642 is 20.6800 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 643, gen_loss: 0.8997, disc_loss: 1.1601\n",
      "Time for epoch 643 is 20.8361 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 644, gen_loss: 0.9546, disc_loss: 1.1949\n",
      "Time for epoch 644 is 20.5512 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 645, gen_loss: 0.9509, disc_loss: 1.2251\n",
      "Time for epoch 645 is 20.6139 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 646, gen_loss: 0.8892, disc_loss: 1.1779\n",
      "Time for epoch 646 is 20.6283 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 647, gen_loss: 0.8856, disc_loss: 1.3568\n",
      "Time for epoch 647 is 20.5660 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 648, gen_loss: 0.9286, disc_loss: 1.1652\n",
      "Time for epoch 648 is 20.6009 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 649, gen_loss: 0.9615, disc_loss: 1.2134\n",
      "Time for epoch 649 is 20.5790 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 650, gen_loss: 0.9444, disc_loss: 1.1881\n",
      "Time for epoch 650 is 20.6760 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 651, gen_loss: 0.8574, disc_loss: 1.3726\n",
      "Time for epoch 651 is 20.5821 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 652, gen_loss: 0.8605, disc_loss: 1.2356\n",
      "Time for epoch 652 is 20.6351 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 653, gen_loss: 0.8648, disc_loss: 1.2767\n",
      "Time for epoch 653 is 20.4737 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 654, gen_loss: 0.9356, disc_loss: 1.1851\n",
      "Time for epoch 654 is 20.7081 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 655, gen_loss: 0.9020, disc_loss: 1.3325\n",
      "Time for epoch 655 is 20.5414 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 656, gen_loss: 0.9589, disc_loss: 1.1826\n",
      "Time for epoch 656 is 20.5867 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 657, gen_loss: 0.9793, disc_loss: 1.0896\n",
      "Time for epoch 657 is 20.5571 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 658, gen_loss: 1.0035, disc_loss: 1.0492\n",
      "Time for epoch 658 is 20.6841 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 659, gen_loss: 1.1259, disc_loss: 1.0043\n",
      "Time for epoch 659 is 20.7670 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 660, gen_loss: 1.0120, disc_loss: 1.1347\n",
      "Time for epoch 660 is 20.6016 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 661, gen_loss: 1.0914, disc_loss: 1.0322\n",
      "Time for epoch 661 is 20.4310 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 662, gen_loss: 1.0691, disc_loss: 0.9885\n",
      "Time for epoch 662 is 20.7910 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 663, gen_loss: 1.0941, disc_loss: 1.0128\n",
      "Time for epoch 663 is 20.9820 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 664, gen_loss: 0.9439, disc_loss: 1.2053\n",
      "Time for epoch 664 is 20.5734 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 665, gen_loss: 0.9540, disc_loss: 1.1371\n",
      "Time for epoch 665 is 20.8763 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 666, gen_loss: 1.0698, disc_loss: 1.1543\n",
      "Time for epoch 666 is 20.5539 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 667, gen_loss: 1.0051, disc_loss: 1.1483\n",
      "Time for epoch 667 is 20.5740 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 668, gen_loss: 0.9261, disc_loss: 1.2253\n",
      "Time for epoch 668 is 20.9696 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 669, gen_loss: 0.8161, disc_loss: 1.3815\n",
      "Time for epoch 669 is 20.6400 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 670, gen_loss: 0.8998, disc_loss: 1.2846\n",
      "Time for epoch 670 is 20.6338 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 671, gen_loss: 0.8255, disc_loss: 1.3444\n",
      "Time for epoch 671 is 20.6885 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 672, gen_loss: 0.8575, disc_loss: 1.3263\n",
      "Time for epoch 672 is 20.8065 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 673, gen_loss: 0.8381, disc_loss: 1.3071\n",
      "Time for epoch 673 is 20.4018 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 674, gen_loss: 0.9126, disc_loss: 1.2431\n",
      "Time for epoch 674 is 20.5272 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 675, gen_loss: 0.8665, disc_loss: 1.2788\n",
      "Time for epoch 675 is 20.9472 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 676, gen_loss: 1.0201, disc_loss: 1.1534\n",
      "Time for epoch 676 is 20.7744 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 677, gen_loss: 0.9114, disc_loss: 1.2517\n",
      "Time for epoch 677 is 20.7658 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 678, gen_loss: 0.9805, disc_loss: 1.1040\n",
      "Time for epoch 678 is 20.5619 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 679, gen_loss: 0.8866, disc_loss: 1.2253\n",
      "Time for epoch 679 is 20.6580 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 680, gen_loss: 0.9935, disc_loss: 1.1263\n",
      "Time for epoch 680 is 20.6544 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 681, gen_loss: 1.0270, disc_loss: 1.0088\n",
      "Time for epoch 681 is 20.4833 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 682, gen_loss: 1.2045, disc_loss: 0.9134\n",
      "Time for epoch 682 is 20.5966 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 683, gen_loss: 1.2795, disc_loss: 0.7910\n",
      "Time for epoch 683 is 20.9303 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 684, gen_loss: 1.1523, disc_loss: 0.9564\n",
      "Time for epoch 684 is 20.3667 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 685, gen_loss: 0.9946, disc_loss: 1.1676\n",
      "Time for epoch 685 is 20.6602 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 686, gen_loss: 1.0237, disc_loss: 1.1973\n",
      "Time for epoch 686 is 20.8352 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 687, gen_loss: 0.9271, disc_loss: 1.2017\n",
      "Time for epoch 687 is 20.4792 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 688, gen_loss: 0.9546, disc_loss: 1.2174\n",
      "Time for epoch 688 is 21.0545 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 689, gen_loss: 1.0348, disc_loss: 1.1150\n",
      "Time for epoch 689 is 20.4753 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 690, gen_loss: 0.8898, disc_loss: 1.2697\n",
      "Time for epoch 690 is 20.4791 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 691, gen_loss: 0.9376, disc_loss: 1.2279\n",
      "Time for epoch 691 is 20.6987 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 692, gen_loss: 0.9840, disc_loss: 1.1125\n",
      "Time for epoch 692 is 21.0627 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 693, gen_loss: 0.8895, disc_loss: 1.3290\n",
      "Time for epoch 693 is 20.4145 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 694, gen_loss: 0.9861, disc_loss: 1.1522\n",
      "Time for epoch 694 is 20.3903 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 695, gen_loss: 1.0666, disc_loss: 1.0475\n",
      "Time for epoch 695 is 21.0168 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 696, gen_loss: 0.9503, disc_loss: 1.1702\n",
      "Time for epoch 696 is 20.4160 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 697, gen_loss: 0.9800, disc_loss: 1.2851\n",
      "Time for epoch 697 is 20.4597 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 698, gen_loss: 0.9311, disc_loss: 1.2672\n",
      "Time for epoch 698 is 20.6835 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 699, gen_loss: 1.0727, disc_loss: 0.9466\n",
      "Time for epoch 699 is 20.6019 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 700, gen_loss: 1.1297, disc_loss: 1.0805\n",
      "Time for epoch 700 is 20.4568 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 701, gen_loss: 0.9451, disc_loss: 1.2428\n",
      "Time for epoch 701 is 20.6258 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 702, gen_loss: 1.0065, disc_loss: 1.1182\n",
      "Time for epoch 702 is 20.7849 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 703, gen_loss: 0.9742, disc_loss: 1.1220\n",
      "Time for epoch 703 is 20.5729 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 704, gen_loss: 0.9391, disc_loss: 1.2371\n",
      "Time for epoch 704 is 20.6232 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 705, gen_loss: 0.9276, disc_loss: 1.2095\n",
      "Time for epoch 705 is 20.5331 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 706, gen_loss: 0.9149, disc_loss: 1.2679\n",
      "Time for epoch 706 is 20.4668 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 707, gen_loss: 0.8312, disc_loss: 1.3776\n",
      "Time for epoch 707 is 20.3926 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 708, gen_loss: 1.0305, disc_loss: 1.1364\n",
      "Time for epoch 708 is 20.6208 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 709, gen_loss: 0.9726, disc_loss: 1.1404\n",
      "Time for epoch 709 is 20.5946 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 710, gen_loss: 0.9229, disc_loss: 1.2333\n",
      "Time for epoch 710 is 20.5851 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 711, gen_loss: 0.9725, disc_loss: 1.1017\n",
      "Time for epoch 711 is 20.6392 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 712, gen_loss: 0.9817, disc_loss: 1.2519\n",
      "Time for epoch 712 is 20.5055 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 713, gen_loss: 0.8797, disc_loss: 1.3406\n",
      "Time for epoch 713 is 20.6642 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 714, gen_loss: 0.8677, disc_loss: 1.3266\n",
      "Time for epoch 714 is 20.4961 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 715, gen_loss: 0.8535, disc_loss: 1.2375\n",
      "Time for epoch 715 is 20.6348 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 716, gen_loss: 0.9469, disc_loss: 1.2250\n",
      "Time for epoch 716 is 20.4109 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 717, gen_loss: 0.8659, disc_loss: 1.3885\n",
      "Time for epoch 717 is 20.4948 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 718, gen_loss: 0.8510, disc_loss: 1.3615\n",
      "Time for epoch 718 is 20.7681 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 719, gen_loss: 0.8644, disc_loss: 1.2296\n",
      "Time for epoch 719 is 20.5555 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 720, gen_loss: 0.7912, disc_loss: 1.3788\n",
      "Time for epoch 720 is 20.3779 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 721, gen_loss: 0.8471, disc_loss: 1.2507\n",
      "Time for epoch 721 is 20.4856 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 722, gen_loss: 0.8398, disc_loss: 1.3791\n",
      "Time for epoch 722 is 20.7681 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 723, gen_loss: 0.8548, disc_loss: 1.3042\n",
      "Time for epoch 723 is 20.5452 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 724, gen_loss: 0.8238, disc_loss: 1.3897\n",
      "Time for epoch 724 is 20.6976 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 725, gen_loss: 0.7782, disc_loss: 1.4501\n",
      "Time for epoch 725 is 20.5807 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 726, gen_loss: 0.8250, disc_loss: 1.3016\n",
      "Time for epoch 726 is 20.5418 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 727, gen_loss: 0.7716, disc_loss: 1.3193\n",
      "Time for epoch 727 is 20.6154 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 728, gen_loss: 0.8790, disc_loss: 1.3262\n",
      "Time for epoch 728 is 20.1593 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 729, gen_loss: 0.8546, disc_loss: 1.3220\n",
      "Time for epoch 729 is 20.5580 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 730, gen_loss: 0.7453, disc_loss: 1.5109\n",
      "Time for epoch 730 is 20.6905 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 731, gen_loss: 0.7881, disc_loss: 1.3960\n",
      "Time for epoch 731 is 20.7728 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 732, gen_loss: 0.8502, disc_loss: 1.2424\n",
      "Time for epoch 732 is 20.8034 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 733, gen_loss: 0.7930, disc_loss: 1.4556\n",
      "Time for epoch 733 is 20.6238 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 734, gen_loss: 0.9354, disc_loss: 1.2267\n",
      "Time for epoch 734 is 20.8892 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 735, gen_loss: 0.9045, disc_loss: 1.2932\n",
      "Time for epoch 735 is 20.3914 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 736, gen_loss: 0.8359, disc_loss: 1.3344\n",
      "Time for epoch 736 is 20.5201 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 737, gen_loss: 0.8946, disc_loss: 1.2368\n",
      "Time for epoch 737 is 20.3513 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 738, gen_loss: 0.8155, disc_loss: 1.3076\n",
      "Time for epoch 738 is 20.6291 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 739, gen_loss: 0.7499, disc_loss: 1.4403\n",
      "Time for epoch 739 is 20.8157 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 740, gen_loss: 0.8169, disc_loss: 1.2872\n",
      "Time for epoch 740 is 20.6146 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 741, gen_loss: 0.8438, disc_loss: 1.2850\n",
      "Time for epoch 741 is 20.5902 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 742, gen_loss: 0.8529, disc_loss: 1.3217\n",
      "Time for epoch 742 is 20.3878 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 743, gen_loss: 0.8234, disc_loss: 1.2484\n",
      "Time for epoch 743 is 20.9061 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 744, gen_loss: 0.8710, disc_loss: 1.2737\n",
      "Time for epoch 744 is 20.4179 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 745, gen_loss: 0.8033, disc_loss: 1.4156\n",
      "Time for epoch 745 is 20.5702 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 746, gen_loss: 0.9051, disc_loss: 1.1553\n",
      "Time for epoch 746 is 20.4930 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 747, gen_loss: 1.0428, disc_loss: 1.0450\n",
      "Time for epoch 747 is 20.6047 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 748, gen_loss: 0.9965, disc_loss: 1.1018\n",
      "Time for epoch 748 is 20.7490 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 749, gen_loss: 0.9490, disc_loss: 1.1602\n",
      "Time for epoch 749 is 20.5638 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 750, gen_loss: 1.0271, disc_loss: 1.0802\n",
      "Time for epoch 750 is 20.6259 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 751, gen_loss: 0.9191, disc_loss: 1.2456\n",
      "Time for epoch 751 is 20.6101 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 752, gen_loss: 0.9855, disc_loss: 1.0606\n",
      "Time for epoch 752 is 20.7011 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 753, gen_loss: 0.9322, disc_loss: 1.1054\n",
      "Time for epoch 753 is 20.9284 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 754, gen_loss: 1.0928, disc_loss: 1.0639\n",
      "Time for epoch 754 is 20.5798 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 755, gen_loss: 1.1224, disc_loss: 1.0126\n",
      "Time for epoch 755 is 20.6718 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 756, gen_loss: 0.9766, disc_loss: 1.1863\n",
      "Time for epoch 756 is 20.5668 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 757, gen_loss: 0.9473, disc_loss: 1.1540\n",
      "Time for epoch 757 is 20.6839 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 758, gen_loss: 0.9560, disc_loss: 1.1705\n",
      "Time for epoch 758 is 20.5421 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 759, gen_loss: 0.9259, disc_loss: 1.1137\n",
      "Time for epoch 759 is 20.7263 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 760, gen_loss: 1.0618, disc_loss: 1.0032\n",
      "Time for epoch 760 is 20.3630 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 761, gen_loss: 1.0942, disc_loss: 1.0000\n",
      "Time for epoch 761 is 20.5568 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 762, gen_loss: 1.1480, disc_loss: 0.9693\n",
      "Time for epoch 762 is 20.5608 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 763, gen_loss: 0.8759, disc_loss: 1.2213\n",
      "Time for epoch 763 is 20.5858 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 764, gen_loss: 0.9726, disc_loss: 1.1589\n",
      "Time for epoch 764 is 20.6041 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 765, gen_loss: 1.0310, disc_loss: 1.1343\n",
      "Time for epoch 765 is 20.4857 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 766, gen_loss: 0.9673, disc_loss: 1.2264\n",
      "Time for epoch 766 is 21.0472 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 767, gen_loss: 1.0124, disc_loss: 1.0384\n",
      "Time for epoch 767 is 20.6002 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 768, gen_loss: 0.9103, disc_loss: 1.2596\n",
      "Time for epoch 768 is 20.6499 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 769, gen_loss: 0.9616, disc_loss: 1.1680\n",
      "Time for epoch 769 is 20.5899 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 770, gen_loss: 0.9336, disc_loss: 1.1764\n",
      "Time for epoch 770 is 20.7788 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 771, gen_loss: 1.0630, disc_loss: 1.0919\n",
      "Time for epoch 771 is 20.6407 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 772, gen_loss: 1.0104, disc_loss: 1.1273\n",
      "Time for epoch 772 is 20.8033 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 773, gen_loss: 1.0406, disc_loss: 0.9914\n",
      "Time for epoch 773 is 20.8578 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 774, gen_loss: 0.9386, disc_loss: 1.2770\n",
      "Time for epoch 774 is 20.6432 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 775, gen_loss: 0.9985, disc_loss: 1.1247\n",
      "Time for epoch 775 is 20.7426 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 776, gen_loss: 1.0277, disc_loss: 1.1889\n",
      "Time for epoch 776 is 21.0421 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 777, gen_loss: 0.9177, disc_loss: 1.2125\n",
      "Time for epoch 777 is 20.5871 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 778, gen_loss: 1.0618, disc_loss: 1.0499\n",
      "Time for epoch 778 is 20.5432 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 779, gen_loss: 0.9313, disc_loss: 1.2701\n",
      "Time for epoch 779 is 20.5977 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 780, gen_loss: 0.9418, disc_loss: 1.1811\n",
      "Time for epoch 780 is 20.5226 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 781, gen_loss: 0.9184, disc_loss: 1.2560\n",
      "Time for epoch 781 is 20.6490 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 782, gen_loss: 1.0885, disc_loss: 0.9843\n",
      "Time for epoch 782 is 20.7500 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 783, gen_loss: 0.9928, disc_loss: 1.1604\n",
      "Time for epoch 783 is 20.8519 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 784, gen_loss: 0.8627, disc_loss: 1.3128\n",
      "Time for epoch 784 is 20.8072 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 785, gen_loss: 0.8808, disc_loss: 1.2921\n",
      "Time for epoch 785 is 20.8289 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 786, gen_loss: 1.0064, disc_loss: 1.0355\n",
      "Time for epoch 786 is 20.9381 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 787, gen_loss: 1.0386, disc_loss: 1.0744\n",
      "Time for epoch 787 is 20.3432 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 788, gen_loss: 1.0562, disc_loss: 1.0165\n",
      "Time for epoch 788 is 20.5511 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 789, gen_loss: 1.1598, disc_loss: 0.9540\n",
      "Time for epoch 789 is 20.5082 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 790, gen_loss: 0.8507, disc_loss: 1.3527\n",
      "Time for epoch 790 is 20.5027 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 791, gen_loss: 0.9399, disc_loss: 1.1300\n",
      "Time for epoch 791 is 20.6346 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 792, gen_loss: 0.9416, disc_loss: 1.1509\n",
      "Time for epoch 792 is 20.7383 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 793, gen_loss: 1.0093, disc_loss: 1.2270\n",
      "Time for epoch 793 is 20.6991 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 794, gen_loss: 0.9062, disc_loss: 1.2278\n",
      "Time for epoch 794 is 20.6902 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 795, gen_loss: 0.9302, disc_loss: 1.2145\n",
      "Time for epoch 795 is 20.6962 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 796, gen_loss: 1.0524, disc_loss: 1.0935\n",
      "Time for epoch 796 is 20.4124 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 797, gen_loss: 1.0311, disc_loss: 1.0835\n",
      "Time for epoch 797 is 20.5374 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 798, gen_loss: 1.0246, disc_loss: 1.1533\n",
      "Time for epoch 798 is 20.7789 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 799, gen_loss: 1.2133, disc_loss: 0.8663\n",
      "Time for epoch 799 is 20.6150 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 800, gen_loss: 1.1239, disc_loss: 0.9668\n",
      "Time for epoch 800 is 20.4922 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 801, gen_loss: 1.0346, disc_loss: 1.1697\n",
      "Time for epoch 801 is 21.1888 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 802, gen_loss: 1.1390, disc_loss: 0.9487\n",
      "Time for epoch 802 is 20.7658 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 803, gen_loss: 1.0312, disc_loss: 1.0962\n",
      "Time for epoch 803 is 20.6038 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 804, gen_loss: 1.0841, disc_loss: 0.9675\n",
      "Time for epoch 804 is 20.5263 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 805, gen_loss: 1.0751, disc_loss: 1.0743\n",
      "Time for epoch 805 is 20.3728 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 806, gen_loss: 0.9296, disc_loss: 1.2244\n",
      "Time for epoch 806 is 20.5248 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 807, gen_loss: 1.0912, disc_loss: 1.0610\n",
      "Time for epoch 807 is 20.8520 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 808, gen_loss: 1.1152, disc_loss: 0.9168\n",
      "Time for epoch 808 is 20.7035 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 809, gen_loss: 1.1408, disc_loss: 1.0066\n",
      "Time for epoch 809 is 20.5002 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 810, gen_loss: 0.9795, disc_loss: 1.2359\n",
      "Time for epoch 810 is 20.7659 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 811, gen_loss: 1.0196, disc_loss: 1.1385\n",
      "Time for epoch 811 is 20.5910 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 812, gen_loss: 0.8669, disc_loss: 1.3160\n",
      "Time for epoch 812 is 20.7085 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 813, gen_loss: 1.0621, disc_loss: 1.1041\n",
      "Time for epoch 813 is 20.6410 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 814, gen_loss: 1.0355, disc_loss: 1.1340\n",
      "Time for epoch 814 is 21.2180 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 815, gen_loss: 1.0911, disc_loss: 1.0258\n",
      "Time for epoch 815 is 20.7842 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 816, gen_loss: 1.0749, disc_loss: 1.0028\n",
      "Time for epoch 816 is 20.4441 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 817, gen_loss: 1.0871, disc_loss: 1.1041\n",
      "Time for epoch 817 is 20.5520 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 818, gen_loss: 0.9539, disc_loss: 1.2748\n",
      "Time for epoch 818 is 20.8083 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 819, gen_loss: 0.9150, disc_loss: 1.3200\n",
      "Time for epoch 819 is 20.4415 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 820, gen_loss: 0.8952, disc_loss: 1.2181\n",
      "Time for epoch 820 is 20.5998 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 821, gen_loss: 0.9556, disc_loss: 1.3694\n",
      "Time for epoch 821 is 20.4892 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 822, gen_loss: 0.9407, disc_loss: 1.2249\n",
      "Time for epoch 822 is 20.6224 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 823, gen_loss: 0.8124, disc_loss: 1.4099\n",
      "Time for epoch 823 is 20.7824 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 824, gen_loss: 0.9576, disc_loss: 1.2561\n",
      "Time for epoch 824 is 20.7344 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 825, gen_loss: 0.9216, disc_loss: 1.2130\n",
      "Time for epoch 825 is 20.7747 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 826, gen_loss: 0.8945, disc_loss: 1.2911\n",
      "Time for epoch 826 is 20.4317 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 827, gen_loss: 0.7808, disc_loss: 1.3836\n",
      "Time for epoch 827 is 20.6525 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 828, gen_loss: 1.0115, disc_loss: 1.1791\n",
      "Time for epoch 828 is 20.7689 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 829, gen_loss: 0.9470, disc_loss: 1.2273\n",
      "Time for epoch 829 is 20.6901 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 830, gen_loss: 0.7746, disc_loss: 1.4619\n",
      "Time for epoch 830 is 20.5961 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 831, gen_loss: 0.9847, disc_loss: 1.1547\n",
      "Time for epoch 831 is 20.7462 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 832, gen_loss: 0.9318, disc_loss: 1.2720\n",
      "Time for epoch 832 is 20.3962 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 833, gen_loss: 0.9506, disc_loss: 1.1649\n",
      "Time for epoch 833 is 20.5019 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 834, gen_loss: 0.8232, disc_loss: 1.4041\n",
      "Time for epoch 834 is 21.0132 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 835, gen_loss: 0.8489, disc_loss: 1.2700\n",
      "Time for epoch 835 is 20.6261 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 836, gen_loss: 0.8838, disc_loss: 1.2552\n",
      "Time for epoch 836 is 20.5480 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 837, gen_loss: 1.0263, disc_loss: 1.0591\n",
      "Time for epoch 837 is 20.4886 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 838, gen_loss: 1.0179, disc_loss: 1.1862\n",
      "Time for epoch 838 is 20.5854 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 839, gen_loss: 0.9742, disc_loss: 1.1705\n",
      "Time for epoch 839 is 20.3929 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 840, gen_loss: 0.9798, disc_loss: 1.1121\n",
      "Time for epoch 840 is 20.6091 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 841, gen_loss: 0.9182, disc_loss: 1.3510\n",
      "Time for epoch 841 is 20.6078 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 842, gen_loss: 1.0693, disc_loss: 0.9346\n",
      "Time for epoch 842 is 20.8516 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 843, gen_loss: 1.0208, disc_loss: 1.2315\n",
      "Time for epoch 843 is 20.5701 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 844, gen_loss: 0.9506, disc_loss: 1.1261\n",
      "Time for epoch 844 is 20.4188 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 845, gen_loss: 0.9821, disc_loss: 1.1564\n",
      "Time for epoch 845 is 20.6143 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 846, gen_loss: 1.0590, disc_loss: 1.1129\n",
      "Time for epoch 846 is 20.6124 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 847, gen_loss: 0.9882, disc_loss: 1.2160\n",
      "Time for epoch 847 is 20.7749 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 848, gen_loss: 0.8153, disc_loss: 1.4967\n",
      "Time for epoch 848 is 20.5532 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 849, gen_loss: 0.8109, disc_loss: 1.4029\n",
      "Time for epoch 849 is 20.7523 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 850, gen_loss: 0.8472, disc_loss: 1.2757\n",
      "Time for epoch 850 is 20.6437 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 851, gen_loss: 0.9805, disc_loss: 1.1356\n",
      "Time for epoch 851 is 20.3937 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 852, gen_loss: 0.9699, disc_loss: 1.0886\n",
      "Time for epoch 852 is 20.6262 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 853, gen_loss: 0.7843, disc_loss: 1.3895\n",
      "Time for epoch 853 is 20.5461 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 854, gen_loss: 0.7862, disc_loss: 1.4355\n",
      "Time for epoch 854 is 20.9309 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 855, gen_loss: 0.9496, disc_loss: 1.1956\n",
      "Time for epoch 855 is 20.7118 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 856, gen_loss: 0.8384, disc_loss: 1.3447\n",
      "Time for epoch 856 is 20.6753 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 857, gen_loss: 0.9119, disc_loss: 1.2117\n",
      "Time for epoch 857 is 20.6360 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 858, gen_loss: 0.9252, disc_loss: 1.1967\n",
      "Time for epoch 858 is 20.6481 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 859, gen_loss: 0.9416, disc_loss: 1.2342\n",
      "Time for epoch 859 is 20.7167 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 860, gen_loss: 0.9656, disc_loss: 1.2390\n",
      "Time for epoch 860 is 20.5126 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 861, gen_loss: 0.9451, disc_loss: 1.1719\n",
      "Time for epoch 861 is 20.6883 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 862, gen_loss: 0.8523, disc_loss: 1.3839\n",
      "Time for epoch 862 is 20.5801 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 863, gen_loss: 0.9372, disc_loss: 1.2365\n",
      "Time for epoch 863 is 20.7465 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 864, gen_loss: 0.8989, disc_loss: 1.3073\n",
      "Time for epoch 864 is 20.5157 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 865, gen_loss: 0.9204, disc_loss: 1.1727\n",
      "Time for epoch 865 is 20.8590 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 866, gen_loss: 0.8588, disc_loss: 1.4349\n",
      "Time for epoch 866 is 20.5685 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 867, gen_loss: 0.9282, disc_loss: 1.2554\n",
      "Time for epoch 867 is 20.5177 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 868, gen_loss: 0.7748, disc_loss: 1.4980\n",
      "Time for epoch 868 is 20.6689 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 869, gen_loss: 0.6991, disc_loss: 1.5136\n",
      "Time for epoch 869 is 20.7670 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 870, gen_loss: 0.9061, disc_loss: 1.1626\n",
      "Time for epoch 870 is 20.6647 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 871, gen_loss: 0.9853, disc_loss: 1.2186\n",
      "Time for epoch 871 is 20.5973 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 872, gen_loss: 1.0054, disc_loss: 1.1252\n",
      "Time for epoch 872 is 20.6505 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 873, gen_loss: 0.8864, disc_loss: 1.2313\n",
      "Time for epoch 873 is 21.0332 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 874, gen_loss: 0.9014, disc_loss: 1.2401\n",
      "Time for epoch 874 is 20.6729 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 875, gen_loss: 0.9199, disc_loss: 1.2576\n",
      "Time for epoch 875 is 20.5851 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 876, gen_loss: 0.8903, disc_loss: 1.2997\n",
      "Time for epoch 876 is 20.5219 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 877, gen_loss: 0.9131, disc_loss: 1.2515\n",
      "Time for epoch 877 is 20.4972 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 878, gen_loss: 0.9184, disc_loss: 1.1766\n",
      "Time for epoch 878 is 20.4735 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 879, gen_loss: 0.9001, disc_loss: 1.2663\n",
      "Time for epoch 879 is 20.8448 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 880, gen_loss: 0.9754, disc_loss: 1.1067\n",
      "Time for epoch 880 is 20.6019 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 881, gen_loss: 0.9751, disc_loss: 1.0783\n",
      "Time for epoch 881 is 20.6641 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 882, gen_loss: 1.0544, disc_loss: 1.0541\n",
      "Time for epoch 882 is 20.6132 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 883, gen_loss: 0.9487, disc_loss: 1.1758\n",
      "Time for epoch 883 is 20.4217 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 884, gen_loss: 0.9300, disc_loss: 1.1746\n",
      "Time for epoch 884 is 20.5711 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 885, gen_loss: 1.0652, disc_loss: 1.0162\n",
      "Time for epoch 885 is 20.5441 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 886, gen_loss: 0.9681, disc_loss: 1.1805\n",
      "Time for epoch 886 is 21.0109 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 887, gen_loss: 0.9532, disc_loss: 1.1467\n",
      "Time for epoch 887 is 20.8031 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 888, gen_loss: 0.9218, disc_loss: 1.1221\n",
      "Time for epoch 888 is 20.5118 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 889, gen_loss: 0.9428, disc_loss: 1.1375\n",
      "Time for epoch 889 is 20.6915 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 890, gen_loss: 0.9402, disc_loss: 1.2416\n",
      "Time for epoch 890 is 20.8361 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 891, gen_loss: 1.0079, disc_loss: 1.0860\n",
      "Time for epoch 891 is 20.7882 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 892, gen_loss: 0.9817, disc_loss: 1.1333\n",
      "Time for epoch 892 is 20.5235 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 893, gen_loss: 0.9799, disc_loss: 1.1835\n",
      "Time for epoch 893 is 20.6705 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 894, gen_loss: 0.9058, disc_loss: 1.3031\n",
      "Time for epoch 894 is 20.4136 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 895, gen_loss: 0.9912, disc_loss: 1.0868\n",
      "Time for epoch 895 is 20.6941 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 896, gen_loss: 1.0023, disc_loss: 1.0733\n",
      "Time for epoch 896 is 20.9144 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 897, gen_loss: 0.9404, disc_loss: 1.2812\n",
      "Time for epoch 897 is 21.6026 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 898, gen_loss: 0.9968, disc_loss: 1.2179\n",
      "Time for epoch 898 is 20.8448 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 899, gen_loss: 0.9737, disc_loss: 1.1215\n",
      "Time for epoch 899 is 22.0931 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 900, gen_loss: 0.9204, disc_loss: 1.3955\n",
      "Time for epoch 900 is 20.3719 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 901, gen_loss: 1.0151, disc_loss: 1.1061\n",
      "Time for epoch 901 is 20.6788 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 902, gen_loss: 0.9714, disc_loss: 1.2518\n",
      "Time for epoch 902 is 20.7412 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 903, gen_loss: 0.9424, disc_loss: 1.1093\n",
      "Time for epoch 903 is 20.2851 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 904, gen_loss: 0.9021, disc_loss: 1.1592\n",
      "Time for epoch 904 is 20.8899 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 905, gen_loss: 0.9962, disc_loss: 1.1936\n",
      "Time for epoch 905 is 20.5250 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 906, gen_loss: 1.0112, disc_loss: 1.1420\n",
      "Time for epoch 906 is 20.7624 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 907, gen_loss: 0.9649, disc_loss: 1.2112\n",
      "Time for epoch 907 is 20.6894 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 908, gen_loss: 0.9242, disc_loss: 1.2277\n",
      "Time for epoch 908 is 20.9412 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 909, gen_loss: 0.9405, disc_loss: 1.1326\n",
      "Time for epoch 909 is 20.5650 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 910, gen_loss: 0.8875, disc_loss: 1.2785\n",
      "Time for epoch 910 is 21.2262 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 911, gen_loss: 0.9713, disc_loss: 1.1333\n",
      "Time for epoch 911 is 21.2731 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 912, gen_loss: 0.9784, disc_loss: 1.1714\n",
      "Time for epoch 912 is 21.2892 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 913, gen_loss: 1.0661, disc_loss: 1.0390\n",
      "Time for epoch 913 is 20.8531 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 914, gen_loss: 1.0403, disc_loss: 1.0842\n",
      "Time for epoch 914 is 20.7051 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 915, gen_loss: 0.9942, disc_loss: 1.1377\n",
      "Time for epoch 915 is 21.6431 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 916, gen_loss: 1.1128, disc_loss: 0.9386\n",
      "Time for epoch 916 is 21.0631 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 917, gen_loss: 1.0048, disc_loss: 1.2803\n",
      "Time for epoch 917 is 21.5485 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 918, gen_loss: 0.9782, disc_loss: 1.1743\n",
      "Time for epoch 918 is 21.0461 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 919, gen_loss: 0.9183, disc_loss: 1.2162\n",
      "Time for epoch 919 is 20.8967 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 920, gen_loss: 0.9493, disc_loss: 1.2313\n",
      "Time for epoch 920 is 21.0847 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 921, gen_loss: 0.9516, disc_loss: 1.1707\n",
      "Time for epoch 921 is 21.6191 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 922, gen_loss: 1.0175, disc_loss: 1.1009\n",
      "Time for epoch 922 is 21.2031 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 923, gen_loss: 0.9830, disc_loss: 1.0785\n",
      "Time for epoch 923 is 21.2757 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 924, gen_loss: 1.0873, disc_loss: 1.0070\n",
      "Time for epoch 924 is 21.5980 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 925, gen_loss: 0.8774, disc_loss: 1.2971\n",
      "Time for epoch 925 is 20.9738 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 926, gen_loss: 1.0260, disc_loss: 1.1052\n",
      "Time for epoch 926 is 21.9399 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 927, gen_loss: 0.9217, disc_loss: 1.2932\n",
      "Time for epoch 927 is 21.0538 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 928, gen_loss: 0.9918, disc_loss: 1.1062\n",
      "Time for epoch 928 is 20.7435 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 929, gen_loss: 1.0991, disc_loss: 1.0290\n",
      "Time for epoch 929 is 21.2558 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 930, gen_loss: 1.0795, disc_loss: 1.0404\n",
      "Time for epoch 930 is 21.2711 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 931, gen_loss: 1.0248, disc_loss: 1.0947\n",
      "Time for epoch 931 is 21.7629 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 932, gen_loss: 0.9597, disc_loss: 1.2122\n",
      "Time for epoch 932 is 21.5232 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 933, gen_loss: 0.9590, disc_loss: 1.1885\n",
      "Time for epoch 933 is 21.5436 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 934, gen_loss: 0.9771, disc_loss: 1.1869\n",
      "Time for epoch 934 is 21.6030 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 935, gen_loss: 1.0403, disc_loss: 1.2232\n",
      "Time for epoch 935 is 21.8554 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 936, gen_loss: 0.9935, disc_loss: 1.0842\n",
      "Time for epoch 936 is 21.2883 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 937, gen_loss: 0.8817, disc_loss: 1.2900\n",
      "Time for epoch 937 is 22.2048 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 938, gen_loss: 0.9990, disc_loss: 1.1343\n",
      "Time for epoch 938 is 21.0982 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 939, gen_loss: 1.1027, disc_loss: 1.0351\n",
      "Time for epoch 939 is 21.3414 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 940, gen_loss: 1.0403, disc_loss: 1.0268\n",
      "Time for epoch 940 is 21.2470 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 941, gen_loss: 0.9865, disc_loss: 1.1598\n",
      "Time for epoch 941 is 21.1939 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 942, gen_loss: 0.9922, disc_loss: 1.0972\n",
      "Time for epoch 942 is 22.0409 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 943, gen_loss: 1.0591, disc_loss: 1.1121\n",
      "Time for epoch 943 is 21.4143 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 944, gen_loss: 1.0525, disc_loss: 1.0850\n",
      "Time for epoch 944 is 21.1784 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 945, gen_loss: 1.1908, disc_loss: 0.8711\n",
      "Time for epoch 945 is 21.7837 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 946, gen_loss: 1.1906, disc_loss: 0.9203\n",
      "Time for epoch 946 is 21.5591 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 947, gen_loss: 1.1369, disc_loss: 0.9268\n",
      "Time for epoch 947 is 21.3910 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 948, gen_loss: 1.1340, disc_loss: 1.0293\n",
      "Time for epoch 948 is 21.3328 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 949, gen_loss: 1.0702, disc_loss: 1.0005\n",
      "Time for epoch 949 is 21.5420 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 950, gen_loss: 1.1307, disc_loss: 0.9888\n",
      "Time for epoch 950 is 21.1554 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 951, gen_loss: 0.9435, disc_loss: 1.3573\n",
      "Time for epoch 951 is 21.0443 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 952, gen_loss: 1.0823, disc_loss: 1.1834\n",
      "Time for epoch 952 is 20.8548 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 953, gen_loss: 1.0432, disc_loss: 1.1345\n",
      "Time for epoch 953 is 20.8229 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 954, gen_loss: 0.9721, disc_loss: 1.0903\n",
      "Time for epoch 954 is 20.8692 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 955, gen_loss: 1.0108, disc_loss: 1.1348\n",
      "Time for epoch 955 is 21.2887 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 956, gen_loss: 1.0395, disc_loss: 1.0974\n",
      "Time for epoch 956 is 22.3889 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 957, gen_loss: 0.9959, disc_loss: 1.1717\n",
      "Time for epoch 957 is 21.0548 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 958, gen_loss: 1.0967, disc_loss: 1.0539\n",
      "Time for epoch 958 is 22.1771 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 959, gen_loss: 1.1280, disc_loss: 1.0205\n",
      "Time for epoch 959 is 21.2342 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 960, gen_loss: 0.8470, disc_loss: 1.4028\n",
      "Time for epoch 960 is 20.5244 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 961, gen_loss: 0.8754, disc_loss: 1.3717\n",
      "Time for epoch 961 is 20.8728 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 962, gen_loss: 1.0494, disc_loss: 1.1092\n",
      "Time for epoch 962 is 20.5999 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 963, gen_loss: 1.0603, disc_loss: 1.2146\n",
      "Time for epoch 963 is 20.8818 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 964, gen_loss: 1.0644, disc_loss: 1.0696\n",
      "Time for epoch 964 is 20.7503 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 965, gen_loss: 1.1212, disc_loss: 1.0544\n",
      "Time for epoch 965 is 20.5200 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 966, gen_loss: 1.0153, disc_loss: 1.1808\n",
      "Time for epoch 966 is 20.6300 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 967, gen_loss: 1.0333, disc_loss: 1.0400\n",
      "Time for epoch 967 is 20.5534 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 968, gen_loss: 1.1033, disc_loss: 1.0020\n",
      "Time for epoch 968 is 21.5561 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 969, gen_loss: 1.0562, disc_loss: 1.0929\n",
      "Time for epoch 969 is 20.8739 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 970, gen_loss: 0.9977, disc_loss: 1.1718\n",
      "Time for epoch 970 is 20.6108 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 971, gen_loss: 1.0588, disc_loss: 1.1435\n",
      "Time for epoch 971 is 20.8192 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 972, gen_loss: 0.9942, disc_loss: 1.2468\n",
      "Time for epoch 972 is 20.8340 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 973, gen_loss: 0.9771, disc_loss: 1.1703\n",
      "Time for epoch 973 is 20.6587 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 974, gen_loss: 0.9529, disc_loss: 1.2130\n",
      "Time for epoch 974 is 20.7610 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 975, gen_loss: 1.1002, disc_loss: 1.0279\n",
      "Time for epoch 975 is 20.9420 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 976, gen_loss: 1.1785, disc_loss: 0.9068\n",
      "Time for epoch 976 is 20.6569 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 977, gen_loss: 1.1015, disc_loss: 1.0540\n",
      "Time for epoch 977 is 20.7559 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 978, gen_loss: 1.2981, disc_loss: 0.9862\n",
      "Time for epoch 978 is 20.4558 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 979, gen_loss: 1.1123, disc_loss: 1.0618\n",
      "Time for epoch 979 is 20.8580 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 980, gen_loss: 0.9880, disc_loss: 1.3035\n",
      "Time for epoch 980 is 20.8043 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 981, gen_loss: 1.1162, disc_loss: 1.0788\n",
      "Time for epoch 981 is 20.5611 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 982, gen_loss: 1.1233, disc_loss: 0.9345\n",
      "Time for epoch 982 is 21.3032 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 983, gen_loss: 1.3131, disc_loss: 0.8209\n",
      "Time for epoch 983 is 20.4614 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 984, gen_loss: 1.1656, disc_loss: 0.9858\n",
      "Time for epoch 984 is 20.9914 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 985, gen_loss: 1.1502, disc_loss: 0.9736\n",
      "Time for epoch 985 is 20.7595 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 986, gen_loss: 1.1087, disc_loss: 1.0628\n",
      "Time for epoch 986 is 20.6070 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 987, gen_loss: 1.1602, disc_loss: 0.9668\n",
      "Time for epoch 987 is 20.6168 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 988, gen_loss: 1.2757, disc_loss: 0.8422\n",
      "Time for epoch 988 is 20.9242 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 989, gen_loss: 1.1673, disc_loss: 0.8862\n",
      "Time for epoch 989 is 20.6783 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 990, gen_loss: 1.0897, disc_loss: 1.0729\n",
      "Time for epoch 990 is 20.9903 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 991, gen_loss: 1.0722, disc_loss: 1.1397\n",
      "Time for epoch 991 is 20.7867 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 992, gen_loss: 1.1105, disc_loss: 1.0398\n",
      "Time for epoch 992 is 20.6528 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 993, gen_loss: 1.0601, disc_loss: 1.1214\n",
      "Time for epoch 993 is 20.6942 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 994, gen_loss: 1.3196, disc_loss: 0.8433\n",
      "Time for epoch 994 is 20.8030 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 995, gen_loss: 1.2580, disc_loss: 0.9507\n",
      "Time for epoch 995 is 20.7896 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 996, gen_loss: 1.2219, disc_loss: 0.9972\n",
      "Time for epoch 996 is 20.7711 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 997, gen_loss: 1.3542, disc_loss: 0.8576\n",
      "Time for epoch 997 is 20.5969 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 998, gen_loss: 1.2062, disc_loss: 0.9030\n",
      "Time for epoch 998 is 20.5662 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 999, gen_loss: 1.2180, disc_loss: 0.9717\n",
      "Time for epoch 999 is 20.6490 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 1000, gen_loss: 1.1885, disc_loss: 0.9764\n",
      "Time for epoch 1000 is 20.5144 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "train(dataset, hparas['N_EPOCH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "a634d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_caption2string(ls):\n",
    "    return \" \".join([id2word_dict[idx] for idx in ls]).strip().split(' <PAD>')[0]\n",
    "\n",
    "def testing_data_generator(caption, index, caption_type='id'):\n",
    "    if caption_type == 'id':\n",
    "        caption = tf.cast(caption, tf.float32)\n",
    "    return caption, index\n",
    "\n",
    "def testing_dataset_generator(batch_size, data_generator, caption_type='id'):\n",
    "    data = pd.read_pickle('./dataset/testData.pkl')\n",
    "    \n",
    "    if caption_type == 'sentence':\n",
    "        data['Captions_string'] = data['Captions'].apply(test_caption2string)\n",
    "        captions = data['Captions_string'].values\n",
    "    elif caption_type == 'id':\n",
    "        captions = data['Captions'].values\n",
    "        \n",
    "    caption = []\n",
    "    for i in range(len(captions)):\n",
    "        caption.append(captions[i])\n",
    "    caption = np.asarray(caption)\n",
    "    \n",
    "    if caption_type == 'id':\n",
    "        caption = caption.astype(np.int)\n",
    "        \n",
    "    datagen_func = lambda cap, img: data_generator(cap, img, caption_type=caption_type)\n",
    "        \n",
    "    index = data['ID'].values\n",
    "    index = np.asarray(index)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((caption, index))\n",
    "    dataset = dataset.map(datagen_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat().batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c7abd09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = testing_dataset_generator(hparas['BATCH_SIZE'], testing_data_generator, caption_type=expSettings.caption_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "88cc621c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (64,)\n",
      "Caption shape: (64,)\n"
     ]
    }
   ],
   "source": [
    "# test the testing dataset\n",
    "for cap, img in testing_dataset.take(1):\n",
    "    print(\"Image shape:\", img.numpy().shape)\n",
    "    print(\"Caption shape:\", cap.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "8d07f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('./dataset/testData.pkl')\n",
    "captions = data['Captions'].values\n",
    "\n",
    "NUM_TEST = len(captions)\n",
    "EPOCH_TEST = int(NUM_TEST / hparas['BATCH_SIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "8f624f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./inference/demo'):\n",
    "    os.makedirs('./inference/demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "6d3d0086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(dataset):\n",
    "    hidden = text_encoder.initialize_hidden_state()\n",
    "    sample_size = hparas['BATCH_SIZE']\n",
    "    sample_seed = np.random.normal(loc=0.0, scale=0.1, size=(sample_size, hparas['Z_DIM'])).astype(np.float32)\n",
    "    print(sample_seed[0:3, :])\n",
    "    \n",
    "    step = 0\n",
    "    start = time.time()\n",
    "    for captions, idx in dataset:\n",
    "        if step > EPOCH_TEST:\n",
    "            break\n",
    "        \n",
    "        fake_image = test_step(captions, sample_seed, hidden)\n",
    "        step += 1\n",
    "        for i in range(hparas['BATCH_SIZE']):\n",
    "            plt.imsave('./inference/demo/inference_{:04d}.jpg'.format(idx[i]), fake_image[i].numpy()*0.5 + 0.5)\n",
    "            \n",
    "            if i == 0 and step == 1: \n",
    "                #print(captions)\n",
    "                text_embed_t, hidden_t = text_encoder(captions, hidden)\n",
    "                #print(text_embed_t)\n",
    "                print(fake_image[0:1, 0:5, 0:5, :])\n",
    "                img_logits, _, debug = generator(text_embed_t, sample_seed, debug_output=True)\n",
    "                print(debug[0][0:3, 0:5, 0:5, 0:5])\n",
    "                print(debug[1][0:3, 0:5, 0:5, 0:5])\n",
    "                print(debug[2][0:3, 0:5, 0:5, 0:5])\n",
    "                print(debug[3][0:3, 0:5, 0:5, 0:5])\n",
    "                print(debug[4][0:3, 0:5, 0:5, 0:5])\n",
    "                print(img_logits[0:3, 0:5, 0:5, :])\n",
    "                pred_logit, pred = discriminator(fake_image, text_embed_t)\n",
    "                print(pred_logit)\n",
    "                \n",
    "            \n",
    "    print('Time for inference is {:.4f} sec'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "d12a53a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring from ./checkpoints/demo\\ckpt-891\n"
     ]
    }
   ],
   "source": [
    "#checkpoint.restore(checkpoint_dir + f'/ckpt-50')\n",
    "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "if latest_checkpoint:\n",
    "    print(f\"Restoring from {latest_checkpoint}\")\n",
    "    checkpoint.restore(latest_checkpoint)\n",
    "else:\n",
    "    print(\"No checkpoint found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "ff59c63a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.76590890e-01 -3.62670831e-02 -5.88861965e-02 ... -1.77671053e-02\n",
      "   1.72591850e-01  3.02505605e-02]\n",
      " [-8.34661871e-02  3.57552022e-02  1.00501038e-05 ...  1.96811911e-02\n",
      "  -4.91746794e-03  1.02292605e-01]\n",
      " [-3.03284191e-02  1.11609578e-01  4.10925858e-02 ...  2.25200132e-02\n",
      "  -1.43049583e-01  1.30498037e-01]]\n",
      "tf.Tensor(\n",
      "[[[[ 0.09060197  0.12390514  0.10596064]\n",
      "   [ 0.13115035  0.13739027  0.09484114]\n",
      "   [ 0.0974274   0.07918742  0.06754562]\n",
      "   [ 0.08504594  0.07736155  0.05447872]\n",
      "   [ 0.06964721  0.04440857  0.02915025]]\n",
      "\n",
      "  [[ 0.11267444  0.09133928  0.10059573]\n",
      "   [-0.02394733 -0.07115721 -0.01652582]\n",
      "   [ 0.07183935  0.05187262  0.04409298]\n",
      "   [-0.03050993 -0.08891862 -0.02702138]\n",
      "   [ 0.05989148  0.03450191  0.03503729]]\n",
      "\n",
      "  [[ 0.0426882   0.03691719  0.044337  ]\n",
      "   [ 0.04776705  0.03963728  0.03349791]\n",
      "   [ 0.05904258  0.04055943  0.0366561 ]\n",
      "   [ 0.05226436  0.04220465  0.03731665]\n",
      "   [ 0.06617492  0.0443062   0.03730223]]\n",
      "\n",
      "  [[ 0.02373693  0.02568267  0.04221135]\n",
      "   [-0.05458223 -0.10312161 -0.04173863]\n",
      "   [ 0.04859852  0.03755365  0.03305192]\n",
      "   [-0.04201621 -0.09473007 -0.03122816]\n",
      "   [ 0.05856048  0.04717772  0.03432706]]\n",
      "\n",
      "  [[ 0.02082802  0.02038283  0.01298802]\n",
      "   [ 0.04542137  0.03784675  0.03447767]\n",
      "   [ 0.04882445  0.03383958  0.0314362 ]\n",
      "   [ 0.07164157  0.06371258  0.05582441]\n",
      "   [ 0.05330189  0.04584454  0.0314354 ]]]], shape=(1, 5, 5, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[ 2.42248178e-03  6.30425930e-01  1.01313424e+00 -5.30546680e-02\n",
      "    -4.94709909e-02]\n",
      "   [ 2.19684768e+00  5.89785933e-01  1.04730439e+00 -1.05832163e-02\n",
      "    -3.28626111e-02]]\n",
      "\n",
      "  [[ 1.03666186e-01  1.27851677e+00  1.25366616e+00 -2.28557922e-02\n",
      "    -5.30159138e-02]\n",
      "   [ 8.38811278e-01  2.39869833e-01  1.51217294e+00 -4.37069498e-02\n",
      "    -4.29289937e-02]]]\n",
      "\n",
      "\n",
      " [[[ 1.01868474e+00  5.91330051e-01  1.57852304e+00 -1.38224244e-01\n",
      "     6.74523711e-01]\n",
      "   [ 1.28176951e+00 -3.13814543e-02  1.35244942e+00 -2.86785960e-02\n",
      "    -1.05127744e-01]]\n",
      "\n",
      "  [[ 8.71270418e-01  7.07306683e-01  3.13598216e-01 -6.84283078e-02\n",
      "    -1.27042279e-01]\n",
      "   [-1.36069179e-01  3.27839613e-01  5.30083001e-01 -2.15833075e-02\n",
      "    -1.16857044e-01]]]\n",
      "\n",
      "\n",
      " [[[ 5.45427918e-01 -9.85777900e-02 -6.98522478e-02  2.86227655e+00\n",
      "    -3.17746773e-02]\n",
      "   [-9.81727690e-02  2.45766544e+00 -1.35702237e-01 -7.17836544e-02\n",
      "    -2.25205417e-03]]\n",
      "\n",
      "  [[-1.47856055e-02 -8.88148770e-02 -1.06117241e-01  3.07441306e+00\n",
      "    -4.03709002e-02]\n",
      "   [-1.38556033e-01 -5.45278080e-02 -7.21019134e-02  3.05948925e+00\n",
      "    -3.24010700e-02]]]], shape=(3, 2, 2, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[ 4.58999991e-01  5.25148094e-01 -2.10777614e-02  2.41487071e-01\n",
      "    -1.81274749e-02]\n",
      "   [-8.06796253e-02 -5.39815426e-02 -7.50457272e-02  1.12151504e+00\n",
      "     6.92999363e-01]\n",
      "   [ 1.12327468e+00 -6.46754429e-02 -6.37969151e-02 -2.45605432e-03\n",
      "    -4.06873189e-02]\n",
      "   [-3.39132249e-02 -2.95267603e-03 -6.75366148e-02 -2.92746462e-02\n",
      "    -2.27393545e-02]]\n",
      "\n",
      "  [[ 1.63734574e-02  5.77567339e-01  1.88438166e-02 -1.36620685e-01\n",
      "    -1.10632770e-01]\n",
      "   [ 2.16926670e+00 -2.63185591e-01 -2.10493669e-01 -1.01191081e-01\n",
      "    -5.98326139e-02]\n",
      "   [-6.27257302e-02  9.61122990e-01  1.84352016e+00 -3.28752041e-01\n",
      "    -1.81251198e-01]\n",
      "   [-5.72124496e-02 -2.24829302e-03 -5.01010977e-02  1.63461760e-01\n",
      "    -3.73136848e-02]]\n",
      "\n",
      "  [[-9.68382731e-02 -5.79957440e-02 -7.29938969e-02  1.94686338e-01\n",
      "    -4.72826734e-02]\n",
      "   [-1.49279937e-01 -2.07548998e-02 -1.36495054e-01 -2.80497856e-02\n",
      "     4.67892438e-01]\n",
      "   [-1.15702383e-01 -1.40279457e-01 -1.26940250e-01  1.19989920e+00\n",
      "     4.20840472e-01]\n",
      "   [-7.06483498e-02 -5.62697127e-02 -8.19608346e-02 -1.16875414e-02\n",
      "    -5.73902503e-02]]\n",
      "\n",
      "  [[-3.88726555e-02  1.03941274e+00  1.02154016e-01 -9.92826149e-02\n",
      "     5.73460162e-01]\n",
      "   [-4.41987924e-02 -1.67507336e-01 -3.17247622e-02  4.61503156e-02\n",
      "    -8.60638469e-02]\n",
      "   [-8.86169896e-02  5.38810790e-01  1.81591347e-01 -1.61367357e-01\n",
      "    -1.00534461e-01]\n",
      "   [-2.88318843e-02 -1.75665673e-02 -2.74531636e-02 -2.16623824e-02\n",
      "    -3.94315533e-02]]]\n",
      "\n",
      "\n",
      " [[[ 3.07795137e-01  6.06196702e-01 -2.98672896e-02  2.39493221e-01\n",
      "    -1.54949231e-02]\n",
      "   [-5.52571975e-02 -1.80215556e-02 -6.93548098e-02  1.13905370e+00\n",
      "     5.50453484e-01]\n",
      "   [ 1.09895349e+00 -6.76975176e-02 -3.59384082e-02 -1.90388616e-02\n",
      "    -4.02325988e-02]\n",
      "   [-3.93877998e-02  6.96130842e-03 -6.18493259e-02 -3.52560580e-02\n",
      "    -2.13214159e-02]]\n",
      "\n",
      "  [[-1.77529715e-02  3.20921928e-01 -5.23897521e-02 -1.06142297e-01\n",
      "    -7.83591419e-02]\n",
      "   [ 1.52908397e+00 -2.07082257e-01 -2.09134564e-01 -9.22669694e-02\n",
      "    -1.08614871e-02]\n",
      "   [-7.30621591e-02  1.38369906e+00  1.73589826e+00 -3.16187292e-01\n",
      "    -1.40517399e-01]\n",
      "   [-5.29161058e-02  2.19350249e-01 -4.80664372e-02  1.16809033e-01\n",
      "    -6.31730864e-03]]\n",
      "\n",
      "  [[-5.76767139e-02 -3.58066969e-02 -8.25175643e-02  1.60140812e-01\n",
      "    -2.05354542e-02]\n",
      "   [-9.42144692e-02  1.72098145e-01 -1.45216569e-01 -2.51582805e-02\n",
      "     2.55095392e-01]\n",
      "   [-7.98370019e-02 -1.05495177e-01 -1.68456778e-01  9.78413343e-01\n",
      "     1.01580977e+00]\n",
      "   [-6.43219277e-02 -4.92398851e-02 -8.51914287e-02 -9.02813114e-03\n",
      "    -6.33602664e-02]]\n",
      "\n",
      "  [[-2.18291860e-02  9.42089558e-01 -4.19498188e-03 -8.40286836e-02\n",
      "     5.67991614e-01]\n",
      "   [-2.44543906e-02 -1.31240740e-01 -2.46389862e-02 -2.02385220e-03\n",
      "    -6.66792318e-02]\n",
      "   [-5.80880940e-02  5.90260148e-01 -2.16646418e-02 -1.47520676e-01\n",
      "    -7.39269853e-02]\n",
      "   [-2.74353717e-02 -8.86401627e-03 -2.56889667e-02 -2.35460792e-02\n",
      "    -1.92678943e-02]]]\n",
      "\n",
      "\n",
      " [[[ 5.33965409e-01 -8.01605210e-02 -2.45660227e-02 -3.75896394e-02\n",
      "     1.29344106e+00]\n",
      "   [-7.67300278e-02 -6.92268163e-02 -7.16105476e-02 -8.26484784e-02\n",
      "    -1.08666765e-02]\n",
      "   [ 7.96609998e-01 -5.78164123e-02 -7.67352730e-02 -1.14129363e-02\n",
      "     1.44823277e+00]\n",
      "   [ 1.76148009e+00 -4.77708094e-02 -4.84972037e-02 -5.07852547e-02\n",
      "    -2.25835964e-02]]\n",
      "\n",
      "  [[-6.95684552e-02  4.02828336e-01  1.08249009e+00 -9.94124487e-02\n",
      "    -8.72355402e-02]\n",
      "   [ 8.80460292e-02 -2.14828640e-01 -3.85458730e-02 -3.45587023e-02\n",
      "    -1.58279151e-01]\n",
      "   [-1.70579001e-01  5.63162148e-01 -1.11292399e-01 -1.39506608e-01\n",
      "    -2.09979758e-01]\n",
      "   [-2.84995716e-02 -5.77251799e-02 -6.47840127e-02 -5.80622442e-02\n",
      "     1.14448857e+00]]\n",
      "\n",
      "  [[-8.54991227e-02 -7.10270479e-02 -7.88543820e-02 -1.44556528e-02\n",
      "    -3.95750031e-02]\n",
      "   [-2.49791145e-01  6.62486494e-01 -1.10848442e-01 -2.60793809e-02\n",
      "    -8.73024389e-02]\n",
      "   [-9.63359997e-02 -2.95590103e-01 -1.24645665e-01  3.65477562e-01\n",
      "     8.15430403e-01]\n",
      "   [-5.41545115e-02 -3.99678685e-02 -8.84319246e-02 -7.89603218e-02\n",
      "     2.32534242e+00]]\n",
      "\n",
      "  [[-3.97179313e-02  3.75438035e-01 -1.80506352e-02 -7.49848112e-02\n",
      "    -6.34865761e-02]\n",
      "   [ 2.20117077e-01 -1.25779077e-01 -6.50743246e-02 -4.05313522e-02\n",
      "     2.17090964e-01]\n",
      "   [-9.66049954e-02  4.54345345e-01  2.03730538e-01 -1.16522729e-01\n",
      "    -9.08617973e-02]\n",
      "   [-7.08813891e-02 -2.06408482e-02 -6.11991547e-02 -7.68678784e-02\n",
      "     3.57320428e-01]]]], shape=(3, 4, 4, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[-5.66534512e-02  2.47055292e-02  2.87113667e-01  4.43634957e-01\n",
      "     1.63468480e-01]\n",
      "   [ 4.71007735e-01 -2.85152551e-02 -1.04791569e-02 -2.48928685e-02\n",
      "    -8.28030631e-02]\n",
      "   [-1.20368794e-01 -3.46139516e-03  1.69833922e+00  2.69344985e-01\n",
      "     2.35433117e-01]\n",
      "   [-3.70238051e-02 -9.54580829e-02 -5.22925332e-02 -4.59189042e-02\n",
      "    -7.29910731e-02]\n",
      "   [-6.39015585e-02 -3.44144367e-02  6.48008958e-02 -1.05867302e-02\n",
      "    -5.39439321e-02]]\n",
      "\n",
      "  [[-6.54895231e-02 -1.60632320e-02  3.32344562e-01  7.71515250e-01\n",
      "    -9.04821008e-02]\n",
      "   [-3.76672926e-03  7.16270983e-01 -1.06737053e-03  7.69131601e-01\n",
      "    -1.93577465e-02]\n",
      "   [ 1.27306187e+00 -5.43336943e-02 -3.45031172e-02  1.73175633e-01\n",
      "     4.54806238e-01]\n",
      "   [-5.48355170e-02 -4.72542085e-02  1.68641448e-01 -1.38627112e-01\n",
      "    -1.20784335e-01]\n",
      "   [-2.82386005e-01 -1.34617791e-01 -1.44034460e-01  9.93998289e-01\n",
      "    -1.56618699e-01]]\n",
      "\n",
      "  [[ 3.55083346e-02  7.70919025e-01  1.18851793e+00  9.42716658e-01\n",
      "    -1.99447130e-03]\n",
      "   [-2.72012651e-02 -9.56813619e-02 -4.64283042e-02 -1.52982399e-01\n",
      "    -5.48323058e-02]\n",
      "   [ 1.07106066e+00 -8.54759067e-02  5.99199057e-01 -5.04550040e-02\n",
      "     3.32994312e-01]\n",
      "   [-2.86297835e-02 -1.97968826e-01  1.33243036e+00 -9.94681846e-03\n",
      "     1.65966392e+00]\n",
      "   [-5.12002371e-02  5.22760987e-01 -6.11737035e-02 -8.58275627e-04\n",
      "    -1.32787421e-01]]\n",
      "\n",
      "  [[-6.42652139e-02 -6.18545488e-02 -7.09310621e-02 -7.49354586e-02\n",
      "    -7.37865120e-02]\n",
      "   [-1.13085888e-01  1.19880521e+00  6.71380281e-01 -8.53207037e-02\n",
      "    -4.62695546e-02]\n",
      "   [-1.14285365e-01 -1.01041608e-01 -1.28192708e-01 -8.13442841e-02\n",
      "     1.74300480e+00]\n",
      "   [-1.15568355e-01 -1.09596550e-01 -6.92080110e-02 -6.00471459e-02\n",
      "    -1.49484456e-01]\n",
      "   [-2.81163901e-01 -2.83656847e-02 -1.98850989e-01 -1.93142280e-01\n",
      "    -3.09459388e-01]]\n",
      "\n",
      "  [[-5.62135875e-02  1.16186321e+00  1.30499050e-01  8.38371456e-01\n",
      "     8.29197943e-01]\n",
      "   [ 1.53290999e+00  3.78734507e-02 -1.18886404e-01 -7.87485689e-02\n",
      "    -3.15354653e-02]\n",
      "   [-1.31653056e-01 -8.33678469e-02 -1.14740811e-01 -9.51658189e-03\n",
      "    -1.12043861e-02]\n",
      "   [ 1.13692403e+00 -3.03658575e-01 -1.70404524e-01 -2.05718994e-01\n",
      "    -1.65492836e-02]\n",
      "   [-2.27981001e-01 -4.38717939e-02 -1.64808273e-01  5.78705192e-01\n",
      "     7.45115802e-02]]]\n",
      "\n",
      "\n",
      " [[[-5.50881140e-02 -2.36429065e-03  3.40357393e-01  3.35953206e-01\n",
      "     1.85280770e-01]\n",
      "   [ 3.27099115e-01 -1.67777706e-02 -5.81463845e-03 -2.62192320e-02\n",
      "    -7.58840367e-02]\n",
      "   [-1.13206699e-01 -5.84412133e-03  1.82223654e+00  1.57111064e-01\n",
      "     2.83219635e-01]\n",
      "   [-4.27879952e-02 -7.58984089e-02 -3.60360555e-02 -4.41753455e-02\n",
      "    -5.65626323e-02]\n",
      "   [-5.51404841e-02 -3.94311883e-02  1.90336391e-01 -1.59021653e-02\n",
      "    -4.38020453e-02]]\n",
      "\n",
      "  [[-5.72633147e-02 -1.96622126e-02  5.25581777e-01  7.36084342e-01\n",
      "    -7.67507777e-02]\n",
      "   [-9.16716363e-03  6.16590202e-01 -2.22456325e-02  6.36333406e-01\n",
      "     2.01984957e-01]\n",
      "   [ 1.61372209e+00 -3.12544592e-02  5.47409095e-02  9.22641456e-02\n",
      "     6.37879252e-01]\n",
      "   [-1.83092114e-02 -1.50527554e-02  3.74637634e-01 -1.26609072e-01\n",
      "    -7.60590211e-02]\n",
      "   [-2.03117058e-01 -1.07742444e-01 -4.85476442e-02  1.04609466e+00\n",
      "    -1.04402058e-01]]\n",
      "\n",
      "  [[-8.05951364e-04  5.33074915e-01  1.19571245e+00  8.37853551e-01\n",
      "     1.21343456e-01]\n",
      "   [-3.16611603e-02 -5.57339191e-02 -2.34261137e-02 -1.47448212e-01\n",
      "    -6.10088222e-02]\n",
      "   [ 7.25581050e-01 -6.07211366e-02  8.15390825e-01 -5.48592769e-02\n",
      "     5.56338549e-01]\n",
      "   [-3.37140523e-02 -1.41580060e-01  1.42336082e+00 -2.28964593e-02\n",
      "     1.68639457e+00]\n",
      "   [-3.23270112e-02  5.13556600e-01 -7.15471944e-03  3.29888873e-02\n",
      "    -1.11836292e-01]]\n",
      "\n",
      "  [[-6.48963079e-02 -5.95249645e-02 -3.17438655e-02 -5.88716529e-02\n",
      "    -6.21128939e-02]\n",
      "   [-8.21174160e-02  1.33100224e+00  6.41090155e-01 -7.18785748e-02\n",
      "    -2.67416276e-02]\n",
      "   [-7.14194924e-02 -7.15192780e-02 -8.54134038e-02 -6.88916966e-02\n",
      "     1.71251214e+00]\n",
      "   [-8.32928047e-02 -7.93294907e-02 -6.53301924e-02 -4.25925292e-02\n",
      "    -1.19354628e-01]\n",
      "   [-1.92278221e-01  2.23011345e-01 -1.45313203e-01 -1.73171625e-01\n",
      "    -2.34010085e-01]]\n",
      "\n",
      "  [[-4.86808717e-02  1.08644533e+00  3.72187018e-01  6.92528725e-01\n",
      "     7.05817819e-01]\n",
      "   [ 1.60617101e+00  3.00029278e-01 -1.02835439e-01 -5.81735782e-02\n",
      "    -3.44205424e-02]\n",
      "   [-1.09627724e-01 -7.45704398e-02 -1.07931614e-01 -2.45129447e-02\n",
      "     1.33347154e-01]\n",
      "   [ 1.08744466e+00 -2.26170287e-01 -1.46645680e-01 -2.01221511e-01\n",
      "     2.68589467e-01]\n",
      "   [-1.83453798e-01 -4.29542623e-02 -1.12078369e-01  4.85005319e-01\n",
      "     2.51556665e-01]]]\n",
      "\n",
      "\n",
      " [[[-1.39982048e-02  3.17262076e-02 -2.29577045e-03  4.47479844e-01\n",
      "     1.15145944e-01]\n",
      "   [ 1.29566479e+00  1.32797778e-01 -2.39707772e-02 -6.83719963e-02\n",
      "    -7.33009353e-02]\n",
      "   [-8.04916844e-02  7.69009948e-01  1.66664600e-01 -3.62264141e-02\n",
      "     1.24486256e+00]\n",
      "   [ 1.44207573e+00 -6.52874857e-02  2.40590230e-01 -4.30815257e-02\n",
      "    -7.83065930e-02]\n",
      "   [-6.02530828e-03  1.11673988e-01  1.15463245e+00  3.94549578e-01\n",
      "    -2.63937842e-02]]\n",
      "\n",
      "  [[ 3.72851253e-01 -3.32738012e-02  5.69778271e-02  4.54699188e-01\n",
      "     3.42801243e-01]\n",
      "   [-2.62492206e-02  1.19880068e+00 -6.01038896e-02  1.56601417e+00\n",
      "    -1.47929117e-02]\n",
      "   [ 7.22278893e-01 -6.34066463e-02 -1.55573279e-01 -5.31270280e-02\n",
      "     1.50931656e+00]\n",
      "   [-9.90861282e-02 -1.05475839e-02 -6.13637529e-02 -3.42391357e-02\n",
      "    -1.28335670e-01]\n",
      "   [-7.97557458e-02 -1.60672605e-01 -6.48417836e-03 -4.75294292e-02\n",
      "     9.75116968e-01]]\n",
      "\n",
      "  [[ 8.73307705e-01  1.61389875e+00  1.41344440e+00  7.15719998e-01\n",
      "     3.86210531e-01]\n",
      "   [-3.36231999e-02 -1.40454054e-01 -1.12971961e-01 -2.36011058e-01\n",
      "    -6.11290634e-02]\n",
      "   [ 2.45629740e+00  2.23916149e+00 -1.12284176e-01 -4.56885733e-02\n",
      "    -6.19759271e-03]\n",
      "   [-2.04065070e-03 -8.99537578e-02 -1.54207438e-01 -9.19870362e-02\n",
      "    -2.32294258e-02]\n",
      "   [ 1.64863288e-01  3.68647909e+00 -6.82872161e-02  1.81370580e+00\n",
      "    -1.92460623e-02]]\n",
      "\n",
      "  [[ 1.04825750e-01 -2.66579837e-02  1.37420952e+00  2.26386741e-01\n",
      "    -2.20922623e-02]\n",
      "   [ 2.45034456e+00  1.37352079e-01  1.88565969e+00 -2.59241788e-03\n",
      "    -1.41677028e-02]\n",
      "   [ 3.16509795e+00 -2.01331019e-01 -2.22404703e-01 -7.85486996e-02\n",
      "     1.14029765e+00]\n",
      "   [ 6.75391018e-01 -1.16484962e-01 -2.53896657e-02 -1.00169674e-01\n",
      "    -1.36279553e-01]\n",
      "   [-5.14877699e-02 -2.36433409e-02 -1.23825811e-01 -1.12011217e-01\n",
      "    -1.26675740e-01]]\n",
      "\n",
      "  [[ 1.21464324e+00  7.45190680e-01  5.66570818e-01  7.11493075e-01\n",
      "     6.00252509e-01]\n",
      "   [ 9.07419324e-01  8.43001187e-01 -6.57129735e-02 -1.66388929e-01\n",
      "    -9.24846753e-02]\n",
      "   [-5.38414670e-03  8.68657708e-01 -3.36578228e-02 -1.00737466e-02\n",
      "     6.61540389e-01]\n",
      "   [ 7.34535813e-01 -1.18360102e-01 -2.25551233e-01 -4.71539386e-02\n",
      "     1.78993452e+00]\n",
      "   [ 2.63243198e+00  8.66621733e-01 -1.27908617e-01  3.39187264e+00\n",
      "     8.87644112e-01]]]], shape=(3, 5, 5, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[ 1.08876437e-01 -2.50268076e-02  3.50178666e-02  3.37259293e-01\n",
      "    -4.42558415e-02]\n",
      "   [ 1.14558637e-01 -1.00644484e-01 -6.06909692e-02  9.47674438e-02\n",
      "    -4.86130500e-03]\n",
      "   [ 8.92549083e-02  2.31774509e-01  3.33593667e-01 -2.48217154e-02\n",
      "    -8.99485424e-02]\n",
      "   [-5.04219113e-03 -4.92261201e-02 -5.70441298e-02  1.31594032e-01\n",
      "     2.29627248e-02]\n",
      "   [ 2.64303505e-01  6.04032837e-02  2.45012785e-03  3.43216598e-01\n",
      "    -7.70835206e-02]]\n",
      "\n",
      "  [[-1.16695445e-02  1.94123149e-01 -1.91038903e-02  6.64941967e-01\n",
      "    -5.28052635e-02]\n",
      "   [-7.30852187e-02 -9.96821672e-02 -9.88951921e-02 -4.19749990e-02\n",
      "    -8.24045297e-03]\n",
      "   [ 1.31073952e+00 -5.71213551e-02 -2.89761368e-02 -2.12287083e-02\n",
      "    -8.41929764e-02]\n",
      "   [ 2.99925178e-01 -1.23268306e-01  3.47921364e-02 -7.54513219e-02\n",
      "    -5.34931244e-03]\n",
      "   [ 1.75312087e-01 -2.10100319e-02  1.31702960e-01  2.34155267e-01\n",
      "    -1.55122146e-01]]\n",
      "\n",
      "  [[ 9.55342501e-02 -7.84510300e-02 -3.62089202e-02  1.37440488e-01\n",
      "    -3.38786803e-02]\n",
      "   [-4.43367921e-02 -3.97172160e-02 -5.32951020e-02 -5.38335145e-02\n",
      "     3.57649297e-01]\n",
      "   [-2.15486833e-03 -1.46945015e-01 -1.49819274e-02 -4.57595661e-02\n",
      "    -2.52755079e-02]\n",
      "   [-6.47103116e-02 -1.16947167e-01  3.08221638e-01 -8.84627476e-02\n",
      "     1.26637354e-01]\n",
      "   [-1.51406741e-02 -4.66578044e-02  3.48497242e-01  1.83875531e-01\n",
      "     2.45372549e-01]]\n",
      "\n",
      "  [[ 3.59993517e-01  1.96414758e-02  1.70821607e-01  6.44043267e-01\n",
      "    -4.11342494e-02]\n",
      "   [-1.52864695e-01 -3.61885503e-02 -1.30860850e-01 -9.47463978e-03\n",
      "    -2.26681828e-02]\n",
      "   [ 5.51146150e-01  1.91221237e-01 -7.84506928e-03  2.34455168e-01\n",
      "    -5.79290874e-02]\n",
      "   [-1.76534981e-01 -1.11173742e-01 -6.87816516e-02 -9.05601531e-02\n",
      "    -4.79047559e-02]\n",
      "   [-8.48208144e-02  2.12684989e+00  5.02714932e-01  1.74163699e-01\n",
      "    -1.79315627e-01]]\n",
      "\n",
      "  [[-5.02182031e-03 -5.93379997e-02 -3.74513827e-02  9.45547968e-02\n",
      "    -2.80996561e-02]\n",
      "   [ 3.72974873e-02  1.22478533e+00 -1.37797907e-01 -5.92206009e-02\n",
      "    -1.01853451e-02]\n",
      "   [ 2.51826346e-01  7.53235966e-02 -8.85305088e-03 -5.92226461e-02\n",
      "    -1.75944939e-01]\n",
      "   [ 1.49680829e+00  1.95018435e+00 -1.22639537e-01 -9.49817374e-02\n",
      "     7.99933910e-01]\n",
      "   [ 8.26079011e-01  1.42959332e+00 -4.51804474e-02  1.58155203e-01\n",
      "    -6.25807866e-02]]]\n",
      "\n",
      "\n",
      " [[[ 1.37335584e-01 -3.58832851e-02  2.05943305e-02  2.79496640e-01\n",
      "    -4.11698036e-02]\n",
      "   [ 1.05548009e-01 -1.19094387e-01 -6.41249865e-02  1.04226023e-01\n",
      "    -2.85466923e-03]\n",
      "   [ 1.29286259e-01  8.19946378e-02  3.04061860e-01 -1.70922745e-02\n",
      "    -8.75079334e-02]\n",
      "   [ 2.58972999e-02 -7.17919692e-02 -5.55008240e-02  1.89628914e-01\n",
      "     2.11210027e-02]\n",
      "   [ 3.26194763e-01 -5.35801006e-03 -2.83528375e-03  3.59860420e-01\n",
      "    -8.22882056e-02]]\n",
      "\n",
      "  [[-6.33975258e-03 -4.79857874e-04 -1.67678278e-02  5.12453854e-01\n",
      "    -5.13421968e-02]\n",
      "   [-8.30989107e-02 -1.09216742e-01 -9.65405330e-02 -4.97956015e-02\n",
      "    -1.93262994e-02]\n",
      "   [ 1.33852541e+00 -5.62122427e-02 -2.98720431e-02 -1.25512304e-02\n",
      "    -9.45165381e-02]\n",
      "   [ 1.29695624e-01 -1.33483335e-01 -1.30667556e-02 -7.86620229e-02\n",
      "    -1.95039809e-02]\n",
      "   [ 3.08104604e-01 -2.46618111e-02  1.72094971e-01  2.04043582e-01\n",
      "    -1.50058761e-01]]\n",
      "\n",
      "  [[ 8.44234154e-02 -8.87068436e-02 -3.87489125e-02  4.57657017e-02\n",
      "    -4.27312404e-02]\n",
      "   [-3.53265256e-02 -5.93733974e-02 -7.05312416e-02 -5.05133383e-02\n",
      "     1.32733375e-01]\n",
      "   [ 3.41707133e-02 -1.49846107e-01 -2.74542216e-02 -2.89654881e-02\n",
      "    -4.11855280e-02]\n",
      "   [-4.13282774e-02 -1.23828582e-01  2.49295220e-01 -9.92052779e-02\n",
      "     1.18171223e-01]\n",
      "   [-7.04281265e-03 -3.55534069e-02  3.16751987e-01  2.09402516e-01\n",
      "    -1.17289471e-02]]\n",
      "\n",
      "  [[ 3.61058623e-01 -5.40880999e-03  1.80131152e-01  6.58739805e-01\n",
      "    -3.90114486e-02]\n",
      "   [-1.40360162e-01 -5.90713397e-02 -1.24498330e-01 -2.02049315e-02\n",
      "    -2.10604221e-02]\n",
      "   [ 6.81540847e-01  2.98993260e-01 -2.82334600e-04  2.86092997e-01\n",
      "    -6.93010911e-02]\n",
      "   [-1.87130362e-01 -1.36413887e-01 -8.75419006e-02 -9.86968502e-02\n",
      "    -4.44304459e-02]\n",
      "   [-7.04296753e-02  2.15374994e+00  3.16383749e-01  1.31800860e-01\n",
      "    -1.98614433e-01]]\n",
      "\n",
      "  [[-9.42378305e-04 -5.99381290e-02 -3.98952141e-02  4.50446382e-02\n",
      "    -4.24186736e-02]\n",
      "   [-4.54883877e-04  9.47256386e-01 -1.41156346e-01 -6.42977208e-02\n",
      "    -2.53050476e-02]\n",
      "   [ 3.46124500e-01 -1.82946827e-02 -1.23794386e-02 -4.69432734e-02\n",
      "    -1.71561643e-01]\n",
      "   [ 1.30253971e+00  1.63620794e+00 -1.07201435e-01 -1.02124892e-01\n",
      "     6.57423973e-01]\n",
      "   [ 7.84793139e-01  1.13954854e+00 -4.15194705e-02  7.77958930e-02\n",
      "    -8.93895999e-02]]]\n",
      "\n",
      "\n",
      " [[[-1.02140233e-02  3.11337322e-01 -1.71659384e-02  3.99004549e-01\n",
      "    -5.31924143e-02]\n",
      "   [ 1.59312829e-01 -1.22169830e-01 -2.15907004e-02 -2.23505758e-02\n",
      "     9.16091800e-02]\n",
      "   [ 9.97327715e-02  8.77270401e-01  1.81913152e-01 -5.82681000e-02\n",
      "    -1.19646572e-01]\n",
      "   [ 6.96043968e-01 -9.21944901e-02 -2.65106503e-02 -4.74992953e-02\n",
      "     2.33671963e-01]\n",
      "   [ 2.03624159e-01  8.17000568e-01  1.02219856e+00 -5.09508327e-03\n",
      "    -8.94538835e-02]]\n",
      "\n",
      "  [[-6.89140186e-02  1.03068221e+00 -4.66227569e-02  6.37422860e-01\n",
      "    -8.95593613e-02]\n",
      "   [-1.65743992e-01 -2.48254612e-02 -5.42577691e-02  5.27117670e-01\n",
      "    -1.18992394e-02]\n",
      "   [ 7.64211237e-01  2.00442895e-01 -4.65142466e-02 -8.73196051e-02\n",
      "    -2.81033844e-01]\n",
      "   [-5.16446233e-02 -7.34625384e-02  8.82479787e-01 -9.71292797e-03\n",
      "    -1.63247526e-01]\n",
      "   [-3.06504853e-02  6.00301996e-02  9.57951769e-02 -1.70119449e-01\n",
      "    -2.54871815e-01]]\n",
      "\n",
      "  [[-1.41912540e-02 -5.21867089e-02 -7.33089224e-02  5.34338295e-01\n",
      "    -6.68618530e-02]\n",
      "   [-6.27058521e-02 -1.95385832e-02 -6.73503149e-03 -1.96385622e-01\n",
      "     8.82938445e-01]\n",
      "   [-6.70853630e-02  3.28983963e-01 -7.72975460e-02 -1.64114788e-01\n",
      "    -1.93884060e-01]\n",
      "   [-3.15801031e-03 -1.28053457e-01 -1.24517441e-01 -2.91145921e-01\n",
      "    -7.83888157e-03]\n",
      "   [-6.90592406e-03  9.40176666e-01 -1.64943978e-01 -7.43881315e-02\n",
      "    -1.07025996e-01]]\n",
      "\n",
      "  [[ 1.48474440e-01  9.23641264e-01 -3.41578461e-02  8.64671290e-01\n",
      "    -8.87402296e-02]\n",
      "   [-5.56862839e-02 -1.49022803e-01 -1.13617674e-01  8.40697229e-01\n",
      "    -1.80311017e-02]\n",
      "   [ 6.19637966e-01 -5.48188053e-02 -2.20387597e-02 -1.29103288e-01\n",
      "    -1.44682527e-01]\n",
      "   [-2.02238828e-01 -7.96580315e-02 -6.94167763e-02 -2.65342772e-01\n",
      "    -8.86047408e-02]\n",
      "   [-3.41304392e-02  8.92956018e-01  4.27377820e-01 -2.66602755e-01\n",
      "    -2.13628918e-01]]\n",
      "\n",
      "  [[-2.41838675e-02 -1.03030512e-02 -5.28481491e-02  9.41297531e-01\n",
      "    -5.68722971e-02]\n",
      "   [ 6.20095730e-01  1.62913039e-01 -7.15296939e-02 -4.36048768e-02\n",
      "    -2.02978849e-02]\n",
      "   [-1.24636842e-02  2.62392974e+00 -1.00884877e-01 -1.00320376e-01\n",
      "    -2.08790466e-01]\n",
      "   [ 3.47439438e-01  1.48705173e+00 -1.05877630e-01 -2.40553603e-01\n",
      "     1.77446961e+00]\n",
      "   [ 4.33392555e-01  4.64733541e-01 -3.36711966e-02 -1.08200815e-02\n",
      "    -9.73592699e-02]]]], shape=(3, 5, 5, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[ 2.58360296e-01  2.30247527e-01  2.12392718e-01 -8.72571021e-02\n",
      "     1.80965453e-01]\n",
      "   [ 3.50883156e-01  4.60499257e-01  1.41310636e-02 -8.07983875e-02\n",
      "    -3.43990070e-03]\n",
      "   [-5.61104110e-03  3.67033362e-01 -2.97554620e-02 -7.73618743e-02\n",
      "     2.06837300e-02]\n",
      "   [ 2.10202802e-02  4.32530344e-01  1.94531575e-01 -6.94191605e-02\n",
      "     4.77142692e-01]\n",
      "   [-1.10761384e-02  5.19143283e-01 -1.53334113e-02 -9.24468711e-02\n",
      "     7.03510717e-02]]\n",
      "\n",
      "  [[ 1.35131106e-01  4.62371588e-01 -3.69651727e-02 -7.62567297e-02\n",
      "     4.46953744e-01]\n",
      "   [ 2.30631113e-01  3.93927127e-01 -1.02406859e-01 -6.12892024e-02\n",
      "    -1.97356921e-02]\n",
      "   [-6.71394123e-03  2.76219875e-01 -6.39143214e-02 -8.41881186e-02\n",
      "     2.32556328e-01]\n",
      "   [-2.59863641e-02  5.93127429e-01 -8.11202452e-02 -7.06613436e-02\n",
      "    -4.72919270e-03]\n",
      "   [-3.95552255e-02  5.66145003e-01 -5.71398400e-02 -5.04610650e-02\n",
      "     5.61282873e-01]]\n",
      "\n",
      "  [[-2.65067369e-02  4.95267540e-01 -2.62370557e-02 -8.28331187e-02\n",
      "     1.08196512e-01]\n",
      "   [-2.17658989e-02  2.68789768e-01 -1.37689725e-01 -1.42329678e-01\n",
      "     4.57757920e-01]\n",
      "   [ 2.31602475e-01  4.30811703e-01 -5.53271733e-02 -1.41618118e-01\n",
      "    -2.93189343e-02]\n",
      "   [-2.33149491e-02  6.02656603e-01 -4.45322879e-02 -1.30661532e-01\n",
      "     5.37639320e-01]\n",
      "   [-7.91194066e-02  2.50390142e-01 -4.96638678e-02 -1.37032926e-01\n",
      "     1.03750497e-01]]\n",
      "\n",
      "  [[ 2.55870204e-02  2.73968667e-01 -2.84097139e-02 -6.43000528e-02\n",
      "     3.14996362e-01]\n",
      "   [ 2.09733054e-01  4.99820173e-01 -6.58897758e-02 -3.95891741e-02\n",
      "     8.84373039e-02]\n",
      "   [-1.04275008e-03  4.86150354e-01 -2.75987275e-02 -8.38207975e-02\n",
      "     6.20591462e-01]\n",
      "   [-7.33569041e-02  4.21714693e-01 -7.81287476e-02 -4.28624898e-02\n",
      "    -4.88265119e-02]\n",
      "   [-4.69273850e-02  5.01737356e-01 -5.48168011e-02 -5.93182407e-02\n",
      "     2.47910082e-01]]\n",
      "\n",
      "  [[ 3.38937134e-01  1.88819617e-01 -7.27560604e-03 -7.25288391e-02\n",
      "     3.46859843e-01]\n",
      "   [ 3.98537189e-01  5.42039096e-01 -6.31561205e-02 -8.62761810e-02\n",
      "    -5.38459839e-03]\n",
      "   [-2.57981420e-02  3.09733927e-01 -5.05839884e-02 -7.03787878e-02\n",
      "    -2.27185842e-02]\n",
      "   [-9.00771543e-02  2.21381918e-01 -2.91864779e-02 -9.57566872e-02\n",
      "     3.53981078e-01]\n",
      "   [-3.78164612e-02  3.07698250e-01 -6.36330768e-02 -5.42690456e-02\n",
      "    -1.92187159e-04]]]\n",
      "\n",
      "\n",
      " [[[ 3.58014911e-01  1.66120499e-01  2.66011178e-01 -8.37538838e-02\n",
      "     1.67027757e-01]\n",
      "   [ 4.66883272e-01  3.32695097e-01  9.93602872e-02 -8.01781192e-02\n",
      "    -5.71348192e-03]\n",
      "   [ 8.15312341e-02  3.03742886e-01 -2.41621491e-02 -7.45617300e-02\n",
      "     4.84095402e-02]\n",
      "   [ 1.81387126e-01  3.57722491e-01  2.30822235e-01 -7.01017007e-02\n",
      "     5.03063917e-01]\n",
      "   [ 3.19277458e-02  4.86959875e-01 -1.44194607e-02 -8.96419212e-02\n",
      "     1.00251354e-01]]\n",
      "\n",
      "  [[ 3.95325750e-01  3.53100836e-01 -3.36020738e-02 -7.18807802e-02\n",
      "     4.03902173e-01]\n",
      "   [ 4.92215633e-01  2.82073110e-01 -8.71917382e-02 -5.79116419e-02\n",
      "    -2.96921320e-02]\n",
      "   [ 2.04497308e-01  1.91609949e-01 -6.29753992e-02 -7.76523277e-02\n",
      "     2.10080937e-01]\n",
      "   [-1.27633614e-02  4.93926018e-01 -6.97391480e-02 -6.91685602e-02\n",
      "    -2.40018312e-02]\n",
      "   [-8.23243894e-03  4.43265021e-01 -5.74633852e-02 -4.56261002e-02\n",
      "     5.08897483e-01]]\n",
      "\n",
      "  [[ 2.26320978e-02  3.24619472e-01 -1.37594342e-02 -7.84777328e-02\n",
      "     6.99397847e-02]\n",
      "   [ 8.49109665e-02  1.13787591e-01 -1.24840401e-01 -1.35970816e-01\n",
      "     4.46088195e-01]\n",
      "   [ 3.68050605e-01  3.32649052e-01 -4.79700975e-02 -1.35442823e-01\n",
      "    -2.57518273e-02]\n",
      "   [-7.68273091e-03  3.97766173e-01 -4.02723029e-02 -1.12709723e-01\n",
      "     5.11631906e-01]\n",
      "   [-6.46980032e-02  7.68560320e-02 -4.36985902e-02 -1.28787026e-01\n",
      "     8.36737901e-02]]\n",
      "\n",
      "  [[ 2.95676023e-01  1.08530179e-01 -2.20530033e-02 -5.92987239e-02\n",
      "     2.22608089e-01]\n",
      "   [ 5.07597148e-01  4.53636587e-01 -4.70729060e-02 -2.92906761e-02\n",
      "    -8.11051112e-03]\n",
      "   [ 1.99497521e-01  3.98046225e-01 -2.31134556e-02 -7.66996890e-02\n",
      "     5.84316909e-01]\n",
      "   [-6.15382157e-02  3.35593015e-01 -7.15871081e-02 -2.90002283e-02\n",
      "    -6.03376143e-02]\n",
      "   [-2.78347880e-02  3.40610266e-01 -4.50717434e-02 -4.66910787e-02\n",
      "     1.49651617e-01]]\n",
      "\n",
      "  [[ 6.16241753e-01  9.64327455e-02  2.36380473e-02 -6.80215508e-02\n",
      "     3.01716685e-01]\n",
      "   [ 7.18298316e-01  3.24987739e-01 -4.31380384e-02 -7.20474347e-02\n",
      "    -6.05420489e-03]\n",
      "   [-7.80400122e-03  1.86050013e-01 -3.98829244e-02 -6.31179959e-02\n",
      "    -1.84314214e-02]\n",
      "   [-6.81825429e-02  7.31935650e-02 -3.26214246e-02 -7.16958642e-02\n",
      "     3.48769516e-01]\n",
      "   [-1.29326684e-02  2.65624136e-01 -5.45241721e-02 -4.43781577e-02\n",
      "    -1.41949849e-02]]]\n",
      "\n",
      "\n",
      " [[[-3.66956480e-02  3.79794925e-01  2.55727798e-01 -8.76489505e-02\n",
      "     1.01395458e-01]\n",
      "   [-2.23593824e-02  7.46584356e-01  3.32519352e-01 -5.58551550e-02\n",
      "    -2.66232286e-02]\n",
      "   [-7.82599375e-02  4.19333786e-01  6.81521147e-02 -5.21010272e-02\n",
      "    -4.37819362e-02]\n",
      "   [-3.00985519e-02  4.52691674e-01  2.96977550e-01 -5.01352809e-02\n",
      "    -1.90314148e-02]\n",
      "   [-8.32589492e-02  5.69471896e-01  5.70589662e-01 -7.02592358e-02\n",
      "    -1.98285040e-02]]\n",
      "\n",
      "  [[-7.53753409e-02  6.32428646e-01 -1.33335143e-02 -6.49041459e-02\n",
      "     2.68240273e-01]\n",
      "   [-1.38904363e-01  2.31971994e-01 -2.57090423e-02 -5.48802875e-02\n",
      "    -2.34831516e-02]\n",
      "   [-7.97929913e-02  4.12556887e-01 -5.92121184e-02 -5.31862266e-02\n",
      "    -2.00677756e-02]\n",
      "   [-2.57770214e-02  6.31760955e-01 -7.21765980e-02 -8.57859198e-03\n",
      "    -3.72550003e-02]\n",
      "   [-1.83078825e-01  7.51194894e-01  9.72612128e-02 -1.01178125e-01\n",
      "     1.96758777e-01]]\n",
      "\n",
      "  [[-1.22643292e-01  7.99507856e-01 -2.38336045e-02 -7.53379837e-02\n",
      "     2.35195979e-01]\n",
      "   [-2.01016903e-01  6.03629172e-01 -1.02239743e-01 -9.20145437e-02\n",
      "     6.38870656e-01]\n",
      "   [-8.10719207e-02  5.15906155e-01 -8.40632990e-02 -6.06084950e-02\n",
      "    -5.68435676e-02]\n",
      "   [-6.17767237e-02  4.50160325e-01 -2.76792347e-02 -1.02341212e-01\n",
      "     2.23816201e-01]\n",
      "   [-1.49805188e-01 -2.63716020e-02 -1.56060969e-02 -4.36662734e-02\n",
      "     1.31068796e-01]]\n",
      "\n",
      "  [[-9.33423340e-02  6.85965002e-01 -3.05252969e-02 -6.29890785e-02\n",
      "     4.56207454e-01]\n",
      "   [-9.21716318e-02  4.23148453e-01 -5.08166093e-04 -5.40151000e-02\n",
      "     2.63794601e-01]\n",
      "   [-4.01478447e-02  1.15141332e-01 -8.11123382e-03 -4.17742357e-02\n",
      "    -1.88786199e-03]\n",
      "   [-7.11566806e-02 -1.56241404e-02  3.26139212e-01 -8.58606324e-02\n",
      "    -3.95484865e-02]\n",
      "   [-1.09212354e-01  2.69258678e-01  2.95531958e-01  2.62221456e-01\n",
      "    -2.51998305e-02]]\n",
      "\n",
      "  [[-9.89068896e-02  5.32955527e-01 -1.78710632e-02 -7.16024339e-02\n",
      "     3.43903780e-01]\n",
      "   [-3.36390063e-02  9.96246457e-01 -5.96284643e-02 -5.15736230e-02\n",
      "     6.36717975e-02]\n",
      "   [-2.83920951e-02  2.24481910e-01  2.60246009e-01 -3.70082222e-02\n",
      "    -3.85242850e-02]\n",
      "   [-1.26595363e-01 -9.90669355e-02  3.86222899e-01 -5.29385619e-02\n",
      "     2.82918930e-01]\n",
      "   [-1.76219434e-01 -4.26148176e-02  3.27153116e-01  7.97907822e-04\n",
      "     1.08582914e-01]]]], shape=(3, 5, 5, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[ 9.07889381e-02  1.24535486e-01  1.06340975e-01]\n",
      "   [ 1.31931961e-01  1.38279930e-01  9.51135010e-02]\n",
      "   [ 9.77532044e-02  7.93675780e-02  6.76422715e-02]\n",
      "   [ 8.52288455e-02  7.74784163e-02  5.44964820e-02]\n",
      "   [ 6.98038861e-02  4.44846302e-02  2.91828234e-02]]\n",
      "\n",
      "  [[ 1.13140531e-01  9.15821567e-02  1.00917302e-01]\n",
      "   [-2.39236411e-02 -7.12569281e-02 -1.65140312e-02]\n",
      "   [ 7.19675496e-02  5.19303754e-02  4.41318750e-02]\n",
      "   [-3.04842032e-02 -8.91558677e-02 -2.70235576e-02]\n",
      "   [ 5.99983148e-02  3.45400311e-02  3.50767709e-02]]\n",
      "\n",
      "  [[ 4.27283086e-02  3.69438939e-02  4.43682857e-02]\n",
      "   [ 4.78262194e-02  3.96754146e-02  3.35169584e-02]\n",
      "   [ 5.91376051e-02  4.06156555e-02  3.66847366e-02]\n",
      "   [ 5.23082912e-02  4.22507375e-02  3.73302400e-02]\n",
      "   [ 6.62681162e-02  4.43411320e-02  3.73046845e-02]]\n",
      "\n",
      "  [[ 2.37808786e-02  2.57067923e-02  4.22568023e-02]\n",
      "   [-5.46052456e-02 -1.03413083e-01 -4.17443626e-02]\n",
      "   [ 4.86467406e-02  3.76028530e-02  3.30757312e-02]\n",
      "   [-4.19972427e-02 -9.49852690e-02 -3.12105268e-02]\n",
      "   [ 5.86603731e-02  4.72343490e-02  3.43574248e-02]]\n",
      "\n",
      "  [[ 2.08449941e-02  2.04005279e-02  1.29895750e-02]\n",
      "   [ 4.54856530e-02  3.78696695e-02  3.45185809e-02]\n",
      "   [ 4.88821231e-02  3.38640027e-02  3.14673074e-02]\n",
      "   [ 7.18026161e-02  6.38393164e-02  5.59133627e-02]\n",
      "   [ 5.33652902e-02  4.58884016e-02  3.14530805e-02]]]\n",
      "\n",
      "\n",
      " [[[ 1.19331107e-01  1.50344744e-01  1.15535125e-01]\n",
      "   [ 1.61134392e-01  1.79771006e-01  1.10480376e-01]\n",
      "   [ 1.27007037e-01  1.15253419e-01  7.62848482e-02]\n",
      "   [ 1.11547291e-01  1.11659490e-01  6.71980307e-02]\n",
      "   [ 9.61746126e-02  6.96621314e-02  3.91257480e-02]]\n",
      "\n",
      "  [[ 1.52725324e-01  1.31043822e-01  1.16462022e-01]\n",
      "   [ 1.59815829e-02 -3.00546084e-02 -2.84348568e-03]\n",
      "   [ 9.87732932e-02  8.81686434e-02  5.17469980e-02]\n",
      "   [-3.52984498e-04 -5.22565059e-02 -1.61361247e-02]\n",
      "   [ 7.99700990e-02  5.45872040e-02  3.79448161e-02]]\n",
      "\n",
      "  [[ 9.92412567e-02  8.66318345e-02  6.47847131e-02]\n",
      "   [ 7.64433071e-02  6.64956495e-02  3.71660218e-02]\n",
      "   [ 8.82053748e-02  7.18793496e-02  4.29001860e-02]\n",
      "   [ 8.95840377e-02  7.46918768e-02  5.35552688e-02]\n",
      "   [ 9.06866714e-02  6.21589646e-02  3.95134501e-02]]\n",
      "\n",
      "  [[ 7.30435103e-02  6.88060969e-02  5.70957921e-02]\n",
      "   [-3.41176726e-02 -8.08411464e-02 -3.98903750e-02]\n",
      "   [ 8.06819424e-02  6.27014637e-02  3.89605910e-02]\n",
      "   [-1.70998108e-02 -7.14770481e-02 -3.39172445e-02]\n",
      "   [ 8.51870850e-02  6.79823905e-02  3.95916961e-02]]\n",
      "\n",
      "  [[ 9.68433768e-02  8.76232684e-02  4.55783829e-02]\n",
      "   [ 7.81837329e-02  6.98277131e-02  3.93683203e-02]\n",
      "   [ 9.42905843e-02  6.87776580e-02  4.86596264e-02]\n",
      "   [ 1.14545330e-01  9.84377861e-02  7.28566572e-02]\n",
      "   [ 7.65884519e-02  6.87470138e-02  3.42253856e-02]]]\n",
      "\n",
      "\n",
      " [[[ 4.68520075e-02  4.98606302e-02  6.77342638e-02]\n",
      "   [ 1.15017660e-01  1.02284387e-01  1.59630984e-01]\n",
      "   [ 1.27647296e-01  4.95202392e-02  1.61534935e-01]\n",
      "   [ 1.13183133e-01  3.82455587e-02  1.65570930e-01]\n",
      "   [ 1.28038749e-01  1.41555704e-02  1.54384360e-01]]\n",
      "\n",
      "  [[ 6.08333088e-02  1.92584991e-02  1.07199430e-01]\n",
      "   [-2.68827062e-02 -1.13108613e-01  4.09803689e-02]\n",
      "   [ 1.14917509e-01 -1.53138608e-04  1.53401628e-01]\n",
      "   [-2.69166962e-03 -1.38697490e-01  8.80426615e-02]\n",
      "   [ 1.41819805e-01 -1.11488474e-03  1.63852081e-01]]\n",
      "\n",
      "  [[ 9.81030334e-03 -1.74522214e-03  5.02691492e-02]\n",
      "   [ 1.43633997e-02 -2.72834185e-03  6.92627504e-02]\n",
      "   [ 1.53210267e-01  1.58327911e-03  1.69191360e-01]\n",
      "   [ 1.69428542e-01 -1.41605007e-04  1.61859751e-01]\n",
      "   [ 1.71033084e-01  1.88528781e-03  1.69429719e-01]]\n",
      "\n",
      "  [[-2.95246980e-04 -3.05804657e-03  3.83450128e-02]\n",
      "   [-7.07953125e-02 -1.58767924e-01 -2.27490291e-02]\n",
      "   [ 2.08614543e-01 -2.83537462e-04  1.74795583e-01]\n",
      "   [ 1.76010236e-01 -1.27512649e-01  1.07702546e-01]\n",
      "   [ 2.24036530e-01 -3.18521954e-04  1.70373723e-01]]\n",
      "\n",
      "  [[ 1.10717968e-03 -3.10994242e-03  3.43687162e-02]\n",
      "   [ 2.11561490e-02 -3.94735625e-03  4.79765907e-02]\n",
      "   [ 2.18711257e-01  5.39990142e-03  2.09180027e-01]\n",
      "   [ 2.58213371e-01  1.56449918e-02  1.85926557e-01]\n",
      "   [ 1.91302732e-01  4.06147446e-03  1.55451924e-01]]]], shape=(3, 5, 5, 3), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.7330474 ]\n",
      " [ 0.6364398 ]\n",
      " [-0.80292803]\n",
      " [-1.9607987 ]\n",
      " [-0.03298634]\n",
      " [ 0.6996903 ]\n",
      " [-0.10833185]\n",
      " [ 0.31654674]\n",
      " [ 0.6588001 ]\n",
      " [-0.09422082]\n",
      " [ 0.5578816 ]\n",
      " [-0.05290177]\n",
      " [-0.11813443]\n",
      " [-0.19716708]\n",
      " [ 0.0263162 ]\n",
      " [ 0.29462236]\n",
      " [ 0.07541651]\n",
      " [ 0.03791507]\n",
      " [-1.301384  ]\n",
      " [ 0.01705541]\n",
      " [ 0.2800377 ]\n",
      " [-0.03757518]\n",
      " [-0.1446654 ]\n",
      " [ 0.571592  ]\n",
      " [ 0.16298202]\n",
      " [ 0.3853119 ]\n",
      " [-0.3280385 ]\n",
      " [ 0.28889844]\n",
      " [-0.01825701]\n",
      " [-0.13764481]\n",
      " [ 0.96193516]\n",
      " [-1.4912162 ]\n",
      " [ 0.37523788]\n",
      " [-0.08545094]\n",
      " [-0.69500977]\n",
      " [-0.08711087]\n",
      " [-0.3767596 ]\n",
      " [-0.01851731]\n",
      " [-0.10279977]\n",
      " [-1.6155019 ]\n",
      " [-0.08037608]\n",
      " [ 1.3862095 ]\n",
      " [-0.14765243]\n",
      " [ 0.01453615]\n",
      " [-0.06687289]\n",
      " [-1.7731142 ]\n",
      " [ 0.40818334]\n",
      " [ 0.6745443 ]\n",
      " [ 0.5628932 ]\n",
      " [ 0.67801124]\n",
      " [-0.2800907 ]\n",
      " [ 0.6571805 ]\n",
      " [-0.2994401 ]\n",
      " [-0.07143586]\n",
      " [-0.12705807]\n",
      " [ 0.4541952 ]\n",
      " [-0.15048783]\n",
      " [ 0.6623275 ]\n",
      " [ 0.23542286]\n",
      " [-0.0028184 ]\n",
      " [ 0.75507957]\n",
      " [-0.67771035]\n",
      " [ 0.07533414]\n",
      " [-0.8166626 ]], shape=(64, 1), dtype=float32)\n",
      "Time for inference is 3.4401 sec\n"
     ]
    }
   ],
   "source": [
    "inference(testing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "c8616a11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator_8/dense_block_8/dense_50/kernel:0 [[-0.04498814 -0.23571591  0.05061483 ... -0.07926965 -0.06415971\n",
      "  -0.08199308]\n",
      " [ 0.05829757  0.21634753  0.02969032 ...  0.02306199  0.16618606\n",
      "   0.02117582]\n",
      " [ 0.03605476 -0.06150118  0.07170997 ...  0.16611832  0.10298007\n",
      "   0.02841652]\n",
      " ...\n",
      " [-0.00112796  0.00504179  0.00708564 ... -0.02090279 -0.00069093\n",
      "  -0.02018782]\n",
      " [ 0.01602916 -0.018421   -0.00192075 ... -0.01871504  0.00557119\n",
      "  -0.00656456]\n",
      " [-0.02177091  0.01424693  0.00438795 ... -0.01453981 -0.02062936\n",
      "   0.01695392]]\n",
      "generator_8/dense_block_8/dense_50/bias:0 [-8.6428727e-06 -6.6864864e-05  1.8376473e-05 ... -1.8091770e-05\n",
      " -8.9352479e-06 -3.2261182e-06]\n",
      "generator_8/dense_block_8/batch_normalization_128/gamma:0 [0.9478327  0.94250154 1.071583   ... 1.2639962  1.1563675  1.3050067 ]\n",
      "generator_8/dense_block_8/batch_normalization_128/beta:0 [ 0.14056788 -0.32281476  0.19005923 ... -0.0251978  -0.03710499\n",
      " -0.2400612 ]\n",
      "generator_8/dense_block_8/batch_normalization_128/moving_mean:0 [ 0.61419076  0.5931713  -2.592021   ...  2.8242393   0.78500664\n",
      "  2.4193342 ]\n",
      "generator_8/dense_block_8/batch_normalization_128/moving_variance:0 [2.1808684 2.699555  3.1618786 ... 2.0248654 3.6932144 1.9134109]\n"
     ]
    }
   ],
   "source": [
    "for var in generator.starter.variables:\n",
    "    print(var.name, var.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "53e5d27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_8/conv_block_82/conv2d_82/kernel:0 [[[[-2.2866993e-01  2.4309792e-01 -5.7593203e-04 ...  5.0765681e-01\n",
      "    -1.8299033e-01  7.4656770e-02]\n",
      "   [-4.9829939e-01 -4.8093405e-01 -1.8522252e-01 ... -5.3269726e-01\n",
      "     3.6122376e-01  2.9018033e-01]\n",
      "   [-1.3226913e-01 -1.8454133e-02  3.7295622e-01 ... -4.2382467e-01\n",
      "     1.7720783e-01  9.5634125e-03]]\n",
      "\n",
      "  [[ 1.2448568e-01 -3.8422987e-02  6.4998500e-02 ...  1.7700158e-02\n",
      "    -3.2616064e-01 -2.0630422e-01]\n",
      "   [ 3.8726839e-01 -2.8708821e-02 -1.5146399e-01 ...  2.0324646e-01\n",
      "     3.4477569e-02  6.3980669e-03]\n",
      "   [-1.6381900e-01  3.6336344e-01 -4.8993415e-01 ... -2.5162059e-01\n",
      "     1.1920709e-01 -1.4812057e-01]]\n",
      "\n",
      "  [[-6.4685792e-02  1.2510049e-01  6.7997612e-02 ... -2.0516430e-01\n",
      "    -1.2416184e-02 -4.4040132e-01]\n",
      "   [ 1.1142460e-01 -8.6674616e-02  2.5821075e-01 ... -3.1199932e-01\n",
      "     8.7472536e-02 -2.3021638e-01]\n",
      "   [ 1.6607173e-01 -3.4756833e-01 -1.9862036e-01 ...  4.5215395e-01\n",
      "     1.2540741e-01 -1.5188457e-01]]]\n",
      "\n",
      "\n",
      " [[[ 3.5060322e-01  3.2049119e-01 -1.4319196e-01 ...  6.3886118e-01\n",
      "     1.8424511e-01 -2.7426353e-01]\n",
      "   [ 3.8063052e-01 -2.4355121e-01  2.2257334e-01 ... -5.0172681e-01\n",
      "     4.5247905e-02 -1.9933337e-02]\n",
      "   [-2.4302061e-01  4.5567310e-01 -3.0908144e-01 ...  3.7774828e-01\n",
      "     2.7344739e-01  5.5210903e-02]]\n",
      "\n",
      "  [[ 2.5156287e-02  2.1827261e-01 -4.3352362e-02 ...  2.6695293e-01\n",
      "     2.5042921e-01  1.0449665e-01]\n",
      "   [-3.1776071e-02  2.8046334e-01 -5.1708299e-01 ...  5.8629334e-01\n",
      "    -6.1537825e-02 -1.9193569e-01]\n",
      "   [-3.3154538e-01 -7.4428499e-02  4.8027936e-01 ...  3.2529494e-01\n",
      "     2.1410890e-01  7.0388749e-02]]\n",
      "\n",
      "  [[ 1.4411800e-01  6.6387313e-03 -4.2309973e-01 ...  3.5003945e-01\n",
      "    -5.0656784e-01 -3.6048427e-01]\n",
      "   [-4.0149099e-01  6.4855471e-02 -1.0007555e-01 ...  1.6102311e-01\n",
      "     5.6175756e-01 -9.2047922e-02]\n",
      "   [ 3.1368747e-01 -4.5070164e-02  4.2595142e-01 ...  7.0160724e-02\n",
      "    -3.0364105e-01  2.0529646e-01]]]\n",
      "\n",
      "\n",
      " [[[-3.0364910e-01  2.1133392e-01 -3.0197176e-01 ...  3.4061414e-01\n",
      "     1.6379695e-01  3.0065507e-01]\n",
      "   [ 4.7394094e-01 -3.4299260e-01 -8.9139350e-02 ... -3.6886510e-01\n",
      "    -2.7557203e-01 -3.9059925e-01]\n",
      "   [ 2.4765603e-01 -1.6345866e-01  3.8508493e-01 ...  8.5766770e-02\n",
      "    -1.9260256e-01  4.6289435e-01]]\n",
      "\n",
      "  [[ 3.4856060e-01  7.1823642e-02 -1.4948408e-01 ...  2.0554176e-01\n",
      "     3.1898004e-01 -2.7316517e-01]\n",
      "   [ 3.1358933e-01  1.1384933e-01 -4.2424023e-02 ... -4.3828182e-02\n",
      "     1.0665629e-01 -1.7566063e-01]\n",
      "   [-2.0270255e-01 -3.2226738e-01  2.7142820e-01 ...  6.3495684e-01\n",
      "    -4.1450210e-02  1.8471980e-01]]\n",
      "\n",
      "  [[-2.7030930e-01  8.1891678e-02 -3.7165800e-01 ...  4.8490498e-02\n",
      "     3.1705651e-01  8.9626878e-02]\n",
      "   [ 1.3864206e-01  3.4483263e-01  6.2239552e-01 ...  2.1045722e-01\n",
      "     2.7314892e-01 -6.1190087e-01]\n",
      "   [-2.0783974e-01  2.5100258e-01 -2.0554218e-01 ... -5.0210530e-01\n",
      "     2.7545020e-01 -3.9143458e-01]]]]\n",
      "discriminator_8/conv_block_82/conv2d_82/bias:0 [ 3.23548011e-04 -3.00981246e-05 -3.20461841e-04  4.39055322e-04\n",
      " -7.95124564e-04 -1.77451584e-04  1.07688800e-04 -6.05912055e-06\n",
      " -2.70006509e-04 -7.36729489e-05 -1.84867240e-04  2.07627745e-05\n",
      " -5.43718561e-05 -2.88117571e-05 -6.14706427e-04 -2.03754898e-04\n",
      " -3.24685185e-04 -5.10525482e-04  1.02848957e-04  4.43702302e-04\n",
      " -2.76650593e-04 -1.11959680e-05  8.59498396e-05 -5.40391717e-04\n",
      "  1.55609596e-05 -8.64177782e-05  3.44383850e-04 -3.65848915e-04\n",
      " -1.22417723e-05 -6.36226789e-04 -3.37626785e-04  4.85353929e-04\n",
      " -9.82126148e-05 -5.51212055e-04 -2.08549108e-03  1.66519036e-04\n",
      "  4.15465474e-04 -2.20626593e-04  8.48667580e-04  4.15514893e-04\n",
      "  3.90774047e-04  8.92933807e-04 -1.00577704e-03 -2.16955683e-04\n",
      " -2.21170543e-04  6.73702161e-05  2.86604482e-04  1.07426883e-03\n",
      " -4.84282558e-04 -5.08768600e-04 -2.61217356e-04 -7.48266524e-04\n",
      " -1.62121694e-04  4.38894713e-05 -1.33718186e-06 -3.73011921e-04\n",
      " -1.86054574e-04  3.65248939e-04  7.30167012e-05 -8.35373430e-05\n",
      " -1.59065574e-04 -3.47022462e-04 -4.22792073e-04  9.09129230e-05\n",
      " -6.08133734e-04 -3.35728982e-04  2.51974707e-05  6.60484366e-05\n",
      " -1.17997243e-03 -3.40293569e-04  1.96910987e-04  2.82695371e-04\n",
      "  4.27116291e-04  7.67067308e-04  2.32029473e-04 -4.40368836e-04\n",
      "  2.62727663e-05  3.44210866e-06  2.88640440e-04 -1.19545926e-04\n",
      " -2.73005444e-05  7.89458863e-04 -3.18549108e-04 -3.20568040e-04\n",
      "  1.84494638e-05  5.01799832e-06  6.00367675e-05  1.00364350e-03\n",
      " -1.20412100e-04  1.14972610e-03 -6.63518556e-04  4.23262536e-04\n",
      " -1.19642180e-04 -2.59203807e-04  1.48304156e-04  4.06009873e-04\n",
      "  4.51002416e-04  6.10737989e-05 -5.05729462e-04 -3.28264548e-04\n",
      " -3.25796864e-04 -4.12935915e-04 -9.40664206e-04  1.38707494e-03\n",
      " -1.45244936e-04 -5.47375006e-04  8.80860782e-04 -3.14734752e-05\n",
      "  3.96753421e-05 -4.11566958e-04 -6.91064124e-05  3.50532675e-04\n",
      "  5.71149249e-05  1.30838039e-03  5.07419289e-04 -1.23071019e-04\n",
      " -3.52603878e-04  1.83656914e-04 -4.93942003e-04  2.60014029e-04\n",
      "  6.00402418e-05 -1.95882880e-04 -8.17101391e-04 -1.90753359e-04\n",
      "  1.05399682e-04 -2.73647573e-04 -3.98211705e-05 -1.30577937e-05\n",
      "  2.91899982e-04 -3.77375472e-05  6.24369248e-04  3.15773388e-04\n",
      "  2.43062605e-04 -7.26979692e-04 -5.65567207e-05 -9.44050669e-04\n",
      "  7.47739105e-05 -5.42088063e-04  4.97193192e-04 -3.82010621e-05\n",
      " -7.03211059e-04  2.43986124e-05  3.88789085e-05 -2.00036186e-04\n",
      " -4.87377460e-04  1.50848835e-04 -3.93927476e-04 -2.53971171e-04\n",
      "  3.24890716e-05 -4.92895546e-04  1.61229545e-04  2.53608359e-05\n",
      " -1.79888302e-04 -3.89393710e-04  7.97491812e-05  1.52012202e-04\n",
      " -4.61047952e-04  5.75050246e-04  9.63183353e-04  2.54752144e-04\n",
      "  4.95097600e-04 -1.20885539e-04  1.31536144e-04  6.75444317e-04\n",
      " -3.37023142e-04 -3.74883704e-04  1.93566593e-04 -8.27404088e-04\n",
      " -1.14269431e-04 -5.63672336e-04  5.78566222e-04  9.48715955e-04\n",
      "  1.07041339e-03 -2.29788449e-04  4.83136100e-04  4.33884590e-04\n",
      " -1.50284410e-04  4.26189363e-05  7.08297186e-04 -8.80866020e-04\n",
      " -3.11486569e-04 -3.39336373e-04  1.40497461e-04  1.05664693e-03\n",
      " -2.69802666e-04 -1.31137203e-04  1.03254151e-05  1.57247938e-04\n",
      "  2.52671045e-04 -4.64759971e-04 -5.34880091e-04  6.41481194e-04\n",
      "  2.33717030e-04  4.31149965e-06 -2.17201741e-04 -4.32954723e-04\n",
      "  1.16307339e-04 -7.22313649e-04 -2.55441846e-04 -2.80713488e-04\n",
      "  1.05743973e-04  3.22407082e-04 -3.07632261e-04  1.49142637e-04\n",
      " -1.58262570e-04 -3.61453334e-04 -1.16927375e-04 -9.69624962e-04\n",
      "  3.54117044e-04  1.31890789e-04 -2.62451358e-04  4.30859451e-04\n",
      "  6.28051755e-04  1.35397000e-04  2.77706189e-04 -1.79718932e-04\n",
      "  5.49373799e-05  5.90554613e-04 -2.76685547e-04 -6.32363895e-04\n",
      "  1.97129521e-05 -9.11618481e-05 -5.96387952e-04 -1.87594036e-04\n",
      " -2.76828159e-05  8.27062351e-04  9.56678123e-04  1.00700898e-04\n",
      " -9.70757610e-05  1.90192644e-04  1.71970241e-04 -7.48945575e-04\n",
      "  3.94826260e-04  5.14740204e-05 -1.23569602e-03  2.62290676e-04\n",
      "  1.52429411e-05 -1.64029756e-04 -3.22514214e-04  3.33772390e-04\n",
      "  5.34796527e-05  1.39416967e-04  6.11112628e-05  3.47322755e-04\n",
      "  7.63669610e-04  6.27588714e-04 -4.19795862e-04 -3.72953218e-04\n",
      " -1.22962650e-04 -8.56928644e-04 -5.95265155e-05 -3.29136557e-04\n",
      " -1.59095813e-04 -8.07613014e-06  8.91782474e-06 -1.82822827e-04\n",
      "  2.31144986e-05 -2.08268539e-04 -2.14692045e-06 -1.47545536e-03\n",
      " -5.40303474e-04 -1.20975665e-05  2.36529682e-04  4.76785557e-04\n",
      "  6.63055747e-04 -1.27596859e-05  2.58933549e-04 -6.00548054e-04\n",
      "  5.63020469e-04 -1.47707964e-04 -1.40049582e-04 -5.55085076e-04\n",
      " -2.53116421e-04 -6.29786809e-05  7.34345813e-05 -6.81830061e-05\n",
      " -1.92912048e-04 -4.63250384e-04 -2.25596996e-05 -4.10888199e-04\n",
      "  7.64851691e-04 -9.97617026e-05  6.63252082e-04  5.66044124e-04\n",
      " -1.79409453e-05 -1.31007587e-03  6.26379260e-05  4.87958896e-04\n",
      " -7.17175426e-04  5.85471455e-04  1.48792961e-03  1.05704938e-03\n",
      "  5.55962964e-04 -2.53440521e-04  1.38713163e-04 -2.57594686e-04\n",
      " -4.21039469e-04 -8.73509853e-05  3.34963843e-04  4.75453533e-04\n",
      "  8.58903295e-05  6.03372697e-04 -6.13841985e-04 -4.47349012e-04\n",
      " -2.60739413e-04  7.71035731e-04  1.78645452e-04  3.64300977e-05\n",
      " -2.72870791e-04  2.04327487e-04 -1.06555235e-04  3.10878095e-04\n",
      " -2.00981798e-04 -1.20851770e-03  8.00338748e-05  1.52765744e-04\n",
      " -2.83440517e-04 -2.87248531e-05 -3.72527807e-04 -4.76025860e-04\n",
      " -1.84568242e-04 -9.27610236e-05  3.41336243e-04 -1.50537016e-04\n",
      " -2.02311669e-04 -1.10142391e-04  2.20190821e-04  1.87044483e-04\n",
      "  3.77200078e-04 -2.35401851e-04 -4.00481164e-04  1.24326313e-03\n",
      " -3.20473810e-05  2.01072282e-04  4.61261312e-04  3.30834999e-04\n",
      "  6.96764982e-05  2.44472641e-04  1.45618586e-04  5.54228667e-04\n",
      " -6.98294956e-04  8.45399700e-05  2.26551740e-04 -1.17057250e-04\n",
      "  1.97218615e-04  6.70016685e-04 -1.23845052e-03  1.29867127e-04\n",
      " -7.42493372e-04 -9.67558415e-04  6.43132546e-04 -5.45276271e-04\n",
      "  2.22970630e-04  3.22629558e-03  4.49264044e-04 -2.39230896e-04\n",
      " -4.16374591e-04  8.95941848e-05  9.53088020e-05  1.43807483e-04\n",
      " -1.86513877e-04 -8.71234573e-04  2.57334788e-04 -1.07049171e-04\n",
      "  6.57935860e-04  2.36887543e-04  3.36988887e-04 -2.00208175e-04\n",
      " -6.22288790e-05 -3.92347778e-04 -1.37665238e-05 -2.56514089e-04\n",
      "  1.42198449e-04 -6.50828515e-05 -6.06676098e-04  9.70847963e-04\n",
      "  4.39865486e-04  2.30295118e-04  9.81376288e-05 -2.50375975e-04\n",
      " -2.68063508e-04 -6.03443361e-04  1.84859688e-04  3.80062520e-05\n",
      " -2.87754025e-04  6.17192360e-04 -1.09038061e-04 -1.75160123e-04\n",
      "  6.83179314e-05  4.42975550e-04  1.13577757e-04 -6.28525813e-05\n",
      "  5.17371926e-04 -2.85817980e-04 -3.50261485e-04 -1.32627501e-05\n",
      "  1.55036119e-04  1.85099314e-03 -1.19558870e-04 -5.47099975e-04\n",
      "  2.99284264e-04  5.81745582e-04  5.98041690e-04 -5.93591249e-04\n",
      " -1.41745011e-04  2.06781930e-04  4.02605860e-04 -1.18251461e-04\n",
      "  1.74996167e-05  5.35845698e-04  7.08642765e-05  2.54632032e-04\n",
      " -7.93561630e-05 -1.56276021e-03  1.46949067e-04 -3.53923206e-05\n",
      " -2.73549576e-05  3.87008622e-04 -8.27097450e-04 -1.50294486e-03\n",
      " -4.69004299e-04 -2.19466965e-04  5.34652092e-04  2.60956149e-04\n",
      "  1.84382749e-04 -3.31798697e-06 -1.32306450e-04  1.00921621e-04\n",
      " -9.06550849e-04  8.11467122e-04 -6.10205927e-04  8.26156902e-05\n",
      "  2.81388784e-04  5.99671097e-04  6.96621237e-06  9.97558673e-05\n",
      "  4.83350916e-04 -5.63175883e-04 -1.82172196e-04 -1.13367016e-04\n",
      " -2.18384492e-04 -2.17623165e-04  5.37146640e-04 -3.08417017e-04\n",
      "  5.95580750e-05 -2.43381524e-04 -2.47777003e-04  9.08217771e-05\n",
      "  4.66121739e-04  2.65959516e-05 -2.35234867e-04  1.50726381e-04\n",
      "  8.90551892e-05  1.15766496e-04 -1.91776737e-04  6.80708617e-04\n",
      "  7.23639241e-05  1.09871900e-04  3.13319120e-04 -9.14364427e-05\n",
      "  1.33111942e-04 -2.20113798e-04  3.63674597e-04 -8.89751129e-04\n",
      " -1.07007660e-03 -2.47627409e-04  1.39961674e-04 -5.57258027e-04\n",
      "  3.43138148e-04 -1.79998897e-05 -3.59358546e-06 -1.83331920e-03\n",
      " -2.57389824e-04  3.75599484e-04  5.63548470e-04 -1.14231123e-04\n",
      " -1.95637822e-05  2.68466887e-04 -6.05969399e-04 -2.97276652e-04\n",
      " -2.57352920e-04 -1.32152258e-04  1.04992920e-04  2.02533629e-04\n",
      "  9.51345719e-05 -1.47211511e-04 -2.03180520e-04  8.53656209e-04\n",
      " -1.40119009e-04 -5.23842755e-04 -7.44692865e-04 -1.12667936e-03\n",
      " -4.74481058e-04 -3.34374112e-04 -4.22149242e-05  1.56995055e-04\n",
      "  4.05321225e-05 -1.44990481e-04 -1.25310093e-03 -3.81682457e-06\n",
      "  2.92364330e-05  6.69312212e-05 -5.85246789e-06 -1.17635253e-04\n",
      "  4.54961264e-04 -5.66802919e-04  3.75754869e-04 -1.09341570e-04\n",
      "  6.15880999e-04 -2.50753452e-04 -3.43125372e-04 -6.25562052e-06]\n",
      "discriminator_8/conv_block_82/batch_normalization_136/gamma:0 [0.97606474 1.0047202  0.9971799  0.97132474 1.0112909  1.0210828\n",
      " 0.98593676 0.9991997  0.9984038  0.9862995  1.0006875  0.99760085\n",
      " 0.97304153 0.99948865 1.0033661  0.96413386 0.9780452  1.0178365\n",
      " 1.013443   0.98094076 1.0120225  0.98841584 0.9813497  1.0053798\n",
      " 0.9897289  1.0233914  0.9786033  1.0050385  0.9912079  0.99053276\n",
      " 0.9859527  1.0134735  0.9935306  0.9878714  1.0682397  1.0136982\n",
      " 1.0223507  1.0025691  0.98501724 0.99203426 0.98704636 1.0073907\n",
      " 0.9940505  0.9881479  0.99615437 0.98555833 0.9879277  1.0294814\n",
      " 0.99124503 1.001169   0.9946592  1.009533   1.045174   1.0039809\n",
      " 0.982174   1.0247506  0.9861986  0.9926661  1.0033294  0.9912866\n",
      " 0.9930181  1.0036112  1.1407748  1.0186524  1.0412459  0.99582446\n",
      " 1.0509598  1.0151758  0.9890128  0.9929338  1.006193   0.9988879\n",
      " 1.0277381  1.0134014  0.9993024  1.0344869  0.9750731  1.0053331\n",
      " 0.9982954  0.9924156  1.0049739  0.98986316 1.0060202  0.9850842\n",
      " 0.9988974  1.0057998  0.98350364 0.9926546  1.0669963  1.0368581\n",
      " 1.040552   0.9866212  1.0082504  1.0048308  1.0054041  1.0045389\n",
      " 0.9912784  0.9853467  1.0013943  1.1185821  0.9951862  0.9917661\n",
      " 1.0580115  0.9945317  0.99579835 0.9971598  0.98543644 1.0108495\n",
      " 1.0049938  0.9795636  0.9838693  1.0656531  0.9761287  0.99985486\n",
      " 1.0257952  0.99527854 1.0347941  0.9745544  0.98888654 0.9754169\n",
      " 0.9861314  0.9921289  1.0169202  1.012711   1.0030378  1.0049357\n",
      " 0.9897883  0.987522   1.0046993  0.98984784 0.9505973  1.0139958\n",
      " 0.99331623 0.9877655  0.9746666  1.000217   0.9821585  0.99088836\n",
      " 1.0309943  0.9951686  0.97992945 1.0187879  1.0014718  0.9658492\n",
      " 0.98493373 0.9836467  0.9951012  1.0002387  0.9937147  0.96679306\n",
      " 0.9881412  0.9850247  1.0619723  0.97334695 0.97977114 1.0215211\n",
      " 1.0034052  0.9921571  1.1094927  0.9743953  1.0530204  1.1024187\n",
      " 0.95670056 1.0380865  1.005805   0.9941118  0.9953336  1.0465266\n",
      " 0.9775747  0.98761153 0.99945045 1.039902   0.9859352  0.9858665\n",
      " 0.9839916  1.0059711  0.98682946 0.9847287  0.97986776 0.9901766\n",
      " 0.9920793  1.0163541  0.9772166  1.0869592  1.0133954  0.99508494\n",
      " 1.0071403  0.98602396 0.9921667  0.9767291  0.99158514 0.984359\n",
      " 0.987311   0.98157656 0.98972255 0.9751649  0.9814829  0.99441916\n",
      " 0.9979058  0.99025923 0.97835684 1.0201205  1.0250742  0.9931129\n",
      " 0.9821193  0.99520326 1.0622481  0.9784246  0.989185   0.9792169\n",
      " 0.9998438  0.9844071  1.0068821  1.0086554  1.0135893  1.003431\n",
      " 1.0024587  0.9705373  1.0020435  1.0073181  0.9944053  0.98496956\n",
      " 0.99942505 1.0155805  0.9679344  0.97367305 0.9956317  0.99760383\n",
      " 1.0108805  1.0236368  1.0041277  1.0746496  0.9697917  0.9979227\n",
      " 1.0721408  0.98458487 0.99761885 1.00036    0.97739315 1.0034516\n",
      " 1.0002499  0.98085463 1.105177   1.0284392  0.97837913 1.0105672\n",
      " 0.99050426 0.9949093  1.0067307  0.98624283 1.011613   0.988051\n",
      " 0.992982   0.9891953  0.99517244 0.9713669  1.0328846  1.0400859\n",
      " 1.0080062  1.0207479  1.031289   0.9820577  1.0064881  0.99740845\n",
      " 0.98301494 0.9997813  1.0404458  1.0120082  1.0139697  0.96443444\n",
      " 0.99334466 1.0794958  1.0066602  1.0465125  0.9902436  1.0198061\n",
      " 0.98243606 0.99467206 0.99011165 0.974114   1.0012879  0.99093723\n",
      " 0.9895175  0.97019905 0.95978963 1.0165882  1.0004534  1.012612\n",
      " 1.0019015  1.0029851  1.0176274  1.081494   0.99583685 1.012929\n",
      " 1.0007879  1.0190747  0.9978724  1.0512353  0.9960802  0.9963779\n",
      " 0.9822454  1.0096914  0.96556735 1.0015389  1.0039116  0.9878168\n",
      " 1.0532941  1.0287917  0.9976016  0.9863398  0.9753205  1.0086268\n",
      " 0.97919    0.992635   0.9851753  0.9655952  0.9977131  0.97672164\n",
      " 1.0361202  1.0533485  1.0168762  1.0004332  0.9976781  1.0158098\n",
      " 1.0087031  0.9961796  0.9715741  0.97982985 0.98770833 0.99325037\n",
      " 0.98819095 0.99801946 0.9884563  0.9838673  1.0135257  1.0253943\n",
      " 0.9978716  0.995647   0.98807305 0.99599916 0.98713815 0.9760566\n",
      " 0.9528496  0.9861525  0.96427405 0.9854194  0.9984126  1.1312563\n",
      " 1.0025605  0.9992587  1.0235254  0.9768836  0.99341244 1.0862896\n",
      " 0.99329275 1.0081381  1.003356   0.9892807  1.0297503  0.986704\n",
      " 1.006514   1.0987421  1.0110348  0.99552965 1.009795   0.9809644\n",
      " 0.99476653 0.98959273 1.0296917  1.0086708  1.0227773  0.99706197\n",
      " 0.97979504 0.9842455  1.0069032  1.0113608  0.98339105 1.0621914\n",
      " 0.9913087  0.9901317  1.0232656  1.0641301  0.984535   0.9977596\n",
      " 0.9917918  1.0111591  0.9823638  1.0061601  0.9948736  0.9805023\n",
      " 0.9845717  0.9975877  0.9932607  0.9924533  1.0017074  1.0102185\n",
      " 1.013425   0.99121445 1.0111632  1.0022832  0.99518895 0.98592824\n",
      " 0.9914768  1.0180124  0.9862692  0.97939813 1.0140771  0.9775753\n",
      " 0.9891631  0.9928404  0.9999263  0.9914904  1.0169644  0.9980487\n",
      " 1.0559156  0.97898954 0.9850719  1.0034472  0.9954161  0.9722035\n",
      " 0.9876783  0.9837913  1.0222764  1.0455334  1.0002936  0.9966967\n",
      " 0.99106866 1.0097024  0.9847316  0.9973091  0.99747205 0.98236847\n",
      " 1.0318538  1.0692794  1.0178857  1.0067314  1.1018147  1.015507\n",
      " 1.0107147  0.99293524 0.9952496  0.9877     1.0190412  1.0007327\n",
      " 0.98996747 1.0137321  0.9818163  0.9568517  1.0204217  0.98366433\n",
      " 0.99649364 1.0297316  0.97664446 0.9963678  1.0049866  1.0051115\n",
      " 1.0166858  0.97868884 0.98912483 0.9966996  0.9953806  1.0214802\n",
      " 1.0164738  1.0088222  0.9931503  0.9746516  1.0319571  1.019118\n",
      " 1.0122017  1.0007167  0.9940671  0.9948134  0.99719113 1.00286\n",
      " 0.9976402  1.0033464  1.0143591  0.9778903  0.98975545 1.0031418\n",
      " 0.9809155  0.9944297  0.99620926 0.9855437  1.0351585  1.0032368\n",
      " 0.9872566  1.0295347  0.9985458  0.967718   1.0165936  1.0006137\n",
      " 1.0239458  0.98355275 0.9979168  0.995562   0.97760487 1.0009463\n",
      " 0.9995431  1.0275732  0.9879802  1.0101527  1.0153333  1.0344969\n",
      " 0.9925828  0.9929945  0.999244   0.9866788  1.0514202  0.9807063\n",
      " 1.0030909  0.96187305]\n",
      "discriminator_8/conv_block_82/batch_normalization_136/beta:0 [ 2.18007453e-02  3.27748922e-03  1.13858702e-02  2.10940130e-02\n",
      " -2.60962732e-02  9.36432183e-03  8.02826975e-03  9.78761725e-03\n",
      "  8.25416483e-03 -4.92216973e-03 -2.68112496e-02  4.85645980e-03\n",
      "  1.96729340e-02 -1.79369692e-02 -2.46274495e-03 -1.49153955e-02\n",
      " -9.38848220e-03  3.44168916e-02  1.67310759e-02 -2.22195359e-03\n",
      " -3.05818557e-03 -1.42015219e-02  8.45764298e-03 -8.06822814e-03\n",
      " -1.68982930e-02  3.11342105e-02  1.67760756e-02  6.71392260e-03\n",
      "  1.28447050e-02 -1.70389004e-03 -4.10078140e-03  1.61271933e-02\n",
      "  3.28054242e-02  1.27908587e-02  1.24646761e-01  7.52442633e-04\n",
      "  6.99498318e-03  2.52227206e-02  1.35883717e-02 -2.32940982e-03\n",
      " -1.09224990e-02  3.01966630e-03 -8.40834473e-05  2.50354093e-02\n",
      "  2.38189586e-02 -9.41228680e-03 -3.28333378e-02  8.66395086e-02\n",
      "  4.73068299e-04  1.31500373e-03 -6.36451459e-03  3.55656282e-03\n",
      "  1.12868942e-01 -6.48359815e-03 -1.52251171e-02  2.96040103e-02\n",
      "  1.06298039e-03  7.26625696e-03  2.36149449e-02  5.00821974e-03\n",
      "  1.08038886e-02  8.09611566e-03  7.16051906e-02  4.86655021e-03\n",
      " -4.88316128e-03  2.25806292e-02  4.48523536e-02  2.73558889e-02\n",
      "  5.40578328e-02 -1.12426924e-02  9.48178954e-03 -2.28974894e-02\n",
      "  9.45031922e-03  1.01796677e-02 -1.21532651e-02  5.95745519e-02\n",
      "  2.50206306e-03  1.54150501e-02  9.14723333e-03  7.17075961e-03\n",
      " -2.25819857e-03  2.74500460e-03  3.60930542e-04 -2.47137854e-03\n",
      " -1.00736888e-02 -3.06920335e-03  2.07546484e-02  1.44112064e-02\n",
      "  5.34048304e-02  5.23811057e-02  4.09157351e-02  2.27626357e-02\n",
      "  8.04649852e-03  8.60756915e-03  6.47400087e-03 -3.19787227e-02\n",
      " -3.26077524e-03 -1.83149404e-03 -1.98571794e-02  1.51058123e-01\n",
      " -3.45656881e-03  2.04147510e-02  5.50640225e-02 -2.12326478e-02\n",
      "  2.58683022e-02  1.70178767e-02  1.59026310e-02  1.73853361e-03\n",
      " -1.62537247e-02 -5.65035269e-03 -1.78903751e-02  7.54272714e-02\n",
      "  1.57553758e-02  1.30358189e-02  3.54252644e-02 -1.59537923e-02\n",
      "  3.93748917e-02  6.58927951e-03  9.51090530e-02  7.00236065e-03\n",
      " -1.36254122e-02 -7.05419807e-03 -1.26084629e-02  5.59523068e-02\n",
      "  4.72197793e-02  6.68338686e-03  2.14898493e-02 -1.25644812e-02\n",
      "  1.13045648e-02 -5.88917220e-03  2.32221913e-02  1.02870436e-02\n",
      " -1.31921396e-02 -8.84861499e-03 -8.88634752e-03 -2.13326961e-02\n",
      " -1.08329197e-02  9.29980353e-03  2.98724067e-03  9.90077481e-03\n",
      "  2.63136122e-02  2.53211129e-02 -1.38749965e-04 -2.21719146e-02\n",
      " -1.19922087e-02 -1.56523427e-03 -3.38990688e-02  1.32692792e-02\n",
      "  2.83200927e-02 -3.72465514e-03 -9.27748531e-03 -1.07232854e-03\n",
      "  4.81829494e-02 -8.07263795e-03 -1.34269928e-03  9.01739951e-03\n",
      "  4.59267087e-02  1.78390313e-02  9.89442244e-02  1.47931734e-02\n",
      " -4.87659080e-03  2.96144262e-02 -1.77434999e-02  2.87196264e-02\n",
      "  4.49442957e-03  5.93277253e-03 -3.26219626e-04  1.18500419e-01\n",
      "  7.15657510e-03 -5.89979021e-03  8.30002502e-03  7.00319069e-04\n",
      "  1.03931967e-02  4.41761484e-04  8.07987805e-03  3.04148924e-02\n",
      " -1.35972891e-02  4.02766839e-03 -1.35445064e-02  8.42504203e-03\n",
      " -3.29988630e-04  4.14860100e-02 -2.33657509e-02  5.71167134e-02\n",
      " -5.42445155e-03 -5.24638360e-03  1.03407856e-02  2.06242334e-02\n",
      " -2.15906347e-03  2.80277468e-02 -1.20651880e-02  1.31083112e-02\n",
      "  7.26250000e-03 -5.45580871e-04 -6.12370856e-03 -2.67149247e-02\n",
      " -2.80986112e-02 -2.24054400e-02 -2.51760315e-02 -3.60367796e-03\n",
      " -6.44075451e-03  1.85031109e-02  6.76352764e-03 -2.50349808e-02\n",
      " -9.12611838e-03 -1.75965298e-02  8.45583249e-03  9.76165384e-03\n",
      "  1.08651016e-02  1.64217222e-02  2.16091960e-03  2.05814689e-02\n",
      "  2.67979968e-02  2.66795624e-02  4.80180681e-02  1.75463092e-02\n",
      " -1.90532282e-02  2.64158063e-02  3.65780704e-02  3.06207426e-02\n",
      "  2.41421489e-03  2.05283761e-02  2.13890783e-02 -8.01677350e-03\n",
      " -4.02995758e-03  3.39483027e-03  4.94102426e-02 -2.93455515e-02\n",
      "  4.69830679e-03  3.56558003e-02  3.98122557e-02 -9.70473792e-03\n",
      "  3.68138850e-02  6.70280773e-03  5.25399186e-02 -1.74558256e-02\n",
      " -1.46645950e-02  6.40516263e-03  3.95130541e-04  9.56566539e-03\n",
      " -1.14124129e-02 -6.21328456e-03  6.83466792e-02  4.88567390e-02\n",
      " -1.74090602e-02 -9.29296075e-04  3.00494134e-02 -4.41283127e-03\n",
      " -6.35039993e-03  1.27271684e-02 -2.37901392e-03  1.14217047e-02\n",
      " -1.16917919e-02 -6.88995235e-03 -5.37840649e-03 -5.79887023e-03\n",
      "  3.85279395e-02  6.08224645e-02  2.82747541e-02  6.26552999e-02\n",
      "  7.17286766e-03 -9.51938052e-03 -6.30502868e-03 -2.94258948e-02\n",
      " -1.28842229e-02 -1.33755300e-02  3.92380096e-02  3.32872085e-02\n",
      "  1.95768643e-02 -1.37519026e-02  2.15035230e-02  6.41408265e-02\n",
      " -1.61468554e-02  3.65872644e-02  5.86915063e-03  3.15682292e-02\n",
      " -1.59163419e-02 -3.33409086e-02  2.53054071e-02  8.78498331e-03\n",
      "  2.66372808e-03  9.14575811e-03  6.42372807e-03 -1.96533594e-02\n",
      " -1.78034641e-02  4.11405191e-02 -2.91022705e-04  8.91670864e-03\n",
      "  2.60344148e-03  3.52446362e-03 -2.77670962e-03  5.60981221e-02\n",
      "  1.38406381e-02  3.36646028e-02 -2.54295906e-03  3.04822139e-02\n",
      "  1.92396576e-03  5.53988405e-02  1.03470860e-02  4.06144820e-02\n",
      " -4.70478117e-04  1.28642879e-02 -2.21616384e-02 -5.89291521e-05\n",
      "  1.00757321e-02  3.64306802e-03  4.74503972e-02  3.02101579e-02\n",
      "  3.89590748e-02  1.98452324e-02 -2.25464590e-02  2.39206180e-02\n",
      "  5.96896680e-05 -2.40220167e-02 -8.41780100e-03 -4.25858870e-02\n",
      "  4.71462402e-03 -1.89029574e-02  1.35543169e-02  5.12903258e-02\n",
      "  2.13512536e-02 -6.51030662e-03 -6.88602391e-04  3.59907234e-03\n",
      " -6.17399532e-03  2.49626897e-02  9.18110460e-03 -8.17684829e-03\n",
      "  2.49620853e-03 -6.60312101e-02 -2.70346124e-02 -2.02089138e-02\n",
      "  2.12211031e-02 -2.09521339e-03  1.60254631e-02  5.81801012e-02\n",
      " -1.54869677e-02 -2.14432389e-03  1.28890201e-02 -2.10492648e-02\n",
      " -1.39177972e-02 -2.01946730e-03  1.34000136e-03 -6.92251138e-03\n",
      "  3.23897824e-02 -4.21741558e-03  2.94553488e-02  8.05518478e-02\n",
      "  1.14154927e-02 -6.67671347e-03  5.58441621e-04 -2.93342792e-03\n",
      "  7.80446734e-03  1.01582311e-01 -4.02750596e-02 -4.04017139e-03\n",
      "  8.81284475e-03 -1.85763463e-02 -8.74997862e-03  2.95716897e-02\n",
      "  2.09295619e-02  1.05046563e-01  3.36312428e-02  7.88311940e-03\n",
      " -6.43132895e-04  3.51826614e-03  7.10158423e-03 -3.81453484e-02\n",
      "  5.26748709e-02  6.07426912e-02 -3.95203801e-03  2.82038487e-02\n",
      " -8.87252577e-03 -3.07834824e-04  2.35103350e-02  1.05312513e-02\n",
      " -1.52494735e-03  5.04706949e-02 -2.31444407e-02  3.70679684e-02\n",
      " -2.96703875e-02  9.88108851e-03  2.25538365e-03 -7.87510443e-03\n",
      " -1.68181788e-02  2.52996404e-02 -1.32720610e-02  2.20394321e-03\n",
      " -3.91463470e-03 -1.25248572e-02  2.24234480e-02 -9.02055949e-03\n",
      "  1.56226400e-02  1.64105557e-02 -4.43292921e-03  2.24874169e-03\n",
      "  1.92203838e-02  2.06384417e-02  2.35784389e-02  2.85168197e-02\n",
      " -1.81491412e-02 -2.99406741e-02  1.01467883e-02  8.03651474e-03\n",
      " -2.13102642e-02 -5.33519546e-03  3.78831923e-02  1.15404092e-03\n",
      " -1.21931043e-02 -2.03869380e-02 -7.36304966e-04 -3.06470487e-02\n",
      "  2.65260111e-03  1.33354799e-03  2.57738829e-02  1.12324301e-02\n",
      "  1.56065868e-02  3.35421599e-03  1.82724483e-02  1.29471505e-02\n",
      " -1.83723681e-02  2.71153934e-02  7.10658878e-02  4.65618744e-02\n",
      "  7.99839292e-03  4.15858906e-03  1.25849303e-02  1.92215294e-02\n",
      "  8.18265695e-03  4.53611929e-03  9.37510841e-03  1.14908898e-02\n",
      " -2.41252705e-02  8.32059085e-02  5.89728169e-03 -6.37056399e-03\n",
      " -3.88137661e-02  2.59089973e-02  4.82098497e-02 -1.11307241e-02\n",
      " -2.77146837e-03  2.59146504e-02 -3.46732065e-02  6.17582258e-03\n",
      " -4.92787287e-02  4.32708375e-02  2.48469356e-02 -1.69186783e-03\n",
      "  1.98866203e-02 -5.99538209e-03  1.79231223e-02 -4.22645081e-03\n",
      " -1.27662336e-02 -2.48489641e-02 -2.36221571e-02 -4.26125824e-02\n",
      "  7.80601427e-03  2.65204292e-02 -1.08728372e-02  1.10334400e-02\n",
      " -1.39251491e-02 -1.88232027e-02  4.12577465e-02  1.97340008e-02\n",
      "  3.81839043e-03  1.00741014e-02  1.72749422e-02  2.34881099e-02\n",
      "  1.49386832e-02 -1.48309786e-02  1.31131466e-02 -1.75347086e-03\n",
      " -1.52920615e-02  4.21090657e-03  8.57407879e-03  4.00184058e-02\n",
      " -2.88917497e-02  7.01899594e-03  2.00477242e-02 -4.41412861e-03\n",
      " -9.71194450e-03 -1.57038463e-04  6.76631555e-02  1.30153541e-02\n",
      " -1.60569174e-03 -4.19811998e-03 -6.51616231e-03  6.17495738e-03\n",
      " -2.11329721e-02  1.61885992e-02 -6.31776080e-03  2.79953107e-02\n",
      "  1.53709501e-02  2.30365451e-02 -2.13033264e-03 -6.18738774e-03\n",
      " -1.94902178e-02 -1.56636909e-02 -6.64869277e-03  1.54574756e-02\n",
      "  4.72304737e-03  3.28069143e-02  2.61904411e-02  1.68081746e-02\n",
      " -2.96211001e-02  1.30110036e-03  1.16345892e-02  9.77173215e-04\n",
      "  7.22674429e-02 -2.26346366e-02  3.05629498e-03 -3.27180624e-02]\n",
      "discriminator_8/conv_block_83/conv2d_83/kernel:0 [[[[ 0.00553168 -0.0211132   0.10499072 ... -0.03311641  0.10742904\n",
      "    -0.04642761]\n",
      "   [ 0.11395937  0.02058972  0.0943718  ... -0.01726571  0.05556897\n",
      "    -0.07704554]\n",
      "   [-0.05722071 -0.00409059 -0.05879043 ...  0.05484504 -0.03488487\n",
      "     0.00518113]\n",
      "   ...\n",
      "   [ 0.03267632  0.05857894  0.03253837 ... -0.04812733  0.10563185\n",
      "    -0.03716028]\n",
      "   [-0.01063085 -0.04208915  0.0500355  ... -0.00960482 -0.01670625\n",
      "    -0.06807067]\n",
      "   [-0.07202246 -0.02110525 -0.0915951  ... -0.00124998  0.10197917\n",
      "    -0.00162261]]]]\n",
      "discriminator_8/conv_block_83/conv2d_83/bias:0 [-3.96662836e-06 -2.47996672e-06  9.22512481e-05 -3.75882955e-05\n",
      " -8.83099710e-05  5.66575800e-05 -2.97804479e-04 -1.04191149e-05\n",
      " -3.36370977e-05  9.74935610e-05  6.10897405e-05  1.94688415e-04\n",
      " -2.01790135e-05  1.56809165e-06 -4.28531603e-05  4.76033601e-05\n",
      "  4.06066101e-05  2.36958408e-06  1.57049408e-06 -1.13258131e-04\n",
      "  9.94454531e-05  9.09479604e-06  5.48944299e-05 -4.38369352e-05\n",
      " -4.91878818e-05  9.11464940e-06  4.85724522e-05  3.78040895e-05\n",
      "  1.67915539e-04  4.85581113e-05 -3.84961095e-05  1.06949941e-04\n",
      "  6.99135353e-06  5.45388670e-04  1.33326932e-04  1.90479695e-05\n",
      " -1.89588493e-04  2.61904133e-05  2.68834294e-04  2.60764464e-05\n",
      " -6.90501474e-05  1.64604808e-05  6.84965999e-05  1.53263652e-04\n",
      " -6.15673416e-05 -1.07182714e-05  7.45330617e-05  2.63345064e-05\n",
      " -2.99662406e-05 -2.22583578e-04 -2.61624264e-05  1.44324498e-04\n",
      " -2.21497932e-04 -4.01980287e-05 -4.91607643e-05 -1.41696029e-04\n",
      "  7.22041591e-07 -4.72782958e-05 -1.80102536e-04  3.81295540e-05\n",
      " -3.59799924e-06 -7.65275254e-05  7.60666371e-05  1.30374508e-04\n",
      "  1.42692210e-04  1.96849869e-05 -8.73764948e-05 -5.39799203e-06\n",
      " -4.41444718e-05 -3.51821291e-05  1.65378020e-04 -5.38311579e-05\n",
      "  8.55179678e-05  8.81801316e-06  1.07406602e-04  4.22937228e-05\n",
      "  3.21134867e-05 -8.21096764e-05 -9.63743514e-05  7.14066919e-05\n",
      " -1.92966199e-05  1.14669376e-04  1.19707496e-04 -1.35583068e-05\n",
      "  1.07409214e-04  9.15444107e-05  6.86150161e-05 -3.40773004e-05\n",
      " -4.59658804e-05  2.59741228e-06  3.19873594e-04  5.51289959e-05\n",
      "  1.08041677e-05  1.88499089e-05 -3.18488565e-05 -6.30663199e-05\n",
      "  1.42728270e-04 -1.96745765e-04  7.00828736e-04 -7.30737520e-05\n",
      " -1.13239737e-04 -1.72777669e-04  9.76180490e-06 -3.79328958e-05\n",
      " -2.41724883e-05 -1.18499353e-04  1.97233367e-05 -1.02522514e-04\n",
      "  1.77574926e-04  2.94393558e-05  9.20477687e-05  5.18668676e-05\n",
      " -2.58528635e-05  4.47418097e-06  4.45586156e-05  2.37085071e-04\n",
      " -3.75159070e-05  7.36766233e-05  2.20180940e-04 -3.74056290e-05\n",
      "  2.45517385e-05 -1.83451921e-05  3.47809037e-05 -5.11583676e-05\n",
      " -4.95412620e-04 -9.96104973e-06  2.07313758e-04  1.79292492e-05\n",
      " -5.09857455e-05  6.28466005e-05 -2.46344280e-05 -7.18171214e-05\n",
      " -2.31796785e-05  2.89449235e-05  1.42593472e-05  3.00957981e-05\n",
      " -1.35546134e-05  1.75274035e-04  4.49231447e-05 -4.34265276e-05\n",
      " -6.08277478e-05  1.49166408e-05 -2.27282453e-05  5.39403736e-05\n",
      " -5.37173946e-06  5.01510549e-05 -1.09339599e-05 -1.83050113e-04\n",
      "  1.55751943e-04  6.91352000e-07 -9.40627433e-05  1.37872867e-05\n",
      " -1.03772372e-05  9.03086766e-05  2.57305401e-05  1.02516442e-05\n",
      "  3.91459434e-05  1.14037997e-04  4.55311965e-05  2.65987001e-05\n",
      "  4.24177306e-05  2.07186222e-05  1.40832984e-04  1.09351160e-04\n",
      " -4.31023400e-05  3.46931956e-05 -2.50241836e-04 -5.11160251e-05\n",
      " -2.44734547e-05  1.17940806e-04 -1.67119128e-04  4.86142453e-05\n",
      " -3.12144075e-05  7.65572840e-05  1.06964071e-04  3.54369258e-05\n",
      "  7.30042802e-06 -5.73387697e-05 -9.42112019e-05  8.37777625e-05\n",
      "  3.92798574e-05  2.66606312e-05 -3.28596943e-05  4.06849722e-06\n",
      " -2.86670729e-05  1.36043251e-04  3.79838002e-06  5.88366820e-04\n",
      " -3.37172605e-05  2.64589507e-05  8.05270683e-05 -8.29466371e-05\n",
      " -4.20091055e-06 -1.12982198e-04 -4.55632216e-05 -7.95704618e-05\n",
      "  2.96852359e-05 -1.20856283e-04 -4.27059858e-05 -6.59538418e-05\n",
      " -3.60318118e-05  4.82604191e-05  8.40767389e-05  1.44010119e-04\n",
      " -4.40176264e-05  5.40567926e-05  1.22328944e-04  5.01114346e-06\n",
      "  2.60691504e-05 -6.13768934e-05 -1.84571454e-05 -8.73727549e-06\n",
      " -1.13458889e-04  5.84922600e-06 -5.13939340e-05 -1.17441450e-04\n",
      "  1.65628785e-06 -1.10750557e-06 -9.02119791e-06  1.21262812e-04\n",
      "  2.68721604e-04  3.62290972e-04  1.26045461e-05  6.78297220e-05\n",
      " -6.12177755e-05  2.54682054e-05  8.35588435e-05 -2.20195987e-04\n",
      "  1.78199880e-05 -9.96574745e-05  3.81327438e-04  1.35909140e-04\n",
      "  1.58939474e-05 -4.36024447e-06 -5.23198378e-06 -4.63556535e-05\n",
      " -3.20723571e-04 -4.37464041e-05  3.13651726e-05 -1.30570799e-04\n",
      " -6.12113217e-06 -1.12800935e-05  6.68891298e-05 -2.06041314e-05\n",
      " -1.77843118e-04  5.32670128e-06 -4.32072702e-05  9.30838214e-05\n",
      "  4.86745957e-05  7.84478179e-05  5.22133232e-05  7.01694589e-05\n",
      " -1.32114510e-04 -6.94143673e-05 -7.65431196e-06 -6.22606531e-05\n",
      " -3.04931946e-05 -5.84734835e-06 -6.12023723e-05  1.01501246e-04\n",
      " -2.65538576e-04 -2.07052526e-05 -2.79674314e-05  4.58231771e-05\n",
      " -1.42127043e-04  1.44865617e-05 -6.72920651e-05 -1.04974890e-04\n",
      " -1.25654897e-05 -4.20818687e-05 -5.91446769e-06  1.11218680e-04\n",
      " -6.17588375e-05 -1.14587692e-05 -3.68708388e-05 -1.79927210e-05\n",
      "  6.37209814e-05 -3.18146012e-05  2.69803768e-05  2.01445600e-05\n",
      "  2.14806161e-04 -1.28377169e-05  2.75095023e-04 -1.32338930e-04\n",
      "  5.91917285e-07  2.42903989e-05 -4.62321303e-04 -4.71658350e-05\n",
      " -2.17193243e-04 -1.32028988e-04 -1.07115957e-04  1.25112899e-06\n",
      "  9.61834212e-06 -1.27836247e-04  1.12662547e-05 -1.61592674e-04\n",
      " -6.69643705e-05 -1.11675736e-05  4.98845693e-05  1.13055994e-05\n",
      " -5.09224265e-06  5.26464646e-05  3.03770707e-04 -6.41278966e-05\n",
      "  6.77361004e-06  1.17782402e-05 -1.13219039e-05  5.11516082e-05\n",
      "  7.32528542e-06 -5.56189516e-05 -2.65147282e-05  1.20402037e-05\n",
      " -3.25496192e-04  1.55928410e-05 -3.37766164e-06 -2.41819202e-04\n",
      "  1.07437772e-05  1.03303893e-04 -1.82500124e-04 -2.86975875e-04\n",
      " -2.17022789e-05  1.95009652e-05 -4.23680285e-05  4.91219616e-05\n",
      " -2.46270793e-05  3.67901375e-05  3.31612646e-05  7.97861594e-06\n",
      " -6.11400719e-06 -4.30000509e-05  3.04061396e-04 -1.44495076e-04\n",
      "  7.45476937e-05  2.50339683e-04  2.46043783e-05  1.60106880e-04\n",
      "  1.83850279e-04 -1.24157057e-04  8.12856597e-05 -5.88813564e-05\n",
      "  5.62269161e-05  1.27750929e-04 -9.40273458e-05 -8.55752223e-05\n",
      " -1.00680641e-04  7.24906567e-05  1.09946421e-04 -5.94716912e-05\n",
      " -2.10203740e-04  8.39820495e-05 -1.59539577e-05 -6.48341011e-05\n",
      " -2.74537379e-05  2.26010616e-05 -6.02902983e-05 -4.44317229e-05\n",
      "  4.35033435e-05 -4.64469413e-05 -4.68516810e-05 -9.08792936e-05\n",
      "  1.23567195e-04 -1.73840078e-06  1.30207511e-04 -1.92845187e-06\n",
      " -1.15810517e-05 -7.30429247e-06  2.11381266e-04 -2.15154450e-05\n",
      " -3.77341094e-05 -5.08198864e-05  8.69202904e-06  1.81583266e-06\n",
      " -7.12206675e-05  1.18623975e-05  1.05994339e-04 -1.17617776e-04\n",
      " -1.81397671e-04  8.77426137e-05  8.29369310e-05 -6.45723558e-05\n",
      "  1.88160029e-05 -1.13003494e-04 -1.62037919e-04 -2.69236971e-05\n",
      "  5.97336766e-05 -8.28170778e-06 -6.07351758e-05 -3.81479585e-05\n",
      " -1.05226820e-04 -1.90850405e-04  3.44907530e-05  1.81255935e-04\n",
      " -6.42486498e-07  9.10503804e-05  2.01470648e-05  1.95052999e-05\n",
      "  1.82438962e-04 -4.49540239e-05  5.47453092e-05 -1.80025556e-04\n",
      "  5.70013581e-05 -3.35232035e-05  1.55637666e-04  4.01719190e-05\n",
      " -6.28476482e-05  4.31268376e-07  6.61765444e-05  8.05473828e-05\n",
      "  2.95613427e-05  4.31064764e-05  3.39061698e-05 -1.45487465e-05\n",
      "  8.01141796e-05  5.72662029e-05 -8.33442245e-05  9.89638211e-05\n",
      "  6.82027458e-05  9.42712722e-06 -6.37170888e-05 -7.25748178e-05\n",
      "  2.34517047e-05 -6.58393856e-06  1.70831525e-04  5.74455589e-05\n",
      " -2.28896883e-04 -5.63176363e-05  5.83675683e-05  2.65131985e-05\n",
      " -6.09253038e-05 -7.36136280e-05 -3.66790919e-05 -7.49117171e-05\n",
      "  2.16160934e-05 -5.84584304e-05  1.62814817e-04 -1.99293791e-05\n",
      "  6.61364757e-05  1.68254497e-04 -6.22891093e-05  6.86813873e-05\n",
      "  3.13350502e-05  2.61726891e-05 -1.20289755e-04  2.57169362e-04\n",
      "  2.04096159e-05 -5.08655430e-05 -1.23452701e-04  8.25149109e-05\n",
      " -2.64342762e-05  2.98394170e-05  9.55929936e-05 -4.20863435e-05\n",
      " -4.71999992e-05 -8.24768358e-06  2.74098857e-05  4.08339074e-05\n",
      "  3.13202327e-05  1.90701303e-05  1.05212828e-04 -7.07051222e-05\n",
      "  1.20135795e-04 -2.92207042e-05  1.09810790e-04 -1.90691964e-04\n",
      "  2.73730234e-06  2.54116196e-04  6.52546878e-05  5.09175152e-06\n",
      " -7.59645773e-05 -5.40719084e-05  5.26752556e-05  3.31591400e-05\n",
      "  7.32202388e-05 -2.31568833e-04  7.44857025e-05  4.35383590e-05\n",
      " -1.59039526e-04 -8.63619971e-06  3.46339075e-05 -1.53438432e-05\n",
      "  5.15900638e-06  1.55196525e-04 -9.26171415e-05 -1.29742511e-05\n",
      " -9.00142259e-05 -5.23418021e-05  1.62195502e-04  2.10959879e-05\n",
      "  3.02012195e-05  2.14304542e-04  1.64210760e-05 -1.29131258e-05\n",
      "  1.41556529e-05  1.14350369e-04 -2.84438988e-06 -4.52729682e-06\n",
      "  4.40060248e-04  1.05128398e-04 -1.72131604e-05 -6.19372222e-05\n",
      " -5.03425326e-05 -5.57158819e-05 -3.94758594e-04  6.42459645e-06\n",
      " -7.11853454e-06  7.66349422e-06 -2.06035431e-04 -2.86253835e-05\n",
      "  3.66306886e-05 -2.16779863e-05 -1.00250409e-05 -2.34517051e-04]\n",
      "discriminator_8/conv_block_83/batch_normalization_137/gamma:0 [0.9835808  0.9977078  1.0119536  0.9953687  0.996419   0.96835566\n",
      " 1.101505   0.97686625 0.99447984 1.0073982  0.98310757 0.99381816\n",
      " 0.98849684 0.97477573 0.9911093  0.9828019  0.990068   0.99312127\n",
      " 1.0313398  0.98854375 0.98765993 0.99333346 0.9749237  0.99194336\n",
      " 0.99755096 0.98618126 0.9944327  0.98552686 1.0437886  0.99852616\n",
      " 0.98991823 1.0219387  0.9902101  1.0874847  1.0463325  0.9935156\n",
      " 1.0048369  0.9745949  1.0123028  0.99692947 0.9933146  0.9711336\n",
      " 0.9760865  1.0447985  0.99177516 0.9802205  0.98364025 1.0046381\n",
      " 1.0103304  1.0040903  0.97024924 0.9973008  1.0480312  1.0114629\n",
      " 0.99135584 0.9794284  1.0001798  1.0025196  1.0402223  0.9836476\n",
      " 0.96888304 0.96784043 0.96370244 1.0261229  0.9945753  0.9911443\n",
      " 0.98211765 0.9594003  0.9974915  0.9876381  1.0083505  0.971044\n",
      " 0.97342783 1.0003182  1.0014459  1.0073204  0.9971969  1.0588533\n",
      " 0.9855025  0.9844345  0.99719465 1.0348333  1.0213044  0.9957918\n",
      " 0.9950289  0.98015195 0.9973306  0.99056274 0.98414207 0.99541193\n",
      " 1.0768926  0.9769628  0.97642106 0.99246377 0.9922029  0.9882859\n",
      " 0.99640316 1.0229087  1.0692021  1.0104079  0.9980853  1.014466\n",
      " 0.9908093  0.99375635 0.99564147 0.9871297  0.9919442  1.0217687\n",
      " 1.0216091  0.9939787  1.0114844  0.9855451  0.99036664 0.9397174\n",
      " 1.0044527  1.0368456  0.99666613 0.9785712  1.0763186  0.9975077\n",
      " 0.98894846 1.0004497  1.0263175  0.98035675 1.0367746  1.0148137\n",
      " 1.0084574  0.9855474  0.9838765  1.0145367  0.98083055 0.9641006\n",
      " 0.98187125 0.97535217 1.0020078  0.98289436 0.98353    1.0408642\n",
      " 0.9972231  0.96590775 0.9638467  1.0069062  0.9825631  1.0056604\n",
      " 0.9829763  1.0042669  0.96352607 1.0593758  0.9884188  0.97345036\n",
      " 1.0261067  1.0038131  0.9909187  0.9907453  1.0325335  1.0005354\n",
      " 1.0006145  0.9912418  1.0068448  0.98744327 0.9864714  0.99437845\n",
      " 1.0290977  1.0784342  0.98860335 0.9808255  1.0213196  0.99043435\n",
      " 1.0006644  1.0008539  1.0310302  0.9957409  0.9858066  0.98358905\n",
      " 0.9929207  0.98606795 0.95194656 1.0099972  0.99120855 1.019984\n",
      " 1.0012482  0.9906594  0.9618461  0.9975705  0.9949838  0.9877442\n",
      " 0.9701089  1.0088387  0.99629706 0.9878605  1.0155327  0.9876395\n",
      " 0.9846949  0.99390984 0.99331045 1.0262119  1.0408037  1.0137287\n",
      " 1.0121719  0.9676616  0.9789545  0.9788982  1.0237365  1.0547031\n",
      " 0.9511391  0.9983871  1.0928478  1.0101761  1.0048357  0.9804152\n",
      " 0.9543244  1.0005332  1.0317721  0.98915446 0.9749043  0.9974885\n",
      " 0.9719504  0.97972614 1.02073    1.0266429  0.9998729  1.1095086\n",
      " 0.9635194  0.987294   1.0306089  0.97572505 1.0386035  1.0163121\n",
      " 0.97058815 1.0062858  1.0338014  0.99800146 0.9796334  0.97207594\n",
      " 0.9839139  0.9644724  1.0500114  0.9883346  0.9776484  0.97196054\n",
      " 0.98292094 0.9933189  0.9864718  0.97181296 1.0337505  0.9955151\n",
      " 0.9560679  0.98778373 0.9910052  1.0428283  0.96664906 0.9824981\n",
      " 0.9943808  0.9950165  0.9770282  1.0275017  0.9908477  0.98018736\n",
      " 0.96487457 1.0046086  1.0290067  1.0069369  0.99556786 1.0002564\n",
      " 1.0270087  0.9708006  0.98281044 1.005574   1.0162791  0.9952749\n",
      " 0.96475375 1.003672   0.9843001  0.99922335 0.9709568  0.9549656\n",
      " 1.0225521  0.9666315  0.99073386 0.9744752  1.0050335  0.97206235\n",
      " 1.0223286  0.9973526  0.98868424 0.9625528  0.995732   0.9704186\n",
      " 1.0141613  0.99947095 0.9983652  0.97285163 0.9705231  1.0030404\n",
      " 0.97940534 1.0004196  0.98519886 0.9849489  0.97833323 0.9809695\n",
      " 0.9781698  0.9980157  1.0049015  0.9907598  0.9763045  1.0058129\n",
      " 0.9852896  0.9944972  0.9510906  1.0293386  0.9930342  0.96988785\n",
      " 1.0116458  0.9756808  0.95866615 1.0572997  0.97622144 0.99046165\n",
      " 1.0076365  1.0117314  0.9691534  0.9566676  0.9939204  0.99310833\n",
      " 0.9979592  1.0216776  0.94033295 0.98780394 0.9808097  0.9892355\n",
      " 1.0387884  0.9697134  0.99564433 1.0237129  0.98010415 1.0444949\n",
      " 1.0194079  0.9841756  0.9818896  0.9796584  0.9882898  0.99056697\n",
      " 0.9810599  1.0024551  0.9893841  0.9742801  1.0104138  1.0112048\n",
      " 1.0235521  1.065256   0.9512322  1.0009662  1.018182   0.9942265\n",
      " 0.9697939  1.0037856  0.9445581  0.990698   0.99062145 1.0338702\n",
      " 0.99040383 0.9969081  1.0075392  0.986685   0.9787917  0.9925121\n",
      " 1.0145679  1.0023191  1.018665   1.0130292  0.9754942  0.9720695\n",
      " 0.97640306 1.0103192  0.99656796 1.0038149  1.0008836  0.9679721\n",
      " 0.9913017  0.9728553  0.99450374 0.98064876 0.98420864 1.0008148\n",
      " 0.99920595 0.9603034  1.0274681  0.97854024 1.0040556  0.9987424\n",
      " 0.9827292  1.0588136  0.9814183  0.97910196 0.98514557 0.9616359\n",
      " 1.1189924  1.0123202  0.9946274  0.9959525  1.0105516  0.9818655\n",
      " 1.0138528  0.99994135 1.0005326  1.0020554  0.9818389  1.0217061\n",
      " 0.97999483 0.97499067 0.99500346 1.0243009  0.9783675  0.9722442\n",
      " 0.97727835 0.968481   0.9914848  0.96866417 0.9864854  0.98548657\n",
      " 0.98822445 0.98911685 0.9943313  0.98331195 1.0209777  1.0128462\n",
      " 0.9798275  0.9811817  0.99110097 1.0911715  0.9977978  0.9849271\n",
      " 1.015064   0.9747799  0.980562   1.0437793  0.9993195  1.0321652\n",
      " 1.0380311  0.98323196 0.99153674 0.98501676 0.9904251  0.99889123\n",
      " 0.98431087 0.9851661  1.0137554  0.97875285 1.0002413  0.98356736\n",
      " 0.95274687 1.0008972  0.9552769  0.99146193 0.9932622  0.9669783\n",
      " 0.9644422  0.9819319  1.0193906  0.976631   1.0125655  0.97555256\n",
      " 0.98907137 1.0389296  0.95469487 1.0145062  0.97119343 0.9937602\n",
      " 0.9886572  1.0143777  0.96227497 0.99171084 1.0053911  1.0152606\n",
      " 0.98620814 0.98713285 1.0921758  0.9960993  0.97187644 0.99103034\n",
      " 0.9802844  1.0171235  0.9859912  0.9748534  0.99481595 0.98474723\n",
      " 1.170009   0.98431826 0.96469545 1.0711479  0.9913766  0.97517353\n",
      " 0.9766187  0.9968165  0.9774535  1.0003799  1.0289893  1.0022217\n",
      " 1.0034649  0.9752555  0.9715328  0.9755351  1.0631955  0.9852467\n",
      " 1.0167148  1.0187888  1.0417163  1.0698764  1.0433207  1.0040451\n",
      " 0.9979882  1.0095531 ]\n",
      "discriminator_8/conv_block_83/batch_normalization_137/beta:0 [ 0.01960421  0.02344457 -0.00714333  0.02026646 -0.01741515 -0.06780355\n",
      " -0.00168975 -0.0019853  -0.02015752  0.02510078 -0.03475861 -0.00125375\n",
      "  0.01693021 -0.02118576 -0.02916855 -0.01450983 -0.02774089  0.0174122\n",
      " -0.03492314 -0.05399509  0.00848245 -0.02666287 -0.00933476 -0.01642359\n",
      "  0.00022149  0.01026189  0.00082084  0.01366068 -0.03000669 -0.01483995\n",
      " -0.03882124 -0.01431924 -0.00505533  0.03049175 -0.0287007  -0.01251109\n",
      "  0.01694951 -0.02925973 -0.01742566  0.00230642 -0.03384646 -0.01368661\n",
      " -0.0158826  -0.00497761 -0.02006174  0.00237114 -0.00987717  0.01944322\n",
      " -0.00805491 -0.00084985  0.00104119  0.00024985 -0.01338519  0.02303799\n",
      "  0.02749295 -0.02568606 -0.0090499  -0.00651624  0.05227408 -0.031171\n",
      " -0.05321907 -0.02267527 -0.03294776 -0.02706999  0.01896949  0.00676776\n",
      " -0.00149981 -0.02677978 -0.01213657 -0.0054361   0.01507922 -0.01149402\n",
      " -0.0085039   0.02009556  0.01200606  0.03021193 -0.01733571  0.04493893\n",
      " -0.0186236  -0.05497083  0.02376046  0.00317264 -0.04790399  0.03426366\n",
      " -0.01018373 -0.03560922  0.01190879  0.01465286  0.00125699  0.01662857\n",
      "  0.03837128 -0.02762194 -0.01181632 -0.01137488 -0.00785106 -0.00924886\n",
      " -0.0023751   0.01311583  0.01171717  0.04421405  0.01724937 -0.0238685\n",
      " -0.0029507  -0.01283972  0.01536384 -0.0109418  -0.00863608 -0.00713589\n",
      "  0.01029736 -0.00012011  0.00130296  0.00656833 -0.02811343 -0.04271205\n",
      "  0.02304831  0.00419093  0.01607606 -0.03211806  0.01512979 -0.00336666\n",
      " -0.02058561  0.02814793 -0.01044581 -0.03590808  0.01595773  0.0196928\n",
      "  0.01386921  0.0053918  -0.00332686  0.04030137 -0.01941895 -0.02811789\n",
      " -0.02647272 -0.06303503  0.00775002 -0.00655699 -0.02547071  0.00966856\n",
      " -0.00296659 -0.02514906 -0.01381495 -0.02286769 -0.01354576  0.00925672\n",
      " -0.01321952  0.02451197 -0.0284129   0.04949269 -0.04057489 -0.01097064\n",
      "  0.04747217  0.00433964 -0.02983985 -0.00684833 -0.02893782  0.00576777\n",
      "  0.00565641  0.00790019  0.00038103 -0.03063375 -0.01839333  0.0101277\n",
      " -0.01552514  0.05657839  0.02130097 -0.01013483  0.03143331  0.01111328\n",
      " -0.03335408 -0.01811573 -0.01068708  0.01251458 -0.05186483 -0.02319035\n",
      "  0.00381138 -0.01959961 -0.04108571  0.00927342  0.00555821 -0.00226847\n",
      " -0.01264411  0.01049432 -0.04676646  0.00714959  0.0042267  -0.01522224\n",
      " -0.03384282 -0.02383634  0.04231025 -0.0074789   0.01893472  0.01131291\n",
      " -0.00554925 -0.02234493 -0.00489077  0.04769948  0.03217581 -0.02448924\n",
      "  0.04230791 -0.01543766 -0.04578003 -0.02657557 -0.03267394  0.02368956\n",
      " -0.01419656 -0.04762827  0.03708668  0.01271496  0.0388233  -0.02738601\n",
      " -0.05792752 -0.01634325  0.03108221  0.01979129 -0.00522082  0.02002866\n",
      "  0.00162788 -0.02461579 -0.00923045  0.02832547 -0.03486388  0.00523833\n",
      " -0.01678165 -0.02339893  0.03620262 -0.02893054  0.03656687 -0.01952509\n",
      " -0.02325229 -0.02301861 -0.00261389 -0.03213019 -0.01465864 -0.01129917\n",
      "  0.00833408 -0.01451228  0.0468641  -0.0169032  -0.02880653 -0.08143728\n",
      " -0.00481006  0.01162238  0.01305321 -0.06872826  0.00604598 -0.00146844\n",
      " -0.03565484 -0.03288899  0.00602511 -0.01917814 -0.01411785  0.01257621\n",
      "  0.03513331  0.00449671 -0.01602712  0.00221905 -0.01188886 -0.00228723\n",
      " -0.0253661   0.01156986 -0.01105321  0.02431581  0.01058327  0.01090569\n",
      " -0.01603196 -0.0030377  -0.01728005  0.0207368  -0.009166    0.0029677\n",
      "  0.00096144 -0.00247045 -0.00209053  0.01762097  0.0019094  -0.03027404\n",
      "  0.01580614 -0.02985428  0.01258023 -0.00771638 -0.01884389 -0.01194773\n",
      " -0.01243395 -0.00365137  0.02644838 -0.02700269 -0.03411935 -0.01861868\n",
      " -0.02566474  0.01566021 -0.00121207 -0.01991471 -0.02687883  0.015888\n",
      " -0.00976922  0.01667895 -0.00898616 -0.03976235 -0.01286976  0.00644587\n",
      " -0.01405733  0.01031465 -0.00561377  0.00266298 -0.01229632 -0.00499258\n",
      "  0.01514338  0.02103858 -0.0356818   0.03768451 -0.01314152 -0.00768678\n",
      " -0.0178359  -0.02714542 -0.01552227 -0.00775422 -0.0067637   0.0038573\n",
      "  0.01214447 -0.02152653 -0.03544419 -0.02051611 -0.01344038  0.01989384\n",
      " -0.03236301  0.00642375 -0.06176636 -0.01378626 -0.00736886 -0.00791738\n",
      " -0.01666182 -0.00258825  0.02296509  0.02819047 -0.04244447 -0.00220229\n",
      " -0.00704739  0.02846206  0.01196191 -0.00347569  0.01012133 -0.00207437\n",
      " -0.01334309  0.01841774 -0.05760274 -0.01903132  0.00148311 -0.02326232\n",
      "  0.00946158 -0.00795535 -0.03979191 -0.0010053  -0.00269685  0.00538606\n",
      " -0.03913129  0.00991487 -0.03005922 -0.01741387  0.01640638  0.01223503\n",
      " -0.01989782  0.03991146 -0.01775981 -0.01423248 -0.00227239  0.00564557\n",
      " -0.00451205 -0.00620488  0.05036925 -0.0557411  -0.01469972 -0.01918401\n",
      " -0.04825962 -0.01733831  0.00209749 -0.01674408  0.01938748 -0.00936349\n",
      " -0.01643972  0.00997044 -0.02936827 -0.0372961  -0.04975534  0.01067998\n",
      "  0.02254963 -0.00379945  0.01277004 -0.02340779  0.02470673  0.00708905\n",
      " -0.03640925  0.02274713 -0.02923604  0.02516884  0.00235881 -0.0254825\n",
      "  0.01509182 -0.02117145 -0.02074595 -0.01879994  0.03520052 -0.00040427\n",
      " -0.02855084  0.01578587  0.00510349  0.00319059 -0.00096424  0.02036983\n",
      " -0.02269318 -0.03986924  0.02077925 -0.03758857  0.00271641 -0.03211604\n",
      " -0.01308914 -0.04378838 -0.03415859 -0.05998753  0.00575121 -0.00811005\n",
      " -0.00593947  0.00625829 -0.02066798 -0.01655015  0.05115149 -0.00927974\n",
      "  0.00484868  0.00313336 -0.04640313 -0.00858318  0.03722989 -0.05542246\n",
      "  0.0033069  -0.01046618  0.01542067  0.02561666  0.00068285 -0.02793738\n",
      "  0.00951648 -0.04019344 -0.00087399 -0.02621216 -0.02115743 -0.05750132\n",
      " -0.01888176 -0.01330791 -0.00288672 -0.00439795  0.02756481 -0.00733127\n",
      " -0.03215886  0.00291127 -0.03992841 -0.04029454 -0.00821762  0.00553893\n",
      " -0.0048417  -0.02615826  0.00655758 -0.03860996  0.04604     0.01568132\n",
      " -0.08761434  0.04321804 -0.02456279 -0.00905961 -0.00499452  0.00763366\n",
      " -0.04933589 -0.01581488 -0.0301383   0.01704001  0.00742137  0.01510114\n",
      " -0.00762994 -0.00241738  0.06209067  0.00175298 -0.02610835  0.0358016\n",
      " -0.02591502 -0.03963831 -0.02175237 -0.02101618  0.02829535 -0.00742569\n",
      "  0.02273983  0.00471418 -0.03433412  0.00557525  0.01073892 -0.00470063\n",
      " -0.01533292  0.01451928 -0.0542463  -0.00471732  0.00094405  0.00618595\n",
      "  0.01323293 -0.00359339 -0.01362825 -0.02699367  0.00117514 -0.02216653\n",
      "  0.01635357  0.05592046  0.06920879 -0.03180557  0.00687825  0.03570063\n",
      "  0.00596889  0.01361314]\n",
      "discriminator_8/conv_block_84/conv2d_84/kernel:0 [[[[ 3.28489281e-02  1.02053368e-02  2.64428314e-02 ...  1.33861937e-02\n",
      "    -2.60304324e-02  9.15450603e-03]\n",
      "   [ 2.54046284e-02 -7.40084052e-03  1.58724412e-02 ...  5.51515492e-04\n",
      "     7.68684316e-03 -4.11904119e-02]\n",
      "   [-2.86720153e-02 -5.06800599e-02  2.35311012e-03 ...  2.24749534e-03\n",
      "    -3.06299180e-02  4.28195484e-02]\n",
      "   ...\n",
      "   [-2.87988745e-02 -1.11496467e-02 -1.26665169e-02 ... -1.48958350e-02\n",
      "     8.02682713e-04  1.57226548e-02]\n",
      "   [ 4.45100926e-02 -8.72058980e-03 -4.83690342e-03 ...  2.88247615e-02\n",
      "     3.89629640e-02  3.80287282e-02]\n",
      "   [ 9.53375362e-04  1.76471025e-02 -2.95435302e-02 ... -1.86130814e-02\n",
      "    -8.51705205e-03 -8.97400361e-03]]\n",
      "\n",
      "  [[ 1.85259394e-02 -1.47368461e-02 -1.17258448e-02 ...  1.39014451e-02\n",
      "    -2.21650880e-02  2.15247571e-02]\n",
      "   [-3.44680659e-02  4.70255837e-02 -9.44153778e-03 ...  3.55002680e-03\n",
      "    -4.70639579e-03 -1.99574162e-03]\n",
      "   [ 1.93400832e-03  2.56333984e-02  2.65345965e-02 ...  8.45143851e-03\n",
      "    -3.73656489e-02  2.94282474e-02]\n",
      "   ...\n",
      "   [ 7.02926982e-03 -1.15325190e-02 -2.83197369e-02 ... -1.27742486e-03\n",
      "    -2.57352032e-02  3.57923433e-02]\n",
      "   [-2.75030769e-02 -4.78691375e-03 -1.65017843e-02 ... -3.43802348e-02\n",
      "     2.95554120e-02 -9.40963998e-03]\n",
      "   [-1.51629234e-02  7.93809909e-03 -1.49932913e-02 ...  5.48020937e-03\n",
      "     5.86620008e-04  3.14885750e-02]]\n",
      "\n",
      "  [[ 3.44904549e-02  3.58633138e-03  9.94285475e-03 ... -2.41415668e-02\n",
      "    -1.47909205e-02 -3.90149020e-02]\n",
      "   [-2.18394119e-02  1.65005866e-03 -4.58321534e-02 ...  7.26818340e-03\n",
      "     3.23365554e-02 -8.42627510e-03]\n",
      "   [-2.25323588e-02 -2.52971705e-02  3.41993826e-03 ... -1.93229448e-02\n",
      "    -4.50929292e-02 -1.78040043e-02]\n",
      "   ...\n",
      "   [ 2.97278035e-02 -7.67565565e-03  1.00685805e-02 ...  3.27920057e-02\n",
      "     1.69369467e-02 -5.17321518e-03]\n",
      "   [-2.53066042e-04  2.69834418e-02  2.73704827e-02 ...  3.73929031e-02\n",
      "     1.49007037e-03 -8.77384096e-03]\n",
      "   [ 1.75773315e-02  3.90617885e-02 -1.80336758e-02 ... -4.25137356e-02\n",
      "     3.10956445e-02  2.36384105e-03]]]\n",
      "\n",
      "\n",
      " [[[ 2.00438704e-02 -6.65094750e-03  1.28418915e-02 ...  1.41961379e-02\n",
      "    -1.03850458e-02  4.76210611e-03]\n",
      "   [-1.24445669e-02  6.01998344e-03 -3.21101025e-02 ... -1.21845538e-02\n",
      "     4.26391177e-02  1.51569219e-02]\n",
      "   [ 3.52040790e-02 -1.52804004e-02 -1.97029468e-02 ...  4.08626162e-02\n",
      "    -5.74242398e-02 -1.72389706e-03]\n",
      "   ...\n",
      "   [ 2.58085113e-02 -3.52192633e-02  2.00556666e-02 ...  1.51921725e-02\n",
      "    -1.62271112e-02  2.36376245e-02]\n",
      "   [-4.24575061e-03  1.15426946e-02 -6.94112200e-03 ...  2.85909809e-02\n",
      "     2.02312786e-02 -1.72711890e-02]\n",
      "   [-5.84142283e-02  3.60534247e-03 -4.08438314e-03 ... -1.31291179e-02\n",
      "     5.97393587e-02  1.52763706e-02]]\n",
      "\n",
      "  [[ 9.27317815e-05  1.04723061e-02 -6.99933665e-03 ...  2.26273742e-02\n",
      "    -3.28260735e-02 -4.80335206e-03]\n",
      "   [-1.48497876e-02 -3.66326934e-03 -6.59332098e-03 ...  1.48308519e-02\n",
      "    -1.96123719e-02  4.74991277e-02]\n",
      "   [ 3.79285123e-03  2.15271618e-02  8.76844209e-03 ...  1.00786034e-02\n",
      "    -4.46314439e-02  6.31707674e-03]\n",
      "   ...\n",
      "   [ 1.15935281e-02 -9.30994377e-03  6.27436070e-03 ... -1.44336149e-02\n",
      "     1.28057180e-02 -2.12529814e-03]\n",
      "   [-2.29853531e-03  5.60878813e-02  8.85689538e-03 ...  3.43788080e-02\n",
      "    -3.09128896e-03 -7.29484670e-03]\n",
      "   [-1.79098465e-03 -3.29981162e-03  1.78159941e-02 ... -5.34987114e-02\n",
      "    -1.14814602e-02 -5.83754033e-02]]\n",
      "\n",
      "  [[-1.02998465e-02  2.09016586e-03 -1.12883272e-02 ... -3.16607067e-03\n",
      "     2.10905820e-02  5.43250283e-03]\n",
      "   [ 9.50384885e-03 -2.15172675e-02 -1.41155655e-02 ...  9.94140189e-03\n",
      "    -4.30801772e-02  1.72391087e-02]\n",
      "   [-2.69056875e-02  4.13339771e-03 -3.71174403e-02 ... -5.11670485e-03\n",
      "     1.01385033e-02 -3.87232844e-03]\n",
      "   ...\n",
      "   [-2.97177006e-02  6.98837871e-03  2.77257450e-02 ...  4.21597064e-02\n",
      "     9.23116878e-03 -4.20966931e-03]\n",
      "   [-9.49138310e-03  5.71058840e-02 -2.51064319e-02 ...  1.20785302e-02\n",
      "    -2.08534207e-02  1.59591325e-02]\n",
      "   [-2.84253433e-02 -1.93616580e-02 -5.78759909e-02 ... -4.10928875e-02\n",
      "    -2.06988063e-02 -1.98704861e-02]]]\n",
      "\n",
      "\n",
      " [[[ 3.15439664e-02 -2.47819666e-02  1.60489753e-02 ...  1.13555174e-02\n",
      "     1.86153427e-02 -4.35347147e-02]\n",
      "   [-1.28732882e-02 -8.74075014e-03 -3.06069329e-02 ... -1.71372462e-02\n",
      "     4.41671209e-03  3.99087779e-02]\n",
      "   [ 1.44397197e-02 -2.41160262e-02  1.64449010e-02 ... -1.46485225e-03\n",
      "    -2.60509867e-02 -1.66483484e-02]\n",
      "   ...\n",
      "   [-3.83498427e-03  3.07588428e-02 -5.87160662e-02 ...  8.67476501e-03\n",
      "     2.19115485e-02  1.56268403e-02]\n",
      "   [ 6.21934980e-03  2.91999392e-02  1.51197426e-02 ...  3.79455090e-03\n",
      "     1.30278980e-02  2.77529191e-03]\n",
      "   [ 1.86506864e-02  2.06494331e-02 -4.16182727e-02 ... -1.11685530e-03\n",
      "     1.89495776e-02  2.46256627e-02]]\n",
      "\n",
      "  [[ 1.15511054e-02 -1.82187948e-02  3.50431800e-02 ... -1.76305231e-02\n",
      "    -3.83025184e-02 -2.39467863e-02]\n",
      "   [-4.95140022e-03  1.08790472e-02 -3.78676094e-02 ... -2.61766072e-02\n",
      "    -8.38519819e-03  1.59787424e-02]\n",
      "   [-3.71992104e-02 -2.46072728e-02 -1.65140466e-03 ...  2.68888602e-04\n",
      "     3.19655868e-03 -1.85692334e-03]\n",
      "   ...\n",
      "   [ 3.33912224e-02  1.20825302e-02 -2.65332237e-02 ... -5.22666946e-02\n",
      "     4.58148383e-02 -3.13782878e-02]\n",
      "   [-1.76724009e-02  2.69623846e-02 -1.08398562e-02 ...  1.15223862e-02\n",
      "     2.30343118e-02  1.92503817e-02]\n",
      "   [ 2.39935913e-03 -5.37337875e-03 -2.91011985e-02 ... -3.37132551e-02\n",
      "    -7.54587073e-03  1.83975417e-02]]\n",
      "\n",
      "  [[ 3.29932161e-02  1.59739684e-02  1.95189044e-02 ... -4.74830111e-03\n",
      "     1.98153723e-02 -3.38238664e-02]\n",
      "   [ 1.52841853e-02 -1.85053386e-02  1.91552006e-02 ...  2.49175224e-02\n",
      "    -2.92830430e-02 -2.81049088e-02]\n",
      "   [-4.87896204e-02 -4.33452539e-02  5.00667561e-03 ... -5.83206164e-03\n",
      "     2.03626230e-02 -4.58591292e-03]\n",
      "   ...\n",
      "   [-4.64676619e-02  4.12087291e-02 -4.01193947e-02 ... -4.96118795e-03\n",
      "    -1.16133448e-02 -1.06597347e-02]\n",
      "   [-6.08714670e-03  1.76791623e-02  1.56162651e-02 ...  5.22306794e-03\n",
      "    -3.15085612e-03  5.37578529e-03]\n",
      "   [-2.56608389e-02  2.34847013e-02 -3.15143727e-02 ... -5.44406427e-03\n",
      "    -7.37972185e-03  1.79516003e-02]]]]\n",
      "discriminator_8/conv_block_84/conv2d_84/bias:0 [-1.7404227e-05  1.0564042e-05 -2.8361863e-05 -7.2077324e-05\n",
      "  5.5423319e-05 -3.9620777e-06  1.2685420e-04  4.5994508e-05\n",
      " -9.3787285e-06 -2.9543615e-05  1.9606491e-04  4.3714583e-05\n",
      " -5.4510023e-05 -6.7219982e-05 -2.1036552e-05  3.1328578e-05\n",
      " -9.0697613e-05 -8.6854725e-06  1.8806841e-05 -2.3089437e-05\n",
      " -2.2300151e-06 -1.0031359e-03  5.2327494e-05  1.0834029e-05\n",
      " -1.0142328e-06  2.5609246e-05 -2.3032284e-04  4.0432620e-05\n",
      "  2.1150174e-06  3.0418507e-05  1.9488193e-06 -4.2269312e-04\n",
      " -2.2277147e-05  2.7564413e-06  2.8083885e-05  6.5616418e-06\n",
      "  2.4090905e-05 -4.8130073e-06 -2.6013016e-05  7.6069766e-05\n",
      "  2.3358425e-06  5.7528381e-05 -4.7383023e-06 -3.5836879e-04\n",
      " -8.4065696e-06 -7.7025343e-06  7.5168238e-05 -2.0343283e-05\n",
      "  1.5247556e-05 -2.2234683e-05 -1.5401276e-05 -3.6744343e-05\n",
      "  1.9103785e-04 -6.2048508e-05  1.0075239e-05 -1.3912640e-05\n",
      "  3.9810289e-05  6.0130922e-05  4.6954883e-06  4.1564912e-05\n",
      "  2.4912797e-05  8.8596262e-06 -6.6204659e-05  1.4931317e-04\n",
      "  3.0400470e-05  7.7502618e-06 -5.0658989e-05  1.1409087e-05\n",
      "  1.3332637e-05  1.4653680e-06  2.0435982e-05 -3.3990989e-05\n",
      " -1.5032048e-05 -1.5097136e-05 -6.8390018e-06 -1.5372450e-07\n",
      "  6.3975986e-06  3.6027247e-06  4.1413656e-04  3.3599910e-05\n",
      "  1.4936433e-05  1.2523951e-06  6.6425064e-06  4.3604163e-05\n",
      "  3.3687698e-05  1.9122799e-05 -2.5869029e-05 -6.6705102e-06\n",
      " -4.1427415e-05 -1.9880298e-04 -2.0470748e-05  5.0777591e-05\n",
      " -2.0167874e-05 -4.7248384e-05  2.1811671e-05  2.8398827e-06\n",
      " -2.1741649e-05 -4.2018264e-08 -3.0917934e-05  1.8435012e-05\n",
      "  1.2383226e-04  1.3364018e-04 -6.1027935e-05  3.1202023e-06\n",
      " -1.5457172e-05  4.5712906e-05  2.6541557e-05  2.2173746e-05\n",
      " -3.9035582e-05 -2.0456375e-05 -2.0165347e-05 -7.0544927e-05\n",
      " -7.9007601e-05 -8.2406186e-06  4.5100638e-05 -3.6127716e-05\n",
      " -9.5088762e-06 -5.0235112e-06  1.8651814e-05  3.0309606e-05\n",
      "  1.7573970e-05  2.8678300e-05  1.1804463e-05 -2.4467256e-05\n",
      " -2.3173303e-05 -1.2080497e-05 -7.6798926e-05 -2.0895910e-05\n",
      " -1.3817530e-04 -6.3852080e-05  4.0353757e-06  1.9069654e-05\n",
      "  5.9180238e-06  6.0477341e-05 -1.2946112e-05  4.1007626e-04\n",
      " -5.9644834e-05  3.0702802e-05 -1.8625442e-05 -3.4700253e-05\n",
      " -2.8622580e-06 -3.1002488e-05 -2.8168866e-05 -2.0244490e-05\n",
      " -6.6011235e-05 -7.8494573e-05  5.5593900e-05 -1.0013471e-05\n",
      " -5.9345915e-05 -2.8520502e-05 -4.5862009e-05 -2.3757097e-05\n",
      " -1.0542203e-05 -3.8057140e-06 -9.0571499e-05 -2.8226685e-05\n",
      " -5.9777747e-05 -2.2767844e-07  2.2943523e-05 -2.0879897e-05\n",
      " -4.9643873e-05 -5.4813499e-05 -5.8028871e-07  1.2236178e-05\n",
      "  1.4092732e-04 -9.0812537e-06 -1.8915773e-05 -3.6845995e-05\n",
      " -1.8464327e-05  1.2194176e-04  7.7144607e-05  1.5285163e-05\n",
      " -8.4193480e-06  2.5647032e-05 -1.3713089e-04  7.5765565e-05\n",
      " -9.5142648e-05  1.6545069e-07  9.4056959e-06 -5.3191328e-05\n",
      "  8.2008974e-06  3.6890622e-05  1.2335271e-05 -2.8615656e-05\n",
      " -5.6986896e-06  4.5110046e-05  2.7270315e-05  2.9518951e-05\n",
      "  3.1786178e-05 -1.5255973e-05  1.0576262e-04 -9.3542394e-06\n",
      "  9.1516005e-05 -6.0966959e-05 -6.8620597e-05  2.2368020e-05\n",
      "  6.1165374e-05  2.1984260e-05  8.2670304e-06  3.7713980e-06\n",
      "  9.9466604e-05  5.6301510e-06  6.6208777e-05  8.8291781e-05\n",
      "  5.5088618e-05 -6.4086664e-05  5.3416325e-06 -2.6929829e-05\n",
      "  1.9145791e-05  5.9744430e-05  3.1570180e-05  1.8958111e-05\n",
      " -1.3236565e-05  2.7821702e-04 -1.6296355e-05  7.2136509e-06\n",
      " -6.5816523e-05  1.7233739e-05 -4.0922398e-05 -3.0225912e-05\n",
      " -4.6971239e-04  4.4228705e-06  7.5019307e-06 -6.0043909e-05\n",
      " -5.2206989e-05  1.2047306e-05 -2.2464894e-05  1.6044576e-05\n",
      " -5.5451412e-05 -8.1669619e-05  2.7691673e-05  2.8671671e-04\n",
      " -1.7206210e-05 -4.8399554e-05 -9.4942770e-06 -1.6813590e-05\n",
      " -1.8463161e-05  4.0949849e-06 -1.2594138e-06 -2.1607722e-05\n",
      "  1.3591648e-05  9.4771585e-06  6.2244748e-05 -1.7862214e-06\n",
      "  4.5364377e-05 -7.6115633e-08  2.6692667e-05 -1.5332349e-05\n",
      "  5.9098777e-05  9.5054502e-06 -2.9562509e-05 -3.1802672e-05\n",
      "  1.1994651e-06 -1.6633337e-04  2.4067993e-05  2.5459690e-06]\n",
      "discriminator_8/conv_block_84/batch_normalization_138/gamma:0 [1.0354657  0.9837037  0.9995016  1.0097097  1.014368   1.0120751\n",
      " 1.0289415  0.99697465 1.0008984  1.0073323  1.0140272  1.0145984\n",
      " 1.0008273  1.0138237  1.0056572  1.0204207  0.99456203 1.03287\n",
      " 0.98426306 1.0282354  1.0109632  1.014202   1.0167513  0.98502827\n",
      " 0.9776479  0.9915456  1.0091438  0.9957515  0.9815516  1.0140303\n",
      " 0.9837946  0.9866136  0.98779005 1.0115534  1.0018541  0.99655896\n",
      " 1.0397687  1.0031661  0.9917657  1.0011322  0.99552244 0.9935027\n",
      " 0.9966955  1.0167783  1.0087932  1.0145438  0.9919561  0.9933445\n",
      " 1.0063212  0.9846884  1.0169446  1.0051961  0.98339397 1.034647\n",
      " 1.0045925  0.9758131  0.99191517 1.0194788  0.98547584 1.0135652\n",
      " 0.9844687  0.9993557  1.0149499  1.0579764  0.98224586 0.9977541\n",
      " 1.0039567  0.99004996 1.0011073  1.0014951  1.0120851  1.0114721\n",
      " 0.98559034 1.0084574  1.0082376  0.98541725 1.0189477  1.005149\n",
      " 0.99088275 0.9698989  0.99189055 0.99689066 1.0063978  0.9919717\n",
      " 1.0070279  0.9671331  0.9881916  0.99287677 1.0051641  1.0038975\n",
      " 1.0151708  1.0036074  1.0093597  1.0054142  0.9975735  1.0047703\n",
      " 0.99339974 0.99939054 1.0233871  1.0002593  0.99696195 0.9909552\n",
      " 0.99074894 0.9872026  1.0150286  1.0009415  1.0042175  1.0073702\n",
      " 1.0046964  1.023587   0.9954915  1.0165209  1.0297446  0.9846631\n",
      " 1.0110124  1.0045652  1.0202581  1.0026572  0.9856686  0.9926147\n",
      " 1.0276445  1.0223632  0.9921277  1.0085886  1.0125467  1.0154768\n",
      " 1.0073688  1.0163081  0.9966398  1.0137385  0.98412794 0.9790081\n",
      " 1.012093   1.0005955  1.0176789  0.99627614 1.0079734  1.002146\n",
      " 0.99333334 1.0112097  1.0133657  1.0207531  0.98448884 1.0282664\n",
      " 0.9888849  1.000487   1.012677   1.0142671  1.0141691  0.9944658\n",
      " 0.9764629  1.0007501  1.0030148  0.9831971  1.0076425  0.9984807\n",
      " 1.0197408  1.0045199  1.0173908  1.0164778  1.0147582  0.9959504\n",
      " 1.0025617  1.0126967  1.0061164  1.0078949  1.0015713  1.0330726\n",
      " 1.0239112  1.0037811  1.0259693  0.9874849  1.0268989  0.9969808\n",
      " 1.0149081  0.98577535 1.0151432  0.9900117  1.0134661  0.99438506\n",
      " 1.0272152  1.0108584  1.003596   0.9806085  1.0394233  1.0274534\n",
      " 0.98828095 1.0130427  0.9988473  1.0353197  0.9975323  0.99152803\n",
      " 1.0334737  1.006251   1.0514206  0.99785376 1.0161788  1.0007744\n",
      " 0.99739677 0.98413265 1.0111929  0.985342   0.9967617  0.9867337\n",
      " 0.9839601  0.9965354  0.99896264 0.9863723  1.0081211  1.0156814\n",
      " 0.9891068  1.0162145  1.0043833  0.9893676  0.9946002  0.98748714\n",
      " 0.9952732  1.0005958  1.0098379  1.0035928  1.0272629  1.0273957\n",
      " 1.0089388  1.0076874  1.0078707  1.0173866  1.0061398  1.0139847\n",
      " 0.9990459  1.0163838  0.9919295  1.0132443  0.99984163 0.9774935\n",
      " 0.9929837  1.01766    1.0083832  1.0046873  1.0165241  1.0003756\n",
      " 1.0146435  1.0166336  1.0057092  1.0089353  0.99229246 0.99703485\n",
      " 0.98456794 0.996688   0.9790496  1.010296   1.0205609  0.98122525\n",
      " 1.0167235  0.98153776 0.98732126 0.9887795 ]\n",
      "discriminator_8/conv_block_84/batch_normalization_138/beta:0 [ 4.51269709e-02 -3.11036427e-02 -5.04841655e-02 -3.58497947e-02\n",
      "  3.59689072e-03 -6.42160932e-03 -2.10811086e-02 -3.19923647e-02\n",
      "  3.77017958e-03 -1.10341674e-02 -3.79011221e-02  8.64377804e-03\n",
      "  1.56424232e-02 -6.21656375e-03 -4.12036702e-02 -2.87623424e-03\n",
      " -2.74886638e-02  1.31615624e-02 -2.04025004e-02  3.32118422e-02\n",
      " -1.00718457e-02 -1.92609485e-02 -1.51880151e-02 -1.93721168e-02\n",
      " -1.68610327e-02 -4.29968424e-02 -3.10008172e-02 -1.55450767e-02\n",
      "  1.38048464e-02 -3.30270417e-02 -2.38327552e-02 -3.57916467e-02\n",
      " -3.21133323e-02  2.79713906e-02  2.63057579e-03 -1.02594141e-02\n",
      " -3.88881601e-02 -3.54978675e-03 -2.75553558e-02  1.93421021e-02\n",
      "  6.83852099e-03  5.49999857e-03 -8.27895419e-04 -3.56376991e-02\n",
      "  1.66675337e-02  2.87059266e-02 -4.84809801e-02  9.51477210e-04\n",
      " -4.17910283e-03 -5.15442528e-02 -1.10906027e-02  6.72901282e-03\n",
      " -4.23721522e-02 -2.92269532e-02  1.03774443e-02 -2.43864558e-03\n",
      " -1.18420459e-02  3.70139405e-02 -3.85934114e-02  1.95854064e-02\n",
      " -2.22961698e-02  3.12229861e-02  7.53199961e-03 -6.12866879e-02\n",
      " -8.13136459e-04 -1.86070334e-02  7.06070988e-03 -1.31816173e-03\n",
      "  1.71306599e-02 -2.25520902e-03 -2.24397779e-02  3.58058587e-02\n",
      "  1.35868345e-03 -2.15764111e-03 -2.69999951e-02 -2.18092408e-02\n",
      "  2.05817502e-02 -6.15779636e-03 -4.04500067e-02 -2.76110917e-02\n",
      " -7.97671382e-04 -3.59532237e-02 -1.80256609e-02 -4.77905273e-02\n",
      " -1.52916531e-03 -2.74487585e-02 -7.40966797e-02 -2.42466126e-02\n",
      " -5.98611459e-02  7.79545517e-04 -1.47886351e-02 -1.29174627e-02\n",
      "  1.73428236e-03 -2.56193709e-02 -1.09366875e-03 -7.25968881e-03\n",
      " -2.15003602e-02  9.40523576e-03 -3.18544568e-03  3.36170867e-02\n",
      " -5.83621822e-02 -2.92428546e-02 -6.40902855e-03 -3.64867710e-02\n",
      "  1.68671701e-02 -2.40106042e-02  1.90483946e-02 -3.08067035e-02\n",
      "  1.50028560e-02  3.72294411e-02  1.31617226e-02  1.62230153e-02\n",
      " -6.94424426e-03 -1.76673792e-02 -5.28954193e-02 -1.29984273e-02\n",
      "  3.45284045e-02  9.43010952e-03 -2.27069259e-02  1.37266275e-02\n",
      " -1.94699317e-02  2.17540772e-03  8.60083196e-03 -4.40836772e-02\n",
      " -1.43505158e-02  2.75375284e-02 -2.18168329e-02 -1.44160548e-02\n",
      " -3.35724615e-02 -2.17046775e-02 -3.66377383e-02  9.83735267e-03\n",
      " -4.17451886e-03 -2.86732204e-02 -2.10275911e-02 -7.13764429e-02\n",
      " -4.78247926e-03 -1.03088282e-02  3.93617386e-03  1.82614382e-03\n",
      "  1.94008611e-02 -7.35131511e-03 -2.10516006e-02 -1.75967603e-03\n",
      " -2.37374417e-02 -1.17336474e-02 -6.18799515e-02  2.92668380e-02\n",
      "  1.83098838e-02 -2.02913024e-02  2.07268018e-02  1.21105963e-03\n",
      " -1.90031230e-02 -6.57607848e-03 -2.71591656e-02  1.03898318e-02\n",
      "  1.30916992e-02 -4.10824735e-03 -3.87289608e-03 -3.65133397e-02\n",
      " -1.44076040e-02 -1.00377239e-02 -1.37370825e-02  6.83629513e-03\n",
      " -1.86146162e-02 -3.81725170e-02 -1.53831029e-02  1.56096509e-02\n",
      "  7.60165881e-03 -2.11995691e-02 -2.06473493e-03 -1.58847291e-02\n",
      " -9.85540636e-03 -2.74071191e-02 -3.70875150e-02 -2.00444739e-02\n",
      " -6.48361165e-03 -4.72520366e-02  4.53891233e-02 -1.21290563e-02\n",
      "  3.43372002e-02  1.57654248e-02  3.65540641e-03 -3.35510187e-02\n",
      "  7.46916011e-02  3.85632440e-02 -1.47289056e-02  2.61756890e-02\n",
      " -1.40256239e-02  1.87885221e-02 -2.20455267e-02 -7.25425594e-03\n",
      "  4.06918526e-02 -3.74922566e-02  2.99239978e-02 -1.88345090e-02\n",
      "  1.86338648e-02 -2.93145678e-03 -2.93745212e-02  1.45548107e-02\n",
      " -2.73921229e-02 -1.07874004e-02 -4.58881631e-03 -3.84412929e-02\n",
      " -2.65501793e-02  1.05521362e-03  2.51548607e-02 -3.36326919e-02\n",
      " -5.71562946e-02  5.13889863e-05 -2.32778471e-02  2.37687374e-03\n",
      "  1.12665845e-02 -8.46691430e-02 -2.11564172e-02 -1.12066008e-02\n",
      " -2.90859584e-02  6.69187168e-03  8.50152690e-03 -5.34582790e-03\n",
      "  8.83024652e-03 -5.10252453e-03  1.47946626e-02  6.94316952e-03\n",
      "  1.87389590e-02 -1.49289574e-02  9.23177786e-03  1.73993278e-02\n",
      " -1.64314192e-02  1.50205370e-03  7.48480088e-05 -3.15991342e-02\n",
      " -1.73548870e-02 -5.56015968e-03  5.17582055e-03 -8.20298493e-03\n",
      "  5.08138025e-03 -2.89006103e-02  1.36243878e-02 -2.68724002e-02\n",
      "  3.29342894e-02  3.00081559e-02  3.09411567e-02  1.74043793e-02\n",
      " -8.25361237e-02 -3.62031981e-02 -1.06512848e-02 -4.76999860e-03\n",
      " -4.13676426e-02 -4.84560095e-02  5.58571238e-03 -2.97106989e-02\n",
      " -5.63777890e-03 -3.45802866e-02 -2.70454139e-02 -2.21382175e-02]\n",
      "discriminator_8/conv_block_85/conv2d_85/kernel:0 [[[[-0.10948745  0.01677329  0.14755815 ... -0.04416878 -0.04746378\n",
      "     0.16834977]\n",
      "   [-0.03496261 -0.01475672  0.10954005 ... -0.05975242 -0.03921815\n",
      "    -0.03074961]\n",
      "   [-0.02375365 -0.11762004  0.09789357 ... -0.0502792   0.12105781\n",
      "    -0.03278612]\n",
      "   ...\n",
      "   [-0.03117516  0.01121689  0.16094588 ... -0.12949601 -0.10088347\n",
      "    -0.02655747]\n",
      "   [-0.0799155   0.00618883 -0.08098482 ...  0.11715882 -0.00711528\n",
      "    -0.01267685]\n",
      "   [-0.06285736 -0.11420292  0.20301576 ... -0.18008186  0.01165701\n",
      "     0.097999  ]]]]\n",
      "discriminator_8/conv_block_85/conv2d_85/bias:0 [-1.45480240e-04  1.29035281e-04  3.69428162e-05 -7.82921852e-05\n",
      "  4.64834993e-05  3.37043798e-06 -6.75332558e-05 -2.57804586e-05\n",
      " -4.06612344e-06  9.77112222e-07 -3.31757328e-05 -4.59067487e-05\n",
      "  2.03673379e-04  8.34932871e-05  1.09822038e-04  6.39766440e-05\n",
      " -5.12477482e-06  4.77089925e-05  4.04931598e-05  3.88844346e-05\n",
      " -1.23616323e-04  8.85037152e-05  7.80768605e-05  6.83482722e-05\n",
      " -7.53130735e-05  4.37460621e-05  8.91762684e-05 -5.00755341e-05\n",
      " -1.87479000e-05  3.41679442e-05 -1.55623915e-04  1.51833417e-04\n",
      "  3.21128937e-05  5.60352282e-06 -6.50279617e-05 -5.60761546e-05\n",
      " -5.20877766e-05  9.56749864e-06 -7.00203691e-06 -3.00723652e-04\n",
      "  6.73865870e-05 -3.30201328e-05  1.02524435e-04 -6.20955761e-05\n",
      "  3.77382858e-05 -3.35184700e-06  9.96156596e-05  1.45700207e-04\n",
      " -2.03411673e-05  8.38301057e-05 -1.80370509e-04 -8.33374143e-05\n",
      "  3.35612189e-04 -5.72921490e-05  4.05880819e-05  4.32972629e-05\n",
      " -2.75570765e-05  7.57170128e-05  2.33964147e-05  1.49032974e-04\n",
      " -4.21889126e-05  3.12292221e-04 -6.93375769e-05  5.75057566e-05\n",
      " -1.20657089e-04 -1.54610316e-05  3.12016746e-05  6.85263731e-05\n",
      "  5.47387317e-05  9.18596415e-05  5.99009218e-05  5.96783048e-06\n",
      "  2.77123654e-05  5.92000906e-05  1.91452436e-05  1.67582039e-06\n",
      "  6.62982984e-06 -2.23424431e-04  5.38886416e-05  1.25508712e-04\n",
      " -4.59587727e-06  8.81060805e-06  8.51790173e-06 -1.03000079e-04\n",
      " -2.79040723e-05  1.43577636e-04 -6.27136760e-05 -3.18436942e-05\n",
      " -5.68980295e-06 -1.48618392e-05 -1.25802209e-04 -3.52236420e-05\n",
      " -5.23750459e-05  2.28759876e-04 -4.05309474e-05 -9.15397541e-05\n",
      " -2.79482829e-05  5.25945252e-05 -4.14521492e-05 -5.44372087e-05\n",
      "  1.80356401e-05 -1.16636918e-04  1.71267791e-04  8.23663795e-05\n",
      "  2.24382893e-04 -6.60810692e-05 -2.01099494e-04 -1.02722886e-04\n",
      "  1.06471081e-04 -3.18147941e-05  2.02618230e-05  7.51161861e-05\n",
      "  1.68805331e-04  5.33990897e-05  3.46356537e-05 -3.68023320e-05\n",
      " -2.41254884e-06  2.90778971e-05  7.29546300e-05 -4.76482528e-04\n",
      " -2.05464268e-04 -1.28801021e-05 -1.46023940e-05  1.94182503e-04\n",
      " -8.99500956e-05  5.67890420e-05 -2.04630906e-05  1.03595761e-04\n",
      "  3.80692290e-05 -1.07386895e-05  7.96261229e-05  3.94303897e-05\n",
      "  8.04959200e-06 -1.18780554e-05  3.64027946e-05  5.10377613e-05\n",
      " -5.38380627e-05  1.20127654e-04 -4.00398267e-06 -9.73337810e-05\n",
      "  4.03852500e-05  1.35965811e-05 -2.33791470e-05  4.07811385e-05\n",
      "  1.65767822e-04  1.59191241e-05  4.55960726e-05 -1.09294881e-04\n",
      "  1.13701135e-04  1.50595160e-05  2.09240752e-05  1.26515915e-05\n",
      "  1.47452802e-05 -4.99202652e-05  2.08075508e-05 -6.82718164e-05\n",
      "  1.76468056e-05  2.51483343e-05 -9.07158683e-05  2.03316667e-05\n",
      " -7.34029381e-05  6.21966683e-05  3.70910748e-05  4.71372769e-05\n",
      "  3.39951657e-05 -2.06439709e-05 -6.19006505e-06 -2.04498319e-05\n",
      "  5.92657852e-05 -6.42172745e-05  6.22463995e-06  6.47837078e-05\n",
      "  4.26346269e-05 -8.89157764e-06  4.27819259e-06  6.17540209e-04\n",
      " -2.99215098e-05  7.58733950e-05 -8.69418784e-07  3.44690889e-05\n",
      "  1.10708481e-06  3.66412060e-05  1.84507488e-04  3.79384037e-05\n",
      "  3.36937919e-05  2.34457220e-05  2.23480456e-04  1.99424700e-04\n",
      "  3.72000250e-05 -1.53568981e-04 -1.02821388e-04  1.00109348e-04\n",
      " -1.19372271e-05 -7.69519684e-05  2.83980280e-05 -2.25879430e-05\n",
      " -3.74323972e-05 -1.23553385e-04  2.73835303e-05 -4.54688852e-05\n",
      " -7.59816294e-06  7.00246310e-05  1.73412089e-04  1.70762432e-04\n",
      "  1.10144665e-05  6.98410950e-05 -6.67037821e-05  6.69645742e-05\n",
      " -3.18197417e-05 -1.11123109e-05  4.38491443e-05 -2.38612188e-06\n",
      " -1.72411401e-05  5.45527255e-05  1.57191280e-05 -4.81555908e-05\n",
      "  5.82766137e-04  6.42332307e-05 -1.00021840e-04  8.63630557e-05\n",
      "  3.86461943e-05  1.64208308e-04 -8.25947282e-05  7.22461118e-05\n",
      " -2.89547079e-05  3.88675835e-06  2.47276330e-05 -1.41518658e-05\n",
      " -8.90275929e-04 -4.12725713e-05 -3.61989373e-06 -2.04894168e-05\n",
      "  9.31457034e-05  1.53643250e-05 -9.89428736e-05 -7.85087468e-05\n",
      "  1.09558081e-04 -5.50440927e-05  1.40787801e-04 -1.43430716e-05\n",
      "  7.83887808e-05 -6.52389863e-05 -5.52881793e-05  2.11715914e-07\n",
      " -7.62203941e-04 -6.78276865e-06 -6.37638077e-05  8.39052154e-05\n",
      "  1.38180585e-05  9.39030651e-05  8.70784716e-05  8.79278014e-06\n",
      " -9.10660674e-05 -1.15395960e-04 -1.29676031e-04  1.45632112e-05]\n",
      "discriminator_8/conv_block_85/batch_normalization_139/gamma:0 [1.0347701  1.015028   0.9772755  0.9882361  0.99576545 0.97998875\n",
      " 1.0374936  0.99780434 1.0031863  0.9984985  0.9731504  0.9874661\n",
      " 1.0226853  0.98815644 1.0150833  0.9752048  0.9991681  0.97447217\n",
      " 1.0066532  0.99574697 1.0059736  1.0020708  0.9893659  0.9948515\n",
      " 0.9983967  0.9854735  1.011128   1.0443608  0.95596755 1.046476\n",
      " 1.0022961  1.0105889  0.996683   0.985062   0.99247646 1.0195369\n",
      " 0.95793444 0.99276084 0.9866342  1.0152775  1.006359   0.98456484\n",
      " 0.97340816 0.9647557  0.9724196  0.9823587  1.0041382  1.0166593\n",
      " 0.9977534  0.98365957 1.0052797  0.99242115 1.0351729  0.9915696\n",
      " 0.9715302  1.0021305  0.9888177  0.95969504 0.98542714 0.98560214\n",
      " 0.9729158  0.9860179  0.9900122  0.97479874 1.0415117  0.9667592\n",
      " 0.97347087 0.9870084  0.9864365  1.0296769  0.99433494 0.97000635\n",
      " 0.9939635  0.9860134  1.0081264  0.9720439  0.99075925 0.9844773\n",
      " 1.0225788  0.985094   1.0196322  0.99239826 0.9773957  1.0027791\n",
      " 0.98471117 1.0078176  0.9893447  0.9786432  1.0200074  1.011473\n",
      " 0.9988618  0.9962455  0.98940575 1.0133204  0.97919285 0.9836823\n",
      " 0.977106   1.0140795  0.98577845 0.9905036  0.9793894  0.9795539\n",
      " 1.0017709  1.0003946  1.0254748  1.0243275  0.9953996  0.9891351\n",
      " 1.0132171  0.996871   0.96577394 0.999128   1.0233523  0.9920974\n",
      " 0.9928122  0.996871   1.0058779  0.97040045 1.0036751  1.0005666\n",
      " 0.98072696 0.9877036  1.0052876  0.9923345  0.98913294 1.0064545\n",
      " 0.9732791  0.9889302  0.9633585  0.9727139  0.9878708  0.9792487\n",
      " 1.0027305  0.9977396  1.0002455  0.96726215 0.99054587 0.9935391\n",
      " 0.9537412  1.0098612  1.0142353  1.0087091  0.9837067  0.9724484\n",
      " 1.0127573  1.0063329  0.988199   0.9686297  0.99766827 1.0119046\n",
      " 1.0080024  0.9750999  0.9839222  0.9869733  0.99775726 0.9735536\n",
      " 1.0137331  0.98574597 0.99276716 0.97213924 0.9871463  1.0103222\n",
      " 0.9785856  0.9970055  0.9723707  1.0258667  0.9875406  0.99178207\n",
      " 1.000384   0.9907441  0.98153466 0.98540723 0.983149   0.9996284\n",
      " 1.01659    1.0605121  1.0170488  0.9923333  0.9925415  0.9859399\n",
      " 0.9836754  0.9719117  1.0096447  0.99934417 1.0125861  1.000948\n",
      " 1.0002906  1.0028156  1.0121192  0.9917548  0.9722924  0.9982756\n",
      " 1.0023308  0.9750585  0.9731342  0.9817864  0.9827792  0.9796942\n",
      " 0.98579186 0.9884009  0.98335326 0.9795982  0.98353714 0.9896113\n",
      " 0.9983265  0.97766954 1.0017868  0.9704858  0.9789655  1.0380287\n",
      " 0.98027796 0.9901737  0.98727804 1.0263739  0.9753773  1.0123158\n",
      " 1.0304084  0.9839183  0.9793284  0.989474   0.97546965 0.98022646\n",
      " 1.0236492  0.9843043  1.0107832  0.97965246 0.9828067  1.008214\n",
      " 1.0365492  0.9965756  0.99178964 1.0176119  0.99118125 0.9843911\n",
      " 1.0323968  0.98579895 0.99082667 1.0229824  0.9928315  1.0007651\n",
      " 0.98971343 0.97275984 0.99523026 1.0164583  1.0693154  1.0061954\n",
      " 0.98808444 0.9685436  1.0096174  0.98946565 1.034603   1.0013906\n",
      " 0.9982121  0.977025   1.0368664  0.9920309 ]\n",
      "discriminator_8/conv_block_85/batch_normalization_139/beta:0 [-7.59982690e-02  9.16257035e-03 -1.82784777e-02 -8.63619894e-03\n",
      " -1.27932653e-02 -1.33123985e-02 -2.63180528e-02  1.69975683e-02\n",
      "  1.72567237e-02  2.76752897e-02 -4.56447341e-02 -2.36305799e-02\n",
      " -5.11425696e-02 -3.31452377e-02  8.89433362e-03 -1.71255507e-02\n",
      " -3.85321788e-02 -2.67344434e-02 -6.33811206e-02 -4.17404547e-02\n",
      " -2.87057832e-02 -1.03162033e-02 -2.60865726e-02 -2.43590660e-02\n",
      " -1.23699894e-02 -1.58552956e-02  2.47184723e-03 -4.35884707e-02\n",
      " -3.72315873e-03  6.82314858e-02 -2.19550356e-02 -1.99746545e-02\n",
      "  8.79593485e-04 -4.29096036e-02 -1.81694627e-02 -1.26520516e-02\n",
      " -2.91938297e-02  3.07775382e-02 -5.65879941e-02  2.46449769e-03\n",
      "  3.17884572e-02 -2.96626240e-02 -4.94898893e-02 -3.72368321e-02\n",
      " -1.05964318e-02 -1.34823250e-03  3.22809666e-02 -2.46485323e-02\n",
      "  6.54129591e-03 -5.14999358e-03 -5.73978648e-02 -8.11734144e-03\n",
      " -4.42828201e-02 -7.16115767e-03 -1.30286803e-02  3.54310684e-02\n",
      " -9.20889527e-03 -1.64490985e-03 -8.59546196e-03  1.11552356e-02\n",
      "  1.56011647e-02 -3.21671646e-03  9.22087301e-03 -6.05485681e-03\n",
      " -4.96085733e-03 -2.07131333e-03 -3.52028594e-03 -1.20067038e-02\n",
      " -1.16163734e-02 -7.32372049e-03  9.92982741e-03 -2.30158702e-03\n",
      "  3.12069344e-04 -5.91004342e-02 -4.53153774e-02 -1.82000659e-02\n",
      "  1.46230999e-02  1.27433310e-03 -2.22716611e-02 -1.49580548e-02\n",
      " -7.43304044e-02 -1.17610907e-02 -6.28985688e-02  2.97157150e-02\n",
      " -4.61402871e-02  1.42373436e-04  2.17458420e-02 -1.10621583e-02\n",
      " -1.49819860e-02  4.97119427e-02 -1.88400466e-02 -4.87044156e-02\n",
      " -3.18468059e-03  2.19908077e-02 -2.86370255e-02 -1.03541659e-02\n",
      " -2.29071006e-02 -2.28676200e-02 -6.15818426e-03 -8.55979603e-03\n",
      " -2.31350567e-02 -1.49864284e-02 -1.31285228e-02 -2.92816740e-02\n",
      "  3.26032261e-03 -1.10472052e-03 -3.67100127e-02  1.37512665e-02\n",
      " -1.53044686e-02  2.03547738e-02 -6.68798457e-04  6.31728768e-03\n",
      " -3.00981551e-02 -6.57887831e-02  4.82802978e-04 -4.68220655e-03\n",
      " -2.01751031e-02 -1.51434001e-02 -9.12743446e-04 -1.34696681e-02\n",
      " -2.89820507e-02  1.52346864e-02  3.64100980e-03 -1.08214961e-02\n",
      " -1.65865701e-02  5.27799428e-02 -4.91485111e-02 -2.95787528e-02\n",
      "  4.26753936e-03 -6.28061220e-03 -9.49921738e-03 -1.21648181e-02\n",
      "  2.71497462e-02 -5.03013954e-02  9.71238624e-05 -1.33660352e-02\n",
      " -3.22935432e-02 -6.02408201e-02 -4.29347120e-02 -1.21110743e-02\n",
      "  2.10461486e-02 -6.21688962e-02  9.21180751e-03 -4.61498201e-02\n",
      " -1.80365238e-02  2.68482324e-02  3.28925066e-02 -3.13814841e-02\n",
      " -1.16986092e-02 -4.76125479e-02 -5.36963157e-03 -8.56094621e-03\n",
      "  6.73097232e-03 -1.27797679e-03  3.22040990e-02 -7.53773749e-02\n",
      " -1.70976724e-02 -3.78074124e-02 -3.01706083e-02 -5.11268200e-03\n",
      "  3.24062482e-02 -3.61923352e-02 -2.30151564e-02 -9.57738236e-03\n",
      " -1.24456892e-02 -1.99244041e-02 -1.46115357e-02 -3.77579443e-02\n",
      "  1.20364251e-02 -6.21506944e-02 -5.39916269e-02 -2.06225878e-03\n",
      " -1.86275989e-02 -1.66479510e-03 -2.34625172e-02 -5.33723049e-02\n",
      "  2.35394984e-02 -1.33807864e-02  2.00981405e-02 -4.58488539e-02\n",
      " -1.83142219e-02 -3.65881575e-03 -4.35093977e-02 -3.76880094e-02\n",
      " -3.42945009e-03  4.18220200e-02 -1.36987388e-03 -3.04562002e-02\n",
      "  5.35308681e-02  2.44419044e-03 -6.37378246e-02 -2.00215611e-03\n",
      " -6.48878887e-03  2.09588706e-02 -4.42894883e-02  3.85045744e-02\n",
      " -1.75690837e-02 -3.44604105e-02  3.03844427e-04  8.65565334e-03\n",
      " -2.76411325e-02 -4.52407449e-02 -3.06555927e-02 -2.99178250e-02\n",
      "  2.50574853e-03 -2.23446116e-02  3.05951461e-02  6.62475219e-03\n",
      " -2.74766935e-03  3.00114546e-02  2.38329228e-02  9.09398310e-03\n",
      "  9.29041114e-03  5.87666407e-02  5.57228271e-03 -6.11532107e-02\n",
      " -9.66223236e-03 -3.87459956e-02 -5.30973300e-02 -2.94565354e-02\n",
      " -2.80125681e-02 -4.99341190e-02 -5.25991432e-03  1.49117233e-02\n",
      " -3.57088707e-02 -4.85410318e-02 -3.32152136e-02 -2.05825120e-02\n",
      " -2.68356111e-02 -6.94961995e-02  1.06826965e-02 -2.38547251e-02\n",
      " -6.31125420e-02 -3.46604511e-02 -2.66686641e-02 -1.77357271e-02\n",
      "  1.76979937e-02  4.12909947e-02  2.50562504e-02  1.12330271e-02\n",
      "  2.18242337e-03 -1.89379193e-02  3.13815624e-02 -9.30507779e-02\n",
      " -9.08439755e-02 -7.07907695e-03 -2.61996016e-02  1.73178017e-02\n",
      " -3.14988494e-02  2.70870477e-02 -5.95796518e-02 -1.86941065e-02\n",
      " -6.57851174e-02 -3.81471626e-02 -3.32417525e-03 -3.84858176e-02]\n",
      "discriminator_8/conv_block_86/conv2d_86/kernel:0 [[[[-1.74701065e-02  6.30004629e-02 -1.84984207e-02 ... -1.17912632e-03\n",
      "     1.95174795e-02  3.76049839e-02]\n",
      "   [ 1.67458877e-02 -3.58926468e-02  1.32148676e-02 ... -2.63242349e-02\n",
      "     2.16263793e-02 -1.89728402e-02]\n",
      "   [-2.81794090e-02 -1.97700448e-02  1.98914092e-02 ... -2.08720230e-02\n",
      "     2.57513812e-03 -4.76818474e-04]\n",
      "   ...\n",
      "   [-8.41922883e-04  3.64695825e-02  2.28636917e-02 ... -5.10478439e-03\n",
      "    -4.91818823e-02  2.41589043e-02]\n",
      "   [-4.64985669e-02  9.33424570e-03 -1.39256418e-02 ...  1.70161501e-02\n",
      "    -6.59409091e-02  1.71888038e-03]\n",
      "   [-2.90541817e-02  1.24864103e-02 -9.92929563e-03 ... -3.93437594e-02\n",
      "    -3.84670980e-02  2.72542834e-02]]\n",
      "\n",
      "  [[ 3.60119604e-02 -1.94381848e-02 -1.56499520e-02 ... -6.18525175e-03\n",
      "    -3.38492319e-02  5.76917920e-03]\n",
      "   [ 1.80489924e-02  5.27822971e-02  1.93301942e-02 ...  1.75320078e-02\n",
      "     5.21801822e-02  1.69371832e-02]\n",
      "   [ 1.16576320e-02  6.82349177e-03  2.79572140e-02 ...  1.99040063e-02\n",
      "     2.25263219e-02  3.36759016e-02]\n",
      "   ...\n",
      "   [-1.12567618e-02 -4.05136459e-02  2.78049707e-02 ... -5.03325015e-02\n",
      "    -4.39126752e-02 -2.77895574e-02]\n",
      "   [-5.36143854e-02  1.63502637e-02  1.36328992e-02 ...  2.95414478e-02\n",
      "     1.73923990e-03 -2.34681554e-03]\n",
      "   [-4.60567810e-02  5.72051145e-02  3.45447962e-03 ... -2.06841324e-02\n",
      "    -1.74950752e-02 -1.87208075e-02]]\n",
      "\n",
      "  [[ 8.53738468e-03 -7.08738342e-02  4.90664244e-02 ... -5.33721736e-03\n",
      "    -3.72887030e-02 -3.04106232e-02]\n",
      "   [-1.10349525e-02 -5.35852974e-03 -5.55932010e-03 ... -3.48981582e-02\n",
      "    -1.93348303e-02  7.70891877e-03]\n",
      "   [ 5.50586497e-03 -2.58648600e-02  3.15350778e-02 ... -2.98781358e-02\n",
      "    -3.19245993e-03 -1.87868474e-03]\n",
      "   ...\n",
      "   [-2.39263326e-02 -6.96911886e-02  2.83617750e-02 ... -6.19308499e-04\n",
      "    -2.04350315e-02 -2.11425703e-02]\n",
      "   [-4.52021696e-02  1.39612798e-02  5.03423950e-03 ...  1.88706089e-02\n",
      "     4.90700416e-02  3.08713149e-02]\n",
      "   [-1.66726001e-02  3.64225321e-02 -3.07908207e-02 ... -5.06976284e-02\n",
      "    -2.32787710e-03 -5.12559619e-03]]]\n",
      "\n",
      "\n",
      " [[[ 6.45806640e-03  2.97264215e-02 -1.18596479e-02 ...  1.43323699e-02\n",
      "    -2.16143951e-02  1.57249942e-02]\n",
      "   [ 3.51788476e-03  1.46311941e-02 -1.83597039e-02 ...  9.07159224e-03\n",
      "    -2.29988769e-02  4.72408906e-02]\n",
      "   [-9.93630756e-03  4.62122448e-02 -1.51521973e-02 ...  2.21493393e-02\n",
      "    -3.07762325e-02  8.12064037e-02]\n",
      "   ...\n",
      "   [ 5.57362139e-02  3.45266350e-02 -5.83761744e-03 ... -3.16596776e-02\n",
      "    -2.36251224e-02  1.07062804e-02]\n",
      "   [-8.92105252e-02 -5.56063280e-02  1.24141909e-02 ...  2.74700783e-02\n",
      "     1.80759709e-02  1.26331681e-02]\n",
      "   [-4.54545347e-03  1.98347326e-02  4.18578945e-02 ...  2.86633950e-02\n",
      "     4.11406122e-02  8.59145634e-03]]\n",
      "\n",
      "  [[ 2.66264696e-02  2.51573492e-02 -3.23819253e-03 ...  2.16640029e-02\n",
      "    -2.54964661e-02  4.57308367e-02]\n",
      "   [ 4.70449915e-03  3.72199528e-02 -1.44231664e-02 ...  1.43281249e-02\n",
      "    -1.10988542e-02 -5.80219694e-06]\n",
      "   [-3.53362113e-02  2.88223382e-02  4.48588319e-02 ... -1.79781951e-02\n",
      "     7.13828132e-02  2.18274239e-02]\n",
      "   ...\n",
      "   [ 6.85002981e-03 -1.32263135e-02  6.96095172e-04 ... -2.72053963e-04\n",
      "    -5.28605096e-02  2.62370128e-02]\n",
      "   [-6.01617880e-02 -8.06761847e-04 -5.21690771e-03 ...  5.91330491e-02\n",
      "    -7.80054275e-03 -5.44845425e-02]\n",
      "   [-2.14061234e-02  4.57189940e-02 -9.90511663e-03 ...  3.69931497e-02\n",
      "     1.86393447e-02 -4.38559502e-02]]\n",
      "\n",
      "  [[-6.16086740e-03  2.52906070e-03 -8.14619008e-03 ...  2.32638586e-02\n",
      "     2.78067365e-02 -9.26170498e-03]\n",
      "   [ 6.16349606e-03 -3.00313868e-02  1.71229467e-02 ... -3.38549688e-02\n",
      "    -2.16596276e-02  4.56953282e-03]\n",
      "   [ 3.52194086e-02 -1.99904796e-02  1.85490947e-03 ... -2.01160870e-02\n",
      "     4.81624119e-02  6.84958068e-04]\n",
      "   ...\n",
      "   [-1.85588992e-03 -2.48605926e-02  6.50164783e-02 ... -5.25085032e-02\n",
      "     8.06704257e-03 -6.79817498e-02]\n",
      "   [-4.04960178e-02  4.63608578e-02 -2.67378800e-03 ...  6.74900636e-02\n",
      "     6.33015111e-02 -2.46242550e-03]\n",
      "   [-5.43906353e-02 -1.19710499e-02  2.81990226e-02 ... -3.42648812e-02\n",
      "    -1.60952713e-02 -3.91647592e-02]]]\n",
      "\n",
      "\n",
      " [[[-1.86842084e-02 -3.18787619e-03 -1.24195451e-02 ... -8.36673658e-03\n",
      "     3.38312611e-02  8.71610641e-02]\n",
      "   [ 1.33305080e-02 -2.43906374e-03 -6.61879545e-03 ... -6.45748749e-02\n",
      "     8.51271115e-03  4.02300954e-02]\n",
      "   [-4.81871306e-04  1.45969242e-02  2.04705466e-02 ...  3.83845121e-02\n",
      "    -2.89822221e-02  3.89860012e-02]\n",
      "   ...\n",
      "   [-3.71353477e-02  1.17097888e-02  4.48217429e-03 ... -3.32673974e-02\n",
      "    -7.78528601e-02 -6.85383519e-03]\n",
      "   [-2.11053118e-02 -2.35427283e-02  2.69005001e-02 ...  4.65713255e-02\n",
      "    -1.88964158e-02  1.41669447e-02]\n",
      "   [ 2.01429967e-02 -2.53884401e-02  2.38623656e-02 ... -8.82452633e-03\n",
      "     5.27832285e-03 -1.66392289e-02]]\n",
      "\n",
      "  [[-1.09285265e-02  6.30132556e-02  1.13014942e-02 ...  2.67923214e-02\n",
      "     5.67505695e-03  2.27120388e-02]\n",
      "   [ 2.74112504e-02  1.40361050e-02  1.76522252e-03 ...  1.34106865e-03\n",
      "     2.92224884e-02 -4.11836989e-02]\n",
      "   [ 5.66243231e-02  6.41882345e-02 -1.76274683e-02 ...  2.17672326e-02\n",
      "     1.27296234e-02  8.74153301e-02]\n",
      "   ...\n",
      "   [-1.94808375e-02 -3.24216746e-02  2.21636370e-02 ...  4.05827835e-02\n",
      "     2.06055865e-03  5.24802022e-02]\n",
      "   [-6.37482256e-02 -5.61068729e-02 -1.72441825e-02 ...  9.77434739e-02\n",
      "     5.04947118e-02  5.45312883e-03]\n",
      "   [-3.35799120e-02 -4.49320786e-02  5.00411019e-02 ... -2.52543036e-02\n",
      "     1.58322621e-02 -3.92281339e-02]]\n",
      "\n",
      "  [[ 3.17124724e-02  2.66172104e-02  5.41756302e-02 ...  1.15547441e-02\n",
      "    -1.49775166e-02  5.14800362e-02]\n",
      "   [ 1.02279242e-02  6.42972216e-02 -1.38442554e-02 ... -6.04780838e-02\n",
      "     8.90955701e-03 -2.32075970e-03]\n",
      "   [ 2.06771046e-02  1.22192979e-03 -2.42031142e-02 ... -3.85141633e-02\n",
      "     1.88345239e-02  4.65737022e-02]\n",
      "   ...\n",
      "   [-3.79047845e-03 -8.51720572e-03 -1.17593044e-02 ... -2.74411328e-02\n",
      "    -3.52019444e-02  1.72330681e-02]\n",
      "   [-7.06736371e-02  1.32414913e-02  5.20124193e-03 ...  5.59428856e-02\n",
      "     2.16413289e-02  5.11074290e-02]\n",
      "   [-2.52273660e-02 -3.70657607e-03  1.09759690e-02 ... -2.28195023e-02\n",
      "     2.49239709e-02  5.90157183e-03]]]]\n",
      "discriminator_8/conv_block_86/conv2d_86/bias:0 [-3.37188394e-05 -6.38733991e-06 -1.26126484e-04 -8.79439176e-05\n",
      " -7.87333265e-05 -1.91866002e-05 -3.01561122e-05 -1.09436594e-04\n",
      "  1.35305309e-04  2.50724752e-05 -1.66223224e-04  7.77748210e-05\n",
      " -1.43615216e-05  2.04093274e-04  1.78185815e-04  3.46361812e-05\n",
      " -1.27869916e-05  3.12279444e-05 -9.60146062e-05  9.08192451e-05\n",
      "  1.17834432e-04  4.06857271e-06  3.55831762e-05  5.17301960e-05\n",
      "  6.02500631e-06 -7.64321812e-05 -7.86829114e-05 -1.51481901e-04\n",
      " -1.07852547e-05  2.80731601e-05  4.26270963e-05 -2.00516970e-05\n",
      " -7.92065184e-05  8.14736559e-05  1.67218950e-05  5.59709297e-05\n",
      "  3.71515518e-04  5.37808482e-05  2.49319037e-05  7.10039239e-05\n",
      " -6.43910607e-05 -9.46557047e-05 -2.11656588e-05 -6.66998094e-05\n",
      " -6.36745754e-05  6.52165545e-05  1.70766070e-05  4.66716629e-05\n",
      "  4.56593843e-05  3.42113926e-05 -1.38076912e-05 -1.41939861e-04\n",
      "  9.66043153e-05 -7.33471534e-05  2.72259567e-05  1.27352578e-05\n",
      "  7.35463982e-05  1.12777721e-04 -3.87634973e-05 -9.79471406e-06\n",
      " -1.94876193e-04  8.86057969e-05 -1.00246973e-04  4.61454147e-05\n",
      "  1.13082001e-06 -1.04984683e-05 -1.90420142e-05 -8.21107024e-05\n",
      "  5.09969432e-05  2.60358283e-05 -2.08665733e-05 -3.66056047e-05\n",
      " -6.85543710e-05  9.66245134e-05 -6.20190331e-05 -1.59373740e-04\n",
      "  5.38653221e-05  4.85230739e-05  1.46963012e-05 -9.16887657e-05\n",
      " -1.52685112e-04  1.07863663e-04 -6.45140244e-05  9.32530675e-05\n",
      " -2.94891488e-05 -2.08936530e-04 -3.62983665e-05 -1.18992146e-04\n",
      " -7.29728345e-05 -1.19623946e-04  3.55992852e-05 -8.68830248e-05\n",
      " -4.85722121e-05 -2.89983564e-05  1.73090928e-04  6.02092150e-05\n",
      " -6.53557436e-05  5.06683173e-05  1.82790009e-05  3.89075067e-05\n",
      " -2.34746331e-05 -1.73025372e-04  2.02011706e-05  3.90211426e-05\n",
      " -1.27775114e-04  3.91124377e-05 -2.92529403e-05  1.27160150e-04\n",
      " -1.11610725e-05 -2.66386432e-05 -1.85975150e-05  4.14735259e-05\n",
      "  2.95686368e-05  1.73132445e-04 -7.95362648e-05 -7.52782216e-05\n",
      "  1.15731615e-04 -1.27263374e-05  1.87962250e-05  7.03594997e-05\n",
      "  6.88174114e-05  2.00909835e-05  4.76967398e-05 -8.18563858e-05\n",
      "  1.15633098e-04  1.31132647e-05 -4.00437821e-05 -1.24227154e-04]\n",
      "discriminator_8/conv_block_86/batch_normalization_140/gamma:0 [0.9921219  0.9805802  1.0142361  1.0269269  1.014007   1.0316476\n",
      " 1.0020416  0.9979083  1.0046853  1.023939   1.0012999  0.9941069\n",
      " 0.96380484 0.99269074 0.99910074 0.9741965  1.0042326  1.0024754\n",
      " 0.9759255  1.0007443  1.0221963  1.0112038  1.0598415  0.97538966\n",
      " 1.0164895  0.97601587 1.0023369  1.0021578  0.94795746 1.0007743\n",
      " 1.0458907  1.0288246  1.0075111  1.0108477  1.045235   0.98739547\n",
      " 1.0095301  0.9947736  1.0304183  1.029067   1.008939   0.99945945\n",
      " 0.9858058  1.0045263  1.001653   1.0129675  1.0091984  1.004615\n",
      " 0.9835659  0.9990438  0.9871321  0.9701359  1.0014341  1.0150063\n",
      " 0.98890007 0.99295175 1.0023184  1.0124555  1.0132794  1.0113375\n",
      " 1.0023795  1.0111364  1.0296715  1.0090948  1.0108408  1.038522\n",
      " 0.97905266 0.99642724 1.0241406  0.9528772  0.99808574 0.9749365\n",
      " 1.0044312  0.9981678  0.9921187  1.0367793  1.0004834  1.0159521\n",
      " 0.9882267  0.9826876  0.9599919  1.0035725  1.0085108  0.9710291\n",
      " 1.0058988  0.96936625 1.0006714  1.0367746  1.0025206  0.9981578\n",
      " 0.9790673  1.0174518  1.0138049  1.0072793  1.0223097  0.97972584\n",
      " 0.98739976 0.9943858  0.96692187 0.99292517 0.9779515  0.99699044\n",
      " 1.0069541  0.9953835  0.98433113 1.0167702  1.0022898  1.0011593\n",
      " 0.9865013  0.96902233 0.99698627 1.0100248  1.0175593  1.0350298\n",
      " 0.9975611  0.9932812  0.9943786  0.9951066  0.99776924 1.0069025\n",
      " 1.0192087  0.9766391  0.9682419  0.9807441  0.9971074  1.0011506\n",
      " 1.0135018  1.0046103 ]\n",
      "discriminator_8/conv_block_86/batch_normalization_140/beta:0 [-0.00738495  0.03340177 -0.04276711  0.00844356  0.00234246 -0.02011638\n",
      " -0.00865204 -0.02788169  0.02877214 -0.00870089 -0.03971733 -0.03096432\n",
      " -0.00103365 -0.06853854 -0.02873896 -0.03117827  0.02650699  0.00154046\n",
      " -0.01606024 -0.05083168 -0.03572585  0.01525163  0.05875822 -0.02753572\n",
      " -0.02645885  0.01416609 -0.00778995 -0.02016041 -0.06771711 -0.01681501\n",
      "  0.02872169  0.03447331 -0.05528192  0.01334414  0.03764804 -0.0389425\n",
      " -0.04870643 -0.00254399  0.00624871  0.04977688 -0.04926291 -0.0148046\n",
      "  0.01406212  0.02897889 -0.03639358 -0.00606537 -0.03187127 -0.03672464\n",
      " -0.0286745  -0.01166183 -0.01503721 -0.01120096  0.00456856 -0.01029965\n",
      " -0.02723676  0.01012136  0.01626777 -0.01810726 -0.01819314 -0.00385608\n",
      "  0.00453829 -0.03716745 -0.02139357  0.008005    0.03423548  0.03744574\n",
      " -0.06843618 -0.02870659  0.03984159 -0.0275474  -0.03001595 -0.03897392\n",
      "  0.00231528 -0.01332264 -0.01585717 -0.02873209 -0.03219794  0.01023551\n",
      "  0.0073567   0.01934354 -0.05147263 -0.01637755 -0.00185357 -0.00603386\n",
      "  0.00362512 -0.05240853 -0.02707863  0.02365388 -0.00906207 -0.01600188\n",
      " -0.00658888  0.06094263  0.01384034 -0.00627284 -0.00087754  0.00365296\n",
      "  0.01452029 -0.03110302 -0.02654712 -0.00368984 -0.04624914 -0.01775703\n",
      "  0.0164444  -0.03257932 -0.01521987  0.02093423 -0.01740653  0.00842871\n",
      " -0.01515255 -0.00733216  0.01870143 -0.00128819  0.01682298 -0.0248467\n",
      "  0.01188702 -0.03381659 -0.03475164 -0.0359873   0.01136942 -0.00447309\n",
      " -0.06578195 -0.08024413 -0.01666928 -0.00395603  0.00968164 -0.05001161\n",
      "  0.04690893 -0.01524725]\n",
      "discriminator_8/conv_block_87/conv2d_87/kernel:0 [[[[-0.04343547 -0.05462285 -0.28321424 ... -0.05065241 -0.03259346\n",
      "     0.07205324]\n",
      "   [ 0.01630512 -0.27446535 -0.05119492 ...  0.2642685   0.10029822\n",
      "    -0.02096069]\n",
      "   [ 0.1091452   0.24549049 -0.19125113 ...  0.19524476  0.027944\n",
      "    -0.25019383]\n",
      "   ...\n",
      "   [-0.08838873  0.08514076  0.18274051 ...  0.2302342  -0.21313164\n",
      "     0.08951555]\n",
      "   [ 0.1873585  -0.00364646  0.06479955 ...  0.0147123   0.04154402\n",
      "    -0.05597027]\n",
      "   [-0.01149773 -0.08112686  0.1377357  ...  0.16667798 -0.03990851\n",
      "    -0.15051776]]]]\n",
      "discriminator_8/conv_block_87/conv2d_87/bias:0 [-1.91686122e-05  8.34090461e-05 -2.40804711e-05 -1.43404919e-04\n",
      " -3.13694385e-04 -2.58488348e-04 -2.42993585e-04  1.22132275e-04\n",
      "  2.14226573e-04  7.30027095e-05  2.23553056e-04 -1.12425732e-04\n",
      " -1.23777732e-04 -1.00820922e-04  1.91895975e-04 -6.88577493e-05\n",
      " -1.19201301e-04  1.81502633e-04 -9.15812998e-05 -1.22301237e-04\n",
      " -3.28476250e-04  7.39718162e-05 -3.78580116e-05  1.35965689e-04\n",
      " -9.11089010e-05 -6.41531442e-05 -7.85189150e-06  8.16549582e-05\n",
      "  1.16076822e-04 -7.03460755e-05 -7.37499286e-05 -6.62114908e-05\n",
      " -8.11557620e-05 -8.56077022e-05  8.90828596e-06  2.48499455e-05\n",
      "  6.02895088e-05 -3.18212959e-04 -2.83923182e-05 -1.17380790e-04\n",
      " -1.66153688e-06 -2.79643340e-04 -1.93304131e-05 -5.60743429e-05\n",
      "  1.74592613e-04 -4.19939170e-05 -6.48008790e-05  1.08593238e-04\n",
      "  3.51628114e-05 -1.85075623e-04  2.29976795e-04 -8.13845691e-05\n",
      " -6.44628017e-05  5.46899173e-05  1.78673101e-04 -2.76570587e-04\n",
      "  2.16584255e-07  1.83870885e-04 -1.97736095e-04  8.59953361e-05\n",
      "  1.68610422e-04 -4.43879806e-04  2.72286154e-04  2.37898523e-04\n",
      "  1.11841808e-04 -8.06648895e-05 -1.36803385e-04 -2.02590745e-05\n",
      "  5.19958530e-06  3.18744394e-04 -2.49522691e-06  4.84976190e-05\n",
      "  9.25256318e-05 -6.69668734e-05 -1.69107123e-04 -1.26953033e-04\n",
      "  1.81902506e-05  5.56151099e-05  2.77723389e-04  1.54576264e-04\n",
      "  7.79782567e-06 -3.17319755e-05  1.13882452e-04  1.54993919e-04\n",
      "  2.44116472e-05 -1.24925893e-04 -1.39701355e-04  1.08936219e-04\n",
      " -9.49373643e-05  1.23121979e-04 -2.14232682e-06  2.95684858e-05\n",
      "  7.74209257e-05  1.61497446e-05 -2.27627868e-04 -7.23383209e-06\n",
      " -2.84958747e-04 -2.57117441e-04 -6.53027892e-05 -4.42188866e-05\n",
      "  8.08505793e-05 -2.19189285e-04 -2.25293494e-04  1.87422658e-04\n",
      "  2.99751082e-05 -9.68766108e-06  2.75489903e-04 -1.80839688e-05\n",
      " -8.83653047e-05 -1.26226063e-04 -1.82784264e-04 -2.98829575e-04\n",
      " -2.75410770e-04  2.50731653e-04  2.11774255e-04 -1.06103522e-04\n",
      "  4.94085543e-05  8.47437695e-05  4.10057910e-05 -1.93820990e-04\n",
      "  1.75099965e-04  2.55257852e-04  9.96693343e-05  2.28512901e-04\n",
      "  6.56177435e-05 -1.24123369e-04  1.06839645e-04 -2.29604106e-04]\n",
      "discriminator_8/conv_block_87/batch_normalization_141/gamma:0 [0.98332614 1.0059657  0.9815934  0.9841272  0.99537337 1.0218444\n",
      " 0.97510433 1.0081701  0.9991627  1.0105888  1.0240926  0.9774818\n",
      " 1.0167783  0.9752957  0.9880701  0.9940268  1.0083928  1.0069934\n",
      " 1.0149542  0.97429687 1.0157007  0.9811327  0.99566996 1.0121623\n",
      " 1.0235794  0.9852062  0.99349743 1.0041647  1.0194749  1.0466797\n",
      " 0.9980471  1.0034344  1.0086013  1.0060899  0.9697372  0.9920802\n",
      " 1.0022833  1.0204448  0.98826385 1.0152657  0.9635292  0.99496496\n",
      " 1.0359049  1.021103   1.021975   1.0152104  1.0241629  0.9782796\n",
      " 0.9926767  1.0046364  0.99804914 1.0205708  0.939488   1.0052166\n",
      " 0.9839545  1.012482   1.0050236  0.99571574 0.99791026 1.0027207\n",
      " 0.9771933  0.9868756  1.0144775  1.0257639  1.0240947  0.9820674\n",
      " 0.9932586  0.98033327 0.9980158  0.99041325 0.97169065 0.9783393\n",
      " 1.0048805  0.97943187 1.0491749  0.9726218  0.99992436 0.9752898\n",
      " 1.0354081  0.9947981  0.996434   0.9583387  1.0136222  0.9878059\n",
      " 0.98439765 0.9937881  1.0236142  1.0055792  1.0331488  1.0123875\n",
      " 1.0099068  0.99044883 0.99873453 0.98846513 1.0162196  0.9856208\n",
      " 1.0109338  0.9836846  0.9857819  1.0079699  1.0229865  0.9825451\n",
      " 1.0192126  0.9733497  0.9752916  0.97019446 0.9907567  1.0072118\n",
      " 0.98857087 1.0262711  1.0121536  0.98540896 1.0075542  0.9963351\n",
      " 1.0479866  1.0046184  1.0219986  1.0015408  0.94544894 0.9802778\n",
      " 0.99428797 1.0151767  1.0050595  0.95928514 0.9822335  1.039891\n",
      " 0.95228106 1.0271667 ]\n",
      "discriminator_8/conv_block_87/batch_normalization_141/beta:0 [ 0.00947044  0.03048124  0.01798258  0.00278139 -0.00810557  0.04297803\n",
      "  0.00969974 -0.01649034 -0.01367839  0.03919038 -0.00063376 -0.0096693\n",
      "  0.00798219  0.00717312 -0.00866879  0.01490146  0.02952858 -0.02581506\n",
      " -0.01358705  0.05559466  0.02099952 -0.00349364 -0.03447742 -0.03618705\n",
      " -0.00732213 -0.0301064  -0.01582354 -0.02691447  0.01769147  0.02579645\n",
      " -0.00842733 -0.01460795  0.03164679  0.02212783 -0.01836544  0.00132557\n",
      " -0.01841132  0.04347143 -0.00071789  0.00071363  0.00388007  0.01853713\n",
      "  0.02658812 -0.00081    -0.00712914  0.03639071 -0.05070214 -0.02866861\n",
      " -0.04774088 -0.01005988  0.0086537   0.04213548 -0.00386365 -0.0016327\n",
      " -0.04299273 -0.00615969 -0.04362177  0.02446036 -0.00523094 -0.02152026\n",
      " -0.05735015 -0.05983701 -0.01867766 -0.02298747  0.03457667 -0.01670525\n",
      " -0.03594733 -0.03117393 -0.03954231 -0.03046577  0.00207247 -0.02778635\n",
      "  0.00362698 -0.01819362 -0.02519152 -0.00014762  0.00307293 -0.03072098\n",
      " -0.02167308  0.00744564 -0.04044344 -0.04263356  0.02067841  0.02748215\n",
      "  0.00936853 -0.00936627 -0.02347102  0.0133217   0.01769167  0.01382051\n",
      " -0.02032892  0.0295277   0.01848137 -0.01394681 -0.04050333 -0.01651963\n",
      " -0.04865506  0.01333797 -0.01837013 -0.02061292 -0.02649759 -0.04157049\n",
      "  0.0276017   0.00279685  0.00302951 -0.00121987 -0.00430176 -0.00347118\n",
      "  0.02522835 -0.04176658  0.00599702  0.00413704  0.0236182  -0.04297232\n",
      " -0.01976395  0.02865567  0.00246381 -0.04780789 -0.02424401  0.01246357\n",
      " -0.01594197 -0.02228737 -0.00840794 -0.03630562 -0.01356748 -0.02102062\n",
      "  0.01081457  0.05216444]\n",
      "discriminator_8/conv_block_88/conv2d_88/kernel:0 [[[[ 2.73259878e-02  6.31990805e-02 -2.53386013e-02 ... -3.45232002e-02\n",
      "    -4.15572077e-02 -5.34248427e-02]\n",
      "   [-1.03906251e-01  1.63636357e-02  5.99897802e-02 ...  6.06581718e-02\n",
      "     5.10892756e-02  5.31311519e-02]\n",
      "   [ 1.16183814e-02  3.06633003e-02 -7.58875385e-02 ...  5.32461982e-03\n",
      "     1.51923830e-02  4.89958562e-02]\n",
      "   ...\n",
      "   [-8.33459664e-03 -7.58700222e-02  2.25727595e-02 ...  8.58564570e-04\n",
      "     8.39025974e-02  2.45172996e-02]\n",
      "   [ 1.99797656e-02  3.36955339e-02  2.66114697e-02 ... -5.47281988e-02\n",
      "    -3.26948799e-02  6.24219403e-02]\n",
      "   [ 4.43531610e-02  8.36848393e-02 -4.36164886e-02 ... -2.59733107e-02\n",
      "    -3.21712233e-02 -4.33031432e-02]]\n",
      "\n",
      "  [[ 5.33005456e-03  7.47405812e-02  3.56500894e-02 ... -1.39154186e-02\n",
      "    -1.79298744e-02 -7.11105391e-02]\n",
      "   [-4.38433327e-02 -5.02446294e-02 -5.46326712e-02 ... -2.94441003e-02\n",
      "     9.28284973e-02 -3.49482819e-02]\n",
      "   [-6.16250262e-02  1.40172560e-02 -2.94984560e-02 ...  2.84864325e-02\n",
      "     3.90414819e-02  2.87078265e-02]\n",
      "   ...\n",
      "   [-7.03329891e-02 -3.23054555e-05 -2.16421634e-02 ... -4.17717062e-02\n",
      "     4.23052609e-02 -3.13763469e-02]\n",
      "   [-3.01755350e-02 -8.96020234e-03 -1.50021724e-02 ...  1.46850832e-02\n",
      "    -3.29483338e-02 -2.49625407e-02]\n",
      "   [-2.05628145e-02  2.54076254e-03  6.64046267e-03 ... -6.43878579e-02\n",
      "    -3.54208425e-02  7.64520019e-02]]\n",
      "\n",
      "  [[ 7.47931600e-02 -3.20416726e-02 -1.31997718e-02 ...  3.69627122e-03\n",
      "    -2.93747112e-02 -2.89041288e-02]\n",
      "   [-1.20158838e-02 -3.23958285e-02  4.50664461e-02 ...  6.02073818e-02\n",
      "    -3.34860175e-03 -2.13363301e-02]\n",
      "   [ 1.46352537e-02  1.70488376e-02  3.11571900e-02 ...  1.00619994e-01\n",
      "    -2.04328131e-02 -2.71192845e-02]\n",
      "   ...\n",
      "   [-5.40109649e-02 -7.12745562e-02 -3.10710426e-02 ... -3.36553007e-02\n",
      "    -3.64118703e-02  5.65166064e-02]\n",
      "   [-8.53126403e-03 -3.71905193e-02  7.84200558e-04 ...  4.06469069e-02\n",
      "     1.26688452e-02 -6.12583160e-02]\n",
      "   [-6.01569526e-02 -1.77169908e-02 -3.77704799e-02 ...  5.11298142e-02\n",
      "    -5.76048605e-02  3.61765176e-02]]]\n",
      "\n",
      "\n",
      " [[[-2.71360464e-02 -5.39582223e-02  2.06033187e-03 ... -1.23398760e-02\n",
      "    -1.19285006e-02 -5.96443340e-02]\n",
      "   [-1.92739591e-02 -4.42064032e-02  4.09165099e-02 ...  3.57055962e-02\n",
      "    -5.38914315e-02  6.60745353e-02]\n",
      "   [ 1.91008113e-02  3.63735147e-02 -3.56386490e-02 ... -5.67674264e-02\n",
      "    -5.69396392e-02  2.46611517e-02]\n",
      "   ...\n",
      "   [-8.65197778e-02 -1.37909781e-02  1.91065278e-02 ...  7.94994831e-02\n",
      "     5.30871563e-02  4.72345911e-02]\n",
      "   [ 4.78256159e-02 -4.34347503e-02 -8.26002359e-02 ...  3.71544808e-02\n",
      "     9.09384992e-03  3.70555110e-02]\n",
      "   [ 4.42648456e-02  2.83014104e-02  1.18608577e-02 ... -2.65586395e-02\n",
      "    -4.61614653e-02  1.30733261e-02]]\n",
      "\n",
      "  [[ 5.63690737e-02  5.80863655e-02  3.76777351e-02 ... -1.24741104e-02\n",
      "     1.53217872e-03  7.60644600e-02]\n",
      "   [ 1.63305514e-02 -8.28073397e-02  1.03090908e-02 ... -3.60907204e-02\n",
      "     3.71408127e-02  1.48648340e-02]\n",
      "   [ 1.76812150e-02 -5.22809587e-02 -2.79930327e-02 ... -5.43230176e-02\n",
      "     3.63618173e-02 -3.44489552e-02]\n",
      "   ...\n",
      "   [ 8.82851556e-02  4.70204689e-02 -1.40746012e-02 ...  8.52217451e-02\n",
      "     2.30051521e-02 -7.69182816e-02]\n",
      "   [-4.66014296e-02 -4.39411886e-02 -5.74876331e-02 ... -1.72959436e-02\n",
      "    -1.36322621e-02  4.35111634e-02]\n",
      "   [ 3.62223051e-02  6.54283687e-02  6.81521818e-02 ...  3.01833637e-02\n",
      "    -4.00020927e-02 -1.46131115e-02]]\n",
      "\n",
      "  [[ 4.10417430e-02  3.20628323e-02 -4.21826504e-02 ... -3.38644232e-03\n",
      "    -6.78592473e-02 -1.64860059e-02]\n",
      "   [ 7.22940490e-02 -5.65803098e-03  3.34725566e-02 ...  6.25270903e-02\n",
      "     3.12169157e-02  1.82485916e-02]\n",
      "   [-7.76465759e-02 -6.34693727e-02 -5.50117083e-02 ... -6.45483881e-02\n",
      "     1.16692316e-02  1.70994997e-02]\n",
      "   ...\n",
      "   [ 2.43087206e-02 -4.66887112e-04  4.02596816e-02 ...  1.02037311e-01\n",
      "     4.80302721e-02 -3.10144797e-02]\n",
      "   [-9.25569013e-02 -5.49182110e-02 -8.13922808e-02 ... -1.07587846e-02\n",
      "     2.16474812e-02 -4.35742512e-02]\n",
      "   [-5.48095908e-03  4.85375449e-02 -4.82275859e-02 ... -1.88213009e-02\n",
      "    -3.26889418e-02  5.24508618e-02]]]\n",
      "\n",
      "\n",
      " [[[ 1.01978950e-01 -1.61038321e-02  5.70481680e-02 ... -6.70123771e-02\n",
      "     4.40024771e-02  7.36559629e-02]\n",
      "   [ 8.78616609e-03 -2.88460646e-02  7.02660084e-02 ...  5.50842397e-02\n",
      "    -7.92400762e-02  3.42400484e-02]\n",
      "   [ 7.72218630e-02  3.58876167e-03  9.45457909e-03 ... -5.31975813e-02\n",
      "     2.33785268e-02 -7.15045305e-03]\n",
      "   ...\n",
      "   [-1.55354179e-02 -2.72053550e-03  5.02612349e-03 ... -5.25774946e-03\n",
      "    -5.03850430e-02  4.58693430e-02]\n",
      "   [ 2.51118317e-02 -2.44597555e-03  1.79970693e-02 ... -2.33865958e-02\n",
      "    -2.52949968e-02 -2.20009387e-02]\n",
      "   [-7.63987377e-02  7.15505108e-02 -1.48088373e-02 ... -2.50276383e-02\n",
      "    -2.83520017e-02  2.75194459e-02]]\n",
      "\n",
      "  [[-4.60869186e-02 -1.13022765e-02  3.29873078e-02 ...  1.67643894e-02\n",
      "    -3.42349932e-02  2.71550827e-02]\n",
      "   [ 7.97606781e-02 -8.63565579e-02 -4.71284874e-02 ...  5.97140344e-04\n",
      "     2.56442446e-02  4.37654667e-02]\n",
      "   [ 1.98987406e-02 -3.02020404e-02 -2.94850543e-02 ...  4.81890589e-02\n",
      "     1.37730059e-03 -4.87509221e-02]\n",
      "   ...\n",
      "   [ 4.88473661e-02  1.16755879e-02  7.26728290e-02 ... -6.25261851e-03\n",
      "     1.36667471e-02  9.53180119e-02]\n",
      "   [ 3.08615379e-02 -9.88572137e-04 -2.68226638e-02 ... -3.04383934e-02\n",
      "    -2.71276888e-02  3.33074592e-02]\n",
      "   [-7.58147985e-02  3.92219573e-02 -4.09601629e-02 ...  2.75972094e-02\n",
      "    -3.98222404e-03 -3.98236029e-02]]\n",
      "\n",
      "  [[ 6.44756407e-02 -1.41168069e-02  6.42246306e-02 ...  2.02294979e-02\n",
      "    -2.84552127e-02  2.99826097e-02]\n",
      "   [ 5.30243143e-02 -3.07056289e-02 -6.48783520e-02 ... -7.53022805e-02\n",
      "     3.84921692e-02  1.24195963e-03]\n",
      "   [ 4.78382260e-02  8.15548003e-02 -1.49213346e-02 ...  3.87437716e-02\n",
      "    -8.47426504e-02 -1.08044915e-01]\n",
      "   ...\n",
      "   [ 3.05395536e-02 -2.29815990e-02  2.05488279e-02 ...  3.03813405e-02\n",
      "     2.20918022e-02  8.36139917e-02]\n",
      "   [-5.20935729e-02 -3.48965935e-02  2.55552400e-03 ...  2.89353952e-02\n",
      "    -1.76998433e-02 -4.78038713e-02]\n",
      "   [ 1.69696119e-02 -8.31675455e-02 -9.26798657e-02 ...  2.31683571e-02\n",
      "     6.14369325e-02 -1.60958022e-02]]]]\n",
      "discriminator_8/conv_block_88/conv2d_88/bias:0 [ 2.51848804e-04  1.76117639e-04 -4.13972884e-05 -2.75336963e-04\n",
      "  2.67261523e-04 -1.44610371e-04  5.51401230e-04  5.06142038e-04\n",
      " -1.91272702e-05 -8.28309130e-05  1.54593989e-04  2.48263714e-05\n",
      " -1.12912203e-04 -2.22722345e-04  1.85075347e-04  5.38769636e-05\n",
      " -1.54473659e-04 -2.07589037e-04 -5.94087178e-04  1.86045712e-04\n",
      " -7.52598862e-05  8.49025455e-05  5.13122723e-05 -7.96664172e-05\n",
      "  3.55136697e-04 -4.82156669e-04 -1.28221873e-04  1.36013798e-04\n",
      "  1.83706274e-04 -2.52901431e-04 -2.39161716e-04 -3.46963061e-04\n",
      "  1.22030928e-04  2.45616393e-04 -1.70526677e-04 -2.24344301e-04\n",
      "  1.04583036e-04  4.58520895e-04  4.29802632e-04 -2.97346152e-04\n",
      " -6.50885922e-05 -2.45012488e-04  1.66362064e-04  1.83539814e-04\n",
      "  1.48497158e-04 -9.49261594e-05  2.04816111e-04  5.39052533e-04\n",
      "  5.04283176e-04  2.95363607e-05 -8.21002468e-05  9.42743645e-05\n",
      " -1.56003007e-04 -2.44694733e-04 -8.19343113e-05  6.28778216e-05\n",
      "  2.49677050e-05  4.11883608e-04 -1.09498615e-04 -8.18792250e-05\n",
      " -2.51101650e-04  3.15496203e-04 -1.22146113e-04 -6.50127258e-05]\n",
      "discriminator_8/conv_block_88/batch_normalization_142/gamma:0 [1.0113133  1.0164381  1.0479603  1.0033357  1.0063804  1.0132296\n",
      " 0.99142575 1.0028917  0.9682588  0.97689784 0.98729813 1.0012558\n",
      " 1.0108881  0.9759813  0.9542381  0.99322426 1.0309107  1.0129184\n",
      " 0.99441403 1.0162581  0.99898094 1.0134422  1.0233508  1.0000743\n",
      " 0.9859217  1.0192592  1.0154808  1.0098443  0.9959313  1.0204513\n",
      " 0.9638922  1.0235806  0.9664634  1.0381557  1.0443939  1.0225799\n",
      " 1.003567   0.9940411  1.0269018  0.9905759  0.9952984  1.0031711\n",
      " 1.0196534  0.98542345 0.97959566 0.9933322  0.97330385 0.97112256\n",
      " 1.0466117  0.9874845  0.9930298  0.98611975 0.9895407  0.96634954\n",
      " 0.9870437  0.99991274 1.0254916  1.0221379  0.99055564 0.9753869\n",
      " 1.0255094  0.9752975  1.0043697  1.0158265 ]\n",
      "discriminator_8/conv_block_88/batch_normalization_142/beta:0 [ 0.01162411  0.0114971   0.05254183 -0.02555842 -0.00617614  0.00602545\n",
      "  0.01884522 -0.00012197 -0.00608162 -0.00786216 -0.00176708 -0.06997561\n",
      "  0.01888562 -0.03326224 -0.01017952 -0.01045329  0.04019484  0.0190506\n",
      " -0.01425346 -0.00347012 -0.02340632 -0.07815515  0.01599937 -0.04711469\n",
      " -0.05225659  0.00572316 -0.01277698 -0.01413817  0.00388078 -0.01802267\n",
      " -0.0267399   0.03038442 -0.02307165 -0.02691982  0.02412673 -0.09255521\n",
      " -0.00476914  0.00388341  0.01902501 -0.01671755  0.03112363 -0.02043688\n",
      " -0.00074515 -0.03725617 -0.00329083 -0.06112359 -0.02832815  0.0007466\n",
      " -0.01356044  0.00845295 -0.00979051  0.00717781 -0.03134572 -0.03683528\n",
      " -0.0053094   0.001058    0.03579143  0.00043435  0.0048602  -0.00592614\n",
      " -0.0472469  -0.02055445 -0.03513267 -0.03892045]\n",
      "discriminator_8/conv_block_89/conv2d_89/kernel:0 [[[[-0.25419933  0.3109233  -0.09019298 ...  0.28474322 -0.31220537\n",
      "    -0.17956701]\n",
      "   [-0.38808864 -0.21014737 -0.36130124 ...  0.21873234 -0.07801527\n",
      "     0.11309272]\n",
      "   [-0.320149    0.14492898  0.06533394 ...  0.15463156 -0.23797318\n",
      "     0.14470619]\n",
      "   ...\n",
      "   [-0.14231792  0.20771205  0.16510725 ... -0.05009834 -0.09852274\n",
      "    -0.26526582]\n",
      "   [ 0.17022358 -0.08583403  0.1423786  ...  0.18699248 -0.02926506\n",
      "    -0.03145655]\n",
      "   [-0.01855163 -0.24476478 -0.01509115 ...  0.09250344  0.35737607\n",
      "     0.1535103 ]]]]\n",
      "discriminator_8/conv_block_89/conv2d_89/bias:0 [-1.1083320e-04 -8.0628764e-05  1.4163493e-04  5.6644692e-04\n",
      "  2.4916462e-04 -1.0636768e-03 -3.9338044e-04 -3.7126703e-04\n",
      " -1.7191822e-04  6.3635205e-05  2.1964137e-04 -1.9708559e-05\n",
      "  5.8934494e-04 -1.2498452e-04 -5.1026384e-04  5.1557581e-04\n",
      "  1.2297311e-04  9.2638581e-04  1.4767384e-04 -1.3842664e-04\n",
      " -2.0070649e-06 -5.2625960e-04 -2.7776268e-04  5.9081975e-04\n",
      " -3.1651798e-04 -2.1791102e-04 -4.0912005e-04  2.2235603e-04\n",
      " -4.6852417e-04  3.5987643e-05  1.8179242e-04  5.3115587e-06\n",
      "  5.3132977e-04 -3.1875586e-04  1.5998044e-04 -2.8216201e-04\n",
      " -2.5832612e-04  6.7889370e-05  5.6660036e-04 -2.4888795e-04\n",
      "  1.2612456e-04 -4.5398640e-04  5.0268929e-05 -1.1602137e-03\n",
      "  2.8892318e-04 -1.4553512e-04 -7.6855766e-04 -3.8211295e-04\n",
      "  1.0854917e-04  4.9834354e-05  4.2191896e-04  1.2194221e-03\n",
      " -6.8054791e-04 -4.3304794e-05  1.7213316e-04  3.6641405e-04\n",
      " -6.0734735e-04 -7.7639241e-04 -2.7439746e-04  5.8302139e-06\n",
      "  5.8461126e-05 -1.7637579e-04  1.8514479e-04 -7.5459719e-04]\n",
      "discriminator_8/conv_block_89/batch_normalization_143/gamma:0 [1.007181   1.026805   1.0330902  1.0065664  1.0443463  1.0361584\n",
      " 1.0220513  1.0258161  1.0238576  1.0187802  0.9877848  1.0201435\n",
      " 1.0249726  1.0127611  1.0481769  1.0048558  1.0345112  1.0063369\n",
      " 1.0107185  1.0274469  1.0272968  0.9936644  1.018612   1.0240132\n",
      " 1.0166131  1.0104529  1.0154576  0.9861334  0.9943511  1.0182197\n",
      " 0.99526685 0.9914959  1.0033981  1.0192167  1.0178034  1.0113084\n",
      " 0.9930866  1.0154649  1.0225737  1.0151956  1.0197262  0.98865074\n",
      " 1.0001708  1.0737616  1.0326467  0.99484897 1.0262526  1.0095906\n",
      " 0.9876876  1.0018696  0.9818167  1.0357319  1.0374187  1.0121031\n",
      " 1.0062765  1.0190547  1.0316585  1.0059637  1.0162226  1.0449525\n",
      " 1.0888813  0.986285   1.0074766  1.0077614 ]\n",
      "discriminator_8/conv_block_89/batch_normalization_143/beta:0 [ 0.0019426  -0.00055414  0.01704803  0.03455313  0.03336258 -0.01128848\n",
      "  0.01023555  0.01372212 -0.00307743  0.03092487  0.01251769  0.00546433\n",
      " -0.00919879  0.01068042  0.03289524  0.00514761  0.03611585  0.01627821\n",
      "  0.02121253  0.03706016 -0.0120891  -0.00508352  0.0031746   0.0112642\n",
      "  0.02827455  0.01334347 -0.01901226  0.01538101  0.01580601  0.06242826\n",
      "  0.02269363  0.02146803  0.01653252  0.02836946  0.03049309  0.01954618\n",
      "  0.01619527 -0.01032738 -0.01329865 -0.00712965  0.0380775   0.02087744\n",
      "  0.01448464 -0.00486812 -0.00177058  0.0229659   0.03795164  0.01588464\n",
      "  0.01305043  0.00382752  0.01729386  0.01730343  0.0001279  -0.01460896\n",
      "  0.04094473  0.0049227   0.00578225  0.01749444 -0.01996447  0.0126885\n",
      " -0.00651681 -0.01363155  0.02660416  0.01754245]\n",
      "discriminator_8/conv_block_82/batch_normalization_136/moving_mean:0 [ 2.28899792e-01  3.75067830e-01 -3.18937570e-01  3.50279480e-01\n",
      " -7.27196783e-02  2.36426922e-03 -4.68757488e-02 -1.30372539e-01\n",
      "  5.17036498e-01 -9.09411013e-01 -1.49190068e-01 -3.87661089e-03\n",
      "  6.66409671e-01 -1.10671222e+00  4.54090089e-01  4.26509410e-01\n",
      "  7.31126726e-01  9.96630788e-02 -1.21509351e-01  2.12435260e-01\n",
      " -4.64075983e-01  5.11654802e-02  6.20764494e-01 -2.23480836e-01\n",
      " -4.78699386e-01  2.67087728e-01  1.80865258e-01  1.49128869e-01\n",
      " -7.97334909e-01 -6.41077161e-01 -2.49610618e-01  1.24261715e-01\n",
      "  6.63917884e-02  5.01318157e-01 -4.39821146e-02 -1.46075472e-01\n",
      " -4.30039197e-01  2.35188249e-02  3.81822586e-01 -4.53413963e-01\n",
      "  4.58712727e-01 -1.60155490e-01 -1.85978949e-01  4.14108247e-01\n",
      "  2.83980966e-01  6.31852984e-01 -6.18539631e-01  1.53098423e-02\n",
      "  5.66898823e-01 -6.68874502e-01  4.06796068e-01  2.30582103e-01\n",
      "  8.11675265e-02  1.95039958e-01 -1.24655342e+00 -8.42785870e-04\n",
      "  8.51658344e-01 -2.55994081e-01  6.58609211e-01 -7.62534618e-01\n",
      " -4.09796834e-01  1.91098765e-01 -3.58274467e-02 -9.26254764e-02\n",
      "  1.34123899e-02 -1.72711715e-01 -2.75773313e-02 -5.97604930e-01\n",
      " -1.79918692e-01  7.06102669e-01  7.16536045e-01 -1.54811159e-01\n",
      " -1.01091638e-01  4.12410855e-01  1.12897810e-02  1.49042517e-01\n",
      " -4.31729615e-01  5.55622578e-01 -1.90030292e-01  8.78026307e-01\n",
      " -1.02576986e-02 -1.78616256e-01 -3.63464862e-01  2.79023081e-01\n",
      "  5.96964002e-01  2.98070610e-01  2.33584464e-01  5.38486898e-01\n",
      " -1.26787618e-01  6.40996769e-02 -4.39736620e-02  1.13312215e-01\n",
      " -5.67254543e-01  1.02051616e-01  5.27956896e-03 -7.77848363e-01\n",
      "  3.31691206e-01 -3.13547790e-01 -3.22723053e-02 -2.98243333e-02\n",
      "  1.07693994e+00 -3.69457379e-02 -7.89261535e-02  1.96161523e-01\n",
      " -8.76034021e-01 -1.53010219e-01 -3.33657712e-01 -6.28021419e-01\n",
      " -3.63051444e-01 -3.71711254e-01 -9.74942803e-01 -1.97474901e-02\n",
      " -4.83971953e-01 -1.56339541e-01  5.65236919e-02  2.40923613e-01\n",
      " -2.31846377e-01 -1.82117820e-01  2.51471139e-02  3.02927941e-01\n",
      "  1.61673993e-01 -9.46653821e-03  1.70782909e-01 -7.74140880e-02\n",
      "  7.16651678e-01 -7.71315038e-01 -4.04530525e-01  5.23741066e-01\n",
      " -1.04309782e-01  8.14611852e-01  1.65408850e-02 -5.43599799e-02\n",
      " -1.27659261e-01 -3.01169246e-01  8.21415067e-01 -1.73477486e-01\n",
      "  2.74258435e-01 -5.11879146e-01  9.62021053e-02  5.52396536e-01\n",
      "  1.44628525e-01 -3.53194743e-01  5.76459408e-01 -3.65174711e-01\n",
      " -3.13742667e-01  9.31843594e-02 -3.06992501e-01 -4.27183181e-01\n",
      "  7.53536105e-01  2.75261521e-01  7.05399096e-01  1.36212274e-01\n",
      " -4.28247303e-02  2.71415532e-01  7.31513351e-02  1.93030722e-02\n",
      "  2.67001987e-01 -6.57576442e-01 -1.87668260e-02 -1.27155945e-01\n",
      "  9.16826259e-03 -4.84125614e-02  3.40008348e-01 -7.65712634e-02\n",
      "  4.58700769e-02  5.74808955e-01  6.88578010e-01 -1.42415725e-02\n",
      "  2.56258965e-01  3.56798112e-01 -9.91156280e-01 -1.30967144e-03\n",
      "  3.96748722e-01 -5.80141783e-01 -6.28268600e-01  2.77482003e-01\n",
      "  9.43915248e-01  6.35711789e-01 -5.00580907e-01  1.19946711e-01\n",
      "  2.14993313e-01 -5.76465428e-01  2.93146491e-01  3.47288959e-02\n",
      " -5.03404997e-02  3.61464322e-01 -1.08822262e+00  6.79951489e-01\n",
      " -3.32091272e-01  2.58553714e-01  1.03251541e+00  9.24579501e-01\n",
      "  7.52037585e-01  4.04978991e-01 -9.12410617e-01 -9.54258814e-02\n",
      " -6.35855138e-01 -5.02049387e-01 -7.85514116e-01 -2.60739058e-01\n",
      "  3.68234634e-01  2.64195383e-01 -8.87669399e-02 -9.31784809e-01\n",
      " -3.46591830e-01  2.37367880e-02 -1.30353391e-01 -1.39166206e-01\n",
      " -2.79263407e-01 -9.52545106e-01 -1.30944118e-01 -2.30326459e-01\n",
      " -8.57075974e-02  3.20311546e-01  1.30085617e-01  2.58075986e-02\n",
      "  5.75392127e-01  5.98649401e-03  3.39344919e-01  1.83149844e-01\n",
      " -1.05619274e-01  8.00727546e-01  3.67322832e-01 -1.57284528e-01\n",
      "  9.78107303e-02  3.70719582e-01  1.45375669e-01 -5.09228349e-01\n",
      "  9.40794170e-01  8.09687525e-02  7.24659339e-02 -6.40258044e-02\n",
      " -8.32616463e-02 -9.03890312e-01 -2.06199400e-02  5.57141542e-01\n",
      " -5.31462014e-01  9.05507207e-01 -5.30323803e-01 -6.03391886e-01\n",
      " -1.03227949e+00 -3.56698066e-01 -4.17685648e-03 -1.25529594e-03\n",
      " -7.68268434e-03 -3.33935529e-01  5.63860357e-01 -5.37472248e-01\n",
      "  2.14020029e-01  3.52511704e-01  1.01635087e+00  1.60594851e-01\n",
      " -4.78263944e-01 -3.48622561e-01  5.34109354e-01 -5.46499372e-01\n",
      " -3.58812660e-01 -1.69495936e-03 -2.16251254e-01  3.02199484e-03\n",
      "  1.44125998e-01  1.08148269e-01 -4.13038909e-01 -8.47284913e-01\n",
      " -5.48353732e-01 -2.45623216e-01  1.33421440e-02  3.02840948e-01\n",
      " -3.18032026e-01  2.72851974e-01  2.80238479e-01 -1.64918453e-02\n",
      " -9.51900899e-01 -9.12735611e-02  5.83876610e-01  1.87210608e-02\n",
      " -7.44142413e-01  3.54116768e-01  2.32673898e-01  4.46851701e-01\n",
      "  7.13099837e-01  9.43344951e-01 -9.48639438e-02 -6.28621459e-01\n",
      " -7.52538117e-03  9.15224999e-02 -7.61338100e-02 -2.42596805e-01\n",
      "  1.33682357e-03 -7.51806438e-01 -1.85463592e-01 -9.67416819e-03\n",
      " -1.91430785e-02  3.89216870e-01  8.42124522e-01  3.29558849e-02\n",
      " -6.58941388e-01  1.60330404e-02 -3.81232858e-01  4.05289322e-01\n",
      " -3.63423944e-01  1.63801998e-01 -1.11047402e-01 -8.68242264e-01\n",
      "  2.84873605e-01 -3.15848775e-02 -1.84030712e-01  1.21744521e-01\n",
      " -1.14522047e-01  1.33162773e+00 -4.37337726e-01 -1.74590317e-03\n",
      "  5.23090303e-01 -9.44547653e-02 -5.53620517e-01 -1.52591169e-01\n",
      "  9.26966488e-01  1.23043574e-01  4.60772738e-02  3.08870077e-02\n",
      "  2.37770658e-02  4.77029204e-01  9.76383507e-01  2.47656271e-01\n",
      "  1.79423153e-01  2.82388479e-01  1.06732242e-01  6.09619677e-01\n",
      "  4.08165812e-01 -9.63442028e-01  3.24846238e-01 -5.67423105e-01\n",
      "  7.75787055e-01 -5.07783592e-01 -3.30500662e-01 -1.44060478e-01\n",
      " -1.01799972e-01  5.62736750e-01  8.92784536e-01 -1.53388605e-01\n",
      "  1.60235316e-02 -2.90590078e-01 -2.94594228e-01  5.93480706e-01\n",
      "  4.05424356e-01  5.72273791e-01 -2.38152996e-01 -5.22176884e-02\n",
      " -7.56906033e-01  4.01228726e-01  2.91403104e-02 -5.96387923e-01\n",
      "  1.15700054e+00 -3.36873345e-02 -9.70355719e-02  8.48899111e-02\n",
      "  8.21355879e-01  5.26142567e-02 -1.69853315e-01  2.19853163e-01\n",
      "  1.45077512e-01  2.86625698e-03 -2.75992513e-01  1.24890864e+00\n",
      " -4.59580898e-01 -1.58047661e-01 -1.63189635e-01  8.85353088e-01\n",
      "  1.47556484e-01  4.52920934e-03 -7.53621340e-01  7.16558635e-01\n",
      "  5.82171440e-01  5.23954213e-01  1.03122205e-01  2.11985990e-01\n",
      " -1.62180901e-01  9.09900218e-02 -2.94067085e-01 -2.07104921e-01\n",
      " -1.65445447e-01  4.68238071e-02  1.40910566e-01  1.11554539e+00\n",
      " -4.96501416e-01 -7.19543248e-02  1.03570211e+00  6.30868793e-01\n",
      "  2.18143716e-01 -3.27286869e-01  1.40533596e-01 -5.14356084e-02\n",
      " -2.12380335e-01  7.70294249e-01  7.94956386e-01  7.51157925e-02\n",
      "  5.14868915e-01 -1.03482120e-01  2.02469647e-01 -4.40322936e-01\n",
      "  1.19485408e-02  6.29585862e-01  6.84071243e-01 -1.49804622e-01\n",
      " -4.39469606e-01  3.30113351e-01 -2.71083210e-02 -7.54330218e-01\n",
      " -1.62579507e-01  2.65388221e-01 -7.55901158e-01  1.10111758e-02\n",
      " -2.48791501e-01 -5.40024459e-01  3.45276273e-03  5.64296782e-01\n",
      "  7.41298616e-01  1.03787923e+00 -3.70512784e-01 -1.71974599e-01\n",
      " -9.51438118e-03 -2.44151160e-01  5.55112846e-02 -1.34959742e-01\n",
      "  5.14759541e-01  8.91459227e-01 -2.67100096e-01  1.44452736e-01\n",
      "  3.44191968e-01 -5.46012744e-02 -3.02737989e-02 -1.49407431e-01\n",
      " -1.54705048e-01 -2.99521033e-02  1.88173786e-01 -6.64281368e-01\n",
      "  2.39610951e-02 -3.02432906e-02  3.39670926e-01 -5.49115241e-01\n",
      "  7.91742325e-01 -9.10842866e-02  1.58900265e-02 -6.29622877e-01\n",
      "  2.41356716e-01 -6.35313382e-03  3.45762372e-01 -2.55678564e-01\n",
      "  1.60406798e-01  1.76744461e-01  6.29881099e-02 -2.53510684e-01\n",
      " -5.40563703e-01 -3.73596698e-01 -2.45922267e-01 -1.98891044e-01\n",
      " -1.15944386e-01  7.38206923e-01 -3.57709974e-01  6.60246849e-01\n",
      " -6.36071444e-01 -1.29734516e-01  2.14747339e-01  1.49994418e-01\n",
      "  8.82848322e-01  4.41935331e-01 -8.61462504e-02  1.20180048e-01\n",
      " -6.74112095e-03 -6.13373578e-01  8.15282285e-01 -5.56740701e-01\n",
      " -8.15093100e-01 -4.80956882e-01  6.65492475e-01  2.08339021e-01\n",
      "  5.88833749e-01  5.82931936e-01  1.00911245e-01 -3.73773009e-01\n",
      " -1.39151394e-01 -2.00173650e-02  1.08604934e-02  2.98423827e-01\n",
      " -1.47513375e-01 -3.13465223e-02 -1.18979430e+00  6.24198758e-04\n",
      " -6.71732426e-01  2.59146810e-01  9.34151113e-02  2.98528105e-01\n",
      " -7.79281706e-02  8.50963473e-01  1.10684335e+00  7.74911106e-01\n",
      " -2.62726218e-01 -1.81260124e-01  8.64870008e-03 -3.43896717e-01\n",
      "  1.90885618e-01 -1.38288781e-01 -4.68125232e-02  2.00649649e-01\n",
      " -3.83587062e-01 -3.67382914e-01 -2.99875557e-01  3.95812243e-01\n",
      " -3.71859386e-03  8.32746267e-01  6.45880401e-01 -8.15824032e-01]\n",
      "discriminator_8/conv_block_82/batch_normalization_136/moving_variance:0 [0.03945806 0.09928481 0.07831061 0.08998523 0.04409726 0.0664557\n",
      " 0.06488422 0.04034441 0.23094907 0.3404565  0.1314809  0.05867017\n",
      " 0.22869815 0.587922   0.11096846 0.08869507 0.22995976 0.03905155\n",
      " 0.05826844 0.06061656 0.27204564 0.16586179 0.19911559 0.03953101\n",
      " 0.17636614 0.09522309 0.04322366 0.09850404 0.23202558 0.16472036\n",
      " 0.12504137 0.09067897 0.05009509 0.12126495 0.01184404 0.02509764\n",
      " 0.13897403 0.02396818 0.09993778 0.10416792 0.12673452 0.0277529\n",
      " 0.08442815 0.09059294 0.07400711 0.2953564  0.1901564  0.01275093\n",
      " 0.18930174 0.16348854 0.13758773 0.03480204 0.03129909 0.09107253\n",
      " 0.62863094 0.00960317 0.27596763 0.10245225 0.1857657  0.30223244\n",
      " 0.08555351 0.04646938 0.02128526 0.03219995 0.04076925 0.03835173\n",
      " 0.0222365  0.14491804 0.05497117 0.20900433 0.19972008 0.06010493\n",
      " 0.02063735 0.09388814 0.08610739 0.02241778 0.07791808 0.1790401\n",
      " 0.05134252 0.3444338  0.01804004 0.04490597 0.05842161 0.05991224\n",
      " 0.15776053 0.07803362 0.08297329 0.14687209 0.03169769 0.01599216\n",
      " 0.02473343 0.0339324  0.25008318 0.06301164 0.05475638 0.25193188\n",
      " 0.06405429 0.04625578 0.01307075 0.01531142 0.48814335 0.04711788\n",
      " 0.04594241 0.03444513 0.2883236  0.09659813 0.09256117 0.38388512\n",
      " 0.08240285 0.11575219 0.37567407 0.01676497 0.09882312 0.02669889\n",
      " 0.04755568 0.04997056 0.07571299 0.08351257 0.02624989 0.06939574\n",
      " 0.09673064 0.04487432 0.05791523 0.03825406 0.22444111 0.28666136\n",
      " 0.10611886 0.10910536 0.02722755 0.2640243  0.05525012 0.02124403\n",
      " 0.05584832 0.06242627 0.2615814  0.02641691 0.07991887 0.18667752\n",
      " 0.01497112 0.23314449 0.08405854 0.10877584 0.23010428 0.07395191\n",
      " 0.07964062 0.03874944 0.14497282 0.15528525 0.25787273 0.05919006\n",
      " 0.19179553 0.08061475 0.04984812 0.06348976 0.10136303 0.10999539\n",
      " 0.07991036 0.22136536 0.01314839 0.06752864 0.06798705 0.02011923\n",
      " 0.103269   0.0354514  0.03127215 0.17061056 0.2702926  0.01013397\n",
      " 0.05033256 0.08011225 0.44335097 0.04387541 0.0672667  0.14506818\n",
      " 0.17108797 0.03526334 0.34991184 0.16563497 0.12060975 0.04130336\n",
      " 0.08890998 0.16813302 0.13898548 0.00808605 0.05072969 0.12870218\n",
      " 0.5668104  0.24475314 0.07421424 0.07137102 0.49370554 0.33298498\n",
      " 0.26578614 0.0851298  0.27924037 0.02725526 0.15678439 0.1424034\n",
      " 0.2730004  0.07049502 0.07456458 0.05638147 0.1448246  0.4118399\n",
      " 0.11699503 0.05965401 0.07640234 0.01861222 0.04971678 0.36034113\n",
      " 0.03892644 0.10814622 0.03316417 0.1279829  0.08804315 0.04830545\n",
      " 0.19664519 0.07947304 0.13233757 0.07175279 0.04029026 0.2855587\n",
      " 0.06589123 0.0262798  0.03381154 0.06252985 0.01670973 0.12262558\n",
      " 0.429165   0.03223786 0.01616389 0.0329162  0.03456302 0.33318222\n",
      " 0.03474338 0.23324461 0.12859376 0.37446058 0.10443383 0.28849706\n",
      " 0.4346619  0.10705823 0.01713496 0.01311728 0.03213721 0.11198906\n",
      " 0.14768371 0.18358932 0.06773099 0.08033188 0.39117542 0.07897411\n",
      " 0.09830154 0.089456   0.26019362 0.11650469 0.08723128 0.01864434\n",
      " 0.03933268 0.0068892  0.03915455 0.07190769 0.10195221 0.3176362\n",
      " 0.13746001 0.06654429 0.05850532 0.09504603 0.06571873 0.04858856\n",
      " 0.05614779 0.02100905 0.35351223 0.01395843 0.12697506 0.04827248\n",
      " 0.250666   0.10695121 0.09073751 0.158962   0.23094495 0.37808326\n",
      " 0.02556794 0.20724419 0.04399915 0.07913064 0.06538142 0.03712485\n",
      " 0.07662317 0.27264583 0.0576743  0.02311767 0.02211147 0.09034671\n",
      " 0.29398566 0.02308621 0.2217948  0.02121883 0.05986083 0.0885768\n",
      " 0.1651461  0.11043809 0.07655917 0.29755476 0.06231283 0.03443517\n",
      " 0.06655206 0.0228141  0.06599291 0.7586664  0.06612698 0.0410112\n",
      " 0.2180029  0.07497509 0.20334892 0.0947649  0.38721862 0.0449571\n",
      " 0.05637974 0.03011055 0.0498298  0.17234123 0.4658819  0.04670285\n",
      " 0.05298292 0.05849588 0.0238094  0.16583894 0.08801034 0.47101232\n",
      " 0.16116326 0.1520596  0.21220435 0.10853982 0.05388057 0.02399652\n",
      " 0.11485539 0.19461721 0.31620717 0.06613535 0.03589733 0.09193148\n",
      " 0.07275004 0.14499177 0.09557094 0.15702753 0.05458361 0.01128328\n",
      " 0.24216977 0.09234194 0.03128955 0.18796147 0.4831825  0.00988749\n",
      " 0.09671649 0.03395027 0.24490567 0.04998624 0.06039    0.05720184\n",
      " 0.07043197 0.0128974  0.05159441 0.6561886  0.11049509 0.0756214\n",
      " 0.0560259  0.29918656 0.02060803 0.03077664 0.21242166 0.18858486\n",
      " 0.18517265 0.33058232 0.04052928 0.12023254 0.03799681 0.04650719\n",
      " 0.17445834 0.05959486 0.05476202 0.0188003  0.02915482 0.5123784\n",
      " 0.14755455 0.05816539 0.41988963 0.17661959 0.03481507 0.08413642\n",
      " 0.06342323 0.06211568 0.04597043 0.24878235 0.27737454 0.11546715\n",
      " 0.1640167  0.04123843 0.09032173 0.07805312 0.02198739 0.28092986\n",
      " 0.219553   0.04647423 0.12420688 0.19689299 0.02092667 0.22271603\n",
      " 0.04977303 0.06201856 0.28471497 0.02965514 0.12060649 0.10174771\n",
      " 0.0317896  0.1671274  0.20751967 0.3871797  0.12520622 0.03170833\n",
      " 0.06393488 0.08324044 0.04415556 0.04636226 0.1133743  0.2951009\n",
      " 0.04999583 0.03603001 0.1239018  0.05140276 0.03658689 0.05683905\n",
      " 0.03916061 0.01528391 0.08251756 0.22367658 0.02916795 0.04224714\n",
      " 0.23808672 0.19596267 0.31485745 0.07794535 0.06717914 0.15712647\n",
      " 0.07749553 0.0219355  0.05465129 0.06024586 0.0298305  0.04615936\n",
      " 0.07351168 0.03977696 0.15337667 0.09014949 0.0506953  0.07962595\n",
      " 0.09974416 0.24309959 0.17876609 0.20179333 0.18119837 0.04228067\n",
      " 0.03483795 0.08084005 0.35376126 0.11745503 0.0220655  0.13784924\n",
      " 0.02814064 0.25114378 0.28521773 0.14097781 0.29138747 0.08280676\n",
      " 0.17843866 0.03156491 0.17522706 0.13614973 0.04090014 0.09553333\n",
      " 0.04501358 0.20096216 0.03847003 0.15686856 0.06478461 0.08614956\n",
      " 0.71891874 0.00930828 0.16442868 0.05940783 0.04775534 0.06695423\n",
      " 0.06901052 0.42828804 0.5583978  0.2814013  0.07769185 0.08548079\n",
      " 0.08577223 0.11195979 0.0350753  0.04234291 0.01855021 0.03590738\n",
      " 0.05676182 0.0789066  0.09608478 0.09986281 0.01199341 0.42215282\n",
      " 0.17912789 0.26138902]\n",
      "discriminator_8/conv_block_83/batch_normalization_137/moving_mean:0 [-5.00234962e-01 -1.09259021e+00 -1.07213914e+00 -5.52877903e-01\n",
      "  3.28280747e-01  8.36704016e-01 -1.13995736e-02 -1.34499800e+00\n",
      "  4.86303598e-01 -4.44720645e-04  8.36936355e-01 -2.49034837e-01\n",
      " -8.46761942e-01 -4.36928183e-01  1.51782751e+00 -7.62318790e-01\n",
      "  4.90267575e-03 -7.48465598e-01  4.05782014e-02  8.43550086e-01\n",
      " -1.15362287e+00 -9.72800255e-02  3.09274703e-01 -6.60298705e-01\n",
      "  7.26534605e-01 -6.11190379e-01 -5.93768895e-01 -3.94813210e-01\n",
      "  2.60555357e-01  1.17794067e-01 -5.78397334e-01  5.81159890e-02\n",
      "  1.46152031e+00 -1.99671667e-02 -1.23628986e+00  1.29655790e+00\n",
      "  1.75405756e-01  9.34184909e-01 -1.95237473e-02  4.79337186e-01\n",
      "  2.14463666e-01  2.20821379e-03 -2.12627441e-01 -4.11817543e-02\n",
      "  1.58145815e-01 -1.18261206e+00  1.85219240e+00 -1.57693133e-01\n",
      " -8.25036168e-01  1.87644288e-01 -1.67232883e+00  6.67045861e-02\n",
      "  5.68810327e-04 -1.65030372e+00 -5.14619946e-01  1.36439681e+00\n",
      "  5.01868844e-01 -3.84456158e-01 -1.31009603e+00  8.13066781e-01\n",
      " -3.22299540e-01  7.69611597e-01  1.61368465e+00 -6.47633001e-02\n",
      " -3.55870247e-01  1.70284688e-01 -3.74030679e-01  1.78784057e-01\n",
      " -5.36820769e-01  1.35554862e+00  6.68596804e-01  7.00332820e-01\n",
      " -6.31634057e-01 -5.99324763e-01 -3.84673834e-01 -1.01033831e+00\n",
      " -1.03123415e+00 -3.23743001e-02  1.95678994e-02  1.27417707e+00\n",
      " -1.08148682e+00  1.39206514e-01 -1.19339503e-01 -1.22539604e+00\n",
      " -6.90217733e-01  8.75635669e-02 -1.70996264e-01  5.81393316e-02\n",
      " -7.92584777e-01 -1.16921079e+00 -1.83621068e-02  1.58408773e+00\n",
      " -5.19592404e-01  6.21731132e-02  1.57203925e+00 -3.11669797e-01\n",
      "  9.48883966e-02 -4.63290364e-02 -6.38278062e-03 -1.35569882e+00\n",
      " -8.69534433e-01  1.92363870e+00 -1.89335153e-01  4.55667615e-01\n",
      " -1.20582283e+00  1.53573835e+00 -1.22201931e+00 -9.51902092e-01\n",
      "  1.70462821e-02 -1.86565667e-01 -8.77949536e-01 -8.44535232e-01\n",
      "  4.65733796e-01  8.37865695e-02 -1.20966256e+00 -2.78186752e-03\n",
      " -1.48724484e+00  4.11038697e-01 -6.02034777e-02 -6.75623596e-01\n",
      " -5.77256322e-01 -1.78619063e+00  4.44295108e-01 -2.88788348e-01\n",
      " -8.04740116e-02  4.85667825e-01 -1.51318371e-01 -7.60479331e-01\n",
      "  3.73638034e-01 -1.15641987e+00 -2.33714178e-01  3.29715192e-01\n",
      " -1.09190628e-01  2.70965040e-01 -8.59541535e-01  1.86721981e-01\n",
      "  7.88361490e-01  7.92668238e-02  4.97711211e-01 -3.86375934e-02\n",
      "  9.99421358e-01  8.60192776e-01 -1.39386988e+00  5.15245497e-02\n",
      "  1.08860409e+00 -1.12990928e+00  9.64725092e-02  5.97390570e-02\n",
      " -1.14242509e-01 -1.34762776e+00 -2.11025572e+00 -8.01732659e-01\n",
      "  3.39111060e-01  1.41916728e+00 -1.10446833e-01 -4.60245490e-01\n",
      "  3.07633191e-01 -5.53843617e-01 -2.76701033e-01  4.53252755e-02\n",
      "  4.57465649e-01 -2.97410220e-01  3.44519645e-01  4.45415452e-02\n",
      " -1.19041002e+00  3.68778735e-01  3.29750814e-02 -3.47452134e-01\n",
      "  1.67363539e-01  1.08034790e+00 -4.23566923e-02 -1.35702133e+00\n",
      "  6.01265013e-01 -4.13090549e-02 -6.22131415e-02  4.54781353e-01\n",
      " -8.74626637e-01  3.24429542e-01 -6.67591691e-01  2.10116550e-01\n",
      " -4.15317789e-02 -8.57640326e-01  6.43918157e-01  4.42649871e-01\n",
      " -1.04399776e+00  1.15074068e-01  1.65223554e-01  7.28295371e-02\n",
      " -4.64193523e-01 -3.82913142e-01  1.25702098e-01 -1.04725063e-01\n",
      "  1.15433621e+00  1.01565909e+00 -7.29867220e-01 -8.64082932e-01\n",
      "  5.81169277e-02 -9.18647647e-01 -1.48174679e+00  8.42609107e-02\n",
      " -1.14607304e-01  1.21812713e+00 -5.46108067e-01 -4.93584899e-03\n",
      " -4.64868218e-01 -1.46280527e+00 -6.67360500e-02 -5.07547855e-01\n",
      " -1.58559310e+00 -7.11907566e-01 -1.36318773e-01 -1.12101758e+00\n",
      "  9.93541628e-02 -2.53630614e+00 -4.99150664e-01 -9.48402643e-01\n",
      " -1.42347074e+00  6.25045076e-02  1.27627492e-01 -6.63107276e-01\n",
      " -7.88793638e-02 -4.06597480e-02  2.05570534e-01 -3.20044428e-01\n",
      " -2.93928813e-02  2.22119856e+00  4.11033601e-01  3.90420586e-01\n",
      " -9.58468080e-01  2.77288705e-01  3.15534733e-02 -4.44501489e-02\n",
      " -9.42358494e-01 -1.22288489e+00 -4.89177316e-01 -5.57058044e-02\n",
      " -6.86349124e-02  5.04300594e-01 -2.60896266e-01  1.32970238e+00\n",
      " -1.05640851e-02  2.22498924e-01 -8.94864798e-01  1.38093948e+00\n",
      "  3.29160057e-02 -2.75986493e-01 -8.59771430e-01  2.78663695e-01\n",
      " -6.20554090e-01  1.20987957e-02  1.18897593e+00 -2.17091131e+00\n",
      " -9.88950431e-01 -1.39435828e+00 -6.51396871e-01 -1.26545310e+00\n",
      "  1.91911399e+00 -7.93540955e-01 -3.44495028e-01  5.90925157e-01\n",
      " -1.47058025e-01  2.74500668e-01  4.88414198e-01  1.83958098e-01\n",
      " -1.21255234e-01 -9.36959922e-01 -5.75068474e-01 -4.69997168e-01\n",
      " -8.55410576e-01 -2.47183993e-01 -2.91217923e-01 -5.09017110e-01\n",
      " -1.28989768e+00 -5.00429988e-01 -4.28342462e-01 -1.75142825e+00\n",
      " -4.09813933e-02 -1.65613681e-01 -1.84523177e+00 -1.92846811e+00\n",
      "  1.53657749e-01 -3.47283483e-01 -1.41170591e-01 -6.37930393e-01\n",
      " -9.51783180e-01  1.96160331e-01  1.81988907e+00  6.99223340e-01\n",
      " -1.65362626e-01  3.81172299e-01 -2.22456545e-01 -2.67734528e-01\n",
      " -3.41278076e-01 -3.99363071e-01  3.94177139e-02 -1.19909547e-01\n",
      " -5.90639174e-01  1.12008047e+00 -7.39035547e-01  8.96034539e-02\n",
      " -5.08648694e-01 -1.23399720e-02  6.35316670e-02  1.59651518e-01\n",
      " -2.04768494e-01  1.05748355e+00 -1.36516190e+00 -1.34167552e+00\n",
      " -4.51350212e-01 -6.92758501e-01 -2.74049133e-01 -1.03320338e-01\n",
      " -1.29523193e-02  1.31239760e+00 -8.27277720e-01  3.87682132e-02\n",
      " -8.71628940e-01 -6.95682824e-01  3.97621155e-01 -1.09674156e-01\n",
      "  3.19857717e-01 -1.73781678e-01 -7.36356854e-01 -8.07601333e-01\n",
      "  5.21096177e-02 -7.87777424e-01  7.15755343e-01  8.69963244e-02\n",
      " -2.80882776e-01 -5.28787673e-01  3.98226315e-03 -6.90400362e-01\n",
      " -5.58391809e-01  6.08298182e-02 -5.11058532e-02 -5.83880232e-04\n",
      "  4.22541574e-02 -8.96959245e-01 -4.43016022e-01 -1.19045544e+00\n",
      " -4.37879354e-01  2.41588335e-02  8.98920372e-02 -9.87264097e-01\n",
      "  1.38565481e+00  4.40718606e-02 -2.05986604e-01 -7.54034042e-01\n",
      " -1.28022385e+00  6.17449395e-02  4.83952194e-01 -4.76246662e-02\n",
      " -1.61483362e-01  5.17205477e-01  1.03797781e+00 -1.97614002e+00\n",
      " -1.07020366e+00 -2.96055555e-01 -8.91598701e-01 -1.50025591e-01\n",
      "  3.94515991e-01 -1.27663922e+00 -2.20641315e-01  8.96592677e-01\n",
      " -5.20975590e-01 -1.63259971e+00 -6.60802275e-02 -2.54443884e-01\n",
      " -1.12502861e+00 -1.29136980e+00 -1.27252907e-01  7.20485806e-01\n",
      " -2.10298344e-01 -6.79151490e-02 -2.41914123e-01  1.09964859e+00\n",
      " -5.96147954e-01  6.80751681e-01 -5.07628322e-01 -9.85683084e-01\n",
      "  1.02256489e+00  3.57936203e-01 -1.42027184e-01  4.49232817e-01\n",
      " -1.79291570e+00 -1.05375898e+00  1.13714993e+00  3.81546110e-01\n",
      " -2.11603880e+00  1.34473658e+00  3.92864496e-02  6.02886677e-02\n",
      " -5.83853960e-01 -6.55729711e-01 -5.74189723e-02  3.53083819e-01\n",
      "  6.35958761e-02  7.95659661e-01 -1.63511264e+00  1.95679283e+00\n",
      " -1.56166124e+00 -7.25808799e-01 -1.55227613e-02 -6.10936344e-01\n",
      " -5.45067728e-01  1.55266261e+00 -5.54164827e-01 -6.42092943e-01\n",
      "  8.85763466e-01 -3.55181873e-01 -7.04777598e-01 -5.36765099e-01\n",
      " -8.50061297e-01 -1.44876719e-01 -6.42983377e-01  6.42162025e-01\n",
      "  1.34972584e+00  1.19957018e+00 -1.87664628e-02 -1.93126380e-01\n",
      " -6.72379851e-01 -8.21585357e-02  1.00198686e-01  4.47442383e-01\n",
      "  6.60549775e-02 -5.84057808e-01 -1.34391201e+00 -1.35246456e+00\n",
      " -2.32943818e-01 -7.14354143e-02 -1.90186465e+00  1.31069136e+00\n",
      " -5.32690406e-01 -2.34691441e-01 -3.56424153e-01  3.88214029e-02\n",
      "  3.25089723e-01 -1.37046864e-02 -2.25210190e+00 -7.55554318e-01\n",
      " -2.02452019e-01  6.01367712e-01  4.22107846e-01  8.73389065e-01\n",
      " -1.11004817e+00  1.03036118e+00  4.73911427e-02  7.26206601e-02\n",
      "  2.29932755e-01 -9.31852818e-01  7.71697342e-01 -4.26723450e-01\n",
      " -1.32237319e-02  3.01598758e-01  2.83977062e-01 -2.41401148e+00\n",
      " -8.43146563e-01  5.26313722e-01  7.90237356e-03 -1.38498902e-01\n",
      " -1.35005629e+00 -1.42265534e+00  1.69349492e+00  4.21974540e-01\n",
      " -9.16122675e-01 -2.93176174e-02  5.87960064e-01 -1.22148143e-02\n",
      "  1.56310678e+00  2.41872087e-01  5.99183142e-01 -1.48270011e+00\n",
      "  1.55339018e-01  3.57408524e-02  9.53017399e-02  4.16271947e-02\n",
      " -3.85188982e-02  7.64549375e-01  1.22715972e-01 -2.25903893e+00\n",
      "  1.01196766e+00 -2.44452178e-01 -3.29348087e-01 -3.64388525e-02\n",
      " -3.67701761e-02 -9.06780303e-01 -3.11355293e-02  1.18156588e+00\n",
      "  6.16955340e-01 -5.30830435e-02 -5.06460547e-01 -6.73747420e-01\n",
      "  1.05110061e+00  1.64656833e-01  1.15704584e+00  7.01609910e-01\n",
      " -3.83624472e-02 -5.28170705e-01 -4.46825445e-01 -1.68748111e-01\n",
      "  1.72543991e+00  1.33916485e+00  3.15478295e-02  6.20996766e-02\n",
      " -6.76893473e-01 -2.84624904e-01  4.53460634e-01  2.56353039e-02\n",
      " -5.20028621e-02 -8.90976191e-01 -8.91791284e-01  1.10705763e-01]\n",
      "discriminator_8/conv_block_83/batch_normalization_137/moving_variance:0 [0.6145385  1.6445066  0.734337   0.57139206 0.47832003 0.30396223\n",
      " 0.39566118 3.2206588  0.9458082  0.24895045 0.71723664 0.27004403\n",
      " 1.0962913  2.870193   0.9195811  0.46391568 0.20396698 1.5940768\n",
      " 0.387907   0.8706439  2.1375568  0.8092524  0.46656772 0.8339156\n",
      " 1.4136094  0.49065477 0.61427563 1.3186269  0.3825081  0.8038048\n",
      " 0.55297524 0.69310015 0.9136046  0.17494959 0.5858398  1.5741316\n",
      " 0.54223377 3.023923   0.25270563 0.38091898 1.379851   0.5897888\n",
      " 1.1514531  0.3696971  0.33001697 2.5476832  1.0984528  0.21668781\n",
      " 0.41563544 0.3661569  3.3050904  0.5196302  0.2208789  1.4573349\n",
      " 0.4172345  1.3242477  0.494945   0.595819   0.8203775  2.7657042\n",
      " 0.69028425 2.5748453  0.6878707  0.37942785 0.61452895 0.4010032\n",
      " 1.9667308  1.7536937  0.29606748 0.89952666 0.5332297  1.0650239\n",
      " 3.4119537  1.404398   0.4743105  0.5671811  2.0490794  0.14507931\n",
      " 0.82060236 0.87161034 0.44465303 0.43589038 0.23318076 1.1228707\n",
      " 0.25403497 0.39831874 0.39012194 0.9704563  1.0178887  0.92966175\n",
      " 0.15843312 2.7122753  0.7547762  0.47405997 1.9492635  1.4457858\n",
      " 0.29759577 0.8417317  0.08483091 1.1146389  1.193639   0.98450696\n",
      " 1.0976686  1.6512601  1.4962561  1.1797248  0.4935746  0.5982778\n",
      " 0.7577867  0.6553599  0.8140057  1.5098722  1.5665679  0.7647863\n",
      " 0.9707946  0.15808547 1.2665852  0.48078075 0.11009204 0.71944416\n",
      " 0.8742596  1.7075973  0.478446   0.30554405 0.1476882  0.7879423\n",
      " 0.71262157 2.8124523  1.0829841  0.949406   0.79008704 1.617369\n",
      " 0.7756832  1.1219139  3.1911826  0.63598347 1.4008758  0.26625988\n",
      " 0.5698827  0.8181823  1.1677424  0.6287316  3.318586   0.19279459\n",
      " 1.6889826  1.776571   0.77669305 0.37833858 0.4566369  2.5761209\n",
      " 3.291359   1.0852005  0.6504944  1.1252449  0.33809423 0.2578295\n",
      " 0.42053536 1.0733776  0.7600712  0.54941785 1.050557   0.9977232\n",
      " 0.4995574  0.31613788 1.4599631  0.5003281  0.14099173 0.2850901\n",
      " 1.255705   0.63538796 0.4035744  0.75972253 2.2712252  0.6899729\n",
      " 1.1532077  0.5003991  0.8362954  0.5427535  0.785218   0.38619196\n",
      " 0.29663196 0.68424815 0.5590445  1.516914   0.650916   0.5867052\n",
      " 1.3597999  0.1679213  1.2561611  0.4479107  0.32217288 1.8340908\n",
      " 0.54040486 0.6371653  0.4974096  0.67306244 0.50965893 0.6729871\n",
      " 1.785826   0.5047625  1.0268857  1.2039125  0.63867044 0.12969765\n",
      " 1.0235993  1.047397   0.12321689 0.4993681  1.7994303  1.2007197\n",
      " 1.5899618  0.8709882  0.46811518 1.8044137  1.4059068  0.4697055\n",
      " 5.5170193  1.8921032  0.39344487 0.8447342  0.21993278 0.36791283\n",
      " 0.5152754  0.19965039 0.17927961 1.5398237  0.28971276 0.5488781\n",
      " 0.9445646  0.76402074 0.46098813 0.5727557  1.8787656  1.1961907\n",
      " 2.111833   0.36279786 0.25992304 0.9043089  0.40125197 0.81726944\n",
      " 0.75784284 1.1950033  1.46084    0.64582026 0.30852103 0.64244187\n",
      " 1.250638   0.58450097 4.5287776  0.3275139  1.4875289  1.4788324\n",
      " 0.6230376  0.8184561  1.0979066  0.5470132  0.61917657 0.8651334\n",
      " 0.71475023 0.58674353 0.60496396 0.6119002  1.1990156  1.3954496\n",
      " 0.22055125 0.8752789  0.6141242  0.812123   0.9283415  1.1045834\n",
      " 0.7983537  0.6013476  0.52077425 1.6000533  2.645456   0.99801683\n",
      " 0.38401312 0.38994005 1.8432649  2.658494   0.5159379  8.370254\n",
      " 0.2706192  0.8545717  3.027116   0.77780706 0.5968581  2.3105865\n",
      " 0.7298054  0.5792554  0.41014144 0.70714194 0.80252373 0.41043833\n",
      " 1.3668708  0.14710656 1.3034678  0.57991844 0.691483   0.8556493\n",
      " 0.63787436 0.76634395 0.22071624 1.1686301  3.602507   1.9168279\n",
      " 1.616056   1.1476403  0.4354287  1.1117543  0.5457416  1.7016208\n",
      " 0.22727075 0.89680636 0.8009671  0.3850762  2.842402   0.65563947\n",
      " 0.43805465 0.28202453 1.4639106  0.8773943  0.84444225 5.585126\n",
      " 1.2922304  0.70780474 1.2211595  0.84116703 1.3299252  0.49447888\n",
      " 0.14971133 0.32433194 0.60497975 0.19280978 0.61319697 0.18856844\n",
      " 0.25287497 0.899944   1.6896284  0.9798576  0.47063795 0.5006788\n",
      " 0.6195965  0.4886592  1.0684354  4.8169785  0.26737007 0.6404951\n",
      " 0.74280125 0.17292017 1.0999739  0.51161456 0.5816925  0.17848875\n",
      " 1.1409189  0.9847152  1.5829223  0.46864727 1.3601243  0.35361212\n",
      " 0.70077944 1.2972976  0.77051115 0.9770207  0.5805063  1.4474155\n",
      " 0.42496657 0.57759845 0.47631916 0.5974661  0.37991127 1.4311402\n",
      " 1.1191376  0.7654711  1.1255993  0.40035492 0.4018291  1.0682564\n",
      " 0.8372538  4.19695    2.569802   0.97051746 0.3659664  0.4623253\n",
      " 0.9820729  2.3779528  0.73180866 0.76152176 2.5842457  1.3769002\n",
      " 0.5830012  0.3421411  0.97610456 0.67149585 1.1787817  0.41503593\n",
      " 0.26973873 0.53872144 1.426926   0.6682592  1.6275785  0.78895986\n",
      " 0.44063884 1.0592105  0.64231825 1.537748   1.0944773  0.43086302\n",
      " 1.2680821  0.3023681  1.2768481  0.6291999  0.34418705 0.87852085\n",
      " 0.6509442  0.82960635 1.2427883  1.0936986  0.55029225 1.9817109\n",
      " 0.6829434  0.30723342 0.43947288 0.4333193  0.18450353 0.81990165\n",
      " 1.8910306  2.6040027  0.49482173 0.18943644 3.9079015  0.94666314\n",
      " 0.9239536  1.0267639  0.45055494 0.4622314  0.34891757 0.17313534\n",
      " 1.1361014  0.5626412  0.9436676  0.5491646  0.59661245 1.1167884\n",
      " 0.86642176 0.411479   0.4838736  0.7344807  2.2262843  0.51594114\n",
      " 0.4286208  1.1278389  1.4044573  0.51568085 0.73142874 1.4199077\n",
      " 1.0317698  1.1936748  0.1934435  0.4661869  1.0546863  2.9853032\n",
      " 0.51161766 0.5051077  2.4699814  0.32279542 1.5001174  2.5182524\n",
      " 0.5518175  0.279287   2.770968   3.0089417  0.5515552  0.67343473\n",
      " 0.37314108 3.7139575  0.1407831  1.0639621  0.58530027 5.662527\n",
      " 0.9052101  0.43920878 1.1118891  0.98538804 0.2647284  0.87642235\n",
      " 0.15003286 1.1732188  0.5039458  0.14704539 1.0463699  0.89753187\n",
      " 0.9277988  0.43390524 0.61253    1.3875875  0.13772197 1.1895086\n",
      " 1.1104509  0.6883528  1.8375864  2.0189013  0.4373344  1.9711854\n",
      " 1.5842991  0.23349433 0.5124811  0.25307345 0.5640994  0.47228113\n",
      " 0.3878007  0.6952279 ]\n",
      "discriminator_8/conv_block_84/batch_normalization_138/moving_mean:0 [-1.1269690e+00  1.2901791e+00 -9.3534696e-01 -3.3234410e+00\n",
      " -1.5489269e+00  1.3764442e+00 -2.9070156e+00 -3.7489367e+00\n",
      "  4.5106196e+00 -3.1416292e+00 -1.3621868e+00 -1.4677504e+00\n",
      "  4.9711755e-01 -2.4986620e+00 -6.4389038e-01  3.3317893e+00\n",
      "  7.3985237e-01  2.0752871e+00  1.4248822e+00  2.6402805e+00\n",
      "  1.9573133e+00 -2.3817408e+00  1.7244180e-01  6.2638634e-01\n",
      "  1.2931526e+00  3.2453597e+00 -1.5710754e+00 -5.0226421e+00\n",
      "  5.3441343e+00 -1.1475323e+00 -3.6879513e+00 -3.9802735e+00\n",
      "  1.1922265e+00  1.3907870e+00  1.5591561e+00  3.7534633e+00\n",
      "  7.9448968e-01 -9.6538007e-01  1.6952889e-01  2.7821686e+00\n",
      " -1.9491379e-01  4.3982830e+00 -2.4200201e+00 -2.5083976e+00\n",
      " -1.3081540e+00  3.5481949e+00 -1.2323469e+00  3.6518738e+00\n",
      "  2.5663910e+00 -1.5169491e+00  3.2545710e+00 -1.0494868e+00\n",
      " -1.0811777e+00 -1.7272886e+00 -4.6071395e-01 -7.0993811e-01\n",
      " -1.1341084e+00  5.2813721e+00 -2.5260909e+00 -1.9405005e+00\n",
      "  2.9223680e+00  7.8552878e-01 -2.6659775e+00 -2.3730786e+00\n",
      " -9.3591928e-01  3.0338860e+00 -4.2150750e+00  4.1539574e+00\n",
      "  6.6713005e-01  1.7204134e+00 -1.6407080e+00  1.1795195e+00\n",
      " -5.1610358e-03 -1.7330049e+00  7.7638805e-01 -1.6889290e+00\n",
      "  3.0417433e+00 -2.5588224e+00 -1.5149958e-01  1.5505801e+00\n",
      " -1.4222807e+00 -1.9620444e+00  1.1692632e+00 -1.8165101e+00\n",
      " -2.9038413e+00 -3.7931910e+00 -1.5133466e+00 -5.0822359e-01\n",
      "  1.0012090e+00 -2.5561521e+00 -2.2860172e+00  1.0307966e+00\n",
      "  3.4044602e+00 -1.6890024e+00  1.9949749e+00  7.4431187e-01\n",
      " -1.4024632e+00 -4.5424237e+00 -2.2346807e+00  3.3051103e-01\n",
      "  4.5042983e-01 -2.0601633e+00 -4.0142388e+00 -5.4709393e-01\n",
      " -6.8378806e-01 -2.0973220e+00  1.4140682e+00 -4.1009727e+00\n",
      " -2.9367549e+00  5.7541662e-01 -4.1914165e-01  1.8031800e+00\n",
      "  6.5842299e+00  3.3505020e-01  4.4298628e-01  3.2469809e-01\n",
      "  2.6567984e+00 -4.0914459e+00 -2.2285819e+00 -3.4309182e+00\n",
      " -3.2868528e+00 -3.6672735e+00  1.0888207e+00 -3.1275895e+00\n",
      "  1.7673254e+00  2.1315362e+00 -3.9243670e+00 -3.5658462e+00\n",
      " -1.6262209e+00  1.1004971e+00  1.2973301e+00 -8.2386351e-01\n",
      " -2.8199935e+00 -2.8358243e+00 -3.3509140e+00 -9.5072919e-01\n",
      "  1.9993137e-01 -1.5251034e-01 -1.0671855e+00 -3.7987545e+00\n",
      "  2.8882852e+00  4.2684829e-01  2.1583309e+00  5.1596155e+00\n",
      " -3.1886849e-01 -2.7893364e+00 -1.5648110e+00 -1.8779342e+00\n",
      "  2.6364360e+00  3.5826411e+00  7.6300797e+00  8.6778229e-01\n",
      "  1.9184676e+00  4.1422337e-01 -9.5244336e-01  6.2707186e-01\n",
      "  6.6003346e-01  3.4452734e+00  3.1324897e+00  1.1641948e-01\n",
      " -3.9697475e+00  2.0492017e+00  1.0888858e-01  9.8117340e-01\n",
      " -1.2607039e+00 -2.7256649e+00 -8.9234971e-02 -2.5818954e+00\n",
      "  6.5383501e+00 -2.1001308e+00  3.2406416e+00 -1.0433651e+00\n",
      " -1.5806895e+00 -4.2272215e+00 -1.3221300e+00 -2.2441804e+00\n",
      " -3.5994763e+00 -2.5888693e-01  9.0250582e-02  7.1614081e-01\n",
      "  6.7249489e+00 -2.2590847e+00  4.1120610e+00  4.4364977e+00\n",
      "  8.5614281e+00 -3.2526579e+00  1.5228440e+00  4.2087035e+00\n",
      " -8.5479331e-01 -4.3114087e-01 -2.2071304e+00  3.7577574e+00\n",
      " -3.6074467e+00 -3.2785323e+00  6.6869764e+00 -1.5993978e+00\n",
      " -4.8171673e+00  3.7593234e+00 -1.1035526e+00  5.8577366e+00\n",
      " -3.2177153e+00  2.8678951e+00 -2.9724970e+00 -3.0201120e+00\n",
      " -3.6723885e-01 -6.1434669e+00  2.1170566e+00  5.0423604e-01\n",
      " -9.3715847e-01  4.1954589e+00  2.0490375e+00  1.9000721e+00\n",
      "  2.0716512e+00 -2.9255610e+00 -2.6008275e-01  3.1650486e+00\n",
      " -2.0447891e+00  3.1436758e+00  1.8664235e+00  3.9713433e+00\n",
      " -1.4964994e+00  1.7454067e+00  3.2760565e+00  2.1689568e+00\n",
      "  4.6587291e+00 -3.0946934e+00  4.1407046e+00  3.6099522e+00\n",
      "  4.7890034e+00  4.1987343e+00 -1.4421898e+00 -1.7954612e+00\n",
      " -3.5340147e+00  5.8814602e+00  3.7385776e+00  3.3099527e+00\n",
      " -6.6484320e-01 -1.4111513e+00  1.5843713e+00 -1.6218799e+00\n",
      " -2.3061290e+00  3.8167155e-01  1.5947970e+00  5.0435696e+00\n",
      "  1.3503153e+00  1.1984379e+00 -1.2070742e+00 -4.0198393e+00\n",
      " -5.0739002e-01 -2.0969529e+00  3.6260754e-01 -1.0086100e+00\n",
      " -7.1660119e-01 -1.6839861e+00  3.7944155e+00 -1.3061539e+00]\n",
      "discriminator_8/conv_block_84/batch_normalization_138/moving_variance:0 [ 5.037222   4.445931   3.978197   9.775291   4.172287   7.854037\n",
      "  3.1762793  7.262945   4.4846697  6.6382575  4.1946454  6.4841638\n",
      "  6.9157786  7.956634   3.3273444  5.1699576  5.373427   8.550732\n",
      " 15.121954  11.015512   5.2680836  2.995718  16.165783   9.152329\n",
      "  5.6690583  3.511207   6.261257  12.501408   4.753469   4.2673244\n",
      "  7.773908   5.309321  14.707652   3.5138385  5.90811    4.947777\n",
      "  5.5661645  9.729641   9.980529   4.349052  14.245223   9.632956\n",
      "  4.147915   7.1547503  8.080038   7.94479    4.3493257  8.242184\n",
      "  7.4917803  6.1584473  6.5677567  3.76086    4.092259   3.8516607\n",
      " 12.17213    4.850926   7.40908    5.8598804  6.447659  12.706455\n",
      "  6.3978815  3.7546937  8.761392   7.493095  11.27863    7.1622357\n",
      "  8.145573   8.371781   4.0869727  4.008007   4.608241  13.275297\n",
      "  4.8655667  8.167931  13.175372   7.043747   5.08281    7.5846004\n",
      "  0.9284212  7.7072105  4.797072   6.0094137  3.5962584  3.5735922\n",
      "  4.6064816  5.815862   4.890108   5.206377   3.143699   6.7903504\n",
      "  9.116588   5.23589    8.222853   6.5494633 10.883303   5.681576\n",
      "  7.4264545 36.374763  10.890024   7.601738   2.2734718  4.0412383\n",
      "  5.7621846  4.266293  11.969484   7.2313495 11.832881   4.771266\n",
      "  5.352497   3.7828066 21.148113   7.437191   9.02873    3.7833292\n",
      "  7.3296013  4.5801115  5.811784  18.996214   8.342395  10.64622\n",
      "  7.423448   3.642329   8.214568   5.842042   9.02127    9.523001\n",
      "  9.797858   5.0951695  5.5199766  5.0841827  7.4139695 10.003913\n",
      "  4.166977   5.158429   5.374007   1.3334453  5.1572504  3.9510126\n",
      "  6.821336   3.7399254  8.277997   6.3895984  3.5808666 10.937636\n",
      "  1.9997188  4.910541   2.9073632 10.343937   6.3554225  5.2833853\n",
      "  6.610213   5.361564   6.8762126  9.232692   3.2125776  4.437524\n",
      "  4.590382   5.5089836  6.5979786  4.5565825  5.328429   5.5081096\n",
      " 12.318441  11.573001   5.4221964  7.0066533  6.7476788  8.617583\n",
      "  7.0128508  9.679241   6.553143   7.8342257  8.168123   5.704963\n",
      "  4.031059  17.752504   7.8655405  9.145641   5.789331   4.1308594\n",
      " 12.245158   5.0818977 11.893872   6.712459   4.815043   6.4010086\n",
      "  6.613865   9.966457   5.3496614 10.252671  11.199349  15.464801\n",
      "  5.1183567  6.6371098  8.493823   8.390855  11.078233  11.369596\n",
      "  4.498799  11.641376   4.2442336  5.394384   8.438148   5.7540526\n",
      "  7.866694  11.105626  11.203289   3.7252507  6.2400684  6.749537\n",
      "  4.580049  10.992008  10.357758   5.6078687  5.6780467  5.6625094\n",
      "  3.7754629  8.09584   13.344862   8.50471    5.0549192  4.631027\n",
      "  6.1608534  7.3101974  5.3558497  6.7594576  5.4509096  9.956106\n",
      "  5.6977334  7.978419   4.916309   2.0289474  4.3742237  7.031059\n",
      "  9.812591   6.3840857  8.109393   5.2399173  6.3171945 11.650058\n",
      "  8.840575   8.874355  10.01051    4.5893703  6.13822    7.882679\n",
      "  5.1436872  6.803184   3.4480543  4.4865723  4.9198084  9.782661\n",
      "  4.565376   8.482727   7.183432  11.101798 ]\n",
      "discriminator_8/conv_block_85/batch_normalization_139/moving_mean:0 [ 0.6726271   0.5161937   0.7002693   0.22303101  0.46953517  0.612132\n",
      "  0.13288823  0.5268317  -0.16804408 -1.0453315  -0.04136857  0.3297329\n",
      "  1.0197953   0.62827283 -0.37310573  0.91565377  0.8782776   0.09603538\n",
      "  0.4196753   0.87901294  0.5580692  -0.25666428  0.21239929  1.0831\n",
      "  0.08820679  0.9036861  -0.46647635  0.588822   -0.34050006 -1.8976705\n",
      "  0.05614226 -0.4224524   0.6004547   0.7212206  -0.23270859  0.00198005\n",
      "  0.64273334 -1.2100288   0.72656596  1.3362913  -0.3233889   0.48085847\n",
      " -0.10867662 -0.41096514  0.11290107 -0.24314845 -0.07405634 -0.14530173\n",
      " -0.503903    0.18727294  0.4872391  -0.18074988  0.4775603  -0.10469727\n",
      "  0.51271385  0.21443304 -0.09536745  0.12142824  0.3095904  -0.9442835\n",
      " -0.6443832   1.0487558  -0.60888475 -0.2398604   0.37865415 -1.0499723\n",
      " -0.6199521   0.20992044  0.4904571   0.30131623  1.0494251   0.15366876\n",
      "  0.18273538  0.6739935  -0.17022434  0.02365856 -0.9013604  -0.6479846\n",
      "  0.36604574  0.49836984  0.33969316 -0.05002411  0.5918742  -0.68074137\n",
      "  0.65221936  0.4429128  -0.06010258 -0.7618064   0.21478914 -0.20791438\n",
      "  0.95830196  0.07527398 -0.32357225  0.49681678  0.05726606  0.26931772\n",
      "  0.70658475  0.6648313  -0.51237816 -0.08548176 -0.3995      0.2446171\n",
      " -0.08945379 -0.0201902   0.8486422  -0.3060468   0.48568317  0.07184608\n",
      "  0.1949558  -0.01847904 -0.1329309  -0.02784164 -0.39207166  0.02414582\n",
      " -0.11325628  0.35037127  0.23187149 -0.7431148  -0.22963683  0.9995551\n",
      "  1.0214067   0.87442863  0.3505802  -0.19063833  0.7156467  -1.2959297\n",
      "  0.28829154 -0.05366009 -0.37138006 -0.62553465 -0.30764884 -0.44487014\n",
      " -0.60181916  0.60156214  0.4966623   0.17829418  0.87551844 -0.00561285\n",
      " -0.21977358  0.29852322 -0.4022389   0.46679854  0.14797288 -0.35589883\n",
      "  0.5533903  -1.2012448  -1.2729605   0.4520719   0.22610702  0.90804213\n",
      " -0.2734435   0.62213385 -0.7197032  -0.8488699  -0.8079232   0.60185254\n",
      "  0.0991682   0.10249627  0.5480265   0.57926816 -0.5210909   0.6580478\n",
      " -0.12153835  0.5120342   0.96226084  0.49986926  1.1780796   0.41634098\n",
      " -0.00580882  0.69448847  0.71008563  0.99719363 -0.38163856 -0.72211844\n",
      "  0.4344809   0.7179176   0.19810237  0.43235904  0.20206457 -0.26435128\n",
      "  0.06401787 -0.56601673  0.41779083  0.67126393 -0.3711863  -0.70543\n",
      " -0.87662154  0.17917293 -1.1865038   0.5039424   0.72310334  0.32365635\n",
      "  0.5128603  -0.7939913   0.23080634 -0.36268002 -0.18262817  0.66048414\n",
      " -0.21056601 -0.8081816   1.1254338   0.0982107   0.641466    0.01343852\n",
      " -0.7975867   1.1464481  -1.3748722  -1.3610898  -0.19481942 -0.8551371\n",
      " -0.7874873  -0.3976391   0.4338188  -0.8833459  -0.76829624  0.6382423\n",
      " -0.28025374 -0.6090274   0.19169824  0.34204194  0.22213328  1.6239022\n",
      "  0.4812383  -0.16565032  0.56109846  1.5060343  -0.3034066  -0.16056696\n",
      "  0.82767904  0.948517   -0.08146527  0.04833951  0.5059015  -0.3250874\n",
      "  0.02269435 -0.21105945 -1.143319   -0.6538875  -1.0230267  -0.08211702\n",
      " -0.1814263  -0.3493325  -0.73876554  0.883527    1.1658487   0.59672964\n",
      "  1.0777433  -0.3230136   0.38655096 -0.3962037   0.45447725  0.5801847\n",
      "  0.4427088   0.46211192 -0.2196867  -0.4511894 ]\n",
      "discriminator_8/conv_block_85/batch_normalization_139/moving_variance:0 [1.682981   0.8633333  1.5511858  0.7767969  0.5823187  1.1625255\n",
      " 1.1473053  2.1169057  1.2855645  2.153033   1.7453275  0.61608166\n",
      " 1.8477296  0.53936136 1.2444695  0.97853893 1.0244429  0.7658308\n",
      " 0.8806932  0.77547485 0.8966856  1.7233889  0.74880755 1.3613169\n",
      " 0.83924    0.55562    0.55550647 0.94191414 1.3110504  2.0191152\n",
      " 1.5591668  0.8211516  1.4286842  1.2358735  1.5013515  1.1514522\n",
      " 0.53177196 2.6950338  1.5564111  1.6690812  1.5121701  1.2021813\n",
      " 0.90116453 0.683489   1.0511109  1.3782392  0.8900018  0.91539603\n",
      " 1.1882197  0.6028719  2.2069626  1.742321   0.71460706 1.4402176\n",
      " 0.9319241  1.1652654  2.105113   1.118061   0.9397662  1.1831241\n",
      " 1.3086313  1.7353356  1.4828955  0.7811795  2.1774068  1.226047\n",
      " 2.5559688  0.70144355 2.135578   1.1441904  0.9277517  1.6393088\n",
      " 1.4720126  1.2533169  0.82179004 0.9385249  1.543444   0.6582162\n",
      " 0.7582768  0.56935555 0.9995511  0.8080745  1.5449162  1.4107279\n",
      " 0.94555056 0.81501424 1.3341438  1.9195787  0.9016294  1.7611746\n",
      " 0.5549272  1.3190591  1.4659334  0.97135884 1.0259837  1.0085732\n",
      " 0.65148    1.9242616  1.391828   0.905521   1.3285347  0.5793975\n",
      " 0.8058246  0.5444665  0.84593433 0.75613517 1.8996928  0.82920116\n",
      " 0.4735536  1.101019   0.6986104  1.7492008  0.936311   1.0514643\n",
      " 1.3012637  0.5850435  1.5169147  0.80329186 1.7115039  0.56652653\n",
      " 0.8727216  1.7771015  2.37485    0.923477   2.0236337  2.3450494\n",
      " 1.0982364  0.666197   1.6815294  2.6125283  0.80689865 0.7644923\n",
      " 1.9685045  1.8571824  1.8797203  0.75914913 1.2768574  0.6055692\n",
      " 1.3606765  0.9383785  2.934958   2.067914   1.3145466  0.9515029\n",
      " 1.1195722  3.0909064  1.3012679  0.60717374 0.943571   1.0974766\n",
      " 1.4472618  1.6122818  1.0445406  1.2701813  1.8865008  0.7204431\n",
      " 0.9320771  0.80953056 1.589745   2.597424   0.61788213 0.91545945\n",
      " 0.6909793  1.2168622  0.87834525 1.6759822  0.94734216 0.90823007\n",
      " 1.3369797  1.1119149  1.1081647  0.6689219  1.5028636  2.175179\n",
      " 0.6708125  0.99510497 0.9449898  0.58749336 2.6984484  2.083632\n",
      " 0.41970044 1.636631   0.91591054 0.99150664 1.011449   1.797962\n",
      " 1.5402066  0.95361    1.4801835  1.0463125  1.0539643  0.8456393\n",
      " 0.8798332  1.7757896  1.7770802  2.3860147  0.7334824  2.2414818\n",
      " 1.4502417  1.5837326  2.0877585  1.3107939  0.7158731  0.74763274\n",
      " 0.9297008  1.7287729  1.5688393  1.3948236  1.7998098  1.1245551\n",
      " 1.495067   2.9219716  0.754088   1.2981681  1.3326737  1.4620261\n",
      " 0.8573408  2.0066998  0.7840517  1.7187641  1.8879427  0.9020439\n",
      " 0.98175466 1.3664836  1.0154048  0.7108683  1.2805731  0.66922456\n",
      " 0.7066564  1.1256895  0.8801399  1.3788089  1.0519875  0.7536627\n",
      " 1.0200351  0.8304791  2.7704704  1.7189835  2.3155518  1.2174219\n",
      " 1.4498483  0.73249835 1.4483356  2.0924385  1.0152571  1.7396119\n",
      " 1.4124489  0.7513655  1.1758182  1.5489668  1.0376972  1.0297065\n",
      " 1.0659276  0.73126334 0.66837645 0.6270261 ]\n",
      "discriminator_8/conv_block_86/batch_normalization_140/moving_mean:0 [ 1.7383058  -1.1115205   2.2598941   0.9230128   3.0487278  -0.32896075\n",
      "  3.2339134   1.9807315  -1.1833059   2.8685703   0.85142213 -0.33979756\n",
      "  1.6449388   1.5437442   1.5116394   2.193109   -0.78863305  1.3776201\n",
      "  2.6707616   2.0676491   1.7293234   0.9612214  -0.4540162   2.5956914\n",
      " -0.26544535 -1.0046571  -0.07473917  1.4668413   1.7316656   2.3620734\n",
      " -0.5506878   0.17229122  1.1556455   1.1195389  -0.6446813   2.2523541\n",
      " -0.6551761  -0.2590664   0.53381443  2.460819    2.57497     0.5118116\n",
      "  1.6330088  -0.582931    0.5631316   2.2058792   0.5062305   1.0195742\n",
      "  1.966606    1.209728    0.92336094 -0.6829762   2.7477179   0.5347811\n",
      "  1.8751793   0.6927323   1.1987894  -1.3742055   0.25996563 -0.69140446\n",
      "  2.8667786   0.5957195   2.1711736  -0.52071685 -0.2034661   0.01951891\n",
      "  1.9293977   1.8420103   2.0350769   0.97095054  2.0333266   1.104395\n",
      "  1.6525841   1.0554037   3.1478221   2.741939    3.6396337   0.22367632\n",
      "  0.71451527 -0.66163206  0.9948524  -1.2017692   1.7754037   0.36852637\n",
      "  1.3242853   0.81281555  1.7262324   0.9235535   0.28959984 -0.35341668\n",
      "  0.3971166  -2.7756646  -1.0363889   1.8747118   0.94328105  0.9799703\n",
      "  0.3558301   0.7346258   1.347282    2.7039874   2.061229    2.7531471\n",
      " -0.11020237  0.69732857  1.2642246   3.5078876   0.87489337 -1.0194638\n",
      "  2.2482812   0.08144908  0.9770804  -0.44388986 -0.1972442   0.25310427\n",
      " -1.552177    0.14698021  3.179834    1.5610164   0.0291927   0.40438342\n",
      "  1.2962143  -0.1774636   2.2677097   0.9462141   2.854174    0.11345489\n",
      " -0.8582237   1.4700792 ]\n",
      "discriminator_8/conv_block_86/batch_normalization_140/moving_variance:0 [ 2.6446888  6.8839197  4.3495126  1.8805802  6.2308884  2.8869474\n",
      "  7.579436   4.10554    3.7471013  4.69425    3.4027631  2.9372413\n",
      "  4.770444   3.6749015  2.6830916  3.7318966  5.9223914  6.328632\n",
      "  6.1037045  3.3367393  2.53442    3.7522864  5.957148   6.460876\n",
      "  3.0888915  3.8125346  3.1814828  4.4564304  3.7009256  3.9738438\n",
      "  2.88212    6.375177   2.1646338  3.6394827  6.1072903  3.2820172\n",
      "  3.9150226  6.3616905  8.67822    3.9630437  4.971359   2.8526332\n",
      "  7.5980654  4.81178    4.3053374  5.666323   4.7503724  4.052215\n",
      "  6.6388283  2.1101096  4.999666   4.653492   3.1232173  5.3924065\n",
      "  6.848863   2.9592657  5.4035063  3.1983573  2.5351555  5.9273458\n",
      "  7.049204   2.5947747  3.6357968  9.225792   4.7031965  3.151583\n",
      "  3.6652877  4.3159757  2.7556725  3.870179   4.260378   3.6754904\n",
      "  5.0016084  5.0742583  4.8449936  3.2941701  6.071675   4.007994\n",
      "  9.197455   6.014167   3.081179   3.4233084  2.6231897  6.645357\n",
      "  4.270779   8.193762   5.7936726  6.302794   3.6211846  4.299215\n",
      "  6.064929  12.717934   5.559889   3.7302802  3.3327913  7.7461443\n",
      "  6.469174   1.7776114  5.19592    4.944623   3.9419684  6.215629\n",
      "  5.463983   3.536639   4.4750648  2.896984   3.9662147  3.81457\n",
      "  6.0972776 10.192757   5.5431247  7.932243   6.2774453  2.1728597\n",
      "  5.881751   4.9998093  4.910295   4.422219   6.080741   3.3013453\n",
      "  2.7478387  3.3376515  3.825866   4.531925   6.7749043  1.879667\n",
      "  7.1393127  5.247675 ]\n",
      "discriminator_8/conv_block_87/batch_normalization_141/moving_mean:0 [-5.7205230e-01 -4.0109548e-01  4.6200472e-01 -4.7054046e-01\n",
      "  5.4054374e-01 -1.1116910e+00 -8.1356496e-01  3.2040976e-02\n",
      "  3.3183667e-01 -6.7952800e-01 -4.6197649e-02 -1.9980448e-01\n",
      " -4.0147385e-01  8.3515459e-01  2.7885991e-01  3.4415331e-02\n",
      "  2.1875013e-02  8.8271582e-01 -4.3739893e-02 -4.4833466e-01\n",
      "  7.6910289e-04 -7.6478738e-01  2.2063789e-01  2.9418844e-01\n",
      "  4.3174481e-01  4.4131532e-01  4.4591004e-01 -2.8258720e-01\n",
      "  3.5850766e-01  2.2910590e-01  4.9023560e-01 -2.1398090e-02\n",
      "  3.4187686e-01 -3.9959085e-01 -1.5910232e-02  6.5292078e-01\n",
      "  1.0758028e+00  3.3907750e-01  9.9754924e-01  2.3879535e-01\n",
      "  2.0918590e-01 -6.9969523e-01  1.2750484e-01  3.9924741e-01\n",
      " -1.7616870e-02 -7.8981745e-01 -3.5614660e-01  3.4944516e-01\n",
      "  8.5826570e-01  4.3399948e-01  1.0182276e-01 -1.5237169e-01\n",
      " -3.7348694e-01  9.5141864e-01  2.4148799e-01  2.3391663e-01\n",
      "  1.9062521e-01 -4.1641188e-01  1.1288985e-01  4.9287722e-01\n",
      "  4.1353169e-01  5.7110965e-01  1.6499877e-01 -5.3483121e-02\n",
      "  1.6143380e-02  3.7578475e-01  5.2153713e-01 -6.3806766e-01\n",
      "  1.3137320e-01  2.9453307e-01 -5.7508373e-01  9.3739522e-01\n",
      " -2.0743640e-01 -1.3215064e-01 -1.7410301e-01  1.1574563e-01\n",
      "  8.5041344e-02  4.9483992e-02  4.2246699e-01  1.2761742e-01\n",
      "  6.2118220e-01 -2.0739318e-01  4.7532675e-01 -4.2487583e-01\n",
      "  6.5535761e-02  9.2865640e-01  1.8000297e-01  1.4658120e-01\n",
      "  3.3830214e-01 -8.0138981e-02  2.8547314e-01 -9.3430340e-01\n",
      " -6.7026600e-02 -2.2924308e-01  1.5862565e-01 -6.2251762e-02\n",
      "  5.8336854e-01  7.7652049e-01  4.2872053e-01  2.7580246e-01\n",
      "  5.4182631e-01  2.8296238e-01 -9.2614007e-01 -7.9738182e-01\n",
      "  2.2098604e-01 -3.0258137e-01  9.8622805e-01  6.6219252e-01\n",
      " -5.8104330e-01  8.4208983e-01 -4.1903192e-01  3.7226370e-01\n",
      " -4.2741573e-01  9.5100611e-02 -8.5498989e-02 -1.8793954e+00\n",
      "  1.8625203e-01  4.6522477e-01 -6.4777844e-02 -2.7532333e-01\n",
      " -2.6944572e-01 -6.5979116e-02 -1.2760039e-01  5.6242639e-01\n",
      " -3.0724922e-01  5.3867382e-01 -1.0591720e+00 -4.7941473e-01]\n",
      "discriminator_8/conv_block_87/batch_normalization_141/moving_variance:0 [1.0618272  0.70665735 2.030044   1.6177231  1.2744877  3.4946017\n",
      " 1.8795267  0.53426564 0.89518297 1.8701499  1.9083812  0.9175792\n",
      " 0.9892353  2.129343   1.1640905  1.2616464  1.0026565  1.254576\n",
      " 1.1283213  1.7281859  0.64483637 2.5103593  1.7538244  0.92230046\n",
      " 1.0495634  0.91755116 1.4148135  1.2028927  1.2035441  1.2378087\n",
      " 1.6395717  1.2616795  2.757621   2.2244115  0.994306   1.0378768\n",
      " 1.9067166  1.7095337  1.5834157  0.8370952  1.6956918  1.0032926\n",
      " 1.5074116  1.5990186  1.8480439  1.415077   0.8115608  1.4052018\n",
      " 1.4056419  2.5503092  1.5424999  1.2020246  0.99289507 2.3393195\n",
      " 0.9642157  0.97821563 1.252319   1.3569032  1.294325   0.864455\n",
      " 1.2149823  0.9712894  1.529621   0.41505873 1.2703683  1.2937466\n",
      " 0.63912493 0.9489451  0.8145359  1.1920888  1.237982   1.0529362\n",
      " 0.8645053  1.2951862  0.61674935 0.92146856 0.89135885 0.6008992\n",
      " 1.7112558  1.153235   0.85774815 1.0969714  1.6190275  1.8835624\n",
      " 1.3301362  2.828683   1.3163276  0.7188766  0.62527007 0.53912544\n",
      " 0.8703782  2.1780062  1.5898403  1.5248069  0.44060615 0.4815254\n",
      " 1.2268714  1.3658779  0.4540769  1.0440787  0.91133785 0.9108204\n",
      " 1.4998024  1.3697839  0.7742182  0.9541814  1.4142871  1.1577235\n",
      " 1.8402637  1.1575171  0.92865354 1.038983   1.0351633  1.0942912\n",
      " 0.9912293  4.116295   0.7989841  0.75386274 0.76657087 1.0115594\n",
      " 0.50596225 0.6017308  0.6968069  0.6706893  1.9431212  1.2038518\n",
      " 2.8718896  1.1259657 ]\n",
      "discriminator_8/conv_block_88/batch_normalization_142/moving_mean:0 [-0.05928659  0.55332327 -0.08350229  1.2469157   0.4435168   0.18788412\n",
      "  0.04166384 -0.04286228  1.3453254   0.8404855   1.0290995   1.4318504\n",
      " -1.1824801   0.45442382 -1.1217093   1.1215135  -0.23760986 -1.1963321\n",
      "  1.5162475  -0.1897559   1.1260679   1.8671381   0.9640979   0.7866718\n",
      "  0.9546479   1.1590412  -0.3964143   0.87549204  1.1377064   1.6674362\n",
      "  0.30032474 -0.62535393  0.53127384  1.344702    0.11303253  0.25796375\n",
      " -1.0385585  -0.56761533 -0.5405777  -0.28033143 -0.9814223   1.4835341\n",
      "  0.7795369   0.80239177  0.70987517  1.3268871   0.423759   -0.7491181\n",
      "  1.2629371  -0.5400263   0.419715   -0.03532377 -0.51888853  1.3883747\n",
      "  0.96418566 -0.0850317  -1.0218064  -1.0295472  -0.48310885  0.21973035\n",
      "  1.8279321   1.1730659   0.24403876  1.9096525 ]\n",
      "discriminator_8/conv_block_88/batch_normalization_142/moving_variance:0 [2.0072837  1.4252559  3.285794   2.481198   3.193659   2.941678\n",
      " 2.0324402  2.3460245  2.0153487  2.3825088  3.5386686  2.2129197\n",
      " 3.6828036  2.036115   2.9439583  1.1497946  2.7576215  3.4978528\n",
      " 3.2654822  4.6329737  1.8310829  1.3811674  2.687507   2.3175704\n",
      " 0.97025824 2.1419673  2.7874744  3.914455   3.6563356  2.2892141\n",
      " 1.709576   2.8025036  2.3488195  2.012523   2.3105454  2.536178\n",
      " 3.0328045  4.9694424  1.7628317  2.2491481  4.6945677  3.253568\n",
      " 2.1018555  1.9377775  2.7700486  1.6031804  2.8941963  5.2262297\n",
      " 1.7189795  2.9355166  3.5005133  2.3698714  2.3585787  3.4747703\n",
      " 1.8683325  3.805044   3.220363   1.7411959  3.853377   2.8470664\n",
      " 1.6924658  1.7003977  2.2941577  2.2434165 ]\n",
      "discriminator_8/conv_block_89/batch_normalization_143/moving_mean:0 [ 0.22274618  1.3566214   0.33304086  0.12338516 -0.7409967  -0.29654095\n",
      " -0.40148613 -0.23617499  0.76659185 -0.40579322 -0.17054267  0.03503112\n",
      "  0.11942126  0.4766911  -0.39792466 -0.7949308  -0.26509735 -0.07985766\n",
      "  0.50214255 -0.37312275 -0.05099584  0.3095253   0.63039786  0.3004794\n",
      " -0.62039495  0.25934234  0.43547317 -0.17606017 -0.12771194 -0.78410083\n",
      " -1.0738233   0.37421733  0.32061204 -0.4486229   0.24347307 -0.01982422\n",
      "  0.5065327  -0.040127    0.53506553 -0.40220597  0.04952842 -0.681695\n",
      " -0.38718843  1.0074241   0.3205257  -0.92523384  0.02212894  0.09018365\n",
      " -0.3184204   0.11363524 -0.05470068  0.10530477  0.41240886  0.65482616\n",
      "  0.36424503  0.01043344 -0.21452229 -0.38429892  0.50213206  0.0988251\n",
      "  1.1804076  -0.0027385  -0.5910181   0.32076958]\n",
      "discriminator_8/conv_block_89/batch_normalization_143/moving_variance:0 [0.6671196  3.3495798  1.097649   0.8058526  1.3574271  1.1398549\n",
      " 0.80011904 0.8706311  1.7831736  1.3535969  1.1349585  0.8725128\n",
      " 1.0455978  0.8713082  1.2069764  0.7147963  0.59024775 0.5993973\n",
      " 0.8939943  1.2363863  0.989469   1.0363611  0.7695929  0.95638925\n",
      " 0.79522467 1.4170274  1.4193406  0.75220513 1.4081297  1.0305303\n",
      " 2.4773657  1.3708752  0.46156773 0.8956902  0.9405179  1.1156759\n",
      " 1.440042   0.38519287 0.85541326 0.832266   0.4296712  1.4128941\n",
      " 0.90727895 0.7893196  0.9832354  1.1745923  0.54005224 0.63161963\n",
      " 1.3626024  0.9203072  1.2591138  0.54563695 1.180221   0.73465514\n",
      " 0.95838195 0.6667112  0.5357851  1.0417104  0.71879154 0.49731225\n",
      " 1.3201923  0.6601582  0.99987274 0.84293574]\n",
      "discriminator_8/dense_51/kernel:0 [[-0.03063768 -0.08209515 -0.06652367 ...  0.07144672 -0.09542719\n",
      "   0.01286661]\n",
      " [ 0.06099244  0.10467473  0.00785802 ... -0.03962149 -0.03493637\n",
      "  -0.07690941]\n",
      " [ 0.02309886  0.07714711 -0.10397787 ...  0.07121125  0.03892619\n",
      "  -0.00427071]\n",
      " ...\n",
      " [-0.06475168 -0.01774905 -0.0801526  ...  0.08711684  0.06293062\n",
      "   0.06293424]\n",
      " [-0.0188207  -0.0302009  -0.02546487 ... -0.03805801 -0.00930793\n",
      "   0.08037567]\n",
      " [ 0.02946498  0.05702399 -0.02649423 ...  0.10601861  0.03820576\n",
      "  -0.01118793]]\n",
      "discriminator_8/dense_51/bias:0 [-0.00457533  0.01029277 -0.00313656 -0.0078296  -0.00519767 -0.00071682\n",
      "  0.00160127 -0.00817144 -0.00450623  0.00507134 -0.01149495  0.0082549\n",
      "  0.00992826 -0.00536741  0.00633943 -0.00879753  0.00951684  0.01157998\n",
      "  0.01019683 -0.00665631  0.0055016   0.00479354 -0.00845951 -0.00535456\n",
      " -0.00488473  0.00583767 -0.00542345  0.00589059 -0.00567359 -0.00774117\n",
      "  0.00710253  0.00712081 -0.00419658  0.01119029 -0.00689475  0.00979376\n",
      " -0.00723834  0.0082454   0.01057835 -0.00516043 -0.00719865  0.006375\n",
      "  0.01223188  0.01074741 -0.00624947 -0.01016751 -0.00581408  0.01108896\n",
      "  0.0096336   0.0091859  -0.00661273 -0.00826033 -0.00995948  0.00860271\n",
      " -0.00452867 -0.00362774 -0.00688098  0.01071087  0.00031801 -0.00393739\n",
      "  0.01078     0.01251103 -0.0046545  -0.01035951  0.00384581  0.01207623\n",
      "  0.0071926   0.01020596  0.00955941 -0.00684767  0.01154966  0.00366639\n",
      "  0.00874998  0.00869942  0.00886123  0.00409913 -0.00791402 -0.0011631\n",
      " -0.0028463  -0.01184662 -0.00752262 -0.00738869 -0.01149681 -0.00819923\n",
      " -0.00305274  0.00845922 -0.00592641  0.00708974  0.00715138  0.00825638\n",
      "  0.01041665  0.00349679 -0.00263307  0.00878344  0.0089486  -0.01096867\n",
      "  0.0059619   0.01130443  0.0090936  -0.00662137  0.00991338 -0.00603815\n",
      "  0.00908024  0.00925083  0.00867763 -0.00723893 -0.0077035  -0.00579246\n",
      " -0.00494793 -0.00514935  0.00544524 -0.00958709  0.00600773 -0.00798623\n",
      "  0.00885657 -0.00496348  0.00658453 -0.01015125  0.00719052 -0.00546184\n",
      " -0.0067665   0.00709234  0.00828822 -0.01012062 -0.01087605  0.01170344\n",
      "  0.00956421  0.00682364]\n",
      "discriminator_8/dense_52/kernel:0 [[-0.00916765  0.00513122  0.02616711 ... -0.03727672 -0.03041016\n",
      "   0.03243177]\n",
      " [ 0.04434473 -0.00896697  0.04466055 ... -0.05816858  0.02551815\n",
      "  -0.0290257 ]\n",
      " [ 0.02848906  0.00665975 -0.07569943 ... -0.06849498  0.01479861\n",
      "   0.01935704]\n",
      " ...\n",
      " [-0.04461339  0.07310315  0.05277121 ... -0.04898362  0.0568345\n",
      "   0.03299087]\n",
      " [ 0.04567445  0.09016442  0.07582307 ...  0.03987559 -0.023898\n",
      "  -0.03838623]\n",
      " [ 0.00526368  0.02314868 -0.00069429 ... -0.05788932 -0.01123496\n",
      "  -0.05064305]]\n",
      "discriminator_8/dense_52/bias:0 [ 3.22503340e-03 -3.74537427e-03  9.52670700e-04 -2.40178476e-03\n",
      "  2.02190643e-03  7.14955851e-03  7.62526412e-03 -8.31835624e-03\n",
      " -3.28055443e-03  1.12419296e-02  3.42930155e-03 -5.97357610e-03\n",
      " -4.74337023e-03 -1.47989125e-03  4.43723239e-03  3.00071581e-04\n",
      "  1.63544845e-02  1.56776421e-02  5.80087071e-04  4.69375169e-03\n",
      "  1.85892954e-02  2.04823148e-02  9.16429330e-03 -3.33676394e-03\n",
      " -5.37842046e-03  3.43950768e-03  7.39346631e-03 -2.77803885e-03\n",
      "  9.74538177e-03  1.72397122e-03 -4.96091368e-03  1.66861955e-02\n",
      " -1.70398299e-02  6.40858710e-03  6.97159255e-03 -5.75804804e-03\n",
      "  1.67206395e-03  6.42818073e-03  1.24123674e-02  1.65400300e-02\n",
      " -5.88668790e-03 -2.25458108e-03  6.59386301e-03 -1.07177522e-03\n",
      "  7.14300666e-03  5.17278386e-04  8.96831974e-03  1.67643167e-02\n",
      " -2.75858049e-03 -2.61524547e-04  1.18515827e-02  3.52944690e-03\n",
      "  1.27617577e-02  1.59946997e-02 -2.91632186e-03 -7.51992222e-03\n",
      "  1.26481308e-02  4.53565642e-03  1.58291589e-02 -1.10445567e-03\n",
      " -4.20318358e-03  1.11496355e-02  1.24818878e-03  2.06324994e-03\n",
      " -3.97096714e-03 -1.18484851e-02  2.11633351e-02 -3.41957901e-03\n",
      " -5.12498477e-03 -1.53798799e-04  1.70406718e-02  1.48010077e-02\n",
      " -3.86802771e-04  1.03164725e-02 -3.34552419e-03  2.34925784e-02\n",
      "  6.72980957e-03  5.72910125e-04  2.68494058e-03  2.39143446e-02\n",
      "  1.94678288e-02  1.50971487e-02 -9.87032615e-03  5.79516171e-04\n",
      "  8.56099278e-03 -4.94454755e-03 -5.19288750e-03  1.63731687e-02\n",
      "  2.36569531e-03 -1.36113947e-03 -6.43275399e-03  5.44648198e-03\n",
      "  1.29315723e-03  1.59050450e-02 -1.36242248e-02  1.94578934e-02\n",
      "  3.84512870e-03 -5.87715115e-03  1.78413484e-02 -2.28786375e-03\n",
      "  1.46867521e-02 -1.83039512e-02  6.11924846e-03  6.39206264e-05\n",
      " -8.71103490e-04 -1.70290936e-03 -6.45051664e-03 -1.16416644e-02\n",
      " -7.29332026e-03 -1.04948031e-02 -4.46888182e-04  1.38642406e-02\n",
      "  1.08807757e-02 -1.16634869e-03  7.36683281e-03  1.57902334e-02\n",
      "  1.12826070e-02 -1.39535859e-03  5.05315047e-03  2.21587978e-02\n",
      " -2.11978867e-03  2.06383485e-02 -6.76684687e-03  9.12188273e-03\n",
      " -1.93119849e-04  6.25034096e-03  4.18337760e-03  4.59318142e-03]\n",
      "discriminator_8/dense_53/kernel:0 [[-0.1379631 ]\n",
      " [ 0.05827755]\n",
      " [-0.04554205]\n",
      " [-0.06338509]\n",
      " [-0.05042243]\n",
      " [-0.01125164]\n",
      " [-0.14039564]\n",
      " [-0.07157436]\n",
      " [-0.09557565]\n",
      " [ 0.02332108]\n",
      " [-0.12860614]\n",
      " [ 0.1250689 ]\n",
      " [ 0.06193577]\n",
      " [-0.0025906 ]\n",
      " [ 0.16084096]\n",
      " [-0.14054264]\n",
      " [ 0.05979452]\n",
      " [ 0.11149918]\n",
      " [ 0.09053932]\n",
      " [-0.0533351 ]\n",
      " [ 0.01802378]\n",
      " [ 0.1289582 ]\n",
      " [-0.10989107]\n",
      " [-0.13494138]\n",
      " [-0.05496868]\n",
      " [ 0.12644494]\n",
      " [-0.09982767]\n",
      " [ 0.16253398]\n",
      " [-0.03845572]\n",
      " [-0.09022042]\n",
      " [ 0.1259559 ]\n",
      " [ 0.10833237]\n",
      " [-0.00199478]\n",
      " [ 0.07487559]\n",
      " [-0.08253402]\n",
      " [ 0.15472008]\n",
      " [-0.12769237]\n",
      " [ 0.02053306]\n",
      " [ 0.0615605 ]\n",
      " [-0.13508734]\n",
      " [-0.05192824]\n",
      " [ 0.01616225]\n",
      " [ 0.04793657]\n",
      " [ 0.12523058]\n",
      " [-0.02474037]\n",
      " [-0.09755003]\n",
      " [-0.00757912]\n",
      " [ 0.03075104]\n",
      " [ 0.15106961]\n",
      " [ 0.0699688 ]\n",
      " [-0.00432482]\n",
      " [-0.0174293 ]\n",
      " [-0.12241757]\n",
      " [ 0.06860908]\n",
      " [-0.10394155]\n",
      " [-0.03492735]\n",
      " [-0.14539659]\n",
      " [ 0.13585371]\n",
      " [-0.04259744]\n",
      " [-0.13275626]\n",
      " [ 0.02418265]\n",
      " [ 0.03692792]\n",
      " [-0.07816987]\n",
      " [-0.02594246]\n",
      " [ 0.08566647]\n",
      " [ 0.05177   ]\n",
      " [ 0.12440385]\n",
      " [ 0.07272816]\n",
      " [ 0.10284915]\n",
      " [-0.0689036 ]\n",
      " [ 0.13024068]\n",
      " [ 0.03225973]\n",
      " [ 0.15590356]\n",
      " [ 0.04166995]\n",
      " [ 0.07758894]\n",
      " [ 0.08578104]\n",
      " [-0.12496243]\n",
      " [-0.01445909]\n",
      " [-0.1109335 ]\n",
      " [-0.06363081]\n",
      " [-0.1462447 ]\n",
      " [-0.13382284]\n",
      " [-0.1268103 ]\n",
      " [-0.05650017]\n",
      " [-0.16512854]\n",
      " [ 0.09416055]\n",
      " [-0.03931249]\n",
      " [ 0.14518231]\n",
      " [ 0.06938283]\n",
      " [ 0.14280872]\n",
      " [ 0.13030197]\n",
      " [ 0.03218554]\n",
      " [-0.03377118]\n",
      " [ 0.05677383]\n",
      " [ 0.10953894]\n",
      " [-0.14456743]\n",
      " [ 0.02451197]\n",
      " [ 0.04150536]\n",
      " [ 0.12150091]\n",
      " [-0.15020798]\n",
      " [ 0.12341996]\n",
      " [-0.07088695]\n",
      " [ 0.14006026]\n",
      " [ 0.11882488]\n",
      " [ 0.140362  ]\n",
      " [-0.08081593]\n",
      " [-0.14208409]\n",
      " [-0.1270304 ]\n",
      " [-0.06183987]\n",
      " [-0.03459032]\n",
      " [ 0.12998685]\n",
      " [-0.01920304]\n",
      " [ 0.03857001]\n",
      " [-0.01404163]\n",
      " [ 0.05354274]\n",
      " [-0.0705445 ]\n",
      " [ 0.14577252]\n",
      " [-0.08631591]\n",
      " [ 0.15570785]\n",
      " [-0.08571432]\n",
      " [-0.11126991]\n",
      " [ 0.01815747]\n",
      " [ 0.09884286]\n",
      " [-0.1307924 ]\n",
      " [-0.08599943]\n",
      " [ 0.07765323]\n",
      " [ 0.06259458]\n",
      " [ 0.08851256]\n",
      " [-0.11862189]\n",
      " [-0.13284498]\n",
      " [-0.10170594]\n",
      " [-0.07752747]\n",
      " [-0.12355669]\n",
      " [ 0.15741833]\n",
      " [ 0.12035591]\n",
      " [-0.13966167]\n",
      " [-0.0813896 ]\n",
      " [ 0.17022514]\n",
      " [ 0.16537267]\n",
      " [-0.15041678]\n",
      " [-0.08021116]\n",
      " [-0.13544042]\n",
      " [ 0.18294549]\n",
      " [-0.17629908]\n",
      " [ 0.2941673 ]\n",
      " [ 0.24089177]\n",
      " [-0.15154356]\n",
      " [ 0.16230305]\n",
      " [ 0.22195835]\n",
      " [ 0.16521698]\n",
      " [-0.09734768]\n",
      " [-0.16877949]\n",
      " [-0.15225017]\n",
      " [-0.10791852]\n",
      " [ 0.09400419]\n",
      " [-0.10690262]\n",
      " [ 0.22834374]\n",
      " [-0.14327157]\n",
      " [ 0.1411208 ]\n",
      " [ 0.12502724]\n",
      " [-0.0087903 ]\n",
      " [-0.09926198]\n",
      " [ 0.17653784]\n",
      " [-0.10056527]\n",
      " [-0.15145083]\n",
      " [-0.11893946]\n",
      " [ 0.18250854]\n",
      " [ 0.03812027]\n",
      " [-0.16119881]\n",
      " [ 0.13506511]\n",
      " [ 0.12860668]\n",
      " [-0.10955766]\n",
      " [-0.05298816]\n",
      " [-0.05243106]\n",
      " [ 0.2094672 ]\n",
      " [ 0.13408539]\n",
      " [-0.06689534]\n",
      " [-0.17089027]\n",
      " [ 0.03860225]\n",
      " [-0.07642258]\n",
      " [ 0.11215582]\n",
      " [ 0.11585484]\n",
      " [-0.1186182 ]\n",
      " [-0.1362504 ]\n",
      " [ 0.15165998]\n",
      " [-0.07115597]\n",
      " [ 0.10039715]\n",
      " [ 0.20056258]\n",
      " [-0.09679922]\n",
      " [ 0.23547405]\n",
      " [ 0.07363508]\n",
      " [-0.09060352]\n",
      " [ 0.12741251]\n",
      " [-0.11585709]\n",
      " [ 0.20217988]\n",
      " [-0.06385105]\n",
      " [-0.08000944]\n",
      " [-0.16785502]\n",
      " [ 0.07037142]\n",
      " [ 0.09346775]\n",
      " [-0.0581856 ]\n",
      " [ 0.16488278]\n",
      " [-0.17384893]\n",
      " [ 0.0250073 ]\n",
      " [-0.08788277]\n",
      " [-0.09153403]\n",
      " [-0.07559866]\n",
      " [ 0.20176171]\n",
      " [ 0.12436996]\n",
      " [ 0.14853579]\n",
      " [ 0.18790258]\n",
      " [-0.11604413]\n",
      " [ 0.09878999]\n",
      " [-0.12409089]\n",
      " [-0.10887834]\n",
      " [ 0.15080419]\n",
      " [ 0.15836808]\n",
      " [-0.09743284]\n",
      " [-0.14224017]\n",
      " [-0.10604092]\n",
      " [-0.14901198]\n",
      " [ 0.20745961]\n",
      " [-0.11629733]\n",
      " [ 0.11168805]\n",
      " [-0.12979633]\n",
      " [-0.12872349]\n",
      " [ 0.12658784]\n",
      " [-0.16507235]\n",
      " [ 0.21146724]\n",
      " [ 0.10295657]\n",
      " [ 0.14845805]\n",
      " [-0.11491686]\n",
      " [-0.16718578]\n",
      " [-0.06364372]\n",
      " [-0.12971264]\n",
      " [-0.12273293]\n",
      " [-0.08921356]\n",
      " [-0.15352482]\n",
      " [-0.14671463]\n",
      " [ 0.12478094]\n",
      " [-0.0934983 ]\n",
      " [-0.12685639]\n",
      " [ 0.18999328]\n",
      " [ 0.10287796]\n",
      " [-0.16815609]\n",
      " [-0.14818582]\n",
      " [ 0.1399416 ]\n",
      " [ 0.1135134 ]\n",
      " [-0.09497406]\n",
      " [ 0.0594294 ]\n",
      " [ 0.18209478]\n",
      " [-0.12874237]\n",
      " [ 0.18968414]\n",
      " [ 0.1567158 ]\n",
      " [-0.05296981]\n",
      " [ 0.17169121]]\n",
      "discriminator_8/dense_53/bias:0 [-0.00742393]\n"
     ]
    }
   ],
   "source": [
    "for var in discriminator.variables:\n",
    "    print(var.name, var.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "1ca7c064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Courses\\24aut_deep_learning\\24aut-deep-learning\\deep-learning-comp3\\testing\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "--------------Evaluation Success-----------------\n",
      "C:\\Users\\User\\Courses\\24aut_deep_learning\\24aut-deep-learning\\deep-learning-comp3\n"
     ]
    }
   ],
   "source": [
    "%cd ./testing\n",
    "!python inception_score.py ../inference/demo output.csv 21\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "fa35e068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_encoder_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     multiple                  0 (unused)\n",
      "                                                                 \n",
      " gru_8 (GRU)                 multiple                  0 (unused)\n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "efcd9b89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_16 (Flatten)        multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_48 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_49 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_block_8 (dense_block)  multiple                 2107392   \n",
      "                                                                 \n",
      " deconv_block_40 (deconv_blo  multiple                 4196864   \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " deconv_block_41 (deconv_blo  multiple                 2098432   \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " deconv_block_42 (deconv_blo  multiple                 524928    \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " deconv_block_43 (deconv_blo  multiple                 131392    \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " deconv_block_44 (deconv_blo  multiple                 32928     \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " conv_block_80 (conv_block)  multiple                  1184      \n",
      "                                                                 \n",
      " conv_block_81 (conv_block)  multiple                  111       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,093,231\n",
      "Trainable params: 9,087,081\n",
      "Non-trainable params: 6,150\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "7d6f6c25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_block_82 (conv_block)  multiple                  16384     \n",
      "                                                                 \n",
      " conv_block_83 (conv_block)  multiple                  264704    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " conv_block_84 (conv_block)  multiple                  1180928   \n",
      "                                                                 \n",
      " conv_block_85 (conv_block)  multiple                  66816     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " conv_block_86 (conv_block)  multiple                  295552    \n",
      "                                                                 \n",
      " conv_block_87 (conv_block)  multiple                  17024     \n",
      "                                                                 \n",
      " conv_block_88 (conv_block)  multiple                  74048     \n",
      "                                                                 \n",
      " conv_block_89 (conv_block)  multiple                  4416      \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        multiple                  0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            multiple                  65664     \n",
      "                                                                 \n",
      " dense_52 (Dense)            multiple                  131200    \n",
      "                                                                 \n",
      " dense_53 (Dense)            multiple                  257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,116,993\n",
      "Trainable params: 2,113,153\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00f10b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f537e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b128e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a11e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865cbfa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba08b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b304dd53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
