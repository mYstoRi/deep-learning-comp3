{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a26ad83",
   "metadata": {},
   "source": [
    "# Competition 3: Team 21\n",
    "\n",
    "112062649 王俊皓\n",
    "\n",
    "112062650 廖士傑\n",
    "\n",
    "##  Reverse Image Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "414f827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project settings\n",
    "# aug_type: None does nothing; 'explode' considers all possible caption-image pair;\n",
    "# enc / gen / dis: True means using a more complex setting, False means using a setting that is closer to template\n",
    "# enc_do_batchnorm: encoder will perform batch normalization to make the text encoding more variant\n",
    "# dis_backbone: the type of backbone in discriminator, can be 'resnet', 'vgg', 'simple'\n",
    "# delete_checkpoint: deletes all checkpoint files before training\n",
    "\n",
    "class experimental_settings:\n",
    "    def __init__(self,\n",
    "                 aug_type='explode',\n",
    "                 enc=True,\n",
    "                 enc_do_batchnorm=False,\n",
    "                 gen=True,\n",
    "                 dis=True,\n",
    "                 dis_backbone='simple',\n",
    "                 delete_checkpoint=False):\n",
    "        self.aug_type = aug_type\n",
    "        self.enc = enc\n",
    "        self.gen = gen\n",
    "        self.dis = dis\n",
    "        self.dis_backbone = dis_backbone\n",
    "        self.enc_do_batchnorm = enc_do_batchnorm\n",
    "        self.delete_checkpoint = delete_checkpoint # not implemented yet\n",
    "        \n",
    "        # ============================ #\n",
    "        # automatic\n",
    "        # ============================ #\n",
    "        \n",
    "        self.caption_type = 'sentence' if self.enc else 'id'\n",
    "\n",
    "\n",
    "expSettings = experimental_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32322ac2",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "15576cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "import re\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd7b646",
   "metadata": {},
   "source": [
    "GPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "d992c613",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a71f7c6",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "58104ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 5427 vocabularies in total\n",
      "Word to id mapping, for example: flower -> 1\n",
      "Id to word mapping, for example: 1 -> flower\n",
      "Tokens: <PAD>: 5427; <RARE>: 5428\n"
     ]
    }
   ],
   "source": [
    "dictionary_path = './dictionary'\n",
    "vocab = np.load(dictionary_path + '/vocab.npy')\n",
    "print('there are {} vocabularies in total'.format(len(vocab)))\n",
    "\n",
    "word2Id_dict = dict(np.load(dictionary_path + '/word2Id.npy'))\n",
    "id2word_dict = dict(np.load(dictionary_path + '/id2Word.npy'))\n",
    "print('Word to id mapping, for example: %s -> %s' % ('flower', word2Id_dict['flower']))\n",
    "print('Id to word mapping, for example: %s -> %s' % ('1', id2word_dict['1']))\n",
    "print('Tokens: <PAD>: %s; <RARE>: %s' % (word2Id_dict['<PAD>'], word2Id_dict['<RARE>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "3bf3f5d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the flower shown has yellow anther red pistil and bright red petals.\n",
      "['9', '1', '82', '5', '11', '70', '20', '31', '3', '29', '20', '2', '5427', '5427', '5427', '5427', '5427', '5427', '5427', '5427']\n"
     ]
    }
   ],
   "source": [
    "def sent2IdList(line, MAX_SEQ_LENGTH=20):\n",
    "    MAX_SEQ_LIMIT = MAX_SEQ_LENGTH\n",
    "    padding = 0\n",
    "    \n",
    "    # data preprocessing, remove all puntuation in the texts\n",
    "    prep_line = re.sub('[%s]' % re.escape(string.punctuation), ' ', line.rstrip())\n",
    "    prep_line = prep_line.replace('-', ' ')\n",
    "    prep_line = prep_line.replace('-', ' ')\n",
    "    prep_line = prep_line.replace('  ', ' ')\n",
    "    prep_line = prep_line.replace('.', '')\n",
    "    tokens = prep_line.split(' ')\n",
    "    tokens = [\n",
    "        tokens[i] for i in range(len(tokens))\n",
    "        if tokens[i] != ' ' and tokens[i] != ''\n",
    "    ]\n",
    "    l = len(tokens)\n",
    "    padding = MAX_SEQ_LIMIT - l\n",
    "    \n",
    "    # make sure length of each text is equal to MAX_SEQ_LENGTH, and replace the less common word with <RARE> token\n",
    "    for i in range(padding):\n",
    "        tokens.append('<PAD>')\n",
    "    line = [\n",
    "        word2Id_dict[tokens[k]]\n",
    "        if tokens[k] in word2Id_dict else word2Id_dict['<RARE>']\n",
    "        for k in range(len(tokens))\n",
    "    ]\n",
    "\n",
    "    return line\n",
    "\n",
    "text = \"the flower shown has yellow anther red pistil and bright red petals.\"\n",
    "print(text)\n",
    "print(sent2IdList(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "d14b0e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9', '1', '82', '5', '11', '70', '20', '31', '3', '29', '20', '2', '5427', '5427', '5427', '5427', '5427', '5427', '5427', '5427']\n",
      "tf.Tensor(b'the flower shown has yellow anther red pistil and bright red petals <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def id2Sent(ids):\n",
    "    return \" \".join([id2word_dict[idx] for idx in ids]).strip()\n",
    "\n",
    "#def batch_id2Sent(batch_ids):\n",
    "    #return [id2Sent(ids) for ids in batch_ids]\n",
    "    \n",
    "def batch_id2Sent(batch_ids):\n",
    "    def process_single(ids):\n",
    "        # Convert a single tensor of IDs to a sentence\n",
    "        ids = ids.numpy()  # Convert Tensor to NumPy\n",
    "        sentence = \" \".join([id2word_dict.get(idx, \"<UNK>\") for idx in ids])  # Handle unknown IDs\n",
    "        return sentence\n",
    "\n",
    "    # Use tf.py_function to apply Python function inside the TensorFlow graph\n",
    "    sentences = tf.map_fn(\n",
    "        lambda ids: tf.py_function(process_single, [ids], tf.string),\n",
    "        batch_ids,\n",
    "        fn_output_signature=tf.string\n",
    "    )\n",
    "    return sentences\n",
    "\n",
    "\n",
    "print(sent2IdList(text))\n",
    "print(id2Sent(sent2IdList(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "23133915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7370 image in training data\n"
     ]
    }
   ],
   "source": [
    "data_path = './dataset'\n",
    "text2ImgData = pd.read_pickle(data_path + '/text2ImgData.pkl')\n",
    "num_training_sample = len(text2ImgData)\n",
    "n_images_train = num_training_sample\n",
    "print('There are %d image in training data' % (n_images_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "8026c1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70504\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Captions</th>\n",
       "      <th>ImagePath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[9, 2, 17, 9, 1, 6, 14, 13, 18, 3, 41, 8, 11, ...</td>\n",
       "      <td>./102flowers/image_06734.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4, 1, 15, 14, 3, 12, 13, 18, 7, 2, 10, 6, 123...</td>\n",
       "      <td>./102flowers/image_06734.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[9, 16, 2, 41, 149, 17, 12, 7, 12, 70, 3, 120,...</td>\n",
       "      <td>./102flowers/image_06734.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4, 1, 5, 26, 14, 2, 3, 8, 12, 30, 13, 9, 23, ...</td>\n",
       "      <td>./102flowers/image_06734.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4, 1, 5, 2, 10, 6, 14, 3, 5, 8, 11, 19, 5427,...</td>\n",
       "      <td>./102flowers/image_06734.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Captions  \\\n",
       "0  [9, 2, 17, 9, 1, 6, 14, 13, 18, 3, 41, 8, 11, ...   \n",
       "1  [4, 1, 15, 14, 3, 12, 13, 18, 7, 2, 10, 6, 123...   \n",
       "2  [9, 16, 2, 41, 149, 17, 12, 7, 12, 70, 3, 120,...   \n",
       "3  [4, 1, 5, 26, 14, 2, 3, 8, 12, 30, 13, 9, 23, ...   \n",
       "4  [4, 1, 5, 2, 10, 6, 14, 3, 5, 8, 11, 19, 5427,...   \n",
       "\n",
       "                      ImagePath  \n",
       "0  ./102flowers/image_06734.jpg  \n",
       "1  ./102flowers/image_06734.jpg  \n",
       "2  ./102flowers/image_06734.jpg  \n",
       "3  ./102flowers/image_06734.jpg  \n",
       "4  ./102flowers/image_06734.jpg  "
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data augmentation by including all possible captions\n",
    "\n",
    "if expSettings.aug_type == 'explode':\n",
    "    text2ImgData = text2ImgData.explode('Captions', ignore_index=True)\n",
    "print(len(text2ImgData))\n",
    "text2ImgData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "d2c49264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption2string(cap, aug_type=None):\n",
    "    \n",
    "    if aug_type == None:\n",
    "        output = []\n",
    "        for sen in cap:\n",
    "            s = \" \".join([id2word_dict[idx] for idx in sen]).strip()\n",
    "            output.append(s.split(' <PAD>')[0])\n",
    "            \n",
    "    elif aug_type == 'explode':\n",
    "        output = [\" \".join([id2word_dict[idx] for idx in cap]).strip().split(' <PAD>')[0]]\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('aug_type must be None or \\'explode\\'.')\n",
    "        \n",
    "    return output\n",
    "\n",
    "# adding caption as strings\n",
    "c2s_fn = lambda cap: caption2string(cap, aug_type=expSettings.aug_type)\n",
    "text2ImgData['Captions_string'] = text2ImgData['Captions'].apply(c2s_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "cdf9314c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Captions</th>\n",
       "      <th>ImagePath</th>\n",
       "      <th>Captions_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[9, 2, 17, 9, 1, 6, 14, 13, 18, 3, 41, 8, 11, ...</td>\n",
       "      <td>./102flowers/image_06734.jpg</td>\n",
       "      <td>[the petals of the flower are pink in color an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4, 1, 15, 14, 3, 12, 13, 18, 7, 2, 10, 6, 123...</td>\n",
       "      <td>./102flowers/image_06734.jpg</td>\n",
       "      <td>[this flower is pink and white in color with p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[9, 16, 2, 41, 149, 17, 12, 7, 12, 70, 3, 120,...</td>\n",
       "      <td>./102flowers/image_06734.jpg</td>\n",
       "      <td>[the purple petals have shades of white with w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4, 1, 5, 26, 14, 2, 3, 8, 12, 30, 13, 9, 23, ...</td>\n",
       "      <td>./102flowers/image_06734.jpg</td>\n",
       "      <td>[this flower has large pink petals and a white...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4, 1, 5, 2, 10, 6, 14, 3, 5, 8, 11, 19, 5427,...</td>\n",
       "      <td>./102flowers/image_06734.jpg</td>\n",
       "      <td>[this flower has petals that are pink and has ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Captions  \\\n",
       "0  [9, 2, 17, 9, 1, 6, 14, 13, 18, 3, 41, 8, 11, ...   \n",
       "1  [4, 1, 15, 14, 3, 12, 13, 18, 7, 2, 10, 6, 123...   \n",
       "2  [9, 16, 2, 41, 149, 17, 12, 7, 12, 70, 3, 120,...   \n",
       "3  [4, 1, 5, 26, 14, 2, 3, 8, 12, 30, 13, 9, 23, ...   \n",
       "4  [4, 1, 5, 2, 10, 6, 14, 3, 5, 8, 11, 19, 5427,...   \n",
       "\n",
       "                      ImagePath  \\\n",
       "0  ./102flowers/image_06734.jpg   \n",
       "1  ./102flowers/image_06734.jpg   \n",
       "2  ./102flowers/image_06734.jpg   \n",
       "3  ./102flowers/image_06734.jpg   \n",
       "4  ./102flowers/image_06734.jpg   \n",
       "\n",
       "                                     Captions_string  \n",
       "0  [the petals of the flower are pink in color an...  \n",
       "1  [this flower is pink and white in color with p...  \n",
       "2  [the purple petals have shades of white with w...  \n",
       "3  [this flower has large pink petals and a white...  \n",
       "4  [this flower has petals that are pink and has ...  "
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2ImgData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "f4a6b09d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the petals of the flower are pink in color and have a yellow center']]"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2ImgData['Captions_string'][:1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "d5efa616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this competition, you have to generate image in size 64x64x3\n",
    "IMAGE_SIZE = 64\n",
    "IMAGE_HEIGHT = IMAGE_SIZE\n",
    "IMAGE_WIDTH = IMAGE_SIZE\n",
    "IMAGE_CHANNEL = 3\n",
    "\n",
    "def training_data_generator(caption, image_path, caption_type='id'):\n",
    "    # load in the image according to image path\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize(img, size=[IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    img.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL])\n",
    "    if caption_type == 'id':\n",
    "        caption = tf.cast(caption, tf.int32)\n",
    "    elif caption_type == 'sentence':\n",
    "        caption = tf.convert_to_tensor(caption, dtype=tf.string)\n",
    "\n",
    "    return img, caption\n",
    "\n",
    "def dataset_generator(filenames, batch_size, data_generator, caption_type='id'):\n",
    "    # load the training data into two NumPy arrays\n",
    "    if filenames != None:\n",
    "        df = pd.read_pickle(filenames)\n",
    "    else:\n",
    "        df = text2ImgData\n",
    "    \n",
    "    if caption_type == 'id':\n",
    "        captions = df['Captions'].values\n",
    "    elif caption_type == 'sentence':\n",
    "        captions = df['Captions_string'].values\n",
    "    else:\n",
    "        raise ValueError('for dataset_generator, caption_type= should be \\'id\\' or \\'sentence\\'.')\n",
    "        \n",
    "    caption = []\n",
    "    # each image has 1 to 10 corresponding captions\n",
    "    # we choose one of them randomly for training\n",
    "    \n",
    "    # ============================================ #\n",
    "    # TODO: augmentation\n",
    "    # idea 1 (difficulty: easy) (trying)\n",
    "    #     training data has multiple captions, right now it picks a random one.\n",
    "    #     we can make it so that every caption is an entry and multiple captions link to the same image.\n",
    "    # idea 2 (difficulty: medium)\n",
    "    #     after text embedding, use the average of 2 caption embeddings to generate a new caption.\n",
    "    #     the data does not need to have an image tied to it, it just have the label 0 (fake image).\n",
    "    # ============================================ #\n",
    "    for i in range(len(captions)):\n",
    "        if expSettings.aug_type == None:\n",
    "            caption.append(random.choice(captions[i]))\n",
    "        elif expSettings.aug_type == 'explode':\n",
    "            caption.append(captions[i][0])\n",
    "    caption = np.asarray(caption)\n",
    "    \n",
    "    if caption_type == 'id':\n",
    "        caption = caption.astype(np.int)\n",
    "        \n",
    "    image_path = df['ImagePath'].values\n",
    "    \n",
    "    # assume that each row of `features` corresponds to the same row as `labels`.\n",
    "    assert caption.shape[0] == image_path.shape[0]\n",
    "    \n",
    "    datagen_func = lambda cap, img: data_generator(cap, img, caption_type=caption_type)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((caption, image_path))\n",
    "    dataset = dataset.map(datagen_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(min(1000, len(caption))).batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "710669ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "dataset = dataset_generator(\n",
    "    #data_path + '/text2ImgData.pkl',\n",
    "    None,\n",
    "    BATCH_SIZE, \n",
    "    training_data_generator, \n",
    "    caption_type=expSettings.caption_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "d9640f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (64, 64, 64, 3)\n",
      "Caption shape: (64,)\n"
     ]
    }
   ],
   "source": [
    "# dataset testing ground\n",
    "for img, cap in dataset.take(1):\n",
    "    print(\"Image shape:\", img.numpy().shape)\n",
    "    print(\"Caption shape:\", cap.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "4e941524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2DTranspose, Conv2D, BatchNormalization, LeakyReLU, Dense, Dropout\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "\n",
    "# custom layers\n",
    "class flattened_dense(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    a dense layer that is made compatible with convolution layers\n",
    "    by flattening the input first and followed by a dense layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels=64, kernel_initializer=\"glorot_uniform\"):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense = tf.keras.layers.Dense(channels, kernel_initializer=kernel_initializer)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        fl = self.flatten(inputs)\n",
    "        return self.dense(fl)\n",
    "    \n",
    "class conv_block(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    a convolution layer with batch normalization and leaky relu activation\n",
    "    \"\"\"\n",
    "    def __init__(self, filters=128, kernel_size=1, strides=1, kernel_initializer=HeNormal()):\n",
    "        super().__init__()\n",
    "        self.conv = Conv2D(filters=filters,\n",
    "                           kernel_size = (kernel_size, kernel_size),\n",
    "                           strides=(strides, strides),\n",
    "                           padding='same',\n",
    "                           kernel_initializer=kernel_initializer)\n",
    "        self.bn = BatchNormalization()\n",
    "        self.activation = LeakyReLU(alpha=0.1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.activation(self.bn(self.conv(inputs)))\n",
    "    \n",
    "class deconv_block(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    a deconvolution layer with batch normalization and leaky relu activation\n",
    "    \"\"\"\n",
    "    def __init__(self, filters=128, kernel_size=4, strides=2, kernel_initializer='glorot_uniform'):\n",
    "        super().__init__()\n",
    "        self.deconv = Conv2DTranspose(filters=filters,\n",
    "                                    kernel_size = (kernel_size, kernel_size),\n",
    "                                    strides=(strides, strides),\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=kernel_initializer)\n",
    "        self.bn = BatchNormalization()\n",
    "        self.activation = LeakyReLU(alpha=0.1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.activation(self.bn(self.deconv(inputs)))\n",
    "    \n",
    "class dense_block(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    a dense layer with batch normalization and leaky relu activation\n",
    "    \"\"\"\n",
    "    def __init__(self, filters=128, kernel_initializer='glorot_uniform'):\n",
    "        super().__init__()\n",
    "        self.d = Dense(filters, kernel_initializer=kernel_initializer)\n",
    "        self.bn = BatchNormalization()\n",
    "        self.activation = LeakyReLU(alpha=0.1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        outputs = self.d(inputs)\n",
    "        outputs = self.bn(outputs)\n",
    "        return self.activation(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "7b79a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "class TextEncoder(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Encode text (a caption) into hidden representation\n",
    "    input: text, which is a list of ids\n",
    "    output: embedding, or hidden representation of input text in dimension of RNN_HIDDEN_SIZE\n",
    "    \"\"\"\n",
    "    def __init__(self, hparas, experimental=False, do_batchnorm=False):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.exp=experimental\n",
    "        self.do_batchnorm = do_batchnorm\n",
    "        self.hparas = hparas\n",
    "        self.batch_size = self.hparas['BATCH_SIZE']\n",
    "        \n",
    "        # embedding with tensorflow API\n",
    "        self.embedding = layers.Embedding(self.hparas['VOCAB_SIZE'], self.hparas['EMBED_DIM'])\n",
    "        # RNN, here we use GRU cell, another common RNN cell similar to LSTM\n",
    "        self.gru = layers.GRU(self.hparas['RNN_HIDDEN_SIZE'],\n",
    "                              return_sequences=True,\n",
    "                              return_state=True,\n",
    "                              recurrent_initializer='glorot_uniform')\n",
    "        if self.exp:\n",
    "            self.embed = hub.load('./checkpoints/universal_sentence_encoder')\n",
    "    \n",
    "    def call(self, text, hidden):\n",
    "        if self.exp:\n",
    "            with tf.device('/CPU:0'): # TODO if you find a way to use GPU, go for it.\n",
    "                output_last = self.embed(text)\n",
    "                \n",
    "            state = hidden # not updating state for compatibility reasons\n",
    "            \n",
    "        else:\n",
    "            text = self.embedding(text)\n",
    "            output, state = self.gru(text, initial_state = hidden)\n",
    "            output_last = output[:, -1, :]\n",
    "        \n",
    "        # normalization in-batch\n",
    "        if self.do_batchnorm:\n",
    "            mean = tf.reduce_mean(output_last, axis=0, keepdims=True)  # Mean across the batch\n",
    "            std = tf.math.reduce_std(output_last, axis=0, keepdims=True)  # Std across the batch\n",
    "            normalized = (output_last - mean) / (std + 1e-6)  # Avoid division by zero\n",
    "        else:\n",
    "            normalized = output_last\n",
    "        \n",
    "        return normalized, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.hparas['BATCH_SIZE'], self.hparas['RNN_HIDDEN_SIZE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "e7dcc746",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Generate fake image based on given text(hidden representation) and noise z\n",
    "    input: text and noise\n",
    "    output: fake image with size 64*64*3\n",
    "    \"\"\"\n",
    "    def __init__(self, hparas, experimental=False):\n",
    "        super(Generator, self).__init__()\n",
    "        self.exp = experimental\n",
    "        self.hparas = hparas\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.d1 = tf.keras.layers.Dense(self.hparas['DENSE_DIM'], kernel_initializer=\"glorot_uniform\")\n",
    "        self.d2 = tf.keras.layers.Dense(64*64*3, kernel_initializer=\"glorot_uniform\")\n",
    "        if self.exp:\n",
    "            self.deconv_depth = int(math.log(IMAGE_SIZE, 2)) - 1\n",
    "            self.starter = dense_block(filters=2*2*512)\n",
    "            self.deconv = [\n",
    "                deconv_block(filters=512, kernel_initializer=HeNormal()),\n",
    "                #conv_block(filters=512, kernel_size=1, strides=1),\n",
    "                deconv_block(filters=256, kernel_initializer=HeNormal()),\n",
    "                #conv_block(filters=256, kernel_size=1, strides=1),\n",
    "                #Dropout(0.2),\n",
    "                deconv_block(filters=128, kernel_initializer=HeNormal()),\n",
    "                #conv_block(filters=128, kernel_size=1, strides=1),\n",
    "                #Dropout(0.2),\n",
    "                deconv_block(filters=64, kernel_initializer=HeNormal()),\n",
    "                #conv_block(filters=64, kernel_size=1, strides=1),\n",
    "                deconv_block(filters=32, kernel_initializer=HeNormal()),\n",
    "                conv_block(filters=32, kernel_size=1, strides=1),\n",
    "                deconv_block(filters=16, strides=1, kernel_initializer=HeNormal())\n",
    "            ]\n",
    "            self.headf = conv_block(filters=3, kernel_size=1, strides=1)\n",
    "            \n",
    "    def call(self, text, noise_z, debug_output=False, training=False):\n",
    "        # deconvolution\n",
    "        if self.exp:\n",
    "            noisy_text = tf.concat([text, noise_z], axis=1) * 10 # amplify the input a bit, they seem fairly close to 0.\n",
    "            img = self.starter(noisy_text)\n",
    "            \n",
    "            img = tf.reshape(img, [-1, 2, 2, 512])\n",
    "            debug = []\n",
    "            for layer in self.deconv:\n",
    "                if isinstance(layer, tf.keras.layers.Dropout) and training:\n",
    "                    continue\n",
    "                debug.append(img)\n",
    "                img = layer(img)\n",
    "\n",
    "            img = self.headf(img)\n",
    "            logits = tf.reshape(img, [-1, IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "            output = tf.nn.tanh(logits)\n",
    "        \n",
    "        # concatenate input text and random noise\n",
    "        else:\n",
    "            text = self.flatten(text)\n",
    "            text = self.d1(text)\n",
    "            text = tf.nn.leaky_relu(text)\n",
    "            text_concat = tf.concat([noise_z, text], axis=1)\n",
    "            text_concat = self.d2(text_concat)\n",
    "        \n",
    "            logits = tf.reshape(text_concat, [-1, 64, 64, 3])\n",
    "            output = tf.nn.tanh(logits)\n",
    "            debug_output = output\n",
    "        \n",
    "        if debug_output:\n",
    "            return logits, output, debug\n",
    "        else:\n",
    "            return logits, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "a78cfb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50, VGG16\n",
    "\n",
    "class Discriminator(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Differentiate the real and fake image\n",
    "    input: image and corresponding text\n",
    "    output: labels, the real image should be 1, while the fake should be 0\n",
    "    \"\"\"\n",
    "    def __init__(self, hparas, experimental=False, backbone='simple'):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.exp = experimental\n",
    "        self.bbtype = backbone\n",
    "        self.hparas = hparas\n",
    "        if self.exp:\n",
    "            if self.bbtype == 'resnet':\n",
    "                self.resnet_base = ResNet50(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), weights='imagenet', include_top=False)\n",
    "                for layer in self.resnet_base.layers:\n",
    "                    layer.trainable = False\n",
    "            elif self.bbtype == 'vgg':\n",
    "                self.vgg_base = VGG16(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), weights='imagenet', include_top=False)\n",
    "                for layer in self.vgg_base.layers:\n",
    "                    layer.trainable = False\n",
    "            elif self.bbtype == 'simple':\n",
    "                self.conv = [\n",
    "                    conv_block(filters=512, kernel_size=3, strides=2),\n",
    "                    #conv_block(filters=512, kernel_size=3, strides=1),\n",
    "                    conv_block(filters=512, kernel_size=1, strides=1),\n",
    "                    Dropout(hparas['DIS_DROPOUT']),\n",
    "                    conv_block(filters=256, kernel_size=3, strides=2),\n",
    "                    #conv_block(filters=256, kernel_size=3, strides=1),\n",
    "                    conv_block(filters=256, kernel_size=1, strides=1),\n",
    "                    Dropout(hparas['DIS_DROPOUT']),\n",
    "                    conv_block(filters=128, kernel_size=3, strides=2),\n",
    "                    conv_block(filters=128, kernel_size=3, strides=1),\n",
    "                    conv_block(filters=128, kernel_size=1, strides=1),\n",
    "                    #Dropout(hparas['DIS_DROPOUT']),\n",
    "                    conv_block(filters=64, kernel_size=3, strides=2),\n",
    "                    #conv_block(filters=64, kernel_size=3, strides=1),\n",
    "                    conv_block(filters=64, kernel_size=1, strides=1),\n",
    "                    Dropout(hparas['DIS_DROPOUT'] * 2 / 3)\n",
    "                ]\n",
    "                # more simple one\n",
    "                #self.conv1 = conv_block(filters=256, kernel_size=3, strides=1)\n",
    "                #self.conv2 = conv_block(filters=64, kernel_size=3, strides=1)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.d_text = tf.keras.layers.Dense(self.hparas['DENSE_DIM'])\n",
    "        self.d_img = tf.keras.layers.Dense(self.hparas['DENSE_DIM'])\n",
    "        self.d = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, img, text, training=False):\n",
    "        text = self.flatten(text)\n",
    "        text = self.d_text(text)\n",
    "        text = tf.nn.leaky_relu(text)\n",
    "        \n",
    "        if self.exp:\n",
    "            if self.bbtype == 'resnet':\n",
    "                img = self.resnet_base(img)\n",
    "            elif self.bbtype == 'vgg':\n",
    "                img = self.vgg_base(img)\n",
    "            elif self.bbtype == 'simple':\n",
    "                for layer in self.conv: # see init for spec\n",
    "                    if isinstance(layer, Dropout) and training:\n",
    "                        continue\n",
    "                    img = layer(img)\n",
    "        img = self.flatten(img)\n",
    "        img = self.d_img(img)\n",
    "        img = tf.nn.leaky_relu(img)\n",
    "        \n",
    "        # concatenate image with paired text\n",
    "        img_text = tf.concat([text, img], axis=1)\n",
    "        \n",
    "        logits = self.d(img_text)\n",
    "        output = tf.nn.sigmoid(logits)\n",
    "        \n",
    "        return logits, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fac84cb",
   "metadata": {},
   "source": [
    "Parameters and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "46263c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparas = {\n",
    "    'MAX_SEQ_LENGTH': 20,                     # maximum sequence length\n",
    "    'EMBED_DIM': 256,                         # word embedding dimension\n",
    "    'VOCAB_SIZE': len(word2Id_dict),          # size of dictionary of captions\n",
    "    'RNN_HIDDEN_SIZE': 128,                   # number of RNN neurons\n",
    "    'Z_DIM': 512,                             # random noise z dimension\n",
    "    'DENSE_DIM': 128,                         # number of neurons in dense layer\n",
    "    'IMAGE_SIZE': [64, 64, 3],                # render image size\n",
    "    'BATCH_SIZE': 64,\n",
    "    'DIS_DROPOUT': 0.5,                       # chance of dropout in discriminator\n",
    "    'LR_GEN': 1e-4,\n",
    "    'LR_DIS': 1e-5,\n",
    "    'LR_DECAY': 0.5,                          # unused\n",
    "    'CLIPNORM': 0.1,\n",
    "    'BETA_1': 0.5,\n",
    "    'N_EPOCH': 500,                           # number of epoch for demo\n",
    "    'N_SAMPLE': num_training_sample,          # size of training data\n",
    "    'CHECKPOINTS_DIR': './checkpoints/demo',  # checkpoint path\n",
    "    'PRINT_FREQ': 1                           # printing frequency of loss\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "a3d61caf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_encoder = TextEncoder(hparas, \n",
    "                           experimental=expSettings.enc,\n",
    "                           do_batchnorm=expSettings.enc_do_batchnorm)\n",
    "\n",
    "generator = Generator(hparas,\n",
    "                      experimental=expSettings.gen)\n",
    "\n",
    "discriminator = Discriminator(hparas,\n",
    "                              experimental=expSettings.dis,\n",
    "                              backbone=expSettings.dis_backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "90824abe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (64, 64, 64, 3)\n",
      "Caption shape: (64,)\n",
      "Caption embed shape: (64, 512)\n"
     ]
    }
   ],
   "source": [
    "# test text encoder\n",
    "for img, cap in dataset.take(1):\n",
    "    print(\"Image shape:\", img.numpy().shape)\n",
    "    print(\"Caption shape:\", cap.shape)\n",
    "    with tf.device('/CPU:0'):\n",
    "        output, _ = text_encoder(cap, text_encoder.initialize_hidden_state())\n",
    "        print(\"Caption embed shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "220a1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "3a45f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.nn import sigmoid_cross_entropy_with_logits\n",
    "\n",
    "def discriminator_loss(real_logits, fake_logits):\n",
    "    # output value of real image should be 1\n",
    "    real_loss = sigmoid_cross_entropy_with_logits(tf.ones_like(real_logits), real_logits)\n",
    "    # output value of fake image should be 0\n",
    "    fake_loss = sigmoid_cross_entropy_with_logits(tf.zeros_like(fake_logits), fake_logits)\n",
    "    total_loss = tf.reduce_mean(real_loss) + tf.reduce_mean(fake_loss)\n",
    "                                 \n",
    "    return total_loss\n",
    "def generator_loss(fake_output):\n",
    "    # output value of fake image should be 0\n",
    "    return tf.reduce_mean(sigmoid_cross_entropy_with_logits(tf.ones_like(fake_output), fake_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "21f720d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use seperated optimizers for training generator and discriminator\n",
    "generator_optimizer = tf.keras.optimizers.Adam(hparas['LR_GEN'], clipvalue=hparas['CLIPNORM'])\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(hparas['LR_DIS'], clipvalue=hparas['CLIPNORM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "24d5f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "if expSettings.delete_checkpoint:\n",
    "    for f in os.listdir(hparas['CHECKPOINTS_DIR']):\n",
    "        file_path = os.path.join(hparas['CHECKPOINTS_DIR'], f)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "\n",
    "# one benefit of tf.train.Checkpoint() API is we can save everything seperately\n",
    "checkpoint_dir = hparas['CHECKPOINTS_DIR']\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 text_encoder=text_encoder,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "ckptManager = tf.train.CheckpointManager(\n",
    "    checkpoint, directory=hparas['CHECKPOINTS_DIR'], max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "b35f60e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_image, caption, hidden, imshow=False):\n",
    "    # random noise for generator\n",
    "    noise = tf.random.normal(shape=[hparas['BATCH_SIZE'], hparas['Z_DIM']], mean=0.0, stddev=0.1)\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        text_embed, hidden = text_encoder(caption, hidden)\n",
    "        _, fake_image = generator(text_embed, noise, training=True)\n",
    "        if imshow:\n",
    "            plt.imshow(fake_image[0])\n",
    "\n",
    "        real_logits, real_output = discriminator(real_image, text_embed, training=True)\n",
    "        fake_logits, fake_output = discriminator(fake_image, text_embed, training=True)\n",
    "\n",
    "        g_loss = generator_loss(fake_logits)\n",
    "        d_loss = discriminator_loss(real_logits, fake_logits)\n",
    "\n",
    "    grad_g = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    grad_d = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(grad_g, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(grad_d, discriminator.trainable_variables))\n",
    "    \n",
    "    return g_loss, d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "c25ce5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(caption, noise, hidden):\n",
    "    text_embed, hidden = text_encoder(caption, hidden)\n",
    "    _, fake_image = generator(text_embed, noise)\n",
    "    return fake_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf5d5af",
   "metadata": {},
   "source": [
    "Sample Debugging (unused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "d68c0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1], 3))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
    "    return img\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    # getting the pixel values between [0, 1] to save it\n",
    "    return plt.imsave(path, merge(images, size)*0.5 + 0.5)\n",
    "\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(images, size, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "09b260b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_generator(caption, batch_size, caption_type='id'):\n",
    "    if caption_type == 'sentence':\n",
    "        caption = caption2string(caption)\n",
    "    caption = np.asarray(caption)\n",
    "    if caption_type == 'id':\n",
    "        caption = caption.astype(np.int)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(caption)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "e086c8df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ni = int(np.ceil(np.sqrt(hparas['BATCH_SIZE'])))\n",
    "sample_size = hparas['BATCH_SIZE']\n",
    "sample_seed = np.random.normal(loc=0.0, scale=1.0, size=(sample_size, hparas['Z_DIM'])).astype(np.float32)\n",
    "sample_sentence = [\"the flower shown has yellow anther red pistil and bright red petals.\"] * int(sample_size/ni) + \\\n",
    "                  [\"this flower has petals that are yellow, white and purple and has dark lines\"] * int(sample_size/ni) + \\\n",
    "                  [\"the petals on this flower are white with a yellow center\"] * int(sample_size/ni) + \\\n",
    "                  [\"this flower has a lot of small round pink petals.\"] * int(sample_size/ni) + \\\n",
    "                  [\"this flower is orange in color, and has petals that are ruffled and rounded.\"] * int(sample_size/ni) + \\\n",
    "                  [\"the flower has yellow petals and the center of it is brown.\"] * int(sample_size/ni) + \\\n",
    "                  [\"this flower has petals that are blue and white.\"] * int(sample_size/ni) +\\\n",
    "                  [\"these white flowers have petals that start off white in color and end in a white towards the tips.\"] * int(sample_size/ni)\n",
    "\n",
    "for i, sent in enumerate(sample_sentence):\n",
    "    sample_sentence[i] = sent2IdList(sent)\n",
    "sample_sentence = sample_generator(sample_sentence, hparas['BATCH_SIZE'], caption_type=expSettings.caption_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "2946f2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption shape: (64,)\n",
      "Caption embeddings: tf.Tensor(\n",
      "[[-0.01346336  0.06881763 -0.05529514 ... -0.01518281 -0.00633275\n",
      "   0.01500697]\n",
      " [-0.01346336  0.06881763 -0.05529514 ... -0.01518281 -0.00633275\n",
      "   0.01500697]\n",
      " [-0.01346336  0.06881763 -0.05529514 ... -0.01518281 -0.00633275\n",
      "   0.01500697]\n",
      " ...\n",
      " [-0.00790838  0.06233827  0.01107207 ... -0.02398296 -0.03450323\n",
      "  -0.00868433]\n",
      " [-0.00790838  0.06233827  0.01107207 ... -0.02398296 -0.03450323\n",
      "  -0.00868433]\n",
      " [-0.00790838  0.06233827  0.01107207 ... -0.02398296 -0.03450323\n",
      "  -0.00868433]], shape=(64, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# test the sample dataset\n",
    "for cap in sample_sentence.take(1):\n",
    "    print(\"Caption shape:\", cap.numpy().shape)\n",
    "    emb, _ = text_encoder(cap, text_encoder.initialize_hidden_state())\n",
    "    print(\"Caption embeddings:\", emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "c4af2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('samples/demo'):\n",
    "    os.makedirs('samples/demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd34dfd3",
   "metadata": {},
   "source": [
    "Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "620661c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    # hidden state of RNN\n",
    "    hidden = text_encoder.initialize_hidden_state()\n",
    "    steps_per_epoch = int(hparas['N_SAMPLE']/hparas['BATCH_SIZE'])\n",
    "    \n",
    "    lowest_gen_loss = 1e10\n",
    "    \n",
    "    for epoch in range(hparas['N_EPOCH']):\n",
    "        g_total_loss = 0\n",
    "        d_total_loss = 0\n",
    "        batchid = 0\n",
    "        start = time.time()\n",
    "        imshow = False\n",
    "        \n",
    "        for image, caption in dataset:\n",
    "            batchid += 1\n",
    "            g_loss, d_loss = train_step(image, caption, hidden, imshow=imshow)\n",
    "            imshow = False\n",
    "            g_total_loss += g_loss\n",
    "            d_total_loss += d_loss\n",
    "        \n",
    "        time_tuple = time.localtime()\n",
    "        time_string = time.strftime(\"%m/%d/%Y, %H:%M:%S\", time_tuple)\n",
    "            \n",
    "        print(\"Epoch {}, gen_loss: {:.4f}, disc_loss: {:.4f}\".format(epoch+1,\n",
    "                                                                     g_total_loss/steps_per_epoch,\n",
    "                                                                     d_total_loss/steps_per_epoch))\n",
    "        print('Time for epoch {} is {:.4f} sec'.format(epoch+1, time.time()-start))\n",
    "        \n",
    "        # save the model if lower gen loss is achieved\n",
    "        if g_total_loss < lowest_gen_loss:\n",
    "            lowest_gen_loss = g_total_loss\n",
    "            ckptManager.save()\n",
    "            print('new lowest. saving model.')\n",
    "        elif g_total_loss < 3 * lowest_gen_loss:\n",
    "            ckptManager.save()\n",
    "            print('within save threshold. saving model.')\n",
    "        else:\n",
    "            lowest_gen_loss *= 1.02\n",
    "            \n",
    "        print('======================================')\n",
    "        \n",
    "        # visualization\n",
    "        if (epoch + 1) % hparas['PRINT_FREQ'] == 0:\n",
    "            for caption in sample_sentence:\n",
    "                fake_image = test_step(caption, sample_seed, hidden)\n",
    "            save_images(fake_image,\n",
    "                        [ni, ni],\n",
    "                        'samples/demo/train_{:03d}.jpg'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "6c752c76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_20241101\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, gen_loss: 1.8861, disc_loss: 28.5298\n",
      "Time for epoch 1 is 157.0279 sec\n",
      "new lowest. saving model.\n",
      "======================================\n",
      "Epoch 2, gen_loss: 12.8019, disc_loss: 8.6626\n",
      "Time for epoch 2 is 150.1114 sec\n",
      "======================================\n",
      "Epoch 3, gen_loss: 10.6726, disc_loss: 9.3638\n",
      "Time for epoch 3 is 150.2461 sec\n",
      "======================================\n",
      "Epoch 4, gen_loss: 16.8685, disc_loss: 4.5566\n",
      "Time for epoch 4 is 151.5259 sec\n",
      "======================================\n",
      "Epoch 5, gen_loss: 13.9472, disc_loss: 9.9693\n",
      "Time for epoch 5 is 153.3798 sec\n",
      "======================================\n",
      "Epoch 6, gen_loss: 6.9875, disc_loss: 13.6581\n",
      "Time for epoch 6 is 152.1112 sec\n",
      "======================================\n",
      "Epoch 7, gen_loss: 6.7130, disc_loss: 13.6902\n",
      "Time for epoch 7 is 143.6160 sec\n",
      "======================================\n",
      "Epoch 8, gen_loss: 7.2897, disc_loss: 12.8268\n",
      "Time for epoch 8 is 149.8868 sec\n",
      "======================================\n",
      "Epoch 9, gen_loss: 6.6670, disc_loss: 13.5848\n",
      "Time for epoch 9 is 151.8409 sec\n",
      "======================================\n",
      "Epoch 10, gen_loss: 6.6551, disc_loss: 13.5345\n",
      "Time for epoch 10 is 145.2812 sec\n",
      "======================================\n",
      "Epoch 11, gen_loss: 7.8587, disc_loss: 12.0351\n",
      "Time for epoch 11 is 146.3786 sec\n",
      "======================================\n",
      "Epoch 12, gen_loss: 9.4297, disc_loss: 10.5063\n",
      "Time for epoch 12 is 165.8329 sec\n",
      "======================================\n",
      "Epoch 13, gen_loss: 10.6084, disc_loss: 9.3277\n",
      "Time for epoch 13 is 144.9365 sec\n",
      "======================================\n",
      "Epoch 14, gen_loss: 9.1841, disc_loss: 11.2888\n",
      "Time for epoch 14 is 155.8514 sec\n",
      "======================================\n",
      "Epoch 15, gen_loss: 9.5681, disc_loss: 10.6998\n",
      "Time for epoch 15 is 160.4599 sec\n",
      "======================================\n",
      "Epoch 16, gen_loss: 10.5782, disc_loss: 9.8880\n",
      "Time for epoch 16 is 140.7161 sec\n",
      "======================================\n",
      "Epoch 17, gen_loss: 9.7400, disc_loss: 10.7539\n",
      "Time for epoch 17 is 147.5039 sec\n",
      "======================================\n",
      "Epoch 18, gen_loss: 9.4232, disc_loss: 11.0543\n",
      "Time for epoch 18 is 154.5430 sec\n",
      "======================================\n",
      "Epoch 19, gen_loss: 8.9885, disc_loss: 11.6847\n",
      "Time for epoch 19 is 148.5649 sec\n",
      "======================================\n",
      "Epoch 20, gen_loss: 10.2238, disc_loss: 10.0123\n",
      "Time for epoch 20 is 141.8599 sec\n",
      "======================================\n",
      "Epoch 21, gen_loss: 10.1315, disc_loss: 10.4514\n",
      "Time for epoch 21 is 143.0188 sec\n",
      "======================================\n",
      "Epoch 22, gen_loss: 10.5518, disc_loss: 10.0565\n",
      "Time for epoch 22 is 140.9899 sec\n",
      "======================================\n",
      "Epoch 23, gen_loss: 10.6041, disc_loss: 10.0443\n",
      "Time for epoch 23 is 142.5982 sec\n",
      "======================================\n",
      "Epoch 24, gen_loss: 11.4972, disc_loss: 9.3262\n",
      "Time for epoch 24 is 143.7528 sec\n",
      "======================================\n",
      "Epoch 25, gen_loss: 12.3322, disc_loss: 9.0071\n",
      "Time for epoch 25 is 150.9705 sec\n",
      "======================================\n",
      "Epoch 26, gen_loss: 11.9092, disc_loss: 9.5875\n",
      "Time for epoch 26 is 151.4080 sec\n",
      "======================================\n",
      "Epoch 27, gen_loss: 11.1906, disc_loss: 9.8737\n",
      "Time for epoch 27 is 151.4997 sec\n",
      "======================================\n",
      "Epoch 28, gen_loss: 11.4717, disc_loss: 9.4220\n",
      "Time for epoch 28 is 148.3619 sec\n",
      "======================================\n",
      "Epoch 29, gen_loss: 11.9681, disc_loss: 9.2784\n",
      "Time for epoch 29 is 150.5755 sec\n",
      "======================================\n",
      "Epoch 30, gen_loss: 10.9704, disc_loss: 10.1467\n",
      "Time for epoch 30 is 149.2488 sec\n",
      "======================================\n",
      "Epoch 31, gen_loss: 11.2581, disc_loss: 9.5550\n",
      "Time for epoch 31 is 148.4407 sec\n",
      "======================================\n",
      "Epoch 32, gen_loss: 11.0338, disc_loss: 10.3697\n",
      "Time for epoch 32 is 147.7678 sec\n",
      "======================================\n",
      "Epoch 33, gen_loss: 11.6378, disc_loss: 9.3812\n",
      "Time for epoch 33 is 150.5616 sec\n",
      "======================================\n",
      "Epoch 34, gen_loss: 11.5316, disc_loss: 9.5461\n",
      "Time for epoch 34 is 148.9892 sec\n",
      "======================================\n",
      "Epoch 35, gen_loss: 11.7355, disc_loss: 10.0411\n",
      "Time for epoch 35 is 146.3526 sec\n",
      "======================================\n",
      "Epoch 36, gen_loss: 11.7812, disc_loss: 9.7768\n",
      "Time for epoch 36 is 145.2338 sec\n",
      "======================================\n",
      "Epoch 37, gen_loss: 12.5756, disc_loss: 9.0393\n",
      "Time for epoch 37 is 146.1139 sec\n",
      "======================================\n",
      "Epoch 38, gen_loss: 11.7094, disc_loss: 9.8231\n",
      "Time for epoch 38 is 145.3647 sec\n",
      "======================================\n",
      "Epoch 39, gen_loss: 10.8817, disc_loss: 10.6261\n",
      "Time for epoch 39 is 144.9056 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 40, gen_loss: 12.5592, disc_loss: 9.5369\n",
      "Time for epoch 40 is 139.6210 sec\n",
      "======================================\n",
      "Epoch 41, gen_loss: 12.4008, disc_loss: 9.5739\n",
      "Time for epoch 41 is 139.8173 sec\n",
      "======================================\n",
      "Epoch 42, gen_loss: 11.1290, disc_loss: 10.4566\n",
      "Time for epoch 42 is 139.7918 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 43, gen_loss: 10.9402, disc_loss: 10.8273\n",
      "Time for epoch 43 is 139.7366 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 44, gen_loss: 10.9661, disc_loss: 10.5990\n",
      "Time for epoch 44 is 140.8321 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 45, gen_loss: 12.3770, disc_loss: 9.1937\n",
      "Time for epoch 45 is 140.9369 sec\n",
      "======================================\n",
      "Epoch 46, gen_loss: 13.8325, disc_loss: 7.9852\n",
      "Time for epoch 46 is 140.2492 sec\n",
      "======================================\n",
      "Epoch 47, gen_loss: 12.5353, disc_loss: 9.2301\n",
      "Time for epoch 47 is 141.7161 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 48, gen_loss: 13.7703, disc_loss: 7.9244\n",
      "Time for epoch 48 is 140.1238 sec\n",
      "======================================\n",
      "Epoch 49, gen_loss: 13.8232, disc_loss: 8.2790\n",
      "Time for epoch 49 is 139.7105 sec\n",
      "======================================\n",
      "Epoch 50, gen_loss: 13.6659, disc_loss: 8.0709\n",
      "Time for epoch 50 is 140.1657 sec\n",
      "======================================\n",
      "Epoch 51, gen_loss: 15.6774, disc_loss: 7.8667\n",
      "Time for epoch 51 is 141.2760 sec\n",
      "======================================\n",
      "Epoch 52, gen_loss: 15.6268, disc_loss: 7.4172\n",
      "Time for epoch 52 is 147.1054 sec\n",
      "======================================\n",
      "Epoch 53, gen_loss: 15.3481, disc_loss: 7.9955\n",
      "Time for epoch 53 is 139.3489 sec\n",
      "======================================\n",
      "Epoch 54, gen_loss: 15.3782, disc_loss: 8.1130\n",
      "Time for epoch 54 is 140.1327 sec\n",
      "======================================\n",
      "Epoch 55, gen_loss: 14.7453, disc_loss: 8.7962\n",
      "Time for epoch 55 is 139.9071 sec\n",
      "======================================\n",
      "Epoch 56, gen_loss: 13.6503, disc_loss: 9.6226\n",
      "Time for epoch 56 is 140.3922 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 57, gen_loss: 13.6465, disc_loss: 9.4494\n",
      "Time for epoch 57 is 140.1251 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 58, gen_loss: 14.9001, disc_loss: 8.3676\n",
      "Time for epoch 58 is 140.3521 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 59, gen_loss: 14.6174, disc_loss: 8.3146\n",
      "Time for epoch 59 is 140.3428 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 60, gen_loss: 16.1370, disc_loss: 7.0908\n",
      "Time for epoch 60 is 139.8482 sec\n",
      "======================================\n",
      "Epoch 61, gen_loss: 15.2964, disc_loss: 8.7711\n",
      "Time for epoch 61 is 140.5920 sec\n",
      "======================================\n",
      "Epoch 62, gen_loss: 15.5694, disc_loss: 7.5832\n",
      "Time for epoch 62 is 139.9785 sec\n",
      "======================================\n",
      "Epoch 63, gen_loss: 15.9073, disc_loss: 8.6396\n",
      "Time for epoch 63 is 139.1679 sec\n",
      "======================================\n",
      "Epoch 64, gen_loss: 15.8799, disc_loss: 7.4718\n",
      "Time for epoch 64 is 139.3180 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 65, gen_loss: 15.9148, disc_loss: 7.5928\n",
      "Time for epoch 65 is 138.7475 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, gen_loss: 17.1582, disc_loss: 6.8046\n",
      "Time for epoch 66 is 139.8840 sec\n",
      "======================================\n",
      "Epoch 67, gen_loss: 18.4937, disc_loss: 6.7038\n",
      "Time for epoch 67 is 140.1898 sec\n",
      "======================================\n",
      "Epoch 68, gen_loss: 17.5797, disc_loss: 7.1567\n",
      "Time for epoch 68 is 140.0209 sec\n",
      "======================================\n",
      "Epoch 69, gen_loss: 16.2989, disc_loss: 7.7747\n",
      "Time for epoch 69 is 139.9279 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 70, gen_loss: 19.0292, disc_loss: 7.6593\n",
      "Time for epoch 70 is 139.9626 sec\n",
      "======================================\n",
      "Epoch 71, gen_loss: 16.7195, disc_loss: 7.5823\n",
      "Time for epoch 71 is 140.5164 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 72, gen_loss: 17.1161, disc_loss: 7.6399\n",
      "Time for epoch 72 is 140.2308 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 73, gen_loss: 17.6940, disc_loss: 7.4323\n",
      "Time for epoch 73 is 139.7159 sec\n",
      "======================================\n",
      "Epoch 74, gen_loss: 16.9063, disc_loss: 7.3340\n",
      "Time for epoch 74 is 138.1340 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 75, gen_loss: 17.1115, disc_loss: 8.3130\n",
      "Time for epoch 75 is 139.5401 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 76, gen_loss: 16.1341, disc_loss: 7.8865\n",
      "Time for epoch 76 is 139.4158 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 77, gen_loss: 16.5475, disc_loss: 8.2640\n",
      "Time for epoch 77 is 140.3903 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 78, gen_loss: 19.4326, disc_loss: 6.3948\n",
      "Time for epoch 78 is 140.0159 sec\n",
      "======================================\n",
      "Epoch 79, gen_loss: 19.0331, disc_loss: 6.6598\n",
      "Time for epoch 79 is 140.1228 sec\n",
      "======================================\n",
      "Epoch 80, gen_loss: 18.6557, disc_loss: 6.6724\n",
      "Time for epoch 80 is 139.8320 sec\n",
      "======================================\n",
      "Epoch 81, gen_loss: 18.5795, disc_loss: 6.9497\n",
      "Time for epoch 81 is 139.9961 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 82, gen_loss: 17.5553, disc_loss: 7.6959\n",
      "Time for epoch 82 is 140.5072 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 83, gen_loss: 18.4794, disc_loss: 6.9274\n",
      "Time for epoch 83 is 140.1118 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 84, gen_loss: 19.8095, disc_loss: 6.3835\n",
      "Time for epoch 84 is 140.2265 sec\n",
      "======================================\n",
      "Epoch 85, gen_loss: 19.0475, disc_loss: 6.9958\n",
      "Time for epoch 85 is 139.5600 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 86, gen_loss: 18.6787, disc_loss: 7.1755\n",
      "Time for epoch 86 is 140.0090 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 87, gen_loss: 18.9526, disc_loss: 7.4693\n",
      "Time for epoch 87 is 139.7719 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 88, gen_loss: 19.4489, disc_loss: 6.5262\n",
      "Time for epoch 88 is 139.7889 sec\n",
      "======================================\n",
      "Epoch 89, gen_loss: 20.0743, disc_loss: 6.2999\n",
      "Time for epoch 89 is 139.6877 sec\n",
      "======================================\n",
      "Epoch 90, gen_loss: 18.6272, disc_loss: 7.6097\n",
      "Time for epoch 90 is 139.9189 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 91, gen_loss: 21.9970, disc_loss: 5.5618\n",
      "Time for epoch 91 is 139.5255 sec\n",
      "======================================\n",
      "Epoch 92, gen_loss: 21.0963, disc_loss: 6.2847\n",
      "Time for epoch 92 is 139.1310 sec\n",
      "======================================\n",
      "Epoch 93, gen_loss: 19.9957, disc_loss: 7.3974\n",
      "Time for epoch 93 is 138.9813 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 94, gen_loss: 21.0541, disc_loss: 6.7466\n",
      "Time for epoch 94 is 140.2799 sec\n",
      "======================================\n",
      "Epoch 95, gen_loss: 20.8776, disc_loss: 6.0625\n",
      "Time for epoch 95 is 142.3114 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 96, gen_loss: 21.1079, disc_loss: 6.4463\n",
      "Time for epoch 96 is 139.4662 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 97, gen_loss: 20.1640, disc_loss: 6.1568\n",
      "Time for epoch 97 is 139.2698 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 98, gen_loss: 19.9225, disc_loss: 7.5732\n",
      "Time for epoch 98 is 139.1936 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 99, gen_loss: 19.6988, disc_loss: 7.1929\n",
      "Time for epoch 99 is 143.8076 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 100, gen_loss: 20.3151, disc_loss: 6.2612\n",
      "Time for epoch 100 is 143.7756 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 101, gen_loss: 24.1428, disc_loss: 5.4564\n",
      "Time for epoch 101 is 143.5465 sec\n",
      "======================================\n",
      "Epoch 102, gen_loss: 20.9453, disc_loss: 6.3405\n",
      "Time for epoch 102 is 143.1280 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 103, gen_loss: 19.3798, disc_loss: 6.9057\n",
      "Time for epoch 103 is 143.5647 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 104, gen_loss: 18.2669, disc_loss: 7.7800\n",
      "Time for epoch 104 is 143.4807 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 105, gen_loss: 20.5057, disc_loss: 6.3457\n",
      "Time for epoch 105 is 144.1672 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 106, gen_loss: 20.8761, disc_loss: 6.5956\n",
      "Time for epoch 106 is 143.4390 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 107, gen_loss: 19.8856, disc_loss: 7.1251\n",
      "Time for epoch 107 is 143.2732 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 108, gen_loss: 20.3896, disc_loss: 7.3082\n",
      "Time for epoch 108 is 143.6813 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 109, gen_loss: 18.8390, disc_loss: 8.3622\n",
      "Time for epoch 109 is 143.6002 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 110, gen_loss: 19.2464, disc_loss: 7.6056\n",
      "Time for epoch 110 is 143.3697 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 111, gen_loss: 20.4941, disc_loss: 7.4369\n",
      "Time for epoch 111 is 146.9144 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 112, gen_loss: 19.4520, disc_loss: 7.8993\n",
      "Time for epoch 112 is 150.8121 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 113, gen_loss: 20.0817, disc_loss: 6.9056\n",
      "Time for epoch 113 is 143.3161 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 114, gen_loss: 19.8172, disc_loss: 7.2171\n",
      "Time for epoch 114 is 143.4054 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 115, gen_loss: 20.0924, disc_loss: 7.8464\n",
      "Time for epoch 115 is 143.8952 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 116, gen_loss: 20.0674, disc_loss: 8.1253\n",
      "Time for epoch 116 is 143.3674 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 117, gen_loss: 25.3464, disc_loss: 5.3134\n",
      "Time for epoch 117 is 143.4256 sec\n",
      "======================================\n",
      "Epoch 118, gen_loss: 21.9666, disc_loss: 6.2026\n",
      "Time for epoch 118 is 143.0805 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 119, gen_loss: 19.9691, disc_loss: 6.3943\n",
      "Time for epoch 119 is 143.3382 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 120, gen_loss: 19.9556, disc_loss: 7.8084\n",
      "Time for epoch 120 is 143.0539 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 121, gen_loss: 20.8919, disc_loss: 6.3055\n",
      "Time for epoch 121 is 143.4446 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122, gen_loss: 18.3519, disc_loss: 7.6002\n",
      "Time for epoch 122 is 142.8065 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 123, gen_loss: 18.2381, disc_loss: 8.3729\n",
      "Time for epoch 123 is 143.4180 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 124, gen_loss: 19.3381, disc_loss: 7.8335\n",
      "Time for epoch 124 is 143.0156 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 125, gen_loss: 21.1643, disc_loss: 6.5650\n",
      "Time for epoch 125 is 143.3200 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 126, gen_loss: 19.8722, disc_loss: 7.2928\n",
      "Time for epoch 126 is 142.8948 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 127, gen_loss: 21.0080, disc_loss: 7.1238\n",
      "Time for epoch 127 is 143.1770 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 128, gen_loss: 22.7944, disc_loss: 6.7971\n",
      "Time for epoch 128 is 144.0659 sec\n",
      "======================================\n",
      "Epoch 129, gen_loss: 20.2790, disc_loss: 6.5093\n",
      "Time for epoch 129 is 143.4065 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 130, gen_loss: 20.5188, disc_loss: 7.7445\n",
      "Time for epoch 130 is 143.0550 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 131, gen_loss: 21.4505, disc_loss: 6.6045\n",
      "Time for epoch 131 is 143.0519 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 132, gen_loss: 22.4487, disc_loss: 6.5257\n",
      "Time for epoch 132 is 142.8560 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 133, gen_loss: 21.5689, disc_loss: 6.3648\n",
      "Time for epoch 133 is 143.2625 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 134, gen_loss: 19.2864, disc_loss: 8.4680\n",
      "Time for epoch 134 is 142.8047 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 135, gen_loss: 20.0700, disc_loss: 8.4973\n",
      "Time for epoch 135 is 142.8650 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 136, gen_loss: 19.6259, disc_loss: 7.9861\n",
      "Time for epoch 136 is 143.5583 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 137, gen_loss: 19.8014, disc_loss: 7.3751\n",
      "Time for epoch 137 is 143.0742 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 138, gen_loss: 19.1609, disc_loss: 7.9931\n",
      "Time for epoch 138 is 143.1671 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 139, gen_loss: 21.0879, disc_loss: 8.0057\n",
      "Time for epoch 139 is 143.2460 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 140, gen_loss: 18.6857, disc_loss: 8.5365\n",
      "Time for epoch 140 is 142.5658 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 141, gen_loss: 18.2218, disc_loss: 8.5232\n",
      "Time for epoch 141 is 142.5928 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 142, gen_loss: 20.4864, disc_loss: 8.1240\n",
      "Time for epoch 142 is 142.7138 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 143, gen_loss: 20.1020, disc_loss: 7.9971\n",
      "Time for epoch 143 is 142.6137 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 144, gen_loss: 21.4177, disc_loss: 6.8354\n",
      "Time for epoch 144 is 143.6115 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 145, gen_loss: 20.7203, disc_loss: 6.7637\n",
      "Time for epoch 145 is 142.7519 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 146, gen_loss: 21.9338, disc_loss: 7.8856\n",
      "Time for epoch 146 is 142.9880 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 147, gen_loss: 23.4756, disc_loss: 7.3239\n",
      "Time for epoch 147 is 142.9120 sec\n",
      "======================================\n",
      "Epoch 148, gen_loss: 20.0739, disc_loss: 7.5456\n",
      "Time for epoch 148 is 142.6454 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 149, gen_loss: 20.0754, disc_loss: 8.4002\n",
      "Time for epoch 149 is 142.9473 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 150, gen_loss: 19.1550, disc_loss: 8.5916\n",
      "Time for epoch 150 is 143.7266 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 151, gen_loss: 19.9703, disc_loss: 7.7343\n",
      "Time for epoch 151 is 143.3548 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 152, gen_loss: 21.3912, disc_loss: 7.1543\n",
      "Time for epoch 152 is 143.2710 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 153, gen_loss: 21.5418, disc_loss: 7.5960\n",
      "Time for epoch 153 is 142.3763 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 154, gen_loss: 21.3608, disc_loss: 7.3240\n",
      "Time for epoch 154 is 143.1565 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 155, gen_loss: 21.5060, disc_loss: 7.5137\n",
      "Time for epoch 155 is 143.3388 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 156, gen_loss: 21.5006, disc_loss: 6.7506\n",
      "Time for epoch 156 is 142.6459 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 157, gen_loss: 22.0746, disc_loss: 5.8896\n",
      "Time for epoch 157 is 142.7304 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 158, gen_loss: 24.5619, disc_loss: 5.5263\n",
      "Time for epoch 158 is 143.1551 sec\n",
      "======================================\n",
      "Epoch 159, gen_loss: 21.7748, disc_loss: 7.4966\n",
      "Time for epoch 159 is 143.2828 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 160, gen_loss: 22.4121, disc_loss: 6.7825\n",
      "Time for epoch 160 is 143.6753 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 161, gen_loss: 21.8786, disc_loss: 8.7830\n",
      "Time for epoch 161 is 143.2292 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 162, gen_loss: 18.7236, disc_loss: 8.4773\n",
      "Time for epoch 162 is 142.3611 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 163, gen_loss: 20.2852, disc_loss: 7.6945\n",
      "Time for epoch 163 is 142.7814 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 164, gen_loss: 20.0830, disc_loss: 8.6234\n",
      "Time for epoch 164 is 142.9277 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 165, gen_loss: 22.7148, disc_loss: 7.8928\n",
      "Time for epoch 165 is 143.0767 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 166, gen_loss: 23.0457, disc_loss: 7.7072\n",
      "Time for epoch 166 is 143.6301 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 167, gen_loss: 22.5867, disc_loss: 7.8945\n",
      "Time for epoch 167 is 143.3980 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 168, gen_loss: 20.7789, disc_loss: 8.7686\n",
      "Time for epoch 168 is 143.3309 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 169, gen_loss: 21.1139, disc_loss: 9.0919\n",
      "Time for epoch 169 is 143.3980 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 170, gen_loss: 21.8013, disc_loss: 7.6536\n",
      "Time for epoch 170 is 143.2248 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 171, gen_loss: 21.8286, disc_loss: 7.5499\n",
      "Time for epoch 171 is 142.8456 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 172, gen_loss: 20.5475, disc_loss: 8.2257\n",
      "Time for epoch 172 is 143.3081 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 173, gen_loss: 21.1203, disc_loss: 8.7430\n",
      "Time for epoch 173 is 143.0362 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 174, gen_loss: 23.5354, disc_loss: 7.4881\n",
      "Time for epoch 174 is 143.2781 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 175, gen_loss: 21.0818, disc_loss: 7.4575\n",
      "Time for epoch 175 is 143.2127 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 176, gen_loss: 22.3250, disc_loss: 6.8384\n",
      "Time for epoch 176 is 143.1688 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 177, gen_loss: 22.5193, disc_loss: 7.1329\n",
      "Time for epoch 177 is 143.2039 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 178, gen_loss: 22.9843, disc_loss: 7.7611\n",
      "Time for epoch 178 is 143.0438 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 179, gen_loss: 23.5685, disc_loss: 7.2938\n",
      "Time for epoch 179 is 143.3026 sec\n",
      "======================================\n",
      "Epoch 180, gen_loss: 21.0205, disc_loss: 8.7744\n",
      "Time for epoch 180 is 143.8735 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 181, gen_loss: 22.1262, disc_loss: 8.5132\n",
      "Time for epoch 181 is 143.4687 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 182, gen_loss: 24.6318, disc_loss: 7.2340\n",
      "Time for epoch 182 is 143.4273 sec\n",
      "======================================\n",
      "Epoch 183, gen_loss: 20.9348, disc_loss: 8.3807\n",
      "Time for epoch 183 is 143.5663 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 184, gen_loss: 24.0784, disc_loss: 7.8477\n",
      "Time for epoch 184 is 143.2146 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 185, gen_loss: 24.1576, disc_loss: 6.6748\n",
      "Time for epoch 185 is 143.6269 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 186, gen_loss: 25.0695, disc_loss: 6.6475\n",
      "Time for epoch 186 is 143.1337 sec\n",
      "======================================\n",
      "Epoch 187, gen_loss: 25.6476, disc_loss: 6.1762\n",
      "Time for epoch 187 is 143.5702 sec\n",
      "======================================\n",
      "Epoch 188, gen_loss: 23.0894, disc_loss: 7.6524\n",
      "Time for epoch 188 is 143.3430 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 189, gen_loss: 24.0705, disc_loss: 7.2684\n",
      "Time for epoch 189 is 143.8680 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 190, gen_loss: 21.3016, disc_loss: 8.9598\n",
      "Time for epoch 190 is 144.0111 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 191, gen_loss: 24.0624, disc_loss: 7.5413\n",
      "Time for epoch 191 is 144.1719 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 192, gen_loss: 23.6637, disc_loss: 8.4132\n",
      "Time for epoch 192 is 144.1478 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 193, gen_loss: 23.6118, disc_loss: 7.7317\n",
      "Time for epoch 193 is 144.2882 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 194, gen_loss: 23.5398, disc_loss: 7.1368\n",
      "Time for epoch 194 is 148.0470 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 195, gen_loss: 22.8446, disc_loss: 7.5884\n",
      "Time for epoch 195 is 152.3480 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 196, gen_loss: 21.9257, disc_loss: 10.0154\n",
      "Time for epoch 196 is 153.0530 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 197, gen_loss: 24.6994, disc_loss: 7.9553\n",
      "Time for epoch 197 is 156.6060 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 198, gen_loss: 24.5918, disc_loss: 8.0882\n",
      "Time for epoch 198 is 152.9228 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 199, gen_loss: 24.5282, disc_loss: 9.1051\n",
      "Time for epoch 199 is 153.0298 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 200, gen_loss: 21.1651, disc_loss: 10.5208\n",
      "Time for epoch 200 is 153.2830 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 201, gen_loss: 22.8407, disc_loss: 8.3830\n",
      "Time for epoch 201 is 160.2440 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 202, gen_loss: 22.4937, disc_loss: 8.3661\n",
      "Time for epoch 202 is 152.3128 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 203, gen_loss: 23.4891, disc_loss: 7.5540\n",
      "Time for epoch 203 is 149.0260 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 204, gen_loss: 23.6204, disc_loss: 8.4963\n",
      "Time for epoch 204 is 144.3718 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n",
      "Epoch 205, gen_loss: 25.3218, disc_loss: 6.4818\n",
      "Time for epoch 205 is 144.6817 sec\n",
      "within save threshold. saving model.\n",
      "======================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20652\\32322937.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhparas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'N_EPOCH'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20652\\3082361426.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaption\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mbatchid\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mg_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaption\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimshow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mimshow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mg_total_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_20241101\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_20241101\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_20241101\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_20241101\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_20241101\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_20241101\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_20241101\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(dataset, hparas['N_EPOCH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abbb4ec",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "a634d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_caption2string(ls):\n",
    "    return \" \".join([id2word_dict[idx] for idx in ls]).strip().split(' <PAD>')[0]\n",
    "\n",
    "def testing_data_generator(caption, index, caption_type='id'):\n",
    "    if caption_type == 'id':\n",
    "        caption = tf.cast(caption, tf.float32)\n",
    "    return caption, index\n",
    "\n",
    "def testing_dataset_generator(batch_size, data_generator, caption_type='id'):\n",
    "    data = pd.read_pickle('./dataset/testData.pkl')\n",
    "    \n",
    "    if caption_type == 'sentence':\n",
    "        data['Captions_string'] = data['Captions'].apply(test_caption2string)\n",
    "        captions = data['Captions_string'].values\n",
    "    elif caption_type == 'id':\n",
    "        captions = data['Captions'].values\n",
    "        \n",
    "    caption = []\n",
    "    for i in range(len(captions)):\n",
    "        caption.append(captions[i])\n",
    "    caption = np.asarray(caption)\n",
    "    \n",
    "    if caption_type == 'id':\n",
    "        caption = caption.astype(np.int)\n",
    "        \n",
    "    datagen_func = lambda cap, img: data_generator(cap, img, caption_type=caption_type)\n",
    "        \n",
    "    index = data['ID'].values\n",
    "    index = np.asarray(index)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((caption, index))\n",
    "    dataset = dataset.map(datagen_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat().batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "c7abd09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = testing_dataset_generator(hparas['BATCH_SIZE'], testing_data_generator, caption_type=expSettings.caption_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "88cc621c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (64,)\n",
      "Caption shape: (64,)\n"
     ]
    }
   ],
   "source": [
    "# test the testing dataset\n",
    "for cap, img in testing_dataset.take(1):\n",
    "    print(\"Image shape:\", img.numpy().shape)\n",
    "    print(\"Caption shape:\", cap.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "8d07f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('./dataset/testData.pkl')\n",
    "captions = data['Captions'].values\n",
    "\n",
    "NUM_TEST = len(captions)\n",
    "EPOCH_TEST = int(NUM_TEST / hparas['BATCH_SIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "8f624f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./inference/demo'):\n",
    "    os.makedirs('./inference/demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "6d3d0086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(dataset):\n",
    "    hidden = text_encoder.initialize_hidden_state()\n",
    "    sample_size = hparas['BATCH_SIZE']\n",
    "    sample_seed = np.random.normal(loc=0.0, scale=0.1, size=(sample_size, hparas['Z_DIM'])).astype(np.float32)\n",
    "    print(sample_seed[0:3, :])\n",
    "    \n",
    "    step = 0\n",
    "    start = time.time()\n",
    "    for captions, idx in dataset:\n",
    "        if step > EPOCH_TEST:\n",
    "            break\n",
    "        \n",
    "        fake_image = test_step(captions, sample_seed, hidden)\n",
    "        step += 1\n",
    "        for i in range(hparas['BATCH_SIZE']):\n",
    "            plt.imsave('./inference/demo/inference_{:04d}.jpg'.format(idx[i]), fake_image[i].numpy()*0.5 + 0.5)\n",
    "            \n",
    "            if i == 0 and step == 1: \n",
    "                #print(captions)\n",
    "                text_embed_t, hidden_t = text_encoder(captions, hidden)\n",
    "                #print(text_embed_t)\n",
    "                print(fake_image[0:1, 0:5, 0:5, :])\n",
    "                img_logits, _, debug = generator(text_embed_t, sample_seed, debug_output=True)\n",
    "                print(debug[0][0:3, 0:5, 0:5, 0:5])\n",
    "                print(debug[1][0:3, 0:5, 0:5, 0:5])\n",
    "                print(debug[2][0:3, 0:5, 0:5, 0:5])\n",
    "                print(debug[3][0:3, 0:5, 0:5, 0:5])\n",
    "                print(debug[4][0:3, 0:5, 0:5, 0:5])\n",
    "                print(img_logits[0:3, 0:5, 0:5, :])\n",
    "                pred_logit, pred = discriminator(fake_image, text_embed_t)\n",
    "                print(pred_logit)\n",
    "                \n",
    "            \n",
    "    print('Time for inference is {:.4f} sec'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "d12a53a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring from ./checkpoints/demo\\ckpt-129\n"
     ]
    }
   ],
   "source": [
    "#checkpoint.restore(checkpoint_dir + f'/ckpt-50')\n",
    "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "if latest_checkpoint:\n",
    "    print(f\"Restoring from {latest_checkpoint}\")\n",
    "    checkpoint.restore(latest_checkpoint)\n",
    "else:\n",
    "    print(\"No checkpoint found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "ff59c63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10586753  0.1683734  -0.04186799 ... -0.08489064 -0.0329618\n",
      "   0.03781696]\n",
      " [ 0.03922252  0.03296076  0.13910006 ...  0.13605477 -0.0755486\n",
      "   0.09131289]\n",
      " [-0.09989461 -0.01007991  0.012931   ... -0.0011589  -0.02907026\n",
      "  -0.09748437]]\n",
      "tf.Tensor(\n",
      "[[[[ 0.21720769  0.47280306  0.12604918]\n",
      "   [ 0.17457196  0.40070975  0.07731792]\n",
      "   [ 0.14772408  0.28354514  0.01530687]\n",
      "   [ 0.10258732  0.34258884  0.03953101]\n",
      "   [ 0.42752028  0.6867732   0.5655326 ]]\n",
      "\n",
      "  [[-0.00210296  0.2229808  -0.01537495]\n",
      "   [ 0.11066125  0.2839741   0.01735989]\n",
      "   [ 0.17913605  0.293927    0.12320141]\n",
      "   [ 0.37599295  0.5424648   0.36960796]\n",
      "   [ 0.42181563  0.57904196  0.5068701 ]]\n",
      "\n",
      "  [[ 0.28094682  0.5502275   0.19273959]\n",
      "   [ 0.269157    0.43758902  0.16704144]\n",
      "   [ 0.26127547  0.35547554  0.26871258]\n",
      "   [ 0.5230407   0.7386627   0.4779848 ]\n",
      "   [ 0.5606745   0.76229715  0.59335446]]\n",
      "\n",
      "  [[ 0.23168376  0.3678933   0.11534017]\n",
      "   [ 0.33075872  0.40716508  0.32358813]\n",
      "   [ 0.41750866  0.49542183  0.4464383 ]\n",
      "   [ 0.5009935   0.6886381   0.55300444]\n",
      "   [ 0.46377662  0.6445676   0.47256503]]\n",
      "\n",
      "  [[ 0.2393149   0.2669788   0.15992156]\n",
      "   [ 0.3071125   0.34351623  0.27834955]\n",
      "   [ 0.3861297   0.44342557  0.41741925]\n",
      "   [ 0.3684662   0.4799049   0.39322537]\n",
      "   [ 0.5140429   0.74809     0.41641885]]]], shape=(1, 5, 5, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[-2.90220982e-04  7.58786082e-01 -1.95982698e-02 -1.00029163e-01\n",
      "    -3.84476893e-02]\n",
      "   [-1.50914952e-01 -1.44305704e-02 -4.05275710e-02  1.35155892e+00\n",
      "    -3.88811305e-02]]\n",
      "\n",
      "  [[-3.28564011e-02  7.40657270e-01  1.29140830e+00 -6.95107728e-02\n",
      "    -7.86459073e-02]\n",
      "   [ 6.83129072e-01  3.65075856e-01  1.34583545e+00 -7.44131133e-02\n",
      "    -1.17702007e-01]]]\n",
      "\n",
      "\n",
      " [[[ 5.93876600e-01 -3.49740461e-02  8.91326189e-01 -1.16189597e-02\n",
      "    -3.02473549e-02]\n",
      "   [-9.97734293e-02 -7.74611607e-02 -5.49299903e-02  1.12944162e+00\n",
      "    -7.96131194e-02]]\n",
      "\n",
      "  [[ 4.55227494e-01  9.99883175e-01  1.52118027e+00  1.24533415e-01\n",
      "    -2.08627254e-01]\n",
      "   [ 8.23777199e-01  5.06703496e-01  1.50206470e+00 -7.46291801e-02\n",
      "    -2.28689954e-01]]]\n",
      "\n",
      "\n",
      " [[[-5.40293567e-02 -3.23674940e-02  1.06967235e+00  1.89144063e+00\n",
      "    -5.30238152e-02]\n",
      "   [ 2.89161539e+00  1.25886261e+00 -9.14462730e-02 -1.49546728e-01\n",
      "    -1.37131974e-01]]\n",
      "\n",
      "  [[-1.15990877e-01  4.18934047e-01 -1.09390631e-01  5.09153128e-01\n",
      "    -1.16084121e-01]\n",
      "   [ 8.87477934e-01  8.65905285e-01 -1.52223229e-01 -1.12124361e-01\n",
      "    -1.59914091e-01]]]], shape=(3, 2, 2, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[-1.64039116e-02  3.97051722e-01  3.72879244e-02 -2.37906501e-02\n",
      "    -9.16589424e-03]\n",
      "   [ 2.81913489e-01  4.33575422e-01 -6.30949661e-02 -2.65318751e-02\n",
      "    -5.25029488e-02]\n",
      "   [-2.25199442e-02 -5.49787097e-02 -8.00328236e-03 -5.08403480e-02\n",
      "    -8.85203108e-02]\n",
      "   [ 2.50102788e-01  6.31029785e-01  2.29495168e-01  1.24102557e+00\n",
      "    -1.59372035e-02]]\n",
      "\n",
      "  [[-5.84460571e-02 -8.05385411e-02 -1.00197634e-02 -6.84347302e-02\n",
      "    -2.01407503e-02]\n",
      "   [-2.12756857e-01 -7.57266476e-04 -2.03440577e-01  1.51641226e+00\n",
      "    -1.04547456e-01]\n",
      "   [-1.52670428e-01 -1.72199488e-01  8.32055092e-01 -1.12467468e-01\n",
      "     1.05050802e+00]\n",
      "   [-2.21989932e-03  6.31699502e-01 -2.14131430e-01 -3.69972847e-02\n",
      "    -3.68197933e-02]]\n",
      "\n",
      "  [[-1.02142552e-02  5.23361742e-01 -2.87220869e-02 -4.30708490e-02\n",
      "    -1.61480289e-02]\n",
      "   [-5.43177091e-02 -2.06045970e-01 -9.75848436e-02 -1.84566557e-01\n",
      "     6.95512891e-01]\n",
      "   [-7.93283135e-02 -1.24196172e-01  8.96458805e-01 -1.35022774e-01\n",
      "    -1.84652358e-01]\n",
      "   [-2.47525461e-02 -4.43933010e-02 -4.90093194e-02  5.70607603e-01\n",
      "    -7.42411166e-02]]\n",
      "\n",
      "  [[-4.28353474e-02 -6.33852510e-03  1.52180288e-02 -6.35869801e-02\n",
      "    -4.85892333e-02]\n",
      "   [-9.80493128e-02  2.88590372e-01 -4.62374426e-02  4.20915574e-01\n",
      "    -3.24558467e-02]\n",
      "   [-6.43839687e-02 -6.59676492e-02  6.10340655e-01 -1.18639313e-01\n",
      "     9.60164368e-01]\n",
      "   [-3.47956307e-02  7.51068294e-01 -2.94246469e-02  3.49190593e-01\n",
      "    -5.93665354e-02]]]\n",
      "\n",
      "\n",
      " [[[-1.69123169e-02  3.86819661e-01 -2.69412226e-03 -3.76207493e-02\n",
      "    -1.71549339e-02]\n",
      "   [ 2.56632715e-01  5.32428026e-01 -7.57194385e-02 -3.78694758e-02\n",
      "    -7.43394718e-02]\n",
      "   [-3.15362923e-02 -6.86697215e-02 -1.30697833e-02 -6.50782213e-02\n",
      "    -1.01442754e-01]\n",
      "   [ 2.29820564e-01  6.61732554e-01  2.32754290e-01  1.38502800e+00\n",
      "    -3.00804060e-02]]\n",
      "\n",
      "  [[-7.36052319e-02 -9.36644450e-02 -1.77465286e-02 -9.38096493e-02\n",
      "    -3.48603539e-02]\n",
      "   [-2.39903852e-01 -1.12767210e-02 -2.30372503e-01  1.58131802e+00\n",
      "    -1.19698636e-01]\n",
      "   [-1.74820170e-01 -1.69518724e-01  6.78709447e-01 -1.09830931e-01\n",
      "     1.08621860e+00]\n",
      "   [-7.67167984e-03  6.49479628e-01 -2.39293218e-01 -3.68264876e-02\n",
      "    -4.22457866e-02]]\n",
      "\n",
      "  [[-1.65155828e-02  5.20218194e-01 -3.92502286e-02 -5.95470481e-02\n",
      "    -1.78458672e-02]\n",
      "   [-7.76565522e-02 -2.26628497e-01 -1.06835626e-01 -2.15723753e-01\n",
      "     8.49765778e-01]\n",
      "   [-9.23245698e-02 -1.44997984e-01  8.69616568e-01 -1.43336713e-01\n",
      "    -1.97544962e-01]\n",
      "   [-3.35977972e-02 -6.80505782e-02 -5.62776923e-02  5.40872872e-01\n",
      "    -1.03233419e-01]]\n",
      "\n",
      "  [[-4.96708006e-02 -1.03697125e-02 -2.63756257e-03 -7.68078491e-02\n",
      "    -6.24869131e-02]\n",
      "   [-1.12992883e-01  1.82845742e-01 -7.26617053e-02  3.51205587e-01\n",
      "    -7.17080161e-02]\n",
      "   [-7.47552961e-02 -8.31573457e-02  6.18102729e-01 -1.30979270e-01\n",
      "     8.28807652e-01]\n",
      "   [-3.91424187e-02  8.03074837e-01 -3.66232954e-02  3.34265918e-01\n",
      "    -8.34857598e-02]]]\n",
      "\n",
      "\n",
      " [[[ 8.84202302e-01 -5.20964041e-02  1.61284074e-01 -3.59422080e-02\n",
      "    -5.52427173e-02]\n",
      "   [ 6.38614893e-01 -2.60375831e-02 -6.80714697e-02 -2.87788715e-02\n",
      "    -4.59104627e-02]\n",
      "   [-9.25015435e-02 -7.55769685e-02  7.16790020e-01 -1.18411303e-01\n",
      "    -2.62901485e-02]\n",
      "   [ 1.49150074e-01 -4.67935838e-02  6.39365375e-01  9.30346727e-01\n",
      "    -1.17138568e-02]]\n",
      "\n",
      "  [[-1.37560636e-01 -1.36263281e-01 -5.43509126e-02 -1.37483582e-01\n",
      "    -1.15479594e-02]\n",
      "   [-2.43432030e-01  2.59844869e-01 -7.38618150e-02 -4.99780150e-03\n",
      "    -1.47207931e-01]\n",
      "   [-3.58671933e-01 -9.21014175e-02 -1.83848292e-01 -1.91982776e-01\n",
      "     8.49956870e-01]\n",
      "   [ 1.34395242e-01  6.85831964e-01 -2.58009315e-01  1.01761913e+00\n",
      "    -1.55388102e-01]]\n",
      "\n",
      "  [[-6.78315461e-02 -2.19609253e-02 -2.36416366e-02 -8.39511678e-02\n",
      "    -5.64210303e-02]\n",
      "   [-4.70637716e-02 -1.84168443e-01 -1.41835675e-01 -3.01224589e-01\n",
      "    -5.63136153e-02]\n",
      "   [-8.74586999e-02 -2.38456130e-01 -6.57433793e-02 -6.55867085e-02\n",
      "    -9.62490812e-02]\n",
      "   [-3.83971594e-02 -1.00166798e-01 -7.49703124e-02  1.50445059e-01\n",
      "    -7.66278803e-02]]\n",
      "\n",
      "  [[-3.61191556e-02 -1.00699877e-02 -1.60949677e-02 -4.01662216e-02\n",
      "    -5.86384125e-02]\n",
      "   [-1.55157536e-01 -1.10774059e-02 -5.97098358e-02  1.67416260e-01\n",
      "    -3.39914560e-02]\n",
      "   [-1.17236651e-01 -7.22718835e-02 -2.65553650e-02 -8.04682076e-02\n",
      "     8.72128189e-01]\n",
      "   [-5.08626699e-02  5.52957356e-01 -4.11127917e-02  1.92932323e-01\n",
      "    -8.71973932e-02]]]], shape=(3, 4, 4, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[-2.65914034e-02 -4.55021709e-02  2.15402871e-01  1.07255995e-01\n",
      "     8.39648306e-01]\n",
      "   [-1.84934642e-02  1.44384015e+00 -6.24267831e-02 -6.37631072e-03\n",
      "     6.73601747e-01]\n",
      "   [-3.99191305e-02  4.20684338e-01 -2.24655326e-02 -3.87810618e-02\n",
      "    -3.90158482e-02]\n",
      "   [-2.31419336e-02 -1.04148698e-03 -4.61401939e-02  1.11139381e+00\n",
      "    -7.05769882e-02]\n",
      "   [-1.13731518e-01 -6.52670935e-02 -2.52667814e-02  8.72537866e-02\n",
      "    -6.35167062e-02]]\n",
      "\n",
      "  [[ 4.09179151e-01 -3.48547958e-02 -2.60312445e-02  5.03278613e-01\n",
      "    -2.06692852e-02]\n",
      "   [-4.68381308e-02 -7.12591335e-02 -9.43616405e-02 -1.54619068e-02\n",
      "     2.10828996e+00]\n",
      "   [-1.37073323e-01 -3.02347820e-02 -6.66859224e-02 -9.27200988e-02\n",
      "    -2.32002675e-03]\n",
      "   [-2.21339334e-02  1.13899541e+00 -7.81374723e-02 -4.56203967e-02\n",
      "    -3.07094734e-02]\n",
      "   [-1.95779368e-01 -3.97819318e-02 -1.74452752e-01 -1.70747921e-01\n",
      "    -4.83945236e-02]]\n",
      "\n",
      "  [[-4.67645116e-02  4.23413157e-01 -8.62332236e-05 -6.14948273e-02\n",
      "     1.21249044e+00]\n",
      "   [ 6.19503915e-01 -7.54946396e-02 -3.36886421e-02 -4.23816070e-02\n",
      "    -4.27034460e-02]\n",
      "   [-4.13644686e-02 -1.38125673e-01 -1.91283509e-01 -6.41787425e-02\n",
      "    -9.70258638e-02]\n",
      "   [ 7.76300848e-01 -1.11044638e-01 -3.13314907e-02 -1.04284346e-01\n",
      "     1.98551857e+00]\n",
      "   [-3.51327173e-02 -1.15939818e-01 -1.71516538e-01 -8.45541134e-02\n",
      "     4.99027610e-01]]\n",
      "\n",
      "  [[ 2.66710550e-01 -4.26401757e-02 -6.71648756e-02 -1.68563388e-02\n",
      "     1.83669284e-01]\n",
      "   [-8.64513144e-02  1.76449135e-01 -1.55296801e-02 -9.96011347e-02\n",
      "    -9.02615041e-02]\n",
      "   [-2.97903959e-02 -5.56146204e-02 -3.19166258e-02 -6.74321130e-02\n",
      "    -5.11114895e-02]\n",
      "   [-5.38260527e-02 -2.00836346e-01  8.51137936e-01 -8.47198293e-02\n",
      "    -1.77774683e-01]\n",
      "   [-1.97465584e-01 -1.16461195e-01 -1.51420191e-01 -1.75341174e-01\n",
      "    -6.67291805e-02]]\n",
      "\n",
      "  [[-4.34742570e-02 -8.62187147e-02  2.10559875e-01 -8.36770460e-02\n",
      "     7.95312643e-01]\n",
      "   [-5.42405136e-02 -9.47303325e-02 -5.89971431e-02 -2.48057358e-02\n",
      "    -7.88076594e-03]\n",
      "   [-7.56359398e-02 -2.03697115e-01 -1.06064692e-01 -2.93710525e-03\n",
      "    -6.28573522e-02]\n",
      "   [ 3.35097998e-01 -6.47247359e-02 -8.72394443e-02  3.39668930e-01\n",
      "    -2.24761009e-01]\n",
      "   [ 5.30163467e-01 -2.79301047e-01 -1.55824989e-01 -9.70643833e-02\n",
      "    -6.64010048e-02]]]\n",
      "\n",
      "\n",
      " [[[-2.85524819e-02 -5.16966693e-02  1.91423431e-01  7.59003311e-02\n",
      "     8.26895475e-01]\n",
      "   [-2.43396591e-02  1.47801566e+00 -7.41679221e-02 -1.83662008e-02\n",
      "     6.94174230e-01]\n",
      "   [-4.26825583e-02  4.03420687e-01 -3.33124809e-02 -4.93962429e-02\n",
      "    -4.62775603e-02]\n",
      "   [-2.53874958e-02 -8.91601015e-03 -5.35480082e-02  1.11290538e+00\n",
      "    -8.08147490e-02]\n",
      "   [-1.22279041e-01 -7.54449293e-02 -3.21564823e-02  8.44300315e-02\n",
      "    -6.97408542e-02]]\n",
      "\n",
      "  [[ 3.37688893e-01 -4.01002467e-02 -3.15328054e-02  4.64819193e-01\n",
      "    -2.68934406e-02]\n",
      "   [-6.29481077e-02 -8.70122910e-02 -1.09999895e-01 -3.17784362e-02\n",
      "     2.15419197e+00]\n",
      "   [-1.50622711e-01 -4.43933420e-02 -7.79104233e-02 -1.04766108e-01\n",
      "    -1.11164516e-02]\n",
      "   [-2.11342163e-02  1.12611341e+00 -8.98138061e-02 -5.51308505e-02\n",
      "    -4.08766530e-02]\n",
      "   [-2.11133987e-01 -4.79947142e-02 -1.85231656e-01 -1.87924415e-01\n",
      "    -5.82930557e-02]]\n",
      "\n",
      "  [[-5.23672402e-02  3.57755363e-01 -9.85870417e-03 -7.04290345e-02\n",
      "     1.14613545e+00]\n",
      "   [ 5.59216499e-01 -9.62367579e-02 -4.18088250e-02 -5.33133857e-02\n",
      "    -5.10664843e-02]\n",
      "   [-4.88419086e-02 -1.58411130e-01 -2.05478832e-01 -7.10606799e-02\n",
      "    -1.10509060e-01]\n",
      "   [ 7.39108920e-01 -1.24856271e-01 -3.33802141e-02 -1.17856719e-01\n",
      "     2.12439775e+00]\n",
      "   [-4.59705852e-02 -1.33699402e-01 -1.83387861e-01 -9.95703340e-02\n",
      "     3.81954968e-01]]\n",
      "\n",
      "  [[ 2.11815298e-01 -4.78317924e-02 -7.10944831e-02 -1.99875738e-02\n",
      "     1.34731129e-01]\n",
      "   [-9.92632434e-02  1.15781084e-01 -2.66329404e-02 -1.13419831e-01\n",
      "    -1.04998589e-01]\n",
      "   [-3.78937609e-02 -6.88997805e-02 -3.83067504e-02 -6.78872168e-02\n",
      "    -5.68539388e-02]\n",
      "   [-5.22617362e-02 -2.13630468e-01  8.99738193e-01 -1.01755165e-01\n",
      "    -1.81012288e-01]\n",
      "   [-2.18293548e-01 -1.26161024e-01 -1.65090308e-01 -1.85953349e-01\n",
      "    -8.31002370e-02]]\n",
      "\n",
      "  [[-4.31716777e-02 -9.20860842e-02  1.21213734e-01 -9.01893377e-02\n",
      "     7.26228118e-01]\n",
      "   [-6.13052212e-02 -1.10395811e-01 -6.57711402e-02 -3.89616564e-02\n",
      "    -7.16330856e-03]\n",
      "   [-8.21609050e-02 -2.17401743e-01 -1.13973558e-01 -1.04169017e-02\n",
      "    -6.67937025e-02]\n",
      "   [ 3.52463514e-01 -7.97324181e-02 -9.54774693e-02  1.96528837e-01\n",
      "    -2.27051899e-01]\n",
      "   [ 4.75604564e-01 -3.07636082e-01 -1.70885593e-01 -1.12369850e-01\n",
      "    -7.53807351e-02]]]\n",
      "\n",
      "\n",
      " [[[-3.13967578e-02 -5.16348667e-02  5.99930823e-01  2.83757925e-01\n",
      "     4.98119295e-01]\n",
      "   [ 1.41776606e-01 -6.28676042e-02 -6.71713352e-02 -8.48130509e-02\n",
      "     7.13308394e-01]\n",
      "   [-3.46137993e-02 -8.62267613e-02 -7.88129270e-02  7.69656539e-01\n",
      "     4.36151415e-01]\n",
      "   [-1.07146865e-02 -3.45012620e-02 -1.28891736e-01  5.53875184e-03\n",
      "     1.74429631e+00]\n",
      "   [-7.47327283e-02 -7.41720945e-02 -3.41181383e-02  2.15665960e+00\n",
      "     4.73795921e-01]]\n",
      "\n",
      "  [[-8.80278721e-02 -5.73415570e-02 -8.40730816e-02  9.04128790e-01\n",
      "    -8.39115605e-02]\n",
      "   [ 2.46576834e+00 -1.29208211e-02 -7.75756240e-02 -1.07071757e-01\n",
      "     5.59770632e+00]\n",
      "   [-6.84907958e-02 -2.10024357e-01 -2.48484284e-01 -3.17247421e-01\n",
      "     8.85568678e-01]\n",
      "   [-1.06116690e-01  5.58296156e+00 -1.07963286e-01  5.83150089e-01\n",
      "    -2.51146644e-01]\n",
      "   [-9.15105641e-02  8.82691085e-01  2.21014881e+00 -6.40305728e-02\n",
      "     3.10614228e+00]]\n",
      "\n",
      "  [[-9.13199410e-02 -5.03553450e-02 -7.01582059e-02 -3.80294882e-02\n",
      "     1.88862407e+00]\n",
      "   [-8.44312757e-02 -8.90325308e-02  2.00327635e+00 -1.05060153e-01\n",
      "    -7.04508200e-02]\n",
      "   [-1.26419827e-01 -1.24252014e-01 -1.51092410e-01 -1.88393593e-02\n",
      "     9.22007501e-01]\n",
      "   [ 1.39949429e+00  6.31442130e-01 -2.08873942e-01 -5.75619824e-02\n",
      "     1.07587385e+00]\n",
      "   [-1.15338385e-01 -2.67414629e-01 -1.71127826e-01 -1.57101423e-01\n",
      "     5.17416716e-01]]\n",
      "\n",
      "  [[-6.68914840e-02 -4.81842645e-02 -8.12369585e-02  1.40027809e+00\n",
      "    -1.55870123e-02]\n",
      "   [-5.70979491e-02 -2.10162267e-01 -1.40154973e-01 -8.83225277e-02\n",
      "    -2.04576656e-01]\n",
      "   [-2.63149917e-01 -1.14990495e-01 -2.48253271e-01 -2.19972178e-01\n",
      "    -1.30949181e-03]\n",
      "   [-1.19645670e-01 -3.48648340e-01  2.97320843e+00  7.61440814e-01\n",
      "    -1.53325900e-01]\n",
      "   [-2.17495352e-01 -1.86094210e-01 -2.52831250e-01 -3.42510939e-01\n",
      "     1.86609411e+00]]\n",
      "\n",
      "  [[-6.31024688e-02 -3.25385705e-02  1.08264005e+00 -1.35155722e-01\n",
      "     1.36309075e+00]\n",
      "   [-7.60528669e-02 -2.29176283e-01 -5.49710467e-02  2.48577788e-01\n",
      "     4.58293676e+00]\n",
      "   [ 2.92423695e-01 -3.88780551e-04 -3.55130911e-01 -1.46627635e-01\n",
      "    -7.61383697e-02]\n",
      "   [-6.74244538e-02 -3.23280394e-01 -2.79120393e-02  2.01099873e+00\n",
      "    -1.10756136e-01]\n",
      "   [-3.73073548e-01 -4.17501926e-01  9.37506318e-01 -2.45600566e-01\n",
      "     4.01028824e+00]]]], shape=(3, 5, 5, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[ 8.27066004e-02 -9.58850048e-03 -2.25956403e-02  2.19927400e-01\n",
      "    -7.88945612e-03]\n",
      "   [ 8.54415894e-01  6.25665307e-01 -8.23521689e-02 -5.33891395e-02\n",
      "    -9.61109716e-03]\n",
      "   [ 4.70282704e-01 -2.84139009e-04 -1.27978921e-01  4.73178148e-01\n",
      "    -4.41661924e-02]\n",
      "   [ 9.29317623e-03  1.16466358e-01 -4.96809073e-02 -7.22763408e-03\n",
      "    -4.33856472e-02]\n",
      "   [-1.13617852e-01 -1.56080052e-02 -8.50304589e-02  3.47531050e-01\n",
      "     7.98465788e-01]]\n",
      "\n",
      "  [[ 5.26657462e-01 -9.40235481e-02 -2.63111591e-02  1.10825646e+00\n",
      "    -7.31406584e-02]\n",
      "   [ 7.02608347e-01 -1.07447198e-02  5.40794075e-01  1.05526423e+00\n",
      "     1.16232431e+00]\n",
      "   [ 2.82717377e-01 -3.02692745e-02 -9.93340145e-05 -1.15817636e-02\n",
      "    -2.09260304e-02]\n",
      "   [-1.80273026e-01  5.88577509e-01 -2.43573505e-02 -7.78829232e-02\n",
      "    -7.99265131e-02]\n",
      "   [-1.76482007e-01 -3.34362350e-02  2.70879656e-01  1.09371674e+00\n",
      "    -1.80043988e-02]]\n",
      "\n",
      "  [[ 8.56425762e-01 -2.72402447e-02  2.74011314e-01  2.17430480e-02\n",
      "    -8.50688964e-02]\n",
      "   [-6.12481348e-02  3.36814106e-01 -1.47989318e-02 -8.00040290e-02\n",
      "     8.60724866e-01]\n",
      "   [-1.13862239e-01  1.07165980e+00  9.62359190e-01 -4.14370559e-02\n",
      "     3.83133963e-02]\n",
      "   [-1.60050511e-01  1.29285800e+00  1.64500976e+00 -1.23255089e-01\n",
      "    -4.45661917e-02]\n",
      "   [ 1.36168510e-01 -8.34891573e-03 -7.57895634e-02 -7.91045185e-03\n",
      "    -1.53517589e-01]]\n",
      "\n",
      "  [[ 3.01445812e-01 -6.82530254e-02 -5.92241175e-02  1.23634899e+00\n",
      "     4.08289582e-01]\n",
      "   [ 8.37685317e-02 -2.50911247e-02 -6.23651333e-02 -8.55413824e-02\n",
      "    -3.76537703e-02]\n",
      "   [-1.43729327e-02 -6.56626141e-03  2.61515737e+00 -8.39878246e-02\n",
      "    -1.85495004e-01]\n",
      "   [-9.77149531e-02  5.76198041e-01 -1.04248403e-02 -6.75998777e-02\n",
      "    -1.84400249e-02]\n",
      "   [ 7.30790377e-01 -2.26370501e-03  1.25977349e+00 -6.53981268e-02\n",
      "    -8.45992640e-02]]\n",
      "\n",
      "  [[-3.65544483e-02 -1.15888536e-01 -3.09521742e-02  4.68970627e-01\n",
      "    -6.39379621e-02]\n",
      "   [-1.25922322e-01 -2.28212383e-02  8.16854060e-01 -6.25370368e-02\n",
      "     4.34969068e-01]\n",
      "   [ 2.75333953e+00  4.35133055e-02  1.15166759e+00 -1.02875017e-01\n",
      "    -1.91918328e-01]\n",
      "   [-9.36976597e-02  2.96786100e-01 -1.37330115e-01 -1.40759513e-01\n",
      "     2.40389943e+00]\n",
      "   [-1.93419814e-01  1.79623592e+00  9.22494471e-01  2.48982000e+00\n",
      "    -1.50204882e-01]]]\n",
      "\n",
      "\n",
      " [[[ 8.19850117e-02 -8.19301046e-03 -2.17579603e-02  2.04194427e-01\n",
      "    -8.29016324e-03]\n",
      "   [ 9.13922727e-01  6.26624346e-01 -8.43330845e-02 -5.28972335e-02\n",
      "    -1.51145682e-02]\n",
      "   [ 5.06337941e-01 -1.31927535e-03 -1.30221188e-01  4.70442891e-01\n",
      "    -4.14290838e-02]\n",
      "   [ 2.61817854e-02  7.77247921e-02 -5.06472662e-02 -1.22191180e-02\n",
      "    -4.80295643e-02]\n",
      "   [-1.11639693e-01 -1.93744395e-02 -8.38145539e-02  3.29542965e-01\n",
      "     8.36425126e-01]]\n",
      "\n",
      "  [[ 5.43971360e-01 -9.27349627e-02 -2.89315432e-02  1.04669666e+00\n",
      "    -7.10112602e-02]\n",
      "   [ 7.76754737e-01 -1.51798381e-02  4.78423119e-01  1.06005239e+00\n",
      "     1.16687131e+00]\n",
      "   [ 3.41837555e-01 -3.57608125e-02 -4.48600482e-03 -1.07023204e-02\n",
      "    -7.59859243e-03]\n",
      "   [-1.79173291e-01  5.44903815e-01 -2.34200563e-02 -7.82069117e-02\n",
      "    -8.10539648e-02]\n",
      "   [-1.74848869e-01 -3.99033502e-02  1.81777254e-01  1.06546807e+00\n",
      "    -7.69290933e-03]]\n",
      "\n",
      "  [[ 8.75146747e-01 -3.05003077e-02  2.56342798e-01  1.67509653e-02\n",
      "    -7.83313066e-02]\n",
      "   [-6.06931522e-02  2.95205563e-01 -1.65876951e-02 -8.26346055e-02\n",
      "     7.97427177e-01]\n",
      "   [-1.11461401e-01  9.31885481e-01  9.59460795e-01 -4.29668091e-02\n",
      "    -3.57935252e-03]\n",
      "   [-1.59560740e-01  1.22852266e+00  1.56367743e+00 -1.26313910e-01\n",
      "    -5.11753559e-02]\n",
      "   [ 2.48154849e-01 -1.48525611e-02 -7.11355135e-02 -1.95545610e-02\n",
      "    -1.49511859e-01]]\n",
      "\n",
      "  [[ 3.04534078e-01 -6.91448972e-02 -5.23049720e-02  1.15265548e+00\n",
      "     3.53547603e-01]\n",
      "   [ 8.99174660e-02 -2.92913709e-02 -5.41201197e-02 -8.75208899e-02\n",
      "    -4.36952226e-02]\n",
      "   [-1.44538656e-02 -1.26702311e-02  2.43348765e+00 -8.06498528e-02\n",
      "    -1.82285830e-01]\n",
      "   [-9.65094492e-02  5.18071353e-01 -1.32731199e-02 -7.14272112e-02\n",
      "    -2.65961569e-02]\n",
      "   [ 7.09461093e-01 -2.71177804e-03  1.16159773e+00 -5.64745367e-02\n",
      "    -7.92208239e-02]]\n",
      "\n",
      "  [[-3.48642319e-02 -1.12744592e-01 -3.11840605e-02  4.54445422e-01\n",
      "    -5.89380153e-02]\n",
      "   [-1.22523330e-01 -2.57305447e-02  7.50590801e-01 -6.51606992e-02\n",
      "     2.70872355e-01]\n",
      "   [ 2.73905015e+00 -1.12603856e-02  1.09918368e+00 -1.02928601e-01\n",
      "    -1.94400474e-01]\n",
      "   [-8.48840103e-02  2.75038123e-01 -1.30487964e-01 -1.46845296e-01\n",
      "     2.28787184e+00]\n",
      "   [-1.83101922e-01  1.79032290e+00  8.53213191e-01  2.44210815e+00\n",
      "    -1.51528060e-01]]]\n",
      "\n",
      "\n",
      " [[[ 1.45303607e-01 -4.45898138e-02 -1.31296022e-02  4.56031799e-01\n",
      "    -1.70217257e-03]\n",
      "   [ 3.14432740e-01 -8.72341171e-02 -6.15138896e-02  9.55427364e-02\n",
      "    -2.80538364e-03]\n",
      "   [-3.72569114e-02 -8.83478597e-02 -1.18974485e-01  4.37560201e-01\n",
      "    -5.56435287e-02]\n",
      "   [-3.87892313e-02 -9.77023020e-02 -2.28390262e-01 -1.04546703e-01\n",
      "     8.88367966e-02]\n",
      "   [-8.68299901e-02 -1.59428284e-01 -7.64704570e-02  6.42095387e-01\n",
      "     4.77979302e-01]]\n",
      "\n",
      "  [[ 3.36165667e-01 -7.36158341e-02 -2.10228004e-02  6.92932382e-02\n",
      "    -8.77886117e-02]\n",
      "   [-4.86571826e-02 -1.18156269e-01 -1.72234385e-03 -4.29892801e-02\n",
      "     2.38873076e+00]\n",
      "   [-4.52225283e-02 -4.42834310e-02 -7.34518021e-02  4.51453418e-01\n",
      "     1.43350327e+00]\n",
      "   [-6.53014183e-02  6.62347555e-01 -1.00131869e-01 -1.31976470e-01\n",
      "     7.83710003e-01]\n",
      "   [-1.71260148e-01  5.93599796e-01  7.51195312e-01  1.93534970e+00\n",
      "     1.38374567e+00]]\n",
      "\n",
      "  [[-9.72921588e-03 -3.70192826e-02 -5.49342930e-02 -4.25031595e-02\n",
      "    -9.43806767e-02]\n",
      "   [-2.00272486e-01 -1.06524564e-01 -1.33577257e-01  4.99825716e-01\n",
      "    -7.40084946e-02]\n",
      "   [-2.66840067e-02 -1.95186269e-02 -6.36975616e-02 -1.01894112e-02\n",
      "     2.05499840e+00]\n",
      "   [-1.01250768e-01  4.40722972e-01  8.11414700e-03 -1.59192324e-01\n",
      "     5.14910161e-01]\n",
      "   [ 6.14436269e-01 -1.42523587e-01 -1.20203316e-01 -1.01847373e-01\n",
      "    -6.16360381e-02]]\n",
      "\n",
      "  [[ 3.77362609e-01 -8.48914087e-02 -4.15104032e-02  7.28906453e-01\n",
      "     9.08885479e-01]\n",
      "   [ 8.45023766e-02  1.00089520e-01 -5.48160337e-02 -1.16483107e-01\n",
      "     9.71031129e-01]\n",
      "   [-9.58151296e-02  1.35899103e+00  4.35056388e-01 -8.61064047e-02\n",
      "    -1.16098784e-01]\n",
      "   [ 5.06493807e-01  1.86696362e+00  1.20429683e+00  2.46448517e+00\n",
      "    -2.08014801e-01]\n",
      "   [-1.43597469e-01  1.09803987e+00  8.36680353e-01  2.17402935e+00\n",
      "    -2.10812893e-02]]\n",
      "\n",
      "  [[-4.10122834e-02 -4.07341644e-02 -2.41037663e-02 -3.73284630e-02\n",
      "    -7.94354007e-02]\n",
      "   [ 1.82089642e-01 -6.82436898e-02 -1.69304490e-01 -1.67909518e-01\n",
      "    -1.47012740e-01]\n",
      "   [ 2.60998034e+00 -2.35593151e-02 -8.83388445e-02 -9.50120091e-02\n",
      "    -2.71784902e-01]\n",
      "   [ 1.63970554e+00  5.87847173e-01 -1.48567945e-01 -4.95074270e-03\n",
      "     1.75555944e+00]\n",
      "   [-2.02136710e-01  2.38187122e+00  1.68402576e+00 -6.80756196e-02\n",
      "    -6.68971688e-02]]]], shape=(3, 5, 5, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[-3.88738438e-02  1.14959121e-01 -3.95577354e-03  2.40586504e-01\n",
      "    -2.21918728e-02]\n",
      "   [-1.13597117e-01  1.33607686e-01 -4.60393690e-02 -1.89300925e-02\n",
      "    -5.46071166e-03]\n",
      "   [-3.73895280e-02 -5.60264988e-03  2.68988162e-01  1.48545831e-01\n",
      "    -8.27177241e-02]\n",
      "   [-1.78374555e-02 -3.41870710e-02  3.23881418e-01 -8.11076090e-02\n",
      "    -3.00096180e-02]\n",
      "   [-6.64407238e-02 -5.80005310e-02 -1.74683966e-02 -2.73480117e-02\n",
      "    -7.54393190e-02]]\n",
      "\n",
      "  [[-7.26800738e-03 -2.96092778e-03 -9.35032144e-02 -1.88553836e-02\n",
      "     9.70569104e-02]\n",
      "   [ 3.22031999e+00 -9.42238271e-02 -6.19279640e-03  8.53847802e-01\n",
      "     4.69637156e-01]\n",
      "   [ 1.67762721e+00 -9.83473510e-02 -6.28043106e-03 -1.08144663e-01\n",
      "    -1.17802933e-01]\n",
      "   [-4.19746488e-02 -2.26258673e-02 -3.05756507e-03 -3.55616659e-02\n",
      "    -5.60103916e-02]\n",
      "   [ 1.17543012e-01  5.12814939e-01 -3.87727320e-02 -3.81150506e-02\n",
      "    -1.89389393e-01]]\n",
      "\n",
      "  [[-3.00234593e-02 -6.65801018e-02  2.33293384e-01  6.18823655e-02\n",
      "    -4.47545834e-02]\n",
      "   [-6.50074333e-02 -6.70395046e-03 -1.36983022e-01  6.91233352e-02\n",
      "    -7.98665285e-02]\n",
      "   [ 7.70857453e-01 -1.16411947e-01 -9.18110460e-02 -2.99501028e-02\n",
      "    -5.27883060e-02]\n",
      "   [-8.79991651e-02  3.46799165e-01  9.38519061e-01 -3.65606844e-02\n",
      "    -7.41666108e-02]\n",
      "   [ 1.55005670e+00 -1.12907641e-01 -9.92217436e-02 -1.32700177e-02\n",
      "    -6.50476143e-02]]\n",
      "\n",
      "  [[-6.15676120e-02 -3.14625502e-02 -8.02416354e-02 -6.70553371e-02\n",
      "    -3.27751301e-02]\n",
      "   [ 4.28356409e-01  2.64869362e-01 -3.65898348e-02 -7.62489764e-03\n",
      "    -8.57793614e-02]\n",
      "   [-3.52097414e-02 -1.50863543e-01  1.41751826e-01 -6.90525472e-02\n",
      "    -4.02589850e-02]\n",
      "   [ 1.28222990e+00  6.11883044e-01  3.09060156e-01  4.28918540e-01\n",
      "    -1.69349313e-01]\n",
      "   [ 8.42357516e-01 -6.90094307e-02 -1.42245246e-02  1.29212677e-01\n",
      "    -1.09100237e-01]]\n",
      "\n",
      "  [[ 7.66629100e-01 -1.73845347e-02  7.52031684e-01 -5.11675887e-02\n",
      "    -8.34604260e-03]\n",
      "   [ 8.86710227e-01  1.04330322e-02  1.09537888e+00 -2.08346695e-02\n",
      "    -2.40458995e-02]\n",
      "   [ 5.61308265e-01 -3.84133123e-02  1.69785285e+00  1.25209436e-01\n",
      "    -5.26009388e-02]\n",
      "   [-3.01252753e-02 -3.03846933e-02  1.25493395e+00  1.03035748e+00\n",
      "    -1.07278842e-02]\n",
      "   [ 7.82618046e-01 -1.24416307e-01 -4.57922220e-02  1.00193524e+00\n",
      "    -1.41392514e-01]]]\n",
      "\n",
      "\n",
      " [[[-3.71206179e-02  1.05133399e-01 -4.62832116e-03  2.33591735e-01\n",
      "    -2.26298105e-02]\n",
      "   [-1.12811640e-01  1.30771354e-01 -4.47906032e-02 -2.04139613e-02\n",
      "    -6.73481775e-03]\n",
      "   [-3.67423743e-02 -6.62203832e-03  2.59275377e-01  1.39388919e-01\n",
      "    -8.34141299e-02]\n",
      "   [-1.92457568e-02 -3.42333727e-02  3.11530024e-01 -7.96108246e-02\n",
      "    -2.96765268e-02]\n",
      "   [-6.59392402e-02 -5.73929809e-02 -2.09843516e-02 -2.67988127e-02\n",
      "    -7.83528388e-02]]\n",
      "\n",
      "  [[-4.71140677e-03 -2.95122038e-03 -8.87363777e-02 -1.98487099e-02\n",
      "     8.11068863e-02]\n",
      "   [ 3.16482425e+00 -9.39167365e-02 -8.64396151e-03  8.25643837e-01\n",
      "     4.44000959e-01]\n",
      "   [ 1.63311362e+00 -9.67057720e-02 -7.28844060e-03 -1.09416984e-01\n",
      "    -1.18646219e-01]\n",
      "   [-3.44080850e-02 -2.16835998e-02 -3.20006162e-03 -3.38490792e-02\n",
      "    -5.54220974e-02]\n",
      "   [ 5.41006252e-02  5.09114444e-01 -4.86253500e-02 -3.75639796e-02\n",
      "    -1.92567632e-01]]\n",
      "\n",
      "  [[-2.84262057e-02 -6.42982572e-02  2.01894552e-01  4.69238535e-02\n",
      "    -4.30947393e-02]\n",
      "   [-6.79362118e-02 -8.02757684e-03 -1.33127317e-01  5.07987216e-02\n",
      "    -7.79583752e-02]\n",
      "   [ 7.30885565e-01 -1.12302385e-01 -8.85866880e-02 -2.80089714e-02\n",
      "    -5.18325828e-02]\n",
      "   [-8.63479078e-02  3.74362946e-01  8.91200304e-01 -3.25479321e-02\n",
      "    -6.95745945e-02]\n",
      "   [ 1.51907396e+00 -1.05736315e-01 -9.99675617e-02 -1.31200124e-02\n",
      "    -6.88765496e-02]]\n",
      "\n",
      "  [[-6.05247132e-02 -2.90681850e-02 -7.51102194e-02 -6.50182217e-02\n",
      "    -3.40687372e-02]\n",
      "   [ 4.46399808e-01  2.45672673e-01 -3.10369078e-02 -7.92005286e-03\n",
      "    -8.45334083e-02]\n",
      "   [-3.58137675e-02 -1.46247417e-01  1.77871719e-01 -6.81084469e-02\n",
      "    -3.93765569e-02]\n",
      "   [ 1.39220083e+00  6.29431486e-01  3.91442358e-01  3.83243114e-01\n",
      "    -1.65500566e-01]\n",
      "   [ 7.89590538e-01 -6.83681890e-02 -1.80598628e-02  1.85185701e-01\n",
      "    -1.05198398e-01]]\n",
      "\n",
      "  [[ 7.44192123e-01 -1.45920366e-02  7.21626818e-01 -5.18350787e-02\n",
      "    -6.18316885e-03]\n",
      "   [ 8.33543658e-01  3.37440433e-04  1.03867710e+00 -1.36391846e-02\n",
      "    -2.52879765e-02]\n",
      "   [ 6.16263509e-01 -3.81667279e-02  1.63093495e+00  1.51010752e-01\n",
      "    -5.05121462e-02]\n",
      "   [-3.21581103e-02 -3.54811922e-02  1.12854075e+00  1.09288371e+00\n",
      "    -1.16417417e-02]\n",
      "   [ 8.35565269e-01 -1.20345831e-01 -4.99614142e-02  9.01845157e-01\n",
      "    -1.36902779e-01]]]\n",
      "\n",
      "\n",
      " [[[-3.39247994e-02  1.01215817e-01 -2.69995779e-02  1.48965061e-01\n",
      "    -9.25203320e-03]\n",
      "   [-4.90499325e-02  3.00918929e-02 -5.23936450e-02  2.70140581e-02\n",
      "    -1.19424118e-02]\n",
      "   [-2.42958609e-02  2.43895445e-02  6.58660531e-02  1.55613884e-01\n",
      "    -3.27181034e-02]\n",
      "   [-2.36995928e-02 -3.66859660e-02 -3.85855399e-02 -1.48555951e-03\n",
      "     8.42967629e-02]\n",
      "   [ 1.96056012e-02 -2.17454694e-02 -5.70680667e-03  2.64318794e-01\n",
      "    -4.00532372e-02]]\n",
      "\n",
      "  [[ 8.32954720e-02 -7.82209542e-03 -4.21102159e-02  1.66685358e-01\n",
      "    -2.30031367e-02]\n",
      "   [ 1.17504668e+00  4.66731600e-02 -4.29855809e-02  9.40019071e-01\n",
      "     4.19106334e-01]\n",
      "   [ 6.61751628e-02 -5.98307252e-02  1.84843242e-01  1.34747718e-02\n",
      "    -5.25645874e-02]\n",
      "   [-8.73740241e-02 -6.29031062e-02 -9.74457245e-03  7.13965818e-02\n",
      "    -6.42095730e-02]\n",
      "   [-7.91919455e-02  5.88889532e-02 -2.58476939e-02 -4.94650751e-02\n",
      "    -4.51974571e-02]]\n",
      "\n",
      "  [[-3.41340378e-02 -3.46040912e-02 -2.45589800e-02  1.26580745e-01\n",
      "    -2.04749610e-02]\n",
      "   [-8.99820924e-02 -3.32307331e-02  2.99224406e-01 -3.25603336e-02\n",
      "    -4.14082110e-02]\n",
      "   [-7.68214315e-02 -8.48314390e-02 -2.58593261e-02 -1.37566891e-03\n",
      "    -4.29427177e-02]\n",
      "   [ 1.96163043e-01 -1.13687210e-01  1.40180558e-01  1.64404675e-01\n",
      "    -1.28577370e-02]\n",
      "   [-7.46959522e-02 -7.30716512e-02  2.10470632e-01 -6.47994736e-03\n",
      "     1.02867290e-01]]\n",
      "\n",
      "  [[-3.81271094e-02  4.32370640e-02 -4.78880666e-02 -3.82147580e-02\n",
      "    -2.57404745e-02]\n",
      "   [-7.82944169e-03  3.73640247e-02  5.63942492e-02 -5.70965058e-04\n",
      "    -1.48182316e-02]\n",
      "   [ 1.60776556e-01 -1.08727574e-01 -2.89552547e-02 -5.50949574e-02\n",
      "    -6.85121045e-02]\n",
      "   [ 3.98412466e-01 -1.24838976e-02  2.31851637e-01 -4.36517447e-02\n",
      "     7.74128363e-02]\n",
      "   [ 8.55337203e-01 -2.49041449e-02 -1.78528707e-02 -1.41994223e-01\n",
      "    -8.97902921e-02]]\n",
      "\n",
      "  [[ 3.17257852e-03 -8.77636112e-03 -2.55285986e-02  3.12271435e-02\n",
      "    -2.42967494e-02]\n",
      "   [-5.03737219e-02  2.46188492e-01 -1.04871750e-01 -4.06380259e-02\n",
      "     2.78953165e-01]\n",
      "   [-5.43855242e-02 -8.23185779e-03  1.96017548e-01 -8.45708512e-03\n",
      "    -5.80428354e-02]\n",
      "   [-9.26732924e-03 -1.93165943e-01 -5.50781861e-02 -4.47248630e-02\n",
      "     4.89633530e-01]\n",
      "   [ 2.48604029e-01 -2.71278452e-02 -5.74128143e-02 -4.39595757e-03\n",
      "    -1.57958418e-01]]]], shape=(3, 5, 5, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[ 2.20723867e-01  5.13674378e-01  1.26723185e-01]\n",
      "   [ 1.76378459e-01  4.24493879e-01  7.74726346e-02]\n",
      "   [ 1.48812950e-01  2.91532904e-01  1.53079564e-02]\n",
      "   [ 1.02949157e-01  3.57022434e-01  3.95518057e-02]\n",
      "   [ 4.56858277e-01  8.41822147e-01  6.40930593e-01]]\n",
      "\n",
      "  [[-2.10297410e-03  2.26790726e-01 -1.53761311e-02]\n",
      "   [ 1.11116089e-01  2.91999161e-01  1.73618253e-02]\n",
      "   [ 1.81089833e-01  3.02859128e-01  1.23830594e-01]\n",
      "   [ 3.95384848e-01  6.07641518e-01  3.87969583e-01]\n",
      "   [ 4.49898511e-01  6.61019981e-01  5.58509231e-01]]\n",
      "\n",
      "  [[ 2.88709521e-01  6.18707180e-01  1.95181206e-01]\n",
      "   [ 2.75954545e-01  4.69244450e-01  1.68621525e-01]\n",
      "   [ 2.67476618e-01  3.71697187e-01  2.75475711e-01]\n",
      "   [ 5.80516458e-01  9.47529733e-01  5.20369351e-01]\n",
      "   [ 6.33816361e-01  1.00167632e+00  6.82827950e-01]]\n",
      "\n",
      "  [[ 2.35967323e-01  3.85983407e-01  1.15855657e-01]\n",
      "   [ 3.43679994e-01  4.32207942e-01  3.35649669e-01]\n",
      "   [ 4.44670677e-01  5.43220401e-01  4.80243027e-01]\n",
      "   [ 5.50631046e-01  8.45360339e-01  6.22698843e-01]\n",
      "   [ 5.02112150e-01  7.65948713e-01  5.13367891e-01]]\n",
      "\n",
      "  [[ 2.44047031e-01  2.73607612e-01  1.61305889e-01]\n",
      "   [ 3.17353725e-01  3.58073354e-01  2.85891950e-01]\n",
      "   [ 4.07243192e-01  4.76486325e-01  4.44562465e-01]\n",
      "   [ 3.86646986e-01  5.22860408e-01  4.15609568e-01]\n",
      "   [ 5.68209350e-01  9.68603909e-01  4.43352044e-01]]]\n",
      "\n",
      "\n",
      " [[[ 1.60552457e-01  4.52120036e-01  8.68685097e-02]\n",
      "   [ 1.36580661e-01  3.51231813e-01  4.07152288e-02]\n",
      "   [ 1.22294292e-01  2.38738194e-01  5.10376785e-03]\n",
      "   [ 1.06645040e-01  3.33298951e-01  4.77101058e-02]\n",
      "   [ 4.66236502e-01  8.37392032e-01  6.44988060e-01]]\n",
      "\n",
      "  [[-6.15327340e-03  1.61046192e-01 -1.86594743e-02]\n",
      "   [ 7.08694980e-02  2.19024494e-01  3.43208131e-03]\n",
      "   [ 1.39918432e-01  2.21580088e-01  1.11201562e-01]\n",
      "   [ 3.78884137e-01  5.63450634e-01  3.72919768e-01]\n",
      "   [ 4.82105970e-01  7.00212598e-01  6.00537896e-01]]\n",
      "\n",
      "  [[ 2.68419802e-01  5.80493867e-01  1.91465661e-01]\n",
      "   [ 2.49525174e-01  4.17754263e-01  1.61740705e-01]\n",
      "   [ 2.58214325e-01  3.59356493e-01  2.69921482e-01]\n",
      "   [ 5.65428853e-01  9.02986407e-01  5.17228961e-01]\n",
      "   [ 6.42820299e-01  1.00096750e+00  6.88725889e-01]]\n",
      "\n",
      "  [[ 2.26515755e-01  3.65507424e-01  1.13637514e-01]\n",
      "   [ 3.39113086e-01  4.25750047e-01  3.32774937e-01]\n",
      "   [ 4.39855754e-01  5.36602139e-01  4.76884902e-01]\n",
      "   [ 5.51837802e-01  8.38769197e-01  6.49185002e-01]\n",
      "   [ 4.93611723e-01  7.37981081e-01  4.99509692e-01]]\n",
      "\n",
      "  [[ 2.51850456e-01  2.92819083e-01  1.62342429e-01]\n",
      "   [ 3.23291212e-01  3.63325179e-01  2.90286005e-01]\n",
      "   [ 4.21585977e-01  4.93645102e-01  4.50160444e-01]\n",
      "   [ 4.81423318e-01  6.94995284e-01  4.52377051e-01]\n",
      "   [ 6.34314716e-01  1.08661270e+00  4.55537677e-01]]]\n",
      "\n",
      "\n",
      " [[[ 1.09448180e-01  2.90707618e-01  1.06930630e-02]\n",
      "   [ 6.89834580e-02  1.36262819e-01  1.57242864e-02]\n",
      "   [ 7.50432387e-02  1.25510588e-01  4.72522154e-03]\n",
      "   [ 9.97388363e-02  1.62716448e-01  1.55687053e-02]\n",
      "   [ 3.07078362e-01  5.61813951e-01  7.01510385e-02]]\n",
      "\n",
      "  [[ 5.98808005e-02  1.28605485e-01 -1.44006230e-03]\n",
      "   [ 6.23921491e-02  1.25730217e-01 -2.03769887e-04]\n",
      "   [ 1.68352082e-01  1.97641298e-01  6.96567148e-02]\n",
      "   [ 2.58593917e-01  3.18841487e-01  1.10339709e-01]\n",
      "   [ 3.89942110e-01  5.79047620e-01  1.31289288e-01]]\n",
      "\n",
      "  [[ 4.84281555e-02  1.06038123e-01 -5.89297386e-04]\n",
      "   [ 7.06903264e-02  1.19468354e-01 -1.10695756e-03]\n",
      "   [ 1.05825275e-01  1.29290149e-01  1.08836603e-03]\n",
      "   [ 2.32872501e-01  2.57198691e-01  6.89065903e-02]\n",
      "   [ 3.36506814e-01  4.27121133e-01  1.26473755e-01]]\n",
      "\n",
      "  [[ 5.88663556e-02  1.13128923e-01 -2.89068255e-03]\n",
      "   [ 1.08683579e-01  1.62722290e-01  3.25924903e-02]\n",
      "   [ 1.37637272e-01  1.45603940e-01  2.69604605e-02]\n",
      "   [ 2.36372322e-01  2.64674127e-01  8.00788179e-02]\n",
      "   [ 2.62806863e-01  2.64729351e-01  8.54994953e-02]]\n",
      "\n",
      "  [[ 7.16074333e-02  1.33334562e-01 -6.69799265e-05]\n",
      "   [ 8.46127197e-02  1.49177462e-01  1.59396753e-02]\n",
      "   [ 1.19930170e-01  1.66708976e-01  6.31344393e-02]\n",
      "   [ 1.70090213e-01  2.23446190e-01  8.80678967e-02]\n",
      "   [ 2.40771428e-01  2.98944056e-01  1.31684393e-01]]]], shape=(3, 5, 5, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.6080704 ]\n",
      " [ 0.99900913]\n",
      " [ 1.8344336 ]\n",
      " [ 1.4304495 ]\n",
      " [ 1.7685328 ]\n",
      " [ 0.85856533]\n",
      " [ 1.4005933 ]\n",
      " [-0.22262242]\n",
      " [ 0.56798553]\n",
      " [ 0.8557401 ]\n",
      " [ 0.81402063]\n",
      " [ 0.6391001 ]\n",
      " [ 1.407403  ]\n",
      " [-0.05090621]\n",
      " [ 0.869719  ]\n",
      " [ 1.0018411 ]\n",
      " [ 2.3737931 ]\n",
      " [ 0.38093564]\n",
      " [ 2.07663   ]\n",
      " [ 1.3241735 ]\n",
      " [ 0.44860455]\n",
      " [ 0.30267522]\n",
      " [ 1.6844735 ]\n",
      " [ 0.5106182 ]\n",
      " [ 1.1555223 ]\n",
      " [ 0.70831823]\n",
      " [ 0.67494583]\n",
      " [ 1.0761604 ]\n",
      " [ 0.46757504]\n",
      " [ 0.40568587]\n",
      " [ 0.6309662 ]\n",
      " [ 2.0746613 ]\n",
      " [ 0.89633274]\n",
      " [ 1.5044765 ]\n",
      " [ 1.2436461 ]\n",
      " [ 2.269075  ]\n",
      " [ 1.1827831 ]\n",
      " [ 1.3877659 ]\n",
      " [ 0.00798509]\n",
      " [ 1.9212246 ]\n",
      " [ 0.8036976 ]\n",
      " [ 0.34794423]\n",
      " [ 0.8925686 ]\n",
      " [ 0.97656107]\n",
      " [ 1.4354172 ]\n",
      " [ 2.5693526 ]\n",
      " [ 0.9478569 ]\n",
      " [-0.61177397]\n",
      " [ 0.7143674 ]\n",
      " [ 1.3784261 ]\n",
      " [ 0.7201338 ]\n",
      " [ 0.59859276]\n",
      " [ 0.25763413]\n",
      " [ 1.3438649 ]\n",
      " [ 1.4050474 ]\n",
      " [ 1.5910277 ]\n",
      " [ 1.4370136 ]\n",
      " [ 0.8963461 ]\n",
      " [ 0.89320946]\n",
      " [ 1.5420442 ]\n",
      " [ 3.0089726 ]\n",
      " [ 1.5988655 ]\n",
      " [ 0.07498786]\n",
      " [ 2.2271204 ]], shape=(64, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for inference is 3.3475 sec\n"
     ]
    }
   ],
   "source": [
    "inference(testing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "c8616a11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator_11/dense_block_11/dense_68/kernel:0 [[ 1.04421824e-01  1.62826896e-01 -6.50692955e-02 ... -1.60113964e-02\n",
      "   8.78449455e-02 -6.49436191e-02]\n",
      " [ 4.35370542e-02  6.03674501e-02 -2.23204881e-01 ... -4.61561568e-02\n",
      "   3.26780863e-02 -1.17234230e-01]\n",
      " [-1.49605691e-03 -1.22202225e-01 -2.64721271e-02 ... -1.15404315e-01\n",
      "  -5.03560603e-02 -3.60469073e-02]\n",
      " ...\n",
      " [-3.10842823e-02  1.68469623e-02  5.76655753e-02 ...  6.73484709e-03\n",
      "   1.20996928e-03  8.23529437e-03]\n",
      " [-1.79251321e-02  2.56902073e-04 -3.41315903e-02 ...  1.04296429e-04\n",
      "   6.83364645e-03  3.86595144e-03]\n",
      " [-2.72888411e-02 -3.79072465e-02 -3.89734954e-02 ... -5.98441251e-03\n",
      "   6.52544051e-02  3.57083306e-02]]\n",
      "generator_11/dense_block_11/dense_68/bias:0 [-2.8460745e-05 -1.7617382e-04  9.6550197e-05 ... -3.7512651e-05\n",
      " -8.0961553e-07  1.3375393e-04]\n",
      "generator_11/dense_block_11/batch_normalization_203/gamma:0 [0.49476177 0.762858   0.6209676  ... 0.7114634  0.5913795  1.4854782 ]\n",
      "generator_11/dense_block_11/batch_normalization_203/beta:0 [ 0.3298738   0.35316804  0.04576802 ...  0.32850707  0.09469164\n",
      " -0.10524797]\n",
      "generator_11/dense_block_11/batch_normalization_203/moving_mean:0 [ 4.738195   2.8003962 -7.789136  ... -0.956322   2.9254246 -1.4974267]\n",
      "generator_11/dense_block_11/batch_normalization_203/moving_variance:0 [4.76254   4.2609468 6.0188804 ... 2.4206498 4.2468643 2.712347 ]\n"
     ]
    }
   ],
   "source": [
    "for var in generator.starter.variables:\n",
    "    print(var.name, var.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "53e5d27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_11/conv_block_136/conv2d_136/kernel:0 [[[[-5.93960881e-02 -2.95454621e-01  1.63213491e-01 ...  1.34212049e-02\n",
      "     1.85690090e-01 -3.65044832e-01]\n",
      "   [-2.69940883e-01 -4.83936846e-01  2.93261737e-01 ...  2.50138283e-01\n",
      "    -2.58412927e-01  4.39943314e-01]\n",
      "   [-2.37089887e-01  3.11541796e-01 -7.86949843e-02 ...  2.10212722e-01\n",
      "     5.86252570e-01 -1.32484674e-01]]\n",
      "\n",
      "  [[ 2.93688059e-01  3.39040816e-01  1.81222372e-02 ...  5.93196638e-02\n",
      "     1.04732387e-01 -6.72897771e-02]\n",
      "   [-3.89340013e-01 -2.27928653e-01 -3.93214785e-02 ... -3.32181424e-01\n",
      "    -1.40229151e-01 -2.60800600e-01]\n",
      "   [ 3.64359558e-01 -1.81910336e-01 -2.43829787e-01 ...  1.48140311e-01\n",
      "    -3.28003377e-01  2.57840343e-02]]\n",
      "\n",
      "  [[ 5.18545270e-01 -1.35839179e-01 -8.03554803e-02 ... -3.15286934e-01\n",
      "     2.51228750e-01 -7.69500583e-02]\n",
      "   [ 7.54195452e-02 -3.34208727e-01 -1.59700811e-01 ...  4.27713633e-01\n",
      "     1.70536786e-01  1.00157253e-01]\n",
      "   [ 1.28874974e-02  3.55607897e-01  3.75459135e-01 ...  1.52615532e-01\n",
      "     2.06781477e-01  6.11050092e-02]]]\n",
      "\n",
      "\n",
      " [[[-2.13024437e-01 -3.54730815e-01  4.95434999e-01 ... -5.12038291e-01\n",
      "    -2.51733512e-01  1.58831835e-01]\n",
      "   [-3.40531558e-01  4.89037156e-01  1.14204153e-01 ...  5.27455628e-01\n",
      "     5.38865626e-01  3.24391484e-01]\n",
      "   [ 2.65723050e-01 -2.78283894e-01 -3.17916162e-02 ... -1.56827718e-01\n",
      "    -2.73655206e-01 -1.96544096e-01]]\n",
      "\n",
      "  [[ 4.90031809e-01  2.46581227e-01  4.58956897e-01 ...  1.52436048e-01\n",
      "     1.52107090e-01  1.93003058e-01]\n",
      "   [-4.27262545e-01 -3.12638074e-01  4.30615842e-01 ... -8.88591707e-02\n",
      "     2.84542531e-01  5.11820316e-01]\n",
      "   [ 2.57872492e-01  1.75731137e-01  1.50011721e-04 ... -4.29396361e-01\n",
      "    -1.91783100e-01 -3.83225195e-02]]\n",
      "\n",
      "  [[ 7.44960830e-02  1.25272498e-01  5.69822073e-01 ...  2.27555811e-01\n",
      "     4.81996574e-02  2.97183722e-01]\n",
      "   [-1.22749202e-01  1.38475731e-01 -5.17028868e-01 ... -8.39407966e-02\n",
      "     3.31031024e-01 -5.11664510e-01]\n",
      "   [ 4.80534285e-02 -3.23024064e-01  1.76956251e-01 ...  6.89217299e-02\n",
      "     3.33702952e-01  8.64392370e-02]]]\n",
      "\n",
      "\n",
      " [[[ 3.06263287e-03 -2.63673425e-01  2.15889364e-01 ... -3.84900644e-02\n",
      "     5.65829575e-01 -3.67602780e-02]\n",
      "   [ 1.61518410e-01  2.56376952e-01 -8.22689664e-03 ... -3.55440795e-01\n",
      "     1.23779560e-02 -9.54414979e-02]\n",
      "   [-4.83141363e-01  3.35363120e-01 -2.79582709e-01 ...  1.95272252e-01\n",
      "     5.76463699e-01 -2.47228473e-01]]\n",
      "\n",
      "  [[-2.72588199e-03 -2.41342023e-01 -3.90831903e-02 ...  1.57348856e-01\n",
      "    -1.57273367e-01  7.46059567e-02]\n",
      "   [ 1.19862773e-01  4.61978406e-01  2.13240966e-01 ...  3.75262767e-01\n",
      "     1.07897654e-01 -7.17628561e-03]\n",
      "   [ 3.84049444e-03  9.35929194e-02  4.26779866e-01 ... -3.09732229e-01\n",
      "    -1.98371068e-01  4.21053082e-01]]\n",
      "\n",
      "  [[ 5.52979596e-02 -2.84828484e-01  1.43345639e-01 ... -5.48314750e-02\n",
      "    -4.97521758e-01 -2.46432289e-01]\n",
      "   [-4.98193055e-02  7.29037151e-02  1.03932992e-02 ... -2.78339535e-01\n",
      "    -1.32078752e-02  2.47330129e-01]\n",
      "   [-9.26997289e-02  3.17715824e-01 -1.60054937e-01 ... -3.94030541e-01\n",
      "    -4.69620645e-01  5.02446949e-01]]]]\n",
      "discriminator_11/conv_block_136/conv2d_136/bias:0 [ 3.54593823e-04  1.27224965e-04  8.74183315e-05 -1.70459657e-03\n",
      " -1.20653783e-03 -1.81997055e-03  2.68882941e-05  2.53196131e-03\n",
      "  1.05473725e-03 -9.37948411e-04 -4.26277169e-04  2.43139826e-03\n",
      " -1.41677458e-03 -3.04028799e-04 -1.89665682e-03 -4.26554761e-04\n",
      "  1.07455952e-03  8.54546088e-04  2.73186772e-04  4.97229456e-04\n",
      " -4.53569024e-04 -3.53665702e-04  4.14161514e-05  5.40440786e-04\n",
      " -1.83098356e-03  1.58374768e-03  5.58052925e-05  2.12544482e-03\n",
      "  1.65430456e-03 -1.97317335e-04 -1.69627054e-03 -1.68656919e-03\n",
      "  9.06738685e-04  2.75684230e-04 -1.82713917e-03 -1.92620922e-04\n",
      "  1.83790980e-04  9.43920109e-04  1.08370486e-05  9.56886914e-04\n",
      "  1.57299114e-03  1.21252856e-03 -3.27981921e-04  6.22767329e-05\n",
      " -9.86130908e-04  1.19895951e-04 -1.66669383e-03  9.21635146e-05\n",
      " -2.05980241e-03 -4.77100402e-04 -1.40477758e-04  6.11115247e-04\n",
      "  6.90996530e-04 -1.48868142e-03 -1.04245415e-03  5.39509812e-04\n",
      "  6.56304357e-04  1.42708735e-03 -1.22027681e-03  5.52701415e-04\n",
      "  1.48226565e-03 -1.24468002e-03 -4.47835744e-04 -1.03144464e-03\n",
      " -1.03854900e-03 -7.70424376e-04  2.38160093e-04 -3.20902647e-04\n",
      " -5.15515276e-04 -9.15156794e-04 -1.02034118e-03  1.24479400e-03\n",
      " -3.50412360e-04  2.02849624e-03  1.05061533e-03  2.02530704e-04\n",
      " -2.49195087e-04 -1.76802336e-03  5.15552005e-04 -3.41109670e-04\n",
      " -7.31829088e-04  7.19728414e-04  1.31156261e-03 -1.11736765e-03\n",
      " -9.20841776e-05 -2.19780137e-04 -1.28409325e-03  1.64112286e-03\n",
      "  4.98396985e-04 -4.93444968e-04  4.12445283e-04 -1.52235746e-03\n",
      "  1.53596804e-03 -3.22768372e-03  2.16891244e-03  7.39472162e-04\n",
      "  2.62149703e-03 -8.71412456e-04  2.67581199e-03 -7.38904113e-04\n",
      "  4.35070047e-04 -4.98301059e-04  4.76927198e-05 -4.15821327e-04\n",
      "  4.13623260e-04  1.14701281e-03 -2.88235824e-05  5.61270455e-04\n",
      " -6.59101817e-04 -1.47955597e-03  3.81432474e-04 -6.32744865e-04\n",
      " -1.46180461e-03  2.14123796e-03 -6.80743135e-04 -9.18627018e-04\n",
      "  1.52052636e-03 -4.06547129e-04 -1.26683433e-03 -9.79192089e-04\n",
      "  2.08873302e-03 -6.23885891e-04  1.77294447e-03  7.93378422e-05\n",
      " -5.28994133e-04  1.19742705e-03  2.78754189e-04 -4.90118633e-04\n",
      "  2.22404255e-03 -1.85697121e-04  9.57400887e-04  3.14812548e-03\n",
      "  2.30792910e-04  4.62847966e-04  1.06023939e-03 -3.63086537e-03\n",
      "  6.61683680e-06  3.24721652e-04  5.51008969e-04 -9.06472676e-04\n",
      "  3.58691468e-04 -1.76145299e-03  3.51299459e-05 -2.29945476e-03\n",
      " -1.29587215e-03  9.08579095e-04  6.58108329e-04 -2.19892268e-03\n",
      "  6.67354383e-04  6.71507849e-04  9.88230808e-04 -1.29431055e-03\n",
      "  3.94183066e-04 -6.69879257e-04 -4.00993769e-04 -9.09614144e-04\n",
      "  5.09981182e-04 -1.04501226e-03 -1.68015994e-03 -4.45608312e-04\n",
      " -7.13172776e-04  6.31617877e-05 -5.22255956e-04  1.09779066e-03\n",
      " -4.66908590e-04 -9.01850872e-05  8.46147013e-04 -4.34566318e-04\n",
      "  9.54574498e-04 -6.82369515e-04 -2.12203781e-03  1.25511855e-04\n",
      "  9.84799117e-04 -1.37654296e-03  3.37163662e-03  1.39248639e-03\n",
      " -6.35790202e-05  1.86797522e-03  1.34418462e-03  1.59874698e-03\n",
      "  1.08073081e-03 -8.35358340e-04 -5.67758339e-04  3.81840597e-04\n",
      "  1.45053538e-03  1.34602611e-04  1.01893698e-03 -5.60062646e-04\n",
      " -3.32142925e-04  5.42370311e-04  1.74867990e-03 -1.28665695e-03\n",
      " -2.28784024e-03 -1.95821887e-03  2.96600803e-04  1.04138348e-03\n",
      "  8.17309119e-05 -3.23561020e-04  1.39355741e-03 -7.27736682e-04\n",
      "  1.35815970e-03  3.73964285e-04  2.57278385e-04  7.73343432e-04\n",
      "  5.70040080e-04  8.06126336e-04  2.97975214e-03  7.30615691e-04\n",
      "  7.93417275e-04 -1.06191647e-03 -3.54148797e-04 -5.11089980e-04\n",
      " -1.63602014e-03  2.24814564e-03  1.71409198e-03  5.88460593e-04\n",
      " -1.02823286e-03  5.66051458e-04 -1.80348681e-04 -2.88206065e-04\n",
      "  1.55905704e-03  2.30256250e-04  6.31115050e-04  2.35366612e-03\n",
      " -1.45191429e-04  9.22501320e-04  3.39821819e-03 -4.28244566e-05\n",
      "  1.23082427e-04  9.87489591e-04  2.34803403e-04  4.38903196e-04\n",
      " -2.92967277e-04 -5.46130992e-04 -1.47925050e-04  1.83776574e-04\n",
      " -6.12018222e-04 -4.69237537e-04  3.29427276e-04 -1.44852581e-03\n",
      " -1.07055658e-03  3.69265588e-04  2.25395488e-04  1.28244748e-03\n",
      "  4.78232745e-03  3.58251680e-04 -6.59160956e-04  2.76972842e-03\n",
      "  1.40205855e-04  4.19762888e-04 -1.25175953e-04 -1.07421947e-03\n",
      " -6.77646196e-04  1.89747883e-03  6.33040210e-04 -7.10003253e-04\n",
      " -5.03429037e-04 -1.51834730e-03  2.14734511e-03 -5.71417040e-04\n",
      "  3.29705700e-03 -1.21874339e-03  1.10931939e-03  1.10878516e-03\n",
      "  8.36187901e-05 -4.01087163e-04  1.57754123e-03  1.91868294e-03\n",
      " -2.07574572e-03  1.01966574e-03  1.05780235e-03 -3.35976911e-05\n",
      " -3.17719532e-04 -1.57428512e-04  3.60271049e-04  4.76297282e-04\n",
      "  1.09461905e-03  7.06981751e-04 -2.12488137e-03  1.90900511e-03\n",
      "  2.23739562e-03  3.09707684e-04  1.05477590e-03  2.42161608e-04\n",
      "  1.51328486e-03 -1.41023984e-03  2.95234669e-04 -4.36256436e-04\n",
      " -2.09733332e-03 -6.19740422e-06 -6.40496262e-04  7.51588552e-04\n",
      "  4.29838001e-05 -2.51373276e-03  1.23251474e-03  1.10125740e-03\n",
      " -4.83030191e-04 -3.90459230e-04 -1.96798868e-03 -1.99672781e-04\n",
      "  4.15786490e-04  7.33940687e-04  7.13721209e-04 -1.88142329e-03\n",
      "  1.51578395e-04  2.70155124e-06  7.46234437e-04  6.52453455e-04\n",
      " -2.28859275e-03 -6.61845144e-04 -4.22862475e-04  1.47858448e-03\n",
      "  1.20669392e-04 -3.37525475e-04  4.67770005e-04  7.87983940e-04\n",
      "  8.54708371e-04  5.46379481e-04 -2.75645900e-04  1.70991209e-03\n",
      " -3.99819401e-04 -1.37795345e-03 -6.19848084e-04 -2.00875103e-03\n",
      "  7.18383701e-04  9.17482030e-05 -1.05115224e-03  1.68467895e-03\n",
      " -5.27715893e-04  4.88640915e-04 -1.38023240e-03  6.30452763e-04\n",
      " -1.15838775e-03 -6.07180758e-04  2.72739911e-04 -1.00540987e-03\n",
      "  1.23409482e-04 -4.69261955e-04  7.98083202e-05 -2.32967292e-03\n",
      "  3.09116812e-03  1.10472192e-03 -3.12049931e-04  1.18892174e-03\n",
      "  2.85724434e-03 -3.93980136e-03  9.73752118e-04 -2.51130876e-03\n",
      " -1.56027474e-03  3.89248366e-04  9.32977651e-04  2.03293026e-03\n",
      " -1.53567654e-03  2.53137725e-04 -3.70796700e-03  2.33015191e-04\n",
      " -1.80549372e-03 -1.34228007e-03 -9.65318177e-04  2.23592418e-04\n",
      "  1.59621413e-04 -1.19180791e-03 -8.63760186e-04  4.86218123e-05\n",
      "  1.23479636e-03  3.30126932e-04 -7.80688133e-05  1.25383085e-04\n",
      " -2.59971782e-03 -2.85541592e-03 -3.49343335e-03  1.57507474e-03\n",
      " -6.91579131e-04  3.96104188e-05 -3.62404389e-04  1.30301109e-03\n",
      " -5.49029966e-04 -1.10958901e-03 -1.06895364e-04 -1.82276970e-04\n",
      "  4.28285166e-05 -7.39001262e-04 -1.86207856e-03 -1.66238693e-03\n",
      "  1.74962159e-03 -8.38209351e-04 -2.91097956e-03  9.14086413e-04\n",
      " -3.01635754e-03 -9.20530467e-04  2.17407430e-03 -3.22767242e-04\n",
      "  1.83422933e-03 -1.17610430e-03 -1.95254252e-04  4.45307378e-04\n",
      "  1.43604702e-04 -1.34175620e-03 -2.27226550e-03 -4.68794460e-04\n",
      " -4.43048833e-04  9.41717648e-04 -6.00983913e-04  2.39701316e-04\n",
      "  5.04581723e-04  5.44922194e-04 -1.44064805e-04 -6.18307095e-05\n",
      " -4.39750293e-04 -7.06588849e-04 -8.20467132e-04  1.22217403e-03\n",
      "  6.95399882e-04  1.28387904e-03  7.05083075e-04 -1.02095236e-03\n",
      "  8.43949529e-05  1.58537040e-03 -6.99315453e-04  2.42351531e-03\n",
      "  7.04626364e-05  1.42905314e-03 -1.66592043e-04  1.38021342e-03\n",
      " -9.98136937e-04 -1.18488888e-03  7.99469417e-04  8.14234838e-04\n",
      "  7.38488685e-04  2.66829360e-04  4.30810760e-04  1.05663866e-03\n",
      " -4.17771633e-04  2.25544263e-05 -6.73390925e-04  1.56595779e-04\n",
      "  4.32099274e-04 -8.27235344e-04  2.15405016e-03 -2.25659664e-04\n",
      " -1.17648684e-03 -6.18862454e-04  7.20024167e-04 -1.48160360e-03\n",
      " -1.19693857e-03 -1.32018584e-03 -3.89516354e-03  1.64909405e-04\n",
      "  1.02023967e-03 -5.55739280e-05 -1.84539449e-03  2.54956353e-03\n",
      " -1.00967602e-03  5.92513068e-04  6.92336645e-04  1.75071138e-04\n",
      "  1.30639633e-03  4.45411599e-04  3.15534277e-03  8.24742368e-04\n",
      " -1.44166220e-03  1.94437534e-03 -2.52894301e-04  2.49561941e-04\n",
      "  2.52291141e-03 -1.22456008e-03  1.01499807e-03  3.64732085e-04\n",
      " -1.37687323e-03 -1.19682588e-03 -2.34547351e-03 -9.02202097e-04\n",
      "  6.77800039e-04 -7.46656093e-04  2.80260079e-04  1.69297738e-03\n",
      "  1.89663225e-03  1.99263240e-03  2.87736097e-04  3.21819331e-04\n",
      "  1.79779332e-03  1.83583808e-03  3.82928818e-04  9.76089330e-04\n",
      "  1.76193879e-03  2.27565016e-03 -1.80740433e-03 -2.49184854e-03\n",
      "  1.12864561e-03  2.77337560e-04 -1.71716048e-04  2.06744182e-03\n",
      " -1.05429336e-03  8.96310550e-04  5.31148573e-04 -5.53560327e-04\n",
      "  2.21437728e-03 -2.61562644e-04 -3.74937285e-04  5.44602226e-04\n",
      "  2.49785400e-04  1.57738884e-03  9.26726440e-04 -3.14269346e-05\n",
      "  2.58160732e-03 -1.24050805e-03  2.67749798e-04 -2.00553890e-03\n",
      "  1.98194597e-04  2.59797717e-03 -1.14104754e-04  1.44577105e-04]\n",
      "discriminator_11/conv_block_136/batch_normalization_212/gamma:0 [0.9819512  1.0359445  0.9300799  1.0698755  1.0118383  1.0461069\n",
      " 0.9502163  1.0075059  0.9386004  1.008423   0.9546457  1.065562\n",
      " 1.0380167  1.0201304  1.0055875  0.99236614 0.9670755  0.9670262\n",
      " 0.96613353 0.98113006 0.96395713 1.0408864  1.0140254  0.97506356\n",
      " 0.96797866 1.0719283  1.0745577  0.97274196 0.99176574 1.0082115\n",
      " 1.0517802  1.0073546  0.96612346 1.0728681  0.9927307  0.9994072\n",
      " 1.0402607  0.9898221  1.0098544  1.0555471  0.9805454  1.0831671\n",
      " 1.0076725  0.9945625  0.9659094  1.0369902  1.0367516  1.0331991\n",
      " 0.98257965 0.9866699  1.0373923  0.9212168  0.9244756  1.0700403\n",
      " 1.0214862  1.0543361  1.0129787  0.9877636  1.0188763  1.0108149\n",
      " 0.99607617 0.96048564 0.94312084 1.0234661  1.0136204  0.99460274\n",
      " 1.0086676  1.0046765  1.0151752  0.99090296 0.9780723  1.0230777\n",
      " 1.070989   1.0972604  1.0251493  1.0277787  1.0385814  1.0057814\n",
      " 1.0522648  1.0257729  0.9394778  1.0041841  0.9816608  0.9550933\n",
      " 0.9674441  1.0269881  0.9336725  1.0792027  1.0588714  0.9835268\n",
      " 1.0019785  0.9747888  1.0289853  0.9883197  1.0791721  0.9786282\n",
      " 1.0604093  1.0492979  1.0676973  1.020701   0.9404415  0.962563\n",
      " 0.9556558  1.0353625  1.030215   1.0255467  1.0205829  1.0026673\n",
      " 1.034776   1.0394659  0.92027795 1.0020665  0.97381604 1.0360498\n",
      " 1.0857424  0.9678672  0.9493275  0.99814636 1.0006737  1.0018259\n",
      " 0.9519928  1.0067307  1.0526837  1.0189043  0.9775004  0.9733396\n",
      " 0.97223806 1.0482688  0.95557594 0.98620015 0.99979    1.0721862\n",
      " 0.9259292  0.9747162  0.95267797 1.044913   1.0014036  0.96684897\n",
      " 0.95292294 1.01979    1.0395089  0.97106194 1.0507357  1.038686\n",
      " 1.057799   0.99685436 0.9926236  1.0895488  1.059058   1.042563\n",
      " 1.0235695  0.9893592  0.99489963 0.9792952  0.9664208  1.0604684\n",
      " 0.9629224  1.019558   0.98192847 1.0671834  1.0600697  0.9986637\n",
      " 0.95710427 0.96024454 1.0115048  0.96865815 0.97861654 0.9917995\n",
      " 1.0599949  1.0840907  1.0189891  0.98795396 0.9103284  1.0188134\n",
      " 0.99433345 0.9745619  1.159319   0.9983356  1.0032542  1.1607443\n",
      " 1.0645642  0.9883436  0.9570995  0.9266725  0.92532706 1.0562177\n",
      " 0.94858557 1.0228435  0.9338955  0.99952686 0.99313897 0.9497363\n",
      " 0.9979792  0.9571007  1.0444295  1.027789   0.9819508  0.9286982\n",
      " 0.9640533  1.0088353  1.0435652  0.9498122  0.9250478  0.99210864\n",
      " 0.9714531  1.069033   1.0046839  0.97495383 0.97524333 1.0131248\n",
      " 1.0034056  1.1056689  0.9814051  0.99772847 0.99885476 0.97694486\n",
      " 0.9926794  0.98986596 1.1249918  0.985347   1.003208   0.99302727\n",
      " 1.0329604  0.9747483  1.0281701  0.97781515 0.9935947  0.9650863\n",
      " 0.9895863  1.0788606  0.9745254  0.99582547 1.0278795  0.98477554\n",
      " 1.0238338  0.9999563  0.98480594 1.0538083  0.9712903  0.9983139\n",
      " 1.0311538  0.984071   0.9672158  0.9525565  1.173595   0.9852014\n",
      " 0.95542115 1.0085412  0.9862798  1.0036343  0.9570966  1.0163603\n",
      " 0.90826654 0.9838187  1.1196597  1.0390283  0.9933134  0.9661751\n",
      " 0.98332095 1.0305465  1.038209   0.9911619  1.0422839  0.97650796\n",
      " 0.97813237 0.99550706 0.998971   0.97114396 1.0738059  0.9793264\n",
      " 0.9657281  0.97848463 0.9860037  1.0160909  1.0118814  0.9705764\n",
      " 0.9953656  1.0235687  1.0603584  0.9400097  1.1567576  0.94314945\n",
      " 1.0528587  1.0046165  1.0341452  0.9309488  1.1063634  0.95793784\n",
      " 0.9983958  1.001993   0.97577137 1.054179   1.0337394  1.0418981\n",
      " 0.9878465  0.92378104 0.94617707 0.94023645 0.98873377 1.0695078\n",
      " 1.0160958  0.98726344 0.9836439  1.0326425  1.0159258  1.0173172\n",
      " 1.0068475  0.990139   1.0931374  1.0140758  0.9586561  1.0190073\n",
      " 0.9833201  0.96701723 0.99685234 1.0049701  1.0023274  0.9619731\n",
      " 1.0108026  0.98326427 1.0103168  1.0338976  1.0441352  1.08004\n",
      " 1.0365889  0.9650639  0.97450596 0.9909874  1.0007079  1.102049\n",
      " 1.0690327  0.9979855  0.9922662  1.0053499  0.9742138  1.0624638\n",
      " 0.9933991  1.0610828  0.94064    1.1007019  1.0229535  1.0084534\n",
      " 0.9986695  0.9495419  0.89571613 1.0258378  0.9296893  1.1001946\n",
      " 1.0306009  1.0598236  0.9734341  0.9609694  0.98511946 1.0733945\n",
      " 1.0163915  0.97923833 0.9958733  1.011598   0.9941736  0.9705248\n",
      " 0.9986277  1.084184   0.9709583  0.9167848  1.0121727  1.0894365\n",
      " 1.0495155  0.9728547  1.0303756  1.0328428  1.069042   0.9977608\n",
      " 0.96586245 1.0206093  0.97327614 0.96359843 1.0414484  1.0787386\n",
      " 0.9839069  1.0005589  0.951938   1.0138944  0.9494941  1.0359788\n",
      " 0.9894593  1.0459342  1.0721197  0.9931676  1.0689199  0.9983979\n",
      " 0.92739785 0.94785833 0.96324176 0.9953669  1.0062708  1.0110052\n",
      " 0.97037137 1.0078453  0.9384607  1.0080174  1.0165765  0.9791795\n",
      " 1.0055841  0.9921653  0.95850587 1.0209571  1.0008515  0.9583172\n",
      " 1.0330943  1.0086359  1.0094162  1.0571551  1.030237   1.0369523\n",
      " 0.96366304 1.0126126  0.93300444 1.0356678  1.0004224  0.9092825\n",
      " 0.99261284 1.0073924  1.012224   1.0385622  0.97729594 1.0053376\n",
      " 1.0318413  1.0484571  0.9770567  0.98678243 0.9299248  0.9719548\n",
      " 1.0878909  1.0221502  1.0045459  1.0355924  0.9623234  0.9887768\n",
      " 0.96184313 0.9611953  0.9986642  1.0539045  0.9831621  1.0091611\n",
      " 1.1108356  0.9767443  1.0203029  1.0222167  0.95785403 1.0276909\n",
      " 1.0077941  1.0156959  1.0580852  0.9312048  0.9283012  0.95398146\n",
      " 0.99040854 1.0140393  1.0524834  1.0000439  0.9737847  0.98378396\n",
      " 1.0045645  0.9817684  1.0101404  1.072849   1.001563   0.9892049\n",
      " 0.97713894 1.0276557  0.9820522  1.03908    1.0900893  1.009912\n",
      " 1.0273933  1.0654526  0.953443   1.0392547  0.9328351  0.96856624\n",
      " 0.98803794 0.9525107  1.019192   0.95927274 0.96736634 1.082894\n",
      " 1.0231777  1.0290079  1.0763491  1.0227588  1.0027702  1.0298581\n",
      " 0.97197264 0.9678976  0.8892515  1.0004303  1.0833188  1.0351574\n",
      " 0.9479731  0.95777875 0.9946504  1.1624254  0.9912406  0.9485311\n",
      " 0.9975383  0.9731349  1.0073328  1.0308428  0.9966835  1.0522046\n",
      " 1.0318873  0.9772419 ]\n",
      "discriminator_11/conv_block_136/batch_normalization_212/beta:0 [-1.60941649e-02 -9.85900871e-03 -5.17407134e-02  1.08385667e-01\n",
      "  3.71233723e-03  2.99598537e-02 -4.13362235e-02  1.20672118e-02\n",
      " -5.87357171e-02  2.28825416e-02 -1.86720267e-02  6.46102875e-02\n",
      " -4.66312729e-02 -6.96532428e-02 -1.22790365e-02 -4.69694212e-02\n",
      " -3.50555852e-02 -8.94054945e-04 -7.26743601e-03 -8.12515244e-03\n",
      " -6.18177317e-02 -8.60773306e-03  6.26166984e-02 -5.05843619e-03\n",
      " -1.56914629e-02  4.22130227e-02  4.18016016e-02 -4.09297682e-02\n",
      " -1.14439661e-02 -4.19778600e-02  1.11455210e-01 -3.75142992e-02\n",
      " -3.21090445e-02  6.41803071e-02  2.06679273e-02  5.27842948e-03\n",
      "  2.52275560e-02  1.08654415e-02 -2.54577417e-02  4.52871099e-02\n",
      " -2.41999216e-02  1.71677954e-02  5.15369093e-03 -6.75300462e-03\n",
      "  2.41622105e-02  9.03095379e-02  1.22639071e-03  5.31862117e-02\n",
      " -2.00633332e-02 -7.89547618e-03  4.30215150e-02 -6.45757765e-02\n",
      " -3.09154913e-02  3.94468606e-02  1.83445122e-02  9.17069986e-02\n",
      "  7.17918575e-02 -1.38448989e-02 -4.53029061e-03  6.57217875e-02\n",
      " -1.05202198e-02 -1.87191553e-02 -2.57878862e-02  4.12174836e-02\n",
      " -1.59670617e-02  4.98584611e-03  2.70557646e-02  6.73578903e-02\n",
      "  3.28843780e-02 -6.88762451e-03  2.14098878e-02  8.59909598e-03\n",
      "  6.57009259e-02  1.26640387e-02  6.19437844e-02  3.15212235e-02\n",
      "  3.40479426e-02  1.58166736e-02  4.36519869e-02  7.21819922e-02\n",
      " -5.42181358e-02 -5.89645952e-02 -3.86789651e-03 -7.11443499e-02\n",
      " -2.34777629e-02 -7.56499544e-03 -1.71315614e-02  1.06573462e-01\n",
      "  1.38344383e-02  1.08193215e-02 -4.97115310e-03  2.24750452e-02\n",
      " -4.62596631e-03  3.20595503e-02  4.84677218e-02 -4.80849072e-02\n",
      "  9.63872895e-02  2.44376548e-02  5.56761064e-02  5.66523112e-02\n",
      "  1.10011520e-02 -5.69673628e-02 -6.73503801e-02 -6.92106597e-03\n",
      "  6.51015565e-02  1.74050052e-02 -7.99155980e-03 -3.34406756e-02\n",
      "  3.75595018e-02  4.49850969e-02 -7.68155754e-02 -1.40058910e-04\n",
      " -1.84677877e-02  3.07960976e-02  4.73474748e-02 -4.24055662e-03\n",
      " -5.68538159e-02 -1.55833382e-02  2.20023338e-02  3.55940051e-02\n",
      " -1.48001043e-02  4.76911524e-03  3.19117382e-02 -3.49716060e-02\n",
      " -1.37575278e-02  1.22530013e-02 -2.29193699e-02  1.30685056e-02\n",
      "  1.66987740e-02 -1.31015237e-02  9.75785218e-03  7.77093247e-02\n",
      " -5.59323356e-02  2.69339010e-02 -4.67071831e-02  1.16976656e-01\n",
      "  4.28777916e-04  6.13451842e-03 -1.55077921e-03  1.07842013e-02\n",
      "  3.89827974e-02 -3.85269523e-02  3.09105348e-02  7.12206960e-02\n",
      "  1.09376304e-01  3.14922854e-02  2.01852228e-02 -5.76752517e-03\n",
      "  6.06448166e-02  3.02265286e-02  1.35673895e-01  8.38209018e-02\n",
      "  3.71732516e-03 -3.15362290e-02 -5.50406575e-02  1.22680321e-01\n",
      "  7.44886650e-03  3.99014167e-03 -3.61192450e-02  1.73961353e-02\n",
      "  1.79613363e-02 -2.37824377e-02 -8.51887837e-03  3.11903730e-02\n",
      " -2.71866797e-03 -3.00156251e-02 -1.49272010e-02  6.33795038e-02\n",
      "  4.09810543e-02  9.24206600e-02 -1.20094442e-03  9.24446248e-03\n",
      " -2.69004442e-02  1.89033505e-02 -1.37092592e-02 -1.58616174e-02\n",
      "  5.71795888e-02  2.17041746e-02  5.61323715e-04  3.78122240e-01\n",
      "  3.73313352e-02  1.09836623e-01 -3.50256041e-02 -5.68667836e-02\n",
      " -5.16676679e-02  7.67965708e-03 -3.13531165e-03 -3.85635234e-02\n",
      " -2.72728372e-02 -2.28644572e-02 -1.75822191e-02  4.87090740e-03\n",
      "  2.53985468e-02 -2.42774412e-02  3.97313908e-02  1.47828916e-02\n",
      "  1.13053015e-03 -2.02780999e-02 -1.42370509e-02  1.58546008e-02\n",
      "  2.85322778e-02 -4.50221226e-02 -2.31855679e-02  6.45405194e-03\n",
      "  4.58958596e-02  2.80578230e-02 -7.45756254e-02 -6.66826777e-03\n",
      "  1.27955647e-02  1.73646286e-02  4.57008444e-02  8.86403173e-02\n",
      "  1.47269340e-02  1.52337812e-02  2.25061234e-02 -5.92014678e-02\n",
      "  1.38554256e-02 -1.71558056e-02  1.03188612e-01 -2.37690605e-04\n",
      "  3.94981690e-02  5.30900259e-04  2.94871163e-03  2.74779019e-03\n",
      "  3.82818580e-02  1.34681084e-03 -7.62358960e-03 -3.01475897e-02\n",
      " -1.50957052e-03  5.71030639e-02 -3.40405963e-02 -2.71638036e-02\n",
      "  3.05833202e-02 -2.44868994e-02  3.11548747e-02 -2.98518557e-02\n",
      " -2.01511849e-03  1.23506144e-01 -6.40034769e-03  1.55031858e-02\n",
      " -3.56562547e-02 -2.93333139e-02  8.92333779e-03 -7.45703047e-03\n",
      "  1.39724389e-01  1.37401754e-02  2.58248253e-03  2.85832547e-02\n",
      " -3.29530947e-02 -7.30712386e-03 -3.04575097e-02  1.49774533e-02\n",
      " -6.23196810e-02  1.61653887e-02  1.83512300e-01 -5.20380884e-02\n",
      " -8.82732868e-03  2.22219503e-03  1.86131559e-02  3.61019745e-02\n",
      "  4.74142320e-02  5.60718328e-02  3.10330354e-02  6.31269859e-03\n",
      " -1.76451318e-02  2.94618886e-02  1.89321600e-02 -4.28265110e-02\n",
      "  8.65028799e-02 -1.49255544e-02  1.54435290e-02  4.25323546e-02\n",
      " -5.18289246e-02 -1.84958079e-03  3.00457538e-03 -1.54953571e-02\n",
      "  3.24555747e-02  6.17564954e-02  1.98647529e-02 -5.41050248e-02\n",
      "  1.15264438e-01 -5.90264052e-03  4.33058217e-02  3.83485854e-02\n",
      "  6.46361411e-02 -3.72371934e-02  8.56382921e-02 -4.84368764e-03\n",
      "  2.92135719e-02 -2.16122158e-02 -8.81654769e-03  7.70580396e-02\n",
      "  8.40251893e-02  5.17058969e-02 -5.07773384e-02 -2.30142870e-03\n",
      " -6.73108082e-03 -7.54019292e-03 -5.63662015e-02  2.33040377e-02\n",
      " -1.31919906e-02 -1.26329632e-02  3.03460490e-02  3.50943878e-02\n",
      " -2.34506954e-03  6.04732335e-02 -5.62451407e-02 -5.72486669e-02\n",
      "  8.11293721e-02  2.84321550e-02 -3.07049863e-02  3.49686965e-02\n",
      "  3.21730599e-02 -1.19106611e-02  1.31819677e-03 -3.91870625e-02\n",
      "  1.13791293e-02 -6.27682433e-02  2.63225306e-02  6.14512293e-03\n",
      "  2.52033342e-02  7.65701160e-02  8.46317112e-02  9.05663297e-02\n",
      "  9.56730917e-02 -5.55544905e-03  1.49625195e-02 -2.51702778e-02\n",
      " -2.45280564e-02  1.32276595e-01  1.58641152e-02  1.28301298e-02\n",
      "  4.16587777e-02  9.98829007e-02 -3.18007953e-02  1.39327884e-01\n",
      "  1.88712031e-02  3.57747898e-02 -1.00501645e-02  9.13351998e-02\n",
      " -1.67052299e-02 -4.05948386e-02  3.29883257e-03 -1.42726703e-02\n",
      "  3.07207219e-02 -3.00283823e-03 -4.82814386e-02  1.82706445e-01\n",
      "  2.59676744e-04 -6.00813329e-03 -4.04797820e-03 -1.63124446e-02\n",
      "  2.46121064e-02  9.33562443e-02  5.13962656e-02 -1.57982465e-02\n",
      "  8.56659636e-02  3.94767746e-02  3.69577482e-02  3.16158906e-02\n",
      " -1.89022031e-02  4.22084220e-02 -1.99891031e-02 -3.94073948e-02\n",
      "  4.06634947e-03  1.93522334e-01  1.07631877e-01  7.72580598e-03\n",
      "  4.40321211e-03  7.35275298e-02  7.18255937e-02  6.18124148e-03\n",
      "  1.51074510e-02 -2.77559040e-03 -9.84463654e-03  4.90540219e-03\n",
      "  1.60594080e-02  1.58853516e-01 -6.54883236e-02  2.42965985e-02\n",
      " -5.86829446e-02  7.31385255e-04 -1.40808411e-02 -1.10643758e-02\n",
      " -1.42991561e-02  3.81976478e-02  5.33827879e-02  2.49085780e-02\n",
      "  2.39992477e-02 -1.83316171e-02 -8.90121795e-03 -5.40565103e-02\n",
      " -2.52805259e-02  1.40329758e-02  2.70995293e-02  2.53621303e-02\n",
      " -3.70234884e-02  2.83212643e-02 -3.32455263e-02 -1.58801284e-02\n",
      "  2.67944746e-02  8.04691855e-03  1.18563639e-03 -3.59981693e-02\n",
      " -2.54167952e-02  5.00227101e-02  3.06950305e-02 -1.19404111e-03\n",
      "  1.97627563e-02 -6.99919462e-03 -1.89003199e-02  6.32523671e-02\n",
      "  1.49413208e-02  7.41433576e-02  1.76760051e-02  2.22254489e-02\n",
      " -5.33012562e-02  6.89928308e-02  2.46882602e-03 -3.64511088e-02\n",
      " -4.32698987e-03 -1.96345113e-02 -3.00739482e-02  4.32402901e-02\n",
      "  1.32059976e-02 -1.29853720e-02  1.31308967e-02  1.99130863e-01\n",
      " -1.14930542e-02  2.42900923e-02 -3.55204456e-02  1.14154918e-02\n",
      "  1.33110732e-01  5.21092676e-02  5.89475688e-03  3.98725569e-02\n",
      " -4.18101102e-02 -1.77490711e-02  9.88104474e-03 -6.17745854e-02\n",
      " -9.55882948e-03  5.24290949e-02 -3.18002291e-02  3.01739648e-02\n",
      "  1.99828610e-01  4.57668044e-02 -1.60067342e-02  1.36988815e-02\n",
      " -3.62147801e-02  1.65211409e-02  4.27758433e-02  1.79964025e-02\n",
      " -2.27845535e-02 -1.02962285e-01 -5.06840646e-02 -2.05951594e-02\n",
      "  2.06378438e-02 -9.94944572e-03  6.38914779e-02 -1.13013824e-02\n",
      "  3.33231362e-03 -2.17980370e-02  7.74266273e-02 -6.10137638e-03\n",
      " -1.30578047e-02  5.53868003e-02  1.29034454e-02  3.66537422e-02\n",
      " -3.04520223e-02 -1.02309473e-02 -2.58001313e-02 -1.68785534e-03\n",
      "  8.33282396e-02 -3.26918252e-02  6.20958433e-02  1.97172984e-02\n",
      " -6.27835169e-02  1.08934252e-03 -7.59814084e-02  3.07449661e-02\n",
      "  3.78684141e-02 -7.01041222e-02  8.85328501e-02 -4.77767289e-02\n",
      " -2.82111708e-02  5.74724786e-02 -2.91203018e-02  6.85045049e-02\n",
      "  1.05234146e-01  3.25414948e-02  2.11778213e-03  4.46440838e-03\n",
      "  4.77538537e-03 -1.02072842e-02 -3.50037701e-02  4.11735363e-02\n",
      "  8.84744823e-02  3.65344584e-02 -5.91006055e-02 -1.89851131e-02\n",
      " -3.65611305e-03  7.93101862e-02 -1.21427421e-02 -1.22106997e-02\n",
      "  1.12673314e-02  5.12146158e-03  5.25628356e-03  1.75260473e-02\n",
      "  3.75346644e-05  5.21020871e-03  7.49194995e-02  3.97966616e-03]\n",
      "discriminator_11/conv_block_137/conv2d_137/kernel:0 [[[[-0.05409423 -0.02795687  0.02899212 ... -0.09041882 -0.00465689\n",
      "     0.02275137]\n",
      "   [-0.02541458 -0.04593589 -0.04431367 ...  0.04164622 -0.08275384\n",
      "    -0.12891263]\n",
      "   [-0.07042395  0.05174024 -0.02906161 ...  0.0154938   0.07488933\n",
      "    -0.01350512]\n",
      "   ...\n",
      "   [ 0.04453458  0.12749365 -0.01124474 ... -0.03667749 -0.06902781\n",
      "    -0.06992002]\n",
      "   [ 0.07714376  0.04838935 -0.06371861 ...  0.02223187  0.10348473\n",
      "     0.09407079]\n",
      "   [-0.01173261 -0.05095858  0.09591822 ...  0.02851568  0.08592372\n",
      "     0.03222239]]]]\n",
      "discriminator_11/conv_block_137/conv2d_137/bias:0 [ 7.76621280e-04 -1.08947032e-04 -2.59985391e-04  1.20099052e-04\n",
      "  2.28814650e-04  6.10697025e-04  5.33535967e-07 -2.97812250e-04\n",
      "  3.26169902e-05 -6.32274256e-04  7.37784139e-04  1.64977493e-04\n",
      "  1.01432030e-04  5.19908208e-04  1.10680971e-03  5.72521822e-04\n",
      "  5.86425187e-04  5.65017217e-05 -7.06739374e-04  1.00559686e-04\n",
      "  7.81770155e-04 -1.27284584e-04  1.28228903e-05  7.34263813e-06\n",
      "  2.04963551e-04  4.40823642e-04  2.27852911e-06  5.22688904e-04\n",
      "  9.74832947e-05 -1.77882423e-04  3.24763387e-04  4.38035895e-05\n",
      " -1.41357203e-04  1.81892916e-04  8.08639161e-04 -1.36990071e-04\n",
      " -1.63358709e-04 -3.43769963e-04 -5.80000284e-04  3.11763724e-04\n",
      " -2.15716136e-04  3.24606081e-05 -2.53123198e-05  4.53866262e-04\n",
      " -8.11878941e-04 -5.41512018e-05 -3.47847585e-04 -9.82849742e-05\n",
      "  3.72016075e-04  3.82795755e-04 -1.59534859e-04 -3.40830011e-05\n",
      "  6.03389461e-04  2.31804061e-05  3.05553229e-04 -2.63258844e-04\n",
      "  3.13119963e-04 -1.30332628e-04 -1.15197428e-04 -1.11302908e-03\n",
      " -5.14249732e-05 -1.12968974e-05 -2.47302698e-04  3.42622807e-04\n",
      "  2.86911090e-04 -2.92072451e-04  1.78471149e-04  1.54654495e-04\n",
      "  3.74036230e-04 -1.37300385e-05  6.23313652e-04  3.26693407e-06\n",
      "  1.00698404e-03  4.26138286e-05  4.12352587e-04 -5.36461012e-04\n",
      "  2.76038918e-04  7.98302208e-05  4.29816166e-04 -5.14764979e-04\n",
      "  1.46469902e-04 -9.78333992e-05  1.11849964e-04  1.40254138e-04\n",
      "  7.41068579e-05 -8.89889998e-05 -3.80646903e-04 -2.47207703e-04\n",
      "  3.44065222e-04  6.38616912e-05  3.29994364e-04  3.12128832e-04\n",
      "  3.49011607e-05 -6.81981328e-05 -4.92923893e-04  4.88230697e-04\n",
      "  5.57583116e-04  2.19104277e-05  1.44076112e-04 -6.06766516e-05\n",
      "  1.12593007e-04 -1.04331913e-04 -8.00146154e-05 -2.69789666e-06\n",
      " -1.09264647e-05 -9.45469772e-04  2.38545224e-04 -1.77110967e-04\n",
      " -2.74333812e-04 -1.86082383e-04 -4.29631706e-04  3.16387304e-04\n",
      " -6.06192858e-04  6.04510133e-05 -2.10536644e-04 -2.26337754e-04\n",
      "  1.42648030e-04 -3.03476350e-04 -2.09890830e-04  7.50711362e-04\n",
      " -5.07409626e-04  3.46386951e-04 -2.67830706e-04  7.31652661e-04\n",
      "  1.76594302e-04 -3.22735461e-04 -1.52387109e-03  2.28144097e-04\n",
      " -1.28014843e-04  1.23279367e-03 -1.11291301e-04  6.99593103e-04\n",
      " -1.12744761e-04 -2.39424306e-04  3.19168728e-04 -1.09761946e-04\n",
      "  8.72297969e-05  1.19982776e-03 -5.56004816e-04 -5.85546004e-05\n",
      " -1.02490914e-04 -7.42960838e-05 -5.01628732e-04  3.09845520e-04\n",
      "  7.27517996e-04 -7.22522891e-05 -2.59020046e-04  8.25697352e-05\n",
      "  4.49498300e-04 -1.67470804e-04 -2.34549239e-04 -8.38008782e-05\n",
      "  1.43099081e-04  5.94727171e-05  8.09247023e-04 -5.67604075e-05\n",
      "  6.59276702e-05  3.27201531e-04  8.84597393e-05  4.18139360e-04\n",
      " -3.33039876e-04 -1.89501006e-04 -2.38236695e-04 -9.21726460e-05\n",
      " -4.06878331e-04 -6.18594931e-04  4.56428061e-05 -3.30153620e-04\n",
      "  1.67353908e-04  1.03366736e-03  8.93390097e-05 -3.39699582e-05\n",
      "  3.61237559e-04  1.55684698e-04 -6.20895298e-04 -3.96577234e-04\n",
      " -2.11015475e-04 -2.52466612e-06 -6.75998817e-05 -3.96975956e-04\n",
      "  1.36973467e-04 -4.33041016e-04 -7.42860138e-05  1.97392437e-04\n",
      " -2.32098304e-04  6.31440023e-04  5.23081362e-05 -8.43361195e-04\n",
      " -1.05259438e-04 -3.60329839e-04  7.00442644e-04 -1.18228591e-05\n",
      " -4.00406367e-04  2.12228057e-04  3.03805253e-04 -3.43906460e-04\n",
      "  1.98365306e-03 -1.00079633e-04 -9.94333532e-05 -3.61281098e-04\n",
      " -1.63290810e-04 -2.47017655e-04  1.76092799e-04  1.38661897e-04\n",
      " -2.57253007e-04  8.97726859e-05 -5.02792354e-05  6.73773000e-04\n",
      "  2.59589840e-04  5.04046679e-04  4.61455384e-05 -1.55736954e-04\n",
      "  1.58029521e-04  4.61979216e-04  1.84548696e-07  1.49660991e-04\n",
      "  3.93058835e-05 -2.40890821e-03  5.55863313e-04  7.04460312e-04\n",
      "  5.53877435e-05  4.88355872e-04 -1.38713775e-04  2.90330674e-04\n",
      " -2.87264207e-04 -8.95211779e-05  4.29903012e-04 -1.38934978e-04\n",
      "  1.14529720e-03 -4.88281192e-04 -1.08119035e-04 -6.14687102e-04\n",
      "  6.19655548e-05 -4.67883307e-04 -2.28137331e-04  3.64001957e-04\n",
      "  7.34153553e-04 -2.11654842e-04  1.97787085e-04  9.60520410e-04\n",
      " -2.44012277e-04 -5.74047095e-04 -1.36669451e-05 -3.99204437e-04\n",
      "  7.07959116e-05  1.67959937e-04 -2.12473678e-05 -1.64403813e-04\n",
      "  1.11572517e-04  2.74125399e-04  2.49649514e-04 -4.58900358e-05\n",
      " -2.13646505e-04  2.15184933e-04  2.47669494e-04 -1.41629876e-04\n",
      "  1.67120495e-04  4.06854379e-05  1.30558008e-04 -1.42207195e-04\n",
      "  4.16512812e-05 -6.73546805e-04 -1.67016260e-04  1.63093660e-04\n",
      "  1.83163400e-04  2.63576163e-04  8.05407180e-05  3.57698416e-04\n",
      "  1.62541139e-04 -3.88990011e-05  1.80433781e-04 -1.90029488e-04\n",
      " -2.16254295e-04  1.46070786e-03 -8.99994688e-04 -3.40435654e-04\n",
      "  4.93586005e-04  1.23257036e-04  5.16441578e-05 -1.12621361e-04\n",
      "  1.13314250e-04  7.23667254e-05  6.77174598e-04 -3.13461132e-05\n",
      " -6.96717645e-04 -4.86646255e-04 -1.05112478e-04  4.08492633e-04\n",
      "  7.33415218e-05  6.81572885e-04  4.42767108e-04 -1.40131189e-04\n",
      "  3.55952943e-04 -3.68889479e-04  4.51614789e-04  5.92988035e-05\n",
      "  1.71209576e-05  4.26905281e-05 -4.32304310e-04  3.74230644e-04\n",
      "  1.07835789e-04  4.33153364e-05 -5.45762770e-04  1.59473123e-03\n",
      "  8.59757944e-04 -1.17205804e-04 -6.11627591e-04 -8.00707858e-05\n",
      "  7.59451941e-04  9.82016907e-04 -3.81310994e-04  5.05469739e-04\n",
      "  2.03892105e-05 -7.64817814e-05  7.45893922e-05  4.34047706e-06\n",
      "  2.33917366e-04 -1.11757981e-04 -7.09484506e-04  1.08664630e-04\n",
      "  3.50592221e-04 -5.20453788e-04  8.63095454e-04  2.08556175e-05\n",
      " -1.23078455e-04  2.39070636e-04  1.90475999e-04  1.13337621e-04\n",
      " -6.00464991e-04 -2.03559066e-05 -3.50982009e-04 -1.61119417e-04\n",
      " -5.68322372e-04 -6.75104311e-05  1.01040474e-04 -3.95903218e-04\n",
      "  4.00784862e-04  1.26911546e-04 -1.27487129e-03 -5.77321880e-05\n",
      "  2.53507402e-04  3.52347197e-05  1.26545110e-05 -1.35104652e-04\n",
      " -7.06381616e-05 -3.57626996e-04 -9.08178452e-04  4.28119180e-04\n",
      " -3.49043228e-04  5.31220430e-05 -2.42791866e-04 -5.24507661e-04\n",
      " -2.00437906e-04  1.16735951e-04  6.04104134e-04  1.95942848e-04\n",
      "  3.90080495e-05  6.54738687e-04 -7.67740494e-05  5.37192500e-05\n",
      " -1.00066034e-04 -5.45295712e-04 -2.97488150e-04 -3.09337411e-05\n",
      " -6.65905609e-05  3.36976547e-04  2.44785275e-04 -5.83401707e-04\n",
      " -1.10295042e-03 -9.03339824e-05 -4.75181354e-04 -3.89051493e-05\n",
      " -3.76748445e-04 -2.93921563e-04 -3.86354688e-04 -3.52701427e-05\n",
      " -2.19476744e-04  7.67946069e-04  1.77509064e-04 -4.56000416e-04\n",
      " -3.04336254e-06 -9.34880693e-04  2.63763523e-05  5.13709383e-05\n",
      " -3.94442650e-05 -1.02159719e-03  8.15364911e-05 -1.39645883e-04\n",
      "  6.28305541e-04  2.13143139e-05 -2.51096440e-04 -2.96968705e-04\n",
      "  3.34709557e-06 -6.10102317e-04 -4.48564933e-05  1.65523044e-04\n",
      " -1.18921955e-04 -5.92689961e-04 -5.83611909e-05 -2.31418962e-04\n",
      " -3.39190941e-04 -1.96659385e-04  7.88241159e-05  2.77087296e-04\n",
      "  4.67043807e-04 -4.11174464e-04 -1.00227553e-04  1.60700991e-04\n",
      " -1.13077564e-04  7.99047484e-05 -8.04003794e-04 -4.52622684e-04\n",
      "  2.91957957e-04 -4.87373800e-05  1.98280250e-04 -2.87294504e-04\n",
      " -1.19821846e-06  1.49377767e-04  7.63277174e-04 -1.03241451e-04\n",
      " -3.66426568e-04 -4.43433528e-05 -6.01994907e-05  1.30103392e-04\n",
      " -9.12358519e-05 -4.73020100e-06  4.76223911e-04 -3.53692769e-04\n",
      "  7.75169829e-05  3.59118822e-05 -5.46664487e-05  5.19880268e-04\n",
      "  1.10933091e-04  7.00049277e-04 -4.44766338e-05  6.48176181e-04\n",
      " -2.50274461e-04  6.84876344e-04 -1.41151259e-05 -2.65292154e-04\n",
      " -1.38119576e-04  1.85625584e-04 -1.23941712e-03  7.45837111e-04\n",
      " -1.23024482e-04 -1.33008230e-04  5.15491702e-04 -6.97184805e-05\n",
      "  1.65179197e-04  4.46936901e-04 -7.57838861e-05 -1.41367622e-04\n",
      " -3.96037998e-04 -2.22677118e-04  3.33066419e-04 -7.19757751e-04\n",
      "  1.62139157e-04 -3.12551245e-04  4.24052356e-04 -5.31775913e-05\n",
      "  2.99269421e-04  2.40017544e-04  6.36323311e-05  3.05458991e-04\n",
      " -6.64907857e-04  4.10817360e-04  3.62927203e-05  2.56620900e-04\n",
      "  6.68876528e-05 -1.68956700e-04  6.01285901e-05 -7.41091617e-06\n",
      "  2.92293007e-05  3.12456483e-04  4.66741876e-05  7.91098340e-04\n",
      " -7.42677134e-04  5.76889943e-05  2.80009204e-04  2.67010968e-04\n",
      "  9.65244544e-04  9.39253277e-06 -5.58505817e-05 -2.08555241e-04\n",
      "  4.40773641e-04 -3.65170526e-05  5.29249664e-04  2.64552888e-04\n",
      " -1.90316598e-04  1.75918205e-04 -8.48075651e-05  8.07770703e-04\n",
      "  4.29381820e-04 -1.93247412e-04  3.71281727e-04 -2.92815181e-04\n",
      " -4.36732225e-04 -8.83785426e-04  3.84847590e-05  4.81290597e-04\n",
      "  2.68509291e-04 -3.21089639e-04  3.57618468e-04  6.72250462e-04\n",
      " -1.72897155e-04  5.00266964e-04 -4.23632766e-04  4.24089463e-04\n",
      "  2.75286642e-04  4.44177393e-04  5.29972158e-06 -1.08953798e-04]\n",
      "discriminator_11/conv_block_137/batch_normalization_213/gamma:0 [1.0497953  0.9624544  0.9736086  0.99511546 0.99475425 1.0492531\n",
      " 0.98357964 0.96887964 0.9532927  1.0267968  0.9875663  0.9926785\n",
      " 0.96580815 1.008053   1.1568673  0.9680058  0.97275794 1.0355257\n",
      " 0.9819987  0.95162654 1.0727282  0.97873986 0.98897076 0.9925738\n",
      " 1.046571   0.9711811  0.9814021  0.9888689  1.0594434  0.9452087\n",
      " 1.0365093  1.0028874  0.9966341  1.0049322  1.050108   1.0276474\n",
      " 1.0010552  0.9828151  0.97163576 0.981374   1.0003384  1.0094827\n",
      " 1.0222125  1.0627623  0.9595396  1.0059668  0.99548304 0.9799415\n",
      " 1.0213243  1.12952    1.0368785  0.97713    1.0159962  1.0533836\n",
      " 0.97857904 0.96953773 1.0057883  1.0160675  0.98272717 0.9685296\n",
      " 0.9729836  0.9790748  0.9657924  0.9900289  0.9892891  1.1329359\n",
      " 1.003234   0.9980079  1.0223625  0.9753913  0.96979344 1.0127231\n",
      " 1.0677515  0.9787866  0.98749524 1.0994505  0.9718263  0.95546204\n",
      " 0.9469129  1.0302347  0.98080456 1.0498357  1.0625879  1.0621887\n",
      " 0.95365113 1.0225345  1.0200462  1.0214761  0.9945316  1.022257\n",
      " 1.020263   1.00217    0.96818584 0.9221357  0.997347   1.0029596\n",
      " 1.0385504  0.94290113 0.9851684  0.9753302  0.9871164  0.9846606\n",
      " 0.9484646  0.9591261  0.95662767 1.0170774  0.9782028  0.9907262\n",
      " 1.0217448  0.95737684 1.0716224  1.0585679  1.019195   0.97281927\n",
      " 0.94572955 0.95734376 1.0089709  0.9938932  1.0503737  1.0365682\n",
      " 0.97757334 0.9939021  0.97215796 0.9618039  0.98640513 0.9417395\n",
      " 1.1541249  1.0013405  0.97284883 1.1509707  1.0137541  1.032701\n",
      " 0.93835276 0.9668628  1.0602392  0.9901372  1.0379564  1.1309342\n",
      " 0.9881682  0.9616163  0.9902248  1.0289688  1.0770036  1.0001498\n",
      " 1.0162016  0.9473166  0.9853649  1.0356493  0.9856163  0.9998641\n",
      " 0.99108124 1.0457838  1.0009778  1.0058994  1.0096197  0.9855298\n",
      " 0.97297573 0.9905264  0.9606727  1.0575802  0.96763694 1.0928257\n",
      " 0.98546815 1.0706079  1.0257235  1.0187677  0.9826367  0.99068373\n",
      " 0.97653717 1.1205208  0.9893534  0.99434304 0.9716312  0.99083334\n",
      " 0.991335   1.0264591  0.9624839  1.0502508  0.930386   0.96023196\n",
      " 0.9554506  1.0519037  1.0273912  1.1205645  1.0153369  0.9986933\n",
      " 1.0040922  1.0205603  0.9862655  1.0910807  1.0232391  1.0175966\n",
      " 1.0104525  0.9774857  1.0074226  0.99564904 1.1616895  1.0335318\n",
      " 0.97165865 0.9715135  0.99179786 1.0146846  1.0428988  0.9929035\n",
      " 0.9869878  0.97957885 0.99663734 0.9970239  1.05673    0.9840303\n",
      " 1.007454   1.0064381  0.9422745  0.9899181  0.99907726 1.0344561\n",
      " 0.97052526 1.1351734  0.9854104  1.012007   1.0229106  1.0240766\n",
      " 0.9962041  0.9838592  0.9728248  1.0243143  1.063355   1.015447\n",
      " 0.98311543 1.0510579  0.9906941  1.0087672  0.9975454  0.9753733\n",
      " 0.99141216 1.015727   1.001582   1.0496143  0.9994151  1.0610161\n",
      " 0.969161   1.0365506  0.97953445 1.1187165  1.0019602  1.0200312\n",
      " 1.0294937  0.96629125 1.0472275  0.9970871  1.0110998  1.0032192\n",
      " 1.0228148  0.99349046 0.9686659  1.0078548  0.96990806 1.1069313\n",
      " 0.99231184 0.9715864  0.9777629  1.0228359  1.0579429  1.0317516\n",
      " 0.9920694  1.0805663  0.9620239  0.9811176  0.9716063  0.98639935\n",
      " 0.9969083  1.030722   0.99252635 1.0805446  1.0379765  1.0100328\n",
      " 1.0262531  0.96893483 0.97334284 0.99613035 0.96031916 0.9975981\n",
      " 1.1266972  0.98911023 1.0177462  1.0688285  0.9733921  0.9905793\n",
      " 1.0004414  0.9870305  0.9878167  0.9841415  0.97261316 0.99049175\n",
      " 1.007059   1.0200162  1.0137529  1.025067   1.0081679  0.99167705\n",
      " 1.0499773  0.98029214 0.9840314  1.0745412  1.0417124  1.0711851\n",
      " 0.96215504 0.9763181  1.0678346  1.0412376  1.0367919  1.0366333\n",
      " 1.0413048  0.9789892  0.9636378  1.0236729  0.9593698  1.0137961\n",
      " 1.0715007  0.9579868  0.9627391  1.0676728  1.0234251  0.97475934\n",
      " 1.0025481  1.0904887  1.0523796  0.9911892  1.0214013  1.0080049\n",
      " 1.0334678  0.98740524 0.9378038  0.95826894 0.9858777  0.9676732\n",
      " 1.0070825  0.9792789  1.039089   0.9997803  1.0493127  0.9649565\n",
      " 1.0099928  1.0123379  0.99341744 0.9783138  0.9613314  0.9560902\n",
      " 1.0101289  1.1247661  0.9525069  0.9599019  1.0134461  1.0260404\n",
      " 1.0684928  1.0139734  0.9916364  1.0326824  0.97034264 0.9706152\n",
      " 1.0581926  1.0133761  1.0088707  0.98306966 0.975678   1.0971563\n",
      " 0.9953246  1.0731106  1.0632372  0.9790531  0.9821305  0.97905725\n",
      " 1.0489768  0.9688764  0.95335716 0.9940016  1.2781993  0.98062414\n",
      " 1.0129169  1.0082849  0.97159874 1.0323951  0.9990111  0.9759991\n",
      " 1.006601   1.0156051  1.0035704  1.0026134  0.9802835  1.1152421\n",
      " 0.9744283  0.9875987  1.1361436  1.0642638  0.9699066  0.99341285\n",
      " 1.0287853  1.0152546  0.9924483  0.95577127 0.93366    0.9674403\n",
      " 0.97004914 0.9983576  1.0633745  1.0069523  1.040778   0.9995042\n",
      " 0.9412294  0.9949702  0.96434385 1.015949   0.9952492  1.0460298\n",
      " 1.002665   1.0098879  1.0465112  0.9846144  1.120762   0.9617397\n",
      " 0.9887108  1.0199248  1.0310086  1.0446514  0.9944358  1.0018904\n",
      " 1.0110387  0.986298   0.9161897  1.0312314  0.9585273  1.0062506\n",
      " 0.99436516 1.0645798  0.9622125  0.9608834  1.0055141  0.978838\n",
      " 0.928513   0.94967717 0.9434421  0.97824234 1.0211868  1.0879852\n",
      " 0.9682399  1.0604006  0.99093646 0.93383896 0.9764908  1.0235463\n",
      " 0.9870978  0.9760063  0.97829145 0.96456707 1.029779   1.1179751\n",
      " 1.0003048  1.0994015  1.0571767  1.0386405  0.9819995  1.0317348\n",
      " 0.99641126 0.9843229  1.0015326  1.013272   0.9736152  0.997195\n",
      " 0.99978304 0.966287   1.0255336  1.036532   1.0040247  0.9950604\n",
      " 0.9900962  0.95162076 1.0425351  0.9450599  0.94897115 1.1199675\n",
      " 1.0288212  1.0011247  0.99317324 0.9825973  0.97612715 0.9249735\n",
      " 1.0270633  1.0209047  1.0070997  0.9675137  0.99526215 0.98015267\n",
      " 0.9834384  0.9902697  1.0129772  1.0035288  1.0035797  1.0105382\n",
      " 0.98767954 1.0001705  1.0044279  1.0082802  1.0120487  1.0416839\n",
      " 1.1281843  0.9964042  1.0061479  1.0278358  0.99407804 1.004357\n",
      " 0.99223936 0.9924603 ]\n",
      "discriminator_11/conv_block_137/batch_normalization_213/beta:0 [ 0.07090479 -0.00402475 -0.04836465  0.02218518 -0.004578    0.01933802\n",
      "  0.0100758  -0.08286501 -0.05270905  0.04667335 -0.01034614  0.01857492\n",
      " -0.00835348 -0.04194513  0.14835359 -0.0402839  -0.00542123  0.0027608\n",
      " -0.08909263 -0.02112352  0.164945   -0.0308375  -0.04648659 -0.02300764\n",
      " -0.02679946 -0.04405519 -0.05046073 -0.04939096  0.00293048 -0.04364144\n",
      "  0.02598264 -0.00802109  0.03527481 -0.01022443  0.08700713  0.00291741\n",
      "  0.03831914 -0.01970091 -0.03967438  0.0143109  -0.03956361  0.01090245\n",
      "  0.01726594  0.03673997 -0.02568205 -0.01135987 -0.02480267 -0.00450809\n",
      "  0.09522074  0.08403961 -0.03570257 -0.01692886 -0.02304999  0.04108386\n",
      "  0.00890037 -0.05578522 -0.01772297  0.00225655  0.00967655 -0.04173241\n",
      " -0.08016241  0.0220798   0.00048868  0.04043127 -0.02799555  0.12843783\n",
      "  0.02507631  0.01434243  0.05060018 -0.06206641  0.01995438  0.02930536\n",
      " -0.0234145  -0.07520906  0.03139598  0.0441342  -0.03412704 -0.00729661\n",
      " -0.07289848  0.00983132 -0.04061107  0.02069715  0.08891301  0.08963438\n",
      " -0.05262682  0.00248186  0.00098752 -0.02059182 -0.04469001  0.00063742\n",
      " -0.00756927 -0.05297066 -0.00928609 -0.07116751  0.01947851  0.02309307\n",
      "  0.01799594 -0.03347028 -0.01966855  0.03444505 -0.00283445 -0.06349798\n",
      " -0.06012496 -0.01000903 -0.03744987  0.04676915 -0.01133994 -0.00516113\n",
      "  0.01275871 -0.06896213  0.01874712  0.06339432  0.01999806  0.01383878\n",
      " -0.07839463 -0.0258203  -0.03210345  0.03848245  0.07319329  0.04216344\n",
      " -0.02743454 -0.01498434  0.0012204  -0.03915644  0.02639973 -0.06422296\n",
      "  0.12953901  0.0221402  -0.02190894  0.08051037  0.04263827 -0.00782452\n",
      " -0.0543113  -0.05717678  0.00487403 -0.0106327   0.0581138   0.10997925\n",
      "  0.01782862 -0.0037538   0.02600083  0.06114305  0.02657096 -0.02188162\n",
      "  0.01044806 -0.0575108  -0.03361812 -0.00800728 -0.07634433 -0.05128765\n",
      "  0.00699764  0.02889979 -0.00425706  0.03817683 -0.03476106 -0.02971291\n",
      " -0.01149764 -0.01453743 -0.04822295  0.08124439  0.02642981  0.01027935\n",
      "  0.00799295 -0.00849653 -0.01638781 -0.00988752 -0.01288297 -0.00957446\n",
      " -0.0629432   0.08299589  0.04861141 -0.01843221 -0.05160452  0.02169386\n",
      "  0.03302018  0.01804738  0.00734049  0.09069408 -0.06582319 -0.04861058\n",
      " -0.09135664 -0.00978566  0.06610327  0.07469749  0.02991794  0.03133281\n",
      "  0.00697081  0.06351626  0.01109296  0.0910993   0.02095906  0.07465742\n",
      "  0.02985435  0.02441549  0.02552931  0.03565023  0.13775659  0.02113599\n",
      "  0.0030741  -0.01262784  0.00674869 -0.00527579  0.00633734  0.03075319\n",
      "  0.04832041 -0.02062397  0.00418567 -0.07798657  0.00399987 -0.00981269\n",
      "  0.03453962 -0.02701725 -0.08671533  0.01660391 -0.04047683  0.05813393\n",
      " -0.01312461  0.09600291 -0.00802468  0.01615498  0.039336   -0.00909685\n",
      " -0.03303492  0.00824537  0.01263212  0.02709084  0.06234149  0.02250211\n",
      " -0.06544001  0.01243125  0.00895783  0.02880057 -0.01917027 -0.03659318\n",
      " -0.04074836  0.03183845  0.02893132  0.06519169 -0.00436728  0.01387728\n",
      " -0.06911571  0.05786995  0.04045555  0.05856486 -0.02005998  0.06123202\n",
      "  0.01964611 -0.06029636  0.03010466  0.03470391  0.032076    0.02798095\n",
      " -0.01606323  0.01180068 -0.02737353  0.05382123 -0.02808862  0.07939285\n",
      " -0.0071525  -0.03038087 -0.054824    0.00483722  0.10284084  0.09307114\n",
      " -0.02033096  0.04493232 -0.02160786 -0.03245734 -0.0318445  -0.05751355\n",
      "  0.07391049 -0.00154781  0.00271882  0.03027184 -0.01079983  0.06123468\n",
      "  0.02068049 -0.02103003 -0.01955698 -0.00898452 -0.03995612  0.00163956\n",
      "  0.1298679   0.01441241  0.04537288  0.01575475 -0.02869849 -0.0473433\n",
      " -0.00991253 -0.00554277 -0.01527109 -0.02167868 -0.02351263 -0.00464731\n",
      " -0.04293953  0.09043103 -0.03581726  0.01186851  0.0364839  -0.01160782\n",
      "  0.04872666 -0.00776666  0.01269265  0.10877557 -0.04115386  0.08396107\n",
      " -0.06880774 -0.06185663 -0.01630812 -0.04535394  0.00801637  0.06708074\n",
      "  0.0163898  -0.05072558 -0.06610955 -0.00252202 -0.04674558 -0.05565736\n",
      "  0.03443208 -0.10315091 -0.09239317  0.04602569 -0.0238857   0.00982121\n",
      "  0.03074305  0.15140815  0.02426087  0.00703715  0.00943615  0.03622873\n",
      "  0.04726593 -0.06116807 -0.07115386 -0.01477118 -0.01991006 -0.05862596\n",
      " -0.00790159 -0.0057909  -0.00281906 -0.0091623   0.03519484 -0.04782385\n",
      "  0.01975597 -0.01471574 -0.01004811 -0.03367308 -0.07295854 -0.04741338\n",
      " -0.02526383  0.03735048 -0.02391828 -0.03738605  0.03525722  0.03159468\n",
      " -0.03007183 -0.00688519 -0.02373964  0.02221861 -0.02409648 -0.02804131\n",
      "  0.04045938  0.02642126  0.01748703  0.01535092 -0.03785699 -0.01033836\n",
      " -0.00407399 -0.01569702  0.1478379   0.00453656 -0.00391188  0.00780387\n",
      " -0.03698667 -0.0582953  -0.08692438 -0.03009186  0.11569542 -0.0002138\n",
      "  0.04099949 -0.00876217 -0.03414193  0.01261312 -0.0127142   0.01896548\n",
      "  0.01113249 -0.00529487  0.00743207  0.00990167 -0.05195569  0.06827315\n",
      " -0.00414097 -0.05907782  0.07801306  0.0659285  -0.0280867  -0.0469259\n",
      "  0.02286296  0.00222634 -0.01089716 -0.00987693 -0.0478715  -0.01415102\n",
      " -0.00139817 -0.07892462  0.00775877 -0.02856967  0.00313556  0.01092752\n",
      " -0.06291696  0.0018466  -0.04696945  0.01551157 -0.02156947  0.01613663\n",
      "  0.04461692 -0.00617057 -0.02170934 -0.04056552  0.07491467 -0.04395156\n",
      "  0.00275882  0.03137251  0.04220688  0.01130037  0.01443772  0.01441022\n",
      "  0.03780487 -0.05076872 -0.04753387 -0.00763569 -0.01813097  0.01802277\n",
      " -0.00424747  0.0550868  -0.04983221 -0.03424883  0.02559132 -0.04981003\n",
      " -0.07718197 -0.08736601 -0.13837813 -0.00317634  0.04027886  0.09689365\n",
      " -0.05795534  0.08095287 -0.01594699 -0.07498767 -0.00676207  0.05504939\n",
      "  0.00483648 -0.05708941 -0.03069572 -0.07134342  0.02972674  0.00477169\n",
      " -0.01493357  0.04936009  0.04324412  0.02898559  0.02122664  0.0359298\n",
      "  0.03407716 -0.07386866  0.05862204 -0.00850216 -0.01230643  0.00545003\n",
      " -0.04936833 -0.02190203  0.03091281  0.00928662  0.03677094  0.03145417\n",
      " -0.01826544 -0.05388517 -0.00572253 -0.04945871 -0.07190258  0.04291965\n",
      "  0.01410723 -0.02209044 -0.02898551 -0.11351746 -0.00141934 -0.02872047\n",
      "  0.06614101  0.01743121 -0.00420456 -0.01501831  0.00450303 -0.04364754\n",
      " -0.06257311 -0.03509067  0.04195967 -0.01208423 -0.00913252 -0.03379578\n",
      "  0.0061371  -0.03704537  0.00706725  0.04280905  0.02485663  0.04081699\n",
      "  0.00871014 -0.0512008   0.01341169  0.03726794  0.00227893 -0.00191256\n",
      "  0.01270332  0.01288757]\n",
      "discriminator_11/conv_block_138/conv2d_138/kernel:0 [[[[ 1.54882982e-05  2.02681520e-03 -7.91332126e-03 ... -9.64688137e-04\n",
      "     4.17177984e-03  1.40473684e-02]\n",
      "   [ 2.50692777e-02 -1.06893061e-02 -2.49176938e-02 ...  6.69938000e-03\n",
      "     1.67138502e-02 -1.20953685e-02]\n",
      "   [-1.09912064e-02 -2.47618891e-02 -1.15149571e-02 ...  1.82113647e-02\n",
      "     6.82441983e-03 -2.97978409e-02]\n",
      "   ...\n",
      "   [ 3.13580073e-02  1.93832070e-02  1.64536498e-02 ... -1.37933223e-02\n",
      "    -1.66260879e-02  6.70916587e-03]\n",
      "   [-2.37692185e-02 -2.79433746e-02 -3.52703454e-03 ... -8.43930896e-03\n",
      "    -8.74399208e-03 -2.93488968e-02]\n",
      "   [ 2.79015638e-02 -4.96004894e-02 -2.54616495e-02 ...  6.00312650e-03\n",
      "    -2.36179717e-02  6.88485010e-03]]\n",
      "\n",
      "  [[ 3.95971164e-03  1.16005470e-03 -1.17006758e-02 ... -2.39619333e-02\n",
      "    -2.28213575e-02  1.47139123e-02]\n",
      "   [ 9.81650129e-03 -8.11970327e-03  2.57721320e-02 ...  2.97932304e-03\n",
      "     2.31222175e-02 -1.34995021e-02]\n",
      "   [-3.36690317e-03 -1.98546518e-02  5.75260818e-02 ... -1.17009524e-02\n",
      "     1.96065567e-02  2.30548833e-03]\n",
      "   ...\n",
      "   [-3.92694399e-03  4.70271856e-02  4.34905058e-03 ...  2.96287443e-02\n",
      "     2.98121991e-03 -8.61929613e-04]\n",
      "   [ 1.61278527e-02 -1.23088574e-02  1.40660778e-02 ... -4.55423165e-03\n",
      "     1.36274705e-02  2.03537308e-02]\n",
      "   [-1.83492601e-02  2.06631925e-02 -4.17588046e-03 ...  8.42653867e-03\n",
      "    -1.46690896e-02 -8.01847409e-03]]\n",
      "\n",
      "  [[-9.37893335e-03 -4.96752597e-02 -4.10775989e-02 ...  1.26455072e-02\n",
      "    -5.72859775e-03 -1.45048434e-02]\n",
      "   [ 2.83304621e-02  2.73096059e-02  9.98406112e-03 ...  3.82148381e-03\n",
      "     1.90884210e-02  4.19210494e-02]\n",
      "   [ 1.40699334e-02  9.85270715e-04  2.24980060e-02 ...  2.61972137e-02\n",
      "     3.62550374e-03 -2.48315465e-02]\n",
      "   ...\n",
      "   [ 2.05932278e-02 -8.54787882e-03  1.44240903e-02 ... -4.64674830e-03\n",
      "     6.78407552e-04 -4.10877764e-02]\n",
      "   [ 9.29860398e-03 -3.18271704e-02  3.38592418e-02 ... -2.74740066e-03\n",
      "    -4.90525551e-02  2.53888220e-02]\n",
      "   [-3.08238305e-02 -3.08395233e-02  3.16647291e-02 ...  4.26709950e-02\n",
      "    -4.75549027e-02 -1.58890057e-02]]]\n",
      "\n",
      "\n",
      " [[[-1.35115981e-02  6.27081201e-04 -5.63547388e-03 ...  9.31669772e-03\n",
      "    -1.57586690e-02  1.21841626e-03]\n",
      "   [-1.76448897e-02  5.46575040e-02 -1.28585016e-02 ... -2.60559358e-02\n",
      "     3.15479410e-04  3.60243209e-02]\n",
      "   [-2.77245039e-04 -4.50372137e-03  4.87063378e-02 ...  1.99148767e-02\n",
      "     1.48160309e-02 -1.87592173e-03]\n",
      "   ...\n",
      "   [-2.64758170e-02  2.24505439e-02  1.41410325e-02 ... -1.50103895e-02\n",
      "    -2.41132583e-02  2.00310238e-02]\n",
      "   [ 1.17051722e-02  1.52893330e-03  2.78678611e-02 ...  8.51903670e-03\n",
      "    -4.48081680e-02 -2.68018595e-03]\n",
      "   [-1.73717237e-03  2.06410028e-02  2.09000632e-02 ... -3.05507518e-02\n",
      "    -2.31944267e-02 -1.73683129e-02]]\n",
      "\n",
      "  [[-3.23857665e-02 -1.45037267e-02  7.35617522e-03 ... -4.04678918e-02\n",
      "    -3.89104784e-02 -3.33602875e-02]\n",
      "   [ 3.66662294e-02 -4.46180068e-03  1.07609453e-02 ...  2.71129217e-02\n",
      "     5.21746092e-03  1.83348153e-02]\n",
      "   [-2.98796799e-02  8.86193756e-03  1.32975131e-02 ...  3.05749457e-02\n",
      "     1.14642968e-02 -2.52258703e-02]\n",
      "   ...\n",
      "   [ 6.96834977e-05  2.95428932e-02  3.28872749e-03 ... -4.52506429e-05\n",
      "     1.73903238e-02 -2.92742942e-02]\n",
      "   [ 5.80146024e-03 -2.49224771e-02  3.53151304e-03 ...  3.94154452e-02\n",
      "     1.47904234e-03  1.60438952e-03]\n",
      "   [-2.98964605e-02  3.08391843e-02  8.64175986e-03 ...  2.40769386e-02\n",
      "    -2.40988415e-02  4.56382446e-02]]\n",
      "\n",
      "  [[ 8.00368935e-03  7.91024882e-04 -2.93191615e-02 ...  2.93839760e-02\n",
      "    -2.23396998e-02 -3.93583067e-02]\n",
      "   [ 2.41115727e-02  4.46671471e-02  2.28488147e-02 ...  1.04422178e-02\n",
      "    -2.73089437e-03  2.72179805e-02]\n",
      "   [ 4.75427061e-02 -1.55348715e-03 -9.19225439e-03 ...  2.75071692e-02\n",
      "    -3.64970113e-03 -1.68319065e-02]\n",
      "   ...\n",
      "   [ 5.44662261e-03  1.90483350e-02 -3.38262655e-02 ... -3.06978598e-02\n",
      "     6.99766865e-03  5.37394313e-03]\n",
      "   [ 1.88942663e-02 -1.12538859e-02  2.80093588e-02 ...  2.72173099e-02\n",
      "    -6.16746582e-02  2.24585012e-02]\n",
      "   [-1.76570006e-02 -1.11362487e-02  2.41185147e-02 ... -8.79588551e-05\n",
      "     1.90192629e-02 -7.41318380e-03]]]\n",
      "\n",
      "\n",
      " [[[ 1.66138876e-02 -2.80332891e-03  1.16901472e-02 ...  2.76847221e-02\n",
      "    -7.55196996e-03 -3.61674093e-02]\n",
      "   [-3.61099053e-04  3.88523415e-02 -1.52943581e-02 ...  2.44308934e-02\n",
      "     3.54393339e-03  2.86277719e-02]\n",
      "   [ 2.26944257e-02 -3.44730262e-03 -1.55614794e-03 ...  1.42291579e-02\n",
      "    -2.56507266e-02 -1.03011141e-02]\n",
      "   ...\n",
      "   [-1.43058542e-02 -1.36075704e-03 -4.62435884e-03 ...  1.46517167e-02\n",
      "    -1.90189648e-02 -4.21283767e-02]\n",
      "   [ 1.53453564e-02  1.55013418e-02  1.73341893e-02 ... -2.04483513e-02\n",
      "     7.12755555e-03  3.15156928e-03]\n",
      "   [-2.18066480e-02  2.54618824e-02 -3.86210233e-02 ...  1.28903780e-02\n",
      "    -1.99269187e-02 -2.39581633e-02]]\n",
      "\n",
      "  [[ 6.06952980e-03 -8.41223374e-02  6.78373268e-03 ...  2.42392579e-03\n",
      "     2.02211384e-02 -7.20431432e-02]\n",
      "   [-3.84686738e-02  2.46528815e-02 -1.22490739e-02 ... -3.20982235e-03\n",
      "     2.29608510e-02  5.94664067e-02]\n",
      "   [ 2.52100620e-02  9.48752183e-03 -1.08374562e-02 ...  5.64355217e-03\n",
      "    -2.01933328e-02 -5.35255857e-02]\n",
      "   ...\n",
      "   [-8.27408116e-03 -7.93564692e-03  1.95686184e-02 ...  8.37830920e-03\n",
      "     8.63975286e-03 -2.72635873e-02]\n",
      "   [ 8.10545054e-04 -1.05687249e-02  1.19496481e-02 ... -7.72494765e-04\n",
      "    -3.65596302e-02 -3.20908725e-02]\n",
      "   [-2.44956259e-02 -1.93522964e-02 -1.42552992e-02 ... -2.66628414e-02\n",
      "    -3.46846208e-02 -4.49312441e-02]]\n",
      "\n",
      "  [[ 2.19187066e-02 -3.50408070e-03 -2.32484401e-03 ...  1.09680332e-02\n",
      "    -3.11835185e-02 -1.14621529e-02]\n",
      "   [ 1.44302994e-02  1.11675998e-02 -1.98289063e-02 ... -2.00376082e-02\n",
      "     4.12708744e-02  5.45853674e-02]\n",
      "   [-6.91198884e-03 -1.92666743e-02  3.63344215e-02 ...  3.15785632e-02\n",
      "    -2.71090469e-03 -3.23660555e-04]\n",
      "   ...\n",
      "   [-2.35847179e-02  1.42032243e-02 -1.99509524e-02 ...  4.34744917e-03\n",
      "     1.68325491e-02 -3.11030578e-02]\n",
      "   [ 2.73448750e-02 -1.11393700e-03  1.80192087e-02 ... -5.54294151e-04\n",
      "     1.77808236e-02  3.01449690e-02]\n",
      "   [-2.80582998e-02  1.27142081e-02  2.83943769e-03 ...  2.07231138e-02\n",
      "    -3.58163603e-02  2.98464410e-02]]]]\n",
      "discriminator_11/conv_block_138/conv2d_138/bias:0 [-1.41170165e-06  4.48753679e-04 -1.58520852e-05 -6.75191259e-05\n",
      "  1.27204825e-04  6.05673304e-05  2.92689183e-05  9.91217457e-05\n",
      "  3.96319192e-05  3.51111667e-05 -4.20963945e-04  1.02096477e-04\n",
      " -9.15445344e-05  1.52729262e-04 -8.72099554e-05 -6.38499614e-06\n",
      " -2.58596177e-04  1.83292959e-05  3.83435370e-04 -2.05694596e-04\n",
      " -6.23416054e-05  2.16511093e-04 -4.86484605e-05 -1.04137674e-04\n",
      "  1.46859957e-05 -1.15686351e-04 -1.68398663e-04 -6.60970254e-05\n",
      " -3.48774702e-05  1.59440693e-04  7.22834156e-05  5.25998243e-04\n",
      " -6.25552275e-05 -1.03971042e-05 -1.25641920e-04 -1.16007053e-04\n",
      "  1.22988291e-04 -1.35901864e-04  3.81803547e-05  3.88472748e-04\n",
      "  1.65566380e-05 -1.28890184e-04 -4.01371246e-04  1.41288750e-04\n",
      " -3.43224383e-05  1.68747414e-04  3.42108501e-06 -5.95328820e-05\n",
      " -1.28752044e-05  3.32427880e-05  1.93769083e-04  7.28387313e-05\n",
      " -1.10368256e-03  2.95767421e-07 -2.03850883e-04 -6.15674071e-05\n",
      "  2.32968432e-05 -9.00429222e-05 -7.06784922e-05 -6.06142166e-05\n",
      " -3.76669013e-05 -1.03450890e-04  3.96918826e-04 -2.42928028e-04\n",
      " -1.13119153e-04  1.27919906e-04 -3.78665900e-05  5.51513149e-05\n",
      " -1.17067291e-04  3.17995546e-05 -1.88168378e-05  5.98661427e-06\n",
      "  1.13116563e-04 -8.42132140e-05  7.64457727e-05 -3.73307295e-04\n",
      " -1.57772811e-05  6.70616282e-05  6.37367484e-05  4.63252363e-05\n",
      " -3.62685823e-05  5.56672130e-05  2.06106226e-04 -2.36438136e-04\n",
      " -1.22885176e-04  9.55696887e-05 -1.96008245e-04 -3.19780811e-05\n",
      "  1.43342375e-04  8.54997925e-05  2.34278068e-05  2.77935123e-05\n",
      " -5.12089136e-05 -2.03747859e-05 -2.08971469e-04  8.56278202e-05\n",
      " -4.73355698e-07 -5.31857040e-05 -1.05689403e-04 -1.78873976e-04\n",
      "  6.12475778e-05  3.94863273e-05 -1.15053524e-04  4.28054627e-05\n",
      "  2.61075154e-04  1.55366986e-04 -1.20319273e-04 -1.28179474e-03\n",
      "  1.64191006e-03  4.21741925e-06 -6.20134742e-05  1.80016083e-04\n",
      " -1.15959207e-04 -5.38258610e-05  4.99055432e-06  1.76834001e-05\n",
      "  7.17293005e-04  4.49411251e-04  6.17843980e-05 -4.20073520e-05\n",
      " -1.01627479e-03 -1.35570255e-04 -1.15362415e-03 -7.66038793e-05\n",
      " -1.75301757e-04 -1.77380338e-04 -6.75847768e-05  6.15787139e-05\n",
      " -4.03584636e-05  2.44118073e-05  7.12758119e-05 -3.01237997e-05\n",
      " -4.78895381e-05  1.79034541e-05 -2.07534846e-04 -3.71262286e-05\n",
      "  4.23276826e-04 -1.39571421e-04  4.00204772e-05 -3.84448795e-04\n",
      "  1.02836617e-04 -2.94481451e-05  1.39311785e-04  9.50806425e-05\n",
      "  1.00872694e-05 -3.49330294e-05 -2.24875665e-04  7.57633734e-06\n",
      "  5.10833415e-05 -2.78442021e-05  8.84663314e-05  5.12782754e-05\n",
      "  2.12111790e-05 -5.40558613e-05 -2.94895235e-05  6.90332035e-06\n",
      " -1.27092848e-04 -5.99302512e-05  2.84615584e-04 -8.32908918e-05\n",
      " -1.18597338e-04  3.05416179e-05  4.64307741e-05  2.27571873e-05\n",
      "  2.02649790e-05  1.33126311e-03 -7.06388382e-05 -1.06944142e-04\n",
      " -1.27902938e-04 -1.33648355e-04  7.52857813e-05  1.47402188e-05\n",
      "  4.58101886e-06 -6.06969734e-05 -1.90428491e-05 -6.28470443e-05\n",
      " -2.65369448e-03  1.14564835e-04 -1.98013440e-05  2.40676832e-06\n",
      " -2.88354313e-05  1.64014564e-05 -5.09392303e-05  3.16684018e-04\n",
      " -3.90833477e-04  9.68608656e-05 -1.77700858e-05 -4.55500922e-05\n",
      "  1.57929899e-04  5.38652603e-05  6.65718562e-06 -1.55830974e-04\n",
      " -3.15251754e-07  7.19872551e-05 -3.89406996e-05  1.27633088e-04\n",
      " -1.23184011e-03 -7.93031359e-05  4.73692926e-05  3.06711940e-04\n",
      "  9.32663897e-05 -4.43798286e-04  2.20544491e-04 -1.31360386e-04\n",
      "  1.20662817e-05 -6.51992814e-05 -8.31766883e-05 -1.32245041e-04\n",
      "  7.86803139e-05 -3.84996820e-05 -7.94032021e-05  4.29578613e-05\n",
      " -2.84223148e-04 -8.40998255e-04 -4.48808423e-04 -6.13147218e-04\n",
      "  1.03808510e-04 -4.17235897e-05 -4.70855157e-04 -7.57433882e-05\n",
      "  1.50899301e-04 -7.83958385e-05  1.57563743e-04  2.29746569e-04\n",
      "  1.64608809e-05 -3.58976358e-05 -4.58739269e-05 -2.58841261e-04\n",
      "  8.81326123e-05 -4.53924586e-05  6.78886354e-05  2.39797824e-04\n",
      " -1.88149221e-04  4.63289543e-05  6.19709754e-05 -7.27723527e-05\n",
      "  1.00099111e-04 -1.80302213e-05 -7.99963454e-05  7.36757240e-04\n",
      "  9.11819516e-05 -2.66915187e-04  2.53559003e-04 -7.40346324e-04\n",
      "  8.32058213e-05  4.87955767e-05  3.26906502e-06 -6.83589606e-05\n",
      "  5.55232073e-05  4.88990452e-04  8.50111464e-05 -1.97571762e-06\n",
      " -1.17310978e-04 -1.91937033e-05  2.03630465e-04  6.91396199e-05]\n",
      "discriminator_11/conv_block_138/batch_normalization_214/gamma:0 [0.97118163 1.1981246  0.9917305  1.0201933  0.99103194 1.0130862\n",
      " 0.99424523 0.9921247  1.048354   1.0132048  1.0703772  0.97975534\n",
      " 0.98324573 0.9870385  0.99560595 1.0008811  1.007964   0.9915439\n",
      " 1.1708155  1.0123389  1.0071203  0.9232391  0.9826189  0.9919796\n",
      " 0.9870472  1.0234739  0.8672242  0.9779642  1.0009586  0.9763284\n",
      " 1.0174801  0.9774304  0.9865984  1.0066506  0.98484284 0.9995889\n",
      " 0.95008385 0.96870255 1.007994   0.9844172  0.98480177 1.0031756\n",
      " 1.1680675  1.0263437  0.9809076  1.0436499  1.0069516  0.9794591\n",
      " 0.9845555  0.9894897  0.92283803 0.95492846 1.1978581  0.99952924\n",
      " 0.99399394 1.021941   0.99230283 1.0019009  0.95818377 1.0115752\n",
      " 0.9839249  0.9807012  0.86472744 0.9805217  1.0308343  1.024702\n",
      " 1.0059707  0.97160715 1.06411    1.0445391  0.992565   0.97226197\n",
      " 1.0419866  0.99321353 1.0086242  1.0210552  0.9986709  0.9952117\n",
      " 0.9753782  0.99105364 0.95373124 0.9598693  0.9676771  0.94989485\n",
      " 1.0194266  0.96251667 1.0218538  0.94715685 0.96997714 0.9993645\n",
      " 1.002412   0.9876616  0.99984574 1.0499705  1.0041789  0.98882645\n",
      " 1.0148596  0.9861607  1.057662   0.9971637  1.0343769  0.99414283\n",
      " 1.0018985  1.0138434  1.0505325  0.97750336 1.0030822  1.2167108\n",
      " 1.2357159  1.0158259  0.97399014 1.0173106  0.99995553 0.9906492\n",
      " 1.0205932  0.9822458  1.1778936  0.9142893  0.9793058  1.0288002\n",
      " 1.1993679  0.9839372  1.1647885  0.9730811  1.0526054  0.9792569\n",
      " 1.0026389  0.9813147  0.97682095 0.96683097 1.0033058  1.0376801\n",
      " 0.9935565  0.9934215  0.97864604 1.0092658  0.95708376 0.9435306\n",
      " 0.9384615  1.0507991  0.997637   0.967354   0.9803421  0.9783491\n",
      " 0.97718173 1.0199922  0.9967781  1.0162352  1.0233707  0.98370904\n",
      " 0.9978009  1.0279297  0.977738   0.9955929  1.0009487  0.9788254\n",
      " 1.0242492  0.99729884 1.0163583  1.0196459  0.98616254 0.9541721\n",
      " 0.97252584 0.88388956 0.95395184 0.9564567  0.96622777 1.02017\n",
      " 1.0008252  1.0394187  1.0507562  1.0450435  1.0471461  1.018573\n",
      " 0.9802105  0.99767685 1.1886278  1.0022688  1.0343859  1.035585\n",
      " 0.9247749  1.0066415  0.9407681  0.988865   1.0257072  0.998462\n",
      " 0.9862097  0.980971   1.0032486  0.98648286 1.0219809  0.99880946\n",
      " 1.0177174  1.0088036  1.0137514  1.0071758  1.1828794  0.9718315\n",
      " 0.96903664 1.0094981  0.9698052  0.9560481  0.993188   1.0155962\n",
      " 0.9515659  1.0206434  0.98513013 1.0285951  1.0037984  0.9906348\n",
      " 0.9771923  1.0425051  1.0095791  1.1449935  1.1616285  1.1687485\n",
      " 1.0020723  0.9834951  1.0313793  1.0088114  1.0173953  0.9885354\n",
      " 1.0220107  0.95356077 1.039095   1.0006547  1.0056293  1.0267508\n",
      " 0.98823404 0.98407185 1.0015761  0.92102736 1.0239142  1.0218585\n",
      " 1.0176198  1.0995537  1.043297   1.0145048  0.915494   0.98600596\n",
      " 0.96843916 0.9039487  1.1583753  0.91578215 0.99346465 1.0523554\n",
      " 0.98083353 0.99495584 0.9953985  0.88623315 1.0103729  0.94356614\n",
      " 0.9901838  1.0250407  0.9759984  0.97012454]\n",
      "discriminator_11/conv_block_138/batch_normalization_214/beta:0 [ 2.94894371e-02  4.98120114e-02 -6.38098270e-03  3.20813432e-02\n",
      " -1.86413934e-03  3.52995731e-02  1.90994306e-03 -9.72221140e-03\n",
      "  3.15833054e-02 -6.97671203e-03  1.07672652e-02 -2.13590115e-02\n",
      "  1.23360073e-02  2.57991944e-02  8.88773799e-03 -4.23730612e-02\n",
      " -2.21102498e-02 -1.72483046e-02  1.76359750e-02  3.30062285e-02\n",
      "  1.40153952e-02 -3.67313176e-02 -1.75231434e-02 -1.16474433e-02\n",
      " -1.77020468e-02 -7.16924260e-04 -8.19615722e-02 -1.37879690e-02\n",
      "  3.75379883e-02 -2.90520042e-02  2.45078257e-03  3.78364557e-03\n",
      " -2.98015885e-02  1.40053015e-02 -1.61266103e-02 -9.33966599e-03\n",
      " -4.38116118e-03  3.35583696e-03  3.25080119e-02  2.34093741e-02\n",
      "  1.20630441e-02 -2.62618829e-02  4.05347683e-02  1.71584543e-02\n",
      "  2.18154192e-02 -1.89810116e-02  1.02666160e-02 -2.49808049e-03\n",
      " -1.34040427e-03  2.32961308e-02 -2.30966266e-02 -1.14711262e-02\n",
      "  8.37953240e-02  4.04381007e-03  1.65742133e-02 -2.24157702e-02\n",
      " -4.37700469e-03  1.41348215e-02 -3.53302471e-02  3.16126794e-02\n",
      "  2.35062074e-02 -5.67046180e-02 -6.24950863e-02 -3.80064920e-02\n",
      "  1.04775596e-02 -5.30339777e-02 -8.04721192e-02 -3.04814745e-02\n",
      " -4.55468670e-02  4.76988964e-02 -2.62289215e-02 -3.05721611e-02\n",
      "  1.45037090e-02 -1.47827053e-02  8.80323630e-03  6.61067590e-02\n",
      " -9.63358395e-03  1.70348827e-02 -4.62361611e-03 -3.17361881e-03\n",
      " -1.89591388e-04  4.06063767e-03 -5.07195666e-02  1.68650865e-03\n",
      " -3.49362269e-02 -1.49979237e-02  2.98787504e-02 -4.74209934e-02\n",
      " -2.60523520e-02 -2.05818820e-03 -7.83728994e-03  6.70011900e-03\n",
      "  1.33897495e-02  5.43918647e-02 -3.83480042e-02 -1.01961680e-02\n",
      "  3.81582603e-02 -4.68240827e-02  5.73799796e-02  2.51592249e-02\n",
      "  1.42382309e-02  3.37146558e-02 -2.53237016e-03 -1.39819889e-03\n",
      "  7.93084968e-03 -3.24327387e-02 -1.82790570e-02  9.89651904e-02\n",
      "  8.82679448e-02  1.90906450e-02 -7.47266604e-05  8.75050109e-03\n",
      " -8.20183381e-03 -2.11488106e-03  8.21576081e-03 -8.65296368e-03\n",
      "  6.22346215e-02 -6.92991316e-02  3.78084485e-03  3.46030830e-03\n",
      "  5.03764264e-02  2.35578758e-04  9.78337824e-02 -1.14374915e-02\n",
      "  1.28648637e-04 -4.61619981e-02  3.79998647e-02 -2.50196941e-02\n",
      " -2.14472041e-02  2.77828495e-03  2.12705359e-02  7.51701742e-02\n",
      " -2.18804255e-02  1.20270317e-02  8.52754805e-03 -4.00363170e-02\n",
      "  4.04656772e-03 -1.73819643e-02 -6.82292366e-03  2.57033948e-02\n",
      " -2.23889784e-03 -3.50039192e-02 -2.11385041e-02 -3.66531918e-03\n",
      "  1.10140936e-02 -3.21813533e-03 -5.65033890e-02  1.09513775e-02\n",
      "  1.69778578e-02 -2.23886711e-03  4.57819924e-03  1.65730324e-02\n",
      "  2.30025277e-02  1.23020192e-03  2.81998771e-03 -5.30670350e-03\n",
      "  1.45980821e-03  1.69360638e-02  3.78626771e-02  1.36366244e-02\n",
      " -3.49956006e-02 -2.83619501e-02  1.62612973e-03 -3.77313532e-02\n",
      " -2.62690149e-02 -1.29262591e-02  1.14509938e-02 -1.64536405e-02\n",
      " -6.01914972e-02  6.45798594e-02 -8.02089227e-04  1.68439094e-02\n",
      "  9.20878500e-02  4.66543771e-02  2.28743684e-02  2.39803679e-02\n",
      "  3.40675861e-02  5.38437045e-04  1.18927686e-02  3.16164605e-02\n",
      "  2.52329521e-02  1.91095229e-02 -3.60970907e-02  1.57538690e-02\n",
      "  1.90841481e-02  6.92079868e-03  1.49367834e-02 -3.51239997e-03\n",
      "  7.28832139e-03  6.33942196e-03 -8.96255020e-03 -4.71652066e-03\n",
      " -2.17167959e-02 -3.41385491e-02  3.78328538e-03  3.27622308e-03\n",
      "  5.72029129e-02 -2.57349331e-02 -2.76872162e-02 -2.47802939e-02\n",
      "  2.75119673e-02 -9.71519295e-03 -1.65932234e-02 -1.45875718e-02\n",
      " -1.05019147e-02  4.14815769e-02  1.46869188e-02  2.81769671e-02\n",
      "  2.65176292e-03 -2.60688756e-02  1.22537967e-02  2.96415146e-02\n",
      " -1.31007535e-02 -2.77931895e-02  5.23877442e-02  2.13188287e-02\n",
      " -2.22790800e-03 -7.57402275e-03  1.19495429e-02 -8.29832442e-03\n",
      "  1.37913423e-02 -8.29269271e-03 -1.90071184e-02 -1.79907158e-02\n",
      "  2.86774151e-02  1.13698533e-02 -3.46373841e-02  3.47206299e-03\n",
      "  3.85695603e-03  1.33787757e-02 -2.55195610e-02  4.29829210e-03\n",
      " -2.88485666e-03 -2.67000701e-02  2.46996004e-02 -2.21161414e-02\n",
      "  1.09609757e-02  2.05964111e-02 -7.51446979e-03 -1.35417245e-02\n",
      " -1.60835125e-02 -5.62833995e-02  4.36820835e-02 -1.77983679e-02\n",
      " -3.94658409e-02  8.81783962e-02 -1.40517224e-02 -1.30406264e-02\n",
      " -2.62817331e-02 -4.22178581e-02  1.49878822e-02 -3.87149155e-02\n",
      "  3.28458212e-02 -4.31977771e-02 -9.29238088e-03 -3.40452418e-02]\n",
      "discriminator_11/conv_block_139/conv2d_139/kernel:0 [[[[-0.0826573   0.23170067  0.08781264 ...  0.02963487 -0.08628535\n",
      "    -0.03261902]\n",
      "   [-0.01691714  0.05417046  0.0199052  ... -0.01947648 -0.05599643\n",
      "     0.13075416]\n",
      "   [-0.06121346 -0.04735017 -0.03670347 ...  0.04830121 -0.1707911\n",
      "    -0.05012426]\n",
      "   ...\n",
      "   [ 0.01767491 -0.04615824 -0.15082802 ... -0.00774982  0.16524258\n",
      "    -0.04522198]\n",
      "   [ 0.14370836  0.1131182  -0.02860863 ...  0.0197958   0.02909376\n",
      "    -0.06840533]\n",
      "   [-0.05359606 -0.1018443  -0.017487   ...  0.12519711 -0.02473653\n",
      "     0.03148352]]]]\n",
      "discriminator_11/conv_block_139/conv2d_139/bias:0 [-5.55864390e-05 -1.17847985e-05 -5.76859820e-05  3.14172503e-04\n",
      "  1.68448430e-04  1.09444773e-04 -2.94059573e-05 -8.76347694e-05\n",
      " -3.35843851e-07 -1.28589463e-05 -6.28907510e-05  2.04802200e-04\n",
      "  2.39073370e-06 -1.06546016e-04 -9.07938447e-05  3.98883043e-04\n",
      "  6.68539942e-05 -1.89197584e-04 -1.84166511e-05  1.36999934e-05\n",
      " -1.86714897e-05 -2.66708696e-04  1.03350700e-04  4.47618571e-04\n",
      " -1.98884169e-04  2.57049018e-04  2.47864111e-04 -2.19670837e-04\n",
      "  9.82823913e-05  2.84495618e-04  1.35238270e-05 -2.48576631e-04\n",
      "  1.19865574e-04 -4.14926835e-05 -7.87266545e-05  2.86685477e-04\n",
      " -9.76911397e-05  1.64033298e-03  7.33935303e-06  1.32078394e-05\n",
      " -2.71006604e-04 -1.56668524e-04  4.93437037e-05  1.24030819e-04\n",
      "  3.07402479e-05  2.90602202e-05 -6.72585666e-05 -1.97875604e-04\n",
      "  2.55959079e-04 -3.06978400e-05 -2.18811343e-04 -2.14592146e-04\n",
      " -1.05962878e-04 -2.19171525e-05  3.64602718e-04 -3.77907796e-04\n",
      " -6.82643222e-05 -1.04788487e-05  9.96616945e-05 -1.04651059e-04\n",
      "  5.64063594e-05 -1.37736661e-05  4.83002041e-05  4.63878860e-05\n",
      " -1.09381370e-04 -1.77071663e-04 -2.21439797e-04  8.60870350e-05\n",
      " -1.25697494e-04  2.48222699e-04 -2.33891951e-05 -1.11405452e-05\n",
      " -8.71256852e-05 -1.49352309e-05  4.77914204e-04  3.18444479e-04\n",
      " -2.65288458e-04  8.87822680e-05 -6.66083724e-05  1.45588550e-04\n",
      " -3.54484073e-04  9.63835861e-04  1.77190959e-04  8.77939674e-05\n",
      " -1.46342762e-04 -1.20185920e-04  5.83465662e-05 -2.44263967e-04\n",
      " -1.16809725e-03 -3.17084778e-05 -3.25456203e-05 -1.32672154e-04\n",
      "  1.07609176e-05  8.30430436e-05  6.38112033e-05  2.01522867e-04\n",
      " -4.10451757e-05 -1.22991536e-04 -2.40125431e-04  4.13979214e-05\n",
      "  6.91262539e-05 -2.81767396e-04  1.15541574e-04  8.74362740e-06\n",
      " -3.67080618e-04  2.36278865e-04  1.97475543e-04  1.08336651e-04\n",
      " -3.38014826e-04 -1.23487407e-04 -6.21698491e-05 -4.17320029e-04\n",
      " -5.69409400e-04 -2.07514400e-04  1.11014648e-04 -1.93982152e-04\n",
      " -7.61981428e-05  2.10588143e-04 -1.72359549e-04 -2.20016900e-05\n",
      " -9.09398805e-05  7.46277583e-05  3.10077041e-04 -1.39929380e-05\n",
      "  7.97815737e-05  3.04418008e-05 -8.37831431e-06 -4.44682548e-04\n",
      " -1.36744593e-05 -3.62413033e-04  5.50850120e-04 -6.12466072e-04\n",
      "  3.23331216e-04  1.20222496e-04  8.24464587e-05 -9.99732438e-05\n",
      "  4.47719467e-05 -1.10029459e-05  4.69874358e-05 -2.84948783e-05\n",
      "  3.00425687e-04  1.16635601e-04 -1.74352172e-04  4.16961178e-04\n",
      "  9.94922157e-05  1.36262446e-04 -1.69631661e-04 -2.38612178e-04\n",
      "  2.52576254e-04  2.13184801e-04  1.06198186e-05 -1.00380988e-04\n",
      " -9.21170213e-05 -1.07325599e-04 -2.12775165e-04  5.17795124e-05\n",
      " -1.31098565e-03  1.78164686e-04  4.83796830e-05 -9.56798904e-05\n",
      " -6.18127706e-06 -2.23103023e-04  4.59586299e-05 -2.28679964e-05\n",
      " -4.78890252e-05 -1.21068304e-04  5.32731829e-05  8.61783265e-05\n",
      " -3.67783854e-04 -9.16673798e-06  1.04375431e-04  2.16880740e-04\n",
      " -9.55226496e-05 -1.29338325e-04 -2.63234193e-04 -2.73149664e-04\n",
      " -3.89268898e-05 -2.17123830e-04  1.57289949e-04  8.01727991e-04\n",
      " -2.50343088e-04 -9.69989269e-05 -8.66459523e-05 -2.71097990e-04\n",
      "  6.78909943e-04 -1.62311757e-04 -4.65158606e-04  1.12768153e-04\n",
      "  4.73175169e-05  4.27739469e-05 -8.57129053e-05 -5.07091871e-04\n",
      "  1.56597787e-04  4.20552271e-04  1.06947460e-04  3.37117875e-04\n",
      " -8.11272694e-05 -3.31513729e-04  1.82398493e-04  6.95519411e-05\n",
      "  2.32683233e-04 -2.18988935e-04 -3.81797581e-04  5.09276761e-05\n",
      "  2.82709552e-05 -2.34172621e-05  6.06280264e-06 -1.59384901e-04\n",
      " -3.09115392e-04  2.32973354e-04 -1.03442690e-04 -2.28931225e-04\n",
      " -3.50187329e-04 -1.36077666e-04 -4.26613435e-04  8.02653522e-05\n",
      " -1.21642654e-04 -1.13378177e-04 -8.89277799e-05  4.02096426e-04\n",
      "  1.86955818e-04  2.18234112e-04 -3.85407446e-04 -1.63594712e-04\n",
      "  4.72977954e-05 -5.62544155e-04  8.62954912e-05  6.43547755e-05\n",
      "  8.33301419e-06 -1.99114496e-04 -7.47618687e-05 -1.66931670e-04\n",
      " -1.50903012e-04  1.35968643e-04  3.76084034e-04  1.39000971e-04\n",
      "  5.24710140e-06  1.96514331e-04  1.86010409e-04  8.76046488e-06\n",
      "  6.46321627e-04  7.69328690e-05 -1.40739794e-04 -1.60748095e-04\n",
      " -6.78872166e-05 -6.98793592e-05 -1.92017586e-04 -6.80659141e-05\n",
      " -2.88865558e-04 -3.26569279e-04 -5.94513840e-04  1.12185291e-04\n",
      " -2.37744651e-04 -2.28030967e-05 -1.39018593e-04 -1.86487669e-04]\n",
      "discriminator_11/conv_block_139/batch_normalization_215/gamma:0 [1.0019587  0.9831568  1.036363   0.98417896 1.0039619  1.0335134\n",
      " 0.9634996  0.98444146 1.0204998  1.0234588  0.99482954 0.99920255\n",
      " 1.0077806  0.99160504 1.0038637  0.9554191  1.0806082  0.9474613\n",
      " 0.96589017 0.9683229  1.0028105  0.9472945  0.9800515  1.0906435\n",
      " 1.014103   1.0141822  1.019667   1.0155255  1.074114   1.019698\n",
      " 0.95737463 1.0214716  0.94907963 1.0554954  0.98238254 0.98300695\n",
      " 1.0229431  0.96719205 0.94432706 1.13464    0.95356536 0.97335917\n",
      " 0.99854636 1.0362145  0.9865475  0.9915371  1.001794   0.97679347\n",
      " 0.9701522  0.99402773 1.0187774  1.0029875  1.1289862  0.99634165\n",
      " 1.0674757  1.1605853  0.99160355 0.97722894 0.98068696 0.9802395\n",
      " 0.9758832  0.98535275 1.0088409  0.99101233 0.99170303 1.1595278\n",
      " 0.9734996  0.9580452  1.038827   1.0006948  0.96845955 0.98168087\n",
      " 0.9694875  0.97993815 0.9742447  0.9535741  1.0589968  0.9627189\n",
      " 0.99038094 0.9651087  1.1301293  0.95847666 1.0148761  0.9755934\n",
      " 0.9615369  0.9716173  0.97655326 0.9696693  1.196034   1.0194067\n",
      " 1.0103841  0.98712224 1.038196   1.014851   0.9878994  1.0035623\n",
      " 1.0177623  1.1091917  0.9690404  0.94527954 0.9420314  0.9996448\n",
      " 1.0934445  0.95896393 1.0540005  1.0658497  0.96123177 0.9815058\n",
      " 0.9591696  0.9759075  1.0138309  1.0289656  1.002481   1.206322\n",
      " 0.95464706 0.9932037  0.98883724 0.9949486  0.97116095 1.0260419\n",
      " 1.0023644  0.9178985  1.0146534  1.018003   1.016749   1.1306845\n",
      " 0.9740452  0.9421069  0.97065157 0.9964173  0.9631642  0.973\n",
      " 0.96961784 0.97627664 0.9112863  0.98074955 0.99231666 1.0535768\n",
      " 0.9559053  0.9808429  1.0189148  0.9741779  0.98095894 1.0140191\n",
      " 0.999056   1.0136153  0.9794677  1.0066515  0.9751096  1.0391546\n",
      " 0.9879017  1.0173414  1.1924671  1.0968645  0.96687084 0.97646034\n",
      " 1.032394   0.9922378  0.9965213  1.0027897  1.0411956  1.0008247\n",
      " 0.9883492  0.97275674 0.9385332  1.0036547  0.9779303  0.98496675\n",
      " 1.0162474  1.0042799  0.9910916  0.9791217  1.0298016  0.99862003\n",
      " 0.9500858  1.0642501  0.98177826 0.9790527  0.9932269  1.1844438\n",
      " 1.0370544  0.9923951  0.9781612  1.078701   0.9674878  1.0063493\n",
      " 1.0243062  1.0908107  1.0086229  1.0761436  0.9615778  1.001081\n",
      " 1.0191364  1.0115348  0.9799923  0.99989635 1.0158565  0.99333954\n",
      " 0.9957371  0.9822942  0.99453807 1.121001   0.9789286  0.9752242\n",
      " 1.0328783  1.0498247  0.9999227  0.96173763 0.9909866  0.98416466\n",
      " 1.0162853  1.0420598  1.0321734  0.9702985  0.9941521  0.9918812\n",
      " 0.9882742  1.0705543  0.98638076 1.033249   1.028031   0.9708774\n",
      " 1.0436848  0.9830874  0.9624895  0.9760969  0.98855317 0.9825853\n",
      " 0.984711   0.99768245 0.9695517  1.015818   0.9820129  1.0406615\n",
      " 1.023184   1.1506133  1.0110797  0.9855501  1.1579186  0.9852699\n",
      " 1.1887213  0.9927287  1.0049652  0.9981643  1.0099775  1.021467\n",
      " 0.9346033  0.9952823  1.0059108  0.9752145  0.99651706 1.0216318\n",
      " 1.0226512  1.0258557  1.0329218  0.9692025 ]\n",
      "discriminator_11/conv_block_139/batch_normalization_215/beta:0 [ 2.29220726e-02 -3.38265416e-03  1.02043085e-01  2.56297067e-02\n",
      " -1.36960428e-02  5.57479523e-02 -2.37768181e-02 -7.64359981e-02\n",
      " -3.78197692e-02  1.34778228e-02 -3.89492176e-02 -2.78889779e-02\n",
      "  3.69243957e-02  4.17837203e-02  2.14294456e-02 -3.02708987e-02\n",
      " -2.92471889e-02 -2.53360718e-02  3.29551063e-02 -8.16877838e-03\n",
      " -1.35394350e-01 -2.03805063e-02  5.09756729e-02 -8.01882893e-02\n",
      "  7.80615211e-03  2.13483889e-02  6.70997128e-02  5.47780730e-02\n",
      " -5.67919835e-02 -1.93543937e-02 -3.89234126e-02 -5.91324689e-03\n",
      " -6.69152141e-02 -3.58484536e-02 -5.51278377e-03 -9.12527833e-03\n",
      " -5.31858392e-02 -4.03195694e-02 -2.32282653e-02 -1.39944954e-02\n",
      " -2.53706761e-02  2.97001712e-02 -4.17361036e-02  4.37672697e-02\n",
      "  2.43260823e-02  1.97457299e-02  3.59571329e-03 -7.45999143e-02\n",
      " -3.74281816e-02  7.27725998e-02 -2.67826626e-03 -2.28019990e-02\n",
      " -7.19475821e-02 -1.96409095e-02 -5.02198748e-02 -4.59509753e-02\n",
      "  1.70015525e-02 -3.85383479e-02  1.36264917e-02  2.91530490e-02\n",
      " -7.28264591e-03 -4.47842218e-02 -1.32837715e-02  3.20446454e-02\n",
      " -1.08578093e-02 -1.22417510e-01 -1.39741311e-02 -3.13618071e-02\n",
      "  6.53171688e-02 -1.42599572e-03 -4.27212864e-02 -7.28704594e-03\n",
      " -3.04057868e-03  2.19229590e-02 -8.73494148e-03 -4.06415984e-02\n",
      "  8.55032355e-03  1.81407463e-02 -9.21398401e-03 -3.31463129e-03\n",
      " -4.05677631e-02  6.48054667e-03  4.07508053e-02  4.15964685e-02\n",
      " -1.39042415e-04 -1.18077397e-02  2.65206359e-02  7.27207353e-03\n",
      " -1.66359022e-02  3.44272405e-02 -1.03690907e-01 -2.88871918e-02\n",
      " -1.79782435e-02 -4.61141989e-02  5.04500382e-02 -3.31090530e-03\n",
      "  3.70923541e-02 -4.84373793e-02 -3.76077890e-02 -1.97290145e-02\n",
      " -2.96605900e-02 -5.37412288e-03 -3.26852687e-02  7.61988340e-03\n",
      " -4.91633154e-02  2.01697135e-03  2.86304113e-03  1.88841447e-02\n",
      " -2.02267338e-02 -5.50419874e-02  3.92571799e-02  6.40825853e-02\n",
      " -3.77541855e-02  4.15388644e-02  9.12143696e-06  1.28151551e-02\n",
      "  3.25884707e-02 -3.28474939e-02 -1.09505039e-02  5.26253274e-03\n",
      " -6.67907111e-03 -4.88353409e-02  8.06328654e-02 -3.13846022e-02\n",
      "  3.88743501e-05 -3.52482758e-02 -2.81245280e-02 -4.68414314e-02\n",
      "  1.06956447e-02 -2.67453454e-02 -2.86312923e-02 -1.09418491e-02\n",
      " -4.48357873e-02 -2.37930398e-02 -4.62367460e-02 -7.52413599e-03\n",
      "  1.96218714e-02 -7.41577521e-02 -1.96658541e-02 -2.12833472e-02\n",
      "  5.08468933e-02  1.15608862e-02  7.84708560e-03  6.02621436e-02\n",
      " -2.80159852e-03 -4.43853263e-04  3.43879987e-03 -1.19595751e-02\n",
      " -1.79833174e-02 -3.67789306e-02 -1.67858358e-02 -3.49698886e-02\n",
      " -3.53936553e-02 -6.90442026e-02 -2.98359618e-02 -3.13674062e-02\n",
      " -2.27985345e-02  2.51182169e-02 -9.49153770e-03  4.41522859e-02\n",
      "  7.43226409e-02 -1.21485919e-03 -1.09889293e-02 -2.22988557e-02\n",
      " -2.67961752e-02  8.64519272e-03 -1.10159046e-03  3.45944352e-02\n",
      " -3.91760394e-02  3.11506987e-02  7.84033611e-02 -7.77854621e-02\n",
      " -1.48886396e-02 -4.19524536e-02 -1.03689395e-02 -7.11366087e-02\n",
      " -6.47132695e-02 -1.28056034e-02 -9.90660861e-03 -8.22799876e-02\n",
      " -6.98367879e-02  2.37330254e-02 -3.83867435e-02  6.01282227e-04\n",
      " -2.38679014e-02  2.37215339e-04 -8.18746258e-03  1.84477959e-02\n",
      " -4.77252714e-03  4.00807010e-03 -1.00187259e-02 -2.06184071e-02\n",
      "  6.13458231e-02  1.42948190e-02 -5.55115417e-02 -5.82921766e-02\n",
      " -8.69054794e-02 -6.77634915e-03  1.98775381e-02 -3.03672906e-02\n",
      " -6.80999458e-02 -1.11261364e-02 -1.75142847e-02  2.78912531e-03\n",
      "  5.88579997e-02  2.38753632e-02  5.71964942e-02 -1.16295308e-01\n",
      "  2.18380820e-02  1.64728537e-02 -1.04454271e-02  6.42478559e-03\n",
      " -3.35579813e-02  4.86837998e-02 -1.10518662e-02  3.95472674e-03\n",
      "  3.03748045e-02 -5.61050996e-02  2.11400841e-03 -7.68173113e-02\n",
      " -7.41533283e-03  2.16344669e-02  1.15018496e-02 -8.04491341e-04\n",
      "  3.98560287e-03 -1.51998671e-02  2.17485223e-02 -8.85067806e-02\n",
      " -4.71517108e-02  3.23855807e-03  4.81896102e-03  4.20107594e-04\n",
      " -3.20321023e-02 -6.60228804e-02 -3.71118560e-02 -4.52533625e-02\n",
      "  4.58108680e-03  2.39287503e-02 -7.01903552e-02 -4.40459400e-02\n",
      " -6.92517608e-02  5.12705259e-02  2.03359276e-02 -7.83141702e-02\n",
      "  6.10147007e-02  5.54809272e-02 -4.05728407e-02 -8.56510326e-02\n",
      "  2.47432981e-02  1.32405432e-02 -1.21522853e-02  8.80505741e-02\n",
      " -7.55486079e-03  8.06905925e-02  1.02775684e-02  2.51881778e-04]\n",
      "discriminator_11/conv_block_140/conv2d_140/kernel:0 [[[[-2.04271916e-02  2.86845844e-02 -1.35832233e-02 ...  3.70083353e-03\n",
      "     1.79835260e-02 -4.11328999e-03]\n",
      "   [-2.19410770e-02 -1.06947785e-02 -2.43945420e-03 ...  7.50702014e-03\n",
      "     8.09543882e-04 -5.68527787e-04]\n",
      "   [-5.51773086e-02 -9.65946168e-02 -3.24500576e-02 ...  5.71500622e-02\n",
      "    -2.07177307e-02  2.09817495e-02]\n",
      "   ...\n",
      "   [ 2.44397745e-02 -2.03791540e-03 -6.69527501e-02 ... -6.59756875e-03\n",
      "    -9.34362318e-03 -5.63068539e-02]\n",
      "   [-1.94031037e-02  3.11456695e-02 -1.32703306e-02 ... -4.46022376e-02\n",
      "    -1.15736173e-02  1.82132609e-02]\n",
      "   [-2.78940909e-02 -4.27227840e-02  6.30228315e-03 ...  1.60113536e-02\n",
      "    -2.24096812e-02  3.39177772e-02]]\n",
      "\n",
      "  [[ 1.65965240e-02  5.65253384e-02 -5.67462202e-03 ...  1.67236279e-03\n",
      "     3.78840677e-02  5.97754642e-02]\n",
      "   [-5.13226949e-02 -6.65465891e-02 -1.55286221e-02 ...  7.30311200e-02\n",
      "     2.72621808e-04 -3.62189226e-02]\n",
      "   [ 6.24627946e-03 -1.40162837e-02 -5.59242023e-03 ...  3.90100218e-02\n",
      "    -5.51695786e-02 -1.88993085e-02]\n",
      "   ...\n",
      "   [ 1.91379115e-02  8.59023444e-03  4.17488478e-02 ...  1.06123341e-02\n",
      "    -4.14088406e-02 -6.84888512e-02]\n",
      "   [ 3.58758718e-02  5.02664708e-02  1.73726096e-03 ... -1.72172375e-02\n",
      "     2.27009915e-02 -2.87727285e-02]\n",
      "   [ 4.97401170e-02 -2.04203576e-02 -1.82206649e-02 ...  6.54179826e-02\n",
      "    -1.35827903e-02 -1.55453710e-02]]\n",
      "\n",
      "  [[ 5.85163720e-02  3.17692943e-02 -3.12130004e-02 ...  4.93138283e-02\n",
      "    -5.67635335e-02 -4.36003506e-02]\n",
      "   [-5.72732985e-02 -2.97525097e-02  1.05795618e-02 ... -2.57196948e-02\n",
      "     3.03868018e-02 -7.07014184e-03]\n",
      "   [-9.32808071e-02 -5.69715835e-02 -1.30122257e-02 ...  4.83633690e-02\n",
      "    -8.02266877e-03 -1.13166394e-02]\n",
      "   ...\n",
      "   [ 4.81912419e-02 -2.75888685e-02  1.23571418e-02 ... -5.26427962e-02\n",
      "     1.12847378e-02 -1.19709596e-02]\n",
      "   [ 4.85469177e-02  2.35293689e-03 -2.53094062e-02 ... -1.42496225e-04\n",
      "     2.59739533e-02  1.12721906e-03]\n",
      "   [ 2.75203791e-02  3.24180052e-02  4.29170206e-02 ...  1.60964224e-02\n",
      "     2.53141262e-02  2.12551765e-02]]]\n",
      "\n",
      "\n",
      " [[[-1.16883935e-02 -1.26551948e-02 -3.85270603e-02 ...  3.60295624e-02\n",
      "    -2.96087097e-02  4.45037521e-02]\n",
      "   [-3.83869335e-02  1.10489875e-02 -1.12401033e-02 ... -1.31071091e-03\n",
      "    -4.97562764e-03 -8.25888570e-03]\n",
      "   [-7.10335299e-02 -8.53717625e-02 -2.41416246e-02 ...  4.88200411e-02\n",
      "    -1.00499522e-02 -2.00360455e-03]\n",
      "   ...\n",
      "   [ 7.33831078e-02 -2.53528953e-02  5.44545501e-02 ...  6.20298320e-03\n",
      "    -4.18792181e-02  2.63454113e-02]\n",
      "   [ 3.84490639e-02  4.96396571e-02  2.83447304e-03 ... -1.89621467e-02\n",
      "    -1.17144026e-02 -6.33485056e-03]\n",
      "   [ 6.14218116e-02  1.94295645e-02  5.84537024e-03 ...  2.09882203e-02\n",
      "    -4.56201434e-02  1.62962675e-02]]\n",
      "\n",
      "  [[ 5.89871872e-03 -3.25571909e-03 -2.23053060e-02 ...  2.00260971e-02\n",
      "     4.37345207e-02 -1.07003730e-02]\n",
      "   [ 1.75586138e-02 -6.64163567e-03 -4.10791487e-03 ... -2.34496873e-02\n",
      "    -1.43677695e-02  9.62197967e-03]\n",
      "   [-4.83733937e-02 -7.41507262e-02 -4.82160524e-02 ...  5.14089391e-02\n",
      "     1.99405123e-02  2.67546363e-02]\n",
      "   ...\n",
      "   [ 5.39420731e-03 -2.97333840e-02 -6.18068539e-02 ...  2.27838792e-02\n",
      "    -1.13129374e-02  1.85120329e-02]\n",
      "   [-6.58153789e-03  2.94967648e-03 -2.94158608e-03 ... -7.37759769e-02\n",
      "     7.15495367e-03 -5.73976114e-02]\n",
      "   [-1.87272374e-02  2.20917389e-02  2.25242018e-03 ...  7.21835298e-03\n",
      "    -6.53641149e-02  3.21206227e-02]]\n",
      "\n",
      "  [[-4.07813024e-03  7.89621321e-04 -3.90668660e-02 ... -1.20761395e-02\n",
      "    -3.41076478e-02 -6.50263298e-03]\n",
      "   [-1.99251100e-02  1.45944413e-02 -3.71540897e-02 ... -2.52859714e-03\n",
      "     3.98632232e-03 -1.15875248e-03]\n",
      "   [-1.42125696e-01 -1.01611838e-01 -1.21652726e-02 ...  4.78380173e-02\n",
      "    -1.76432654e-02 -1.92454401e-02]\n",
      "   ...\n",
      "   [-7.87177123e-03 -1.85709185e-04 -3.62027176e-02 ...  2.12645344e-02\n",
      "    -1.17776962e-02  4.53804247e-02]\n",
      "   [-1.26442825e-02  5.18399961e-02 -1.44164693e-02 ... -9.41027924e-02\n",
      "     2.81415996e-03 -2.14599166e-03]\n",
      "   [-5.56404926e-02  1.63513478e-02 -4.32142317e-02 ...  1.09207379e-02\n",
      "    -3.37365232e-02  8.23678598e-02]]]\n",
      "\n",
      "\n",
      " [[[ 3.42792049e-02  3.94265354e-02 -1.19399978e-02 ...  4.58177142e-02\n",
      "     5.19002043e-02 -3.44298594e-02]\n",
      "   [-3.90444174e-02 -2.97053326e-02 -1.69787742e-02 ...  4.19500992e-02\n",
      "     1.45014152e-02  1.53384171e-02]\n",
      "   [-9.88647044e-02 -1.45967558e-01  6.39393851e-02 ...  4.40886542e-02\n",
      "    -1.85326841e-02 -2.24607643e-02]\n",
      "   ...\n",
      "   [ 1.76529083e-02  2.85361474e-03 -8.61902721e-03 ... -8.89434479e-03\n",
      "    -4.13939916e-02  1.13022802e-02]\n",
      "   [-3.33186388e-02  7.11553022e-02  9.20238718e-03 ... -3.43506262e-02\n",
      "     2.78898180e-02 -4.25657295e-02]\n",
      "   [-6.84591383e-02 -5.65992557e-02 -1.93750244e-02 ...  2.80083232e-02\n",
      "     3.76976654e-02 -2.56148931e-02]]\n",
      "\n",
      "  [[ 1.39711434e-02 -3.86008918e-02  7.33823376e-03 ...  4.14318815e-02\n",
      "    -2.26433985e-02  3.19184735e-02]\n",
      "   [-3.78082581e-02 -2.21413020e-02  2.08933763e-02 ... -8.54451302e-03\n",
      "     5.01360670e-02 -2.40179454e-03]\n",
      "   [-7.83500895e-02 -8.16120952e-02  1.19464817e-02 ...  6.27089068e-02\n",
      "     3.00676394e-02  3.07997949e-02]\n",
      "   ...\n",
      "   [ 6.01534732e-02  1.15207843e-02  2.67579425e-02 ... -4.98197302e-02\n",
      "    -3.98986228e-02  8.65968596e-03]\n",
      "   [ 1.41261043e-02  1.81278046e-02  4.77817236e-03 ... -6.08103313e-02\n",
      "     3.90213728e-02 -5.40610626e-02]\n",
      "   [ 1.54266739e-03 -4.59932089e-02  5.58943562e-02 ...  5.50898053e-02\n",
      "    -3.66193913e-02  2.93568783e-02]]\n",
      "\n",
      "  [[-7.31981685e-03  3.55942734e-02 -3.14777950e-03 ...  7.78734358e-03\n",
      "    -2.89305691e-02 -4.66396427e-03]\n",
      "   [ 1.92411523e-02 -4.05101688e-04  3.18498313e-02 ... -2.17488892e-02\n",
      "     2.36592796e-02 -3.56211117e-03]\n",
      "   [-1.30995929e-01 -5.02721630e-02  2.12469921e-02 ...  2.59924680e-02\n",
      "     2.22897269e-02  3.28259915e-02]\n",
      "   ...\n",
      "   [ 4.70390692e-02 -1.08061973e-02  3.60689536e-02 ... -2.01016897e-03\n",
      "    -1.72220953e-02  2.67162900e-02]\n",
      "   [-1.12310471e-02  1.24461912e-02 -4.94946539e-02 ... -5.07030748e-02\n",
      "     2.75800414e-02  3.83497886e-02]\n",
      "   [-1.35338260e-02 -2.40012892e-02 -1.26476260e-03 ... -1.34008089e-02\n",
      "     2.36762837e-02  4.31832187e-02]]]]\n",
      "discriminator_11/conv_block_140/conv2d_140/bias:0 [-1.53183020e-04 -1.46455655e-04  2.68596661e-04  1.23128601e-04\n",
      "  7.46802398e-05  1.94579145e-04 -8.63847345e-06 -1.39958443e-04\n",
      " -6.11388532e-05  1.77742884e-04  3.27755733e-05  3.54207674e-04\n",
      "  4.30823246e-04  6.49173671e-07  5.31236992e-06  2.32898630e-04\n",
      " -2.44564289e-04 -7.17932999e-05  1.52208755e-04  1.26146260e-04\n",
      "  1.12412796e-04  2.71515437e-05  1.82091404e-04  1.53910543e-04\n",
      "  1.71666659e-04  6.02970773e-04 -7.92568098e-05  1.02413824e-05\n",
      "  1.27950640e-04  3.11390293e-04 -1.62494980e-04 -1.50290944e-04\n",
      " -5.34767605e-06 -3.18139282e-05 -3.30726762e-04  2.51807796e-04\n",
      " -7.33405323e-05  9.14646225e-05 -6.86237618e-05  1.54651687e-04\n",
      " -1.17391814e-04  8.95229095e-05 -9.19037848e-05 -7.67452439e-05\n",
      " -2.03688305e-05  2.31892136e-06  1.02590799e-04  2.16541652e-04\n",
      "  5.22144604e-04 -3.48705682e-04 -2.47624208e-04 -1.77500679e-05\n",
      "  3.50724382e-04 -3.24385837e-05  9.06188234e-06 -7.46298974e-05\n",
      " -7.94735897e-05  3.57401848e-04  5.65098235e-05  1.49029584e-04\n",
      "  1.81633004e-04  8.20640889e-06  3.19415412e-05  3.74029310e-06\n",
      "  5.24058181e-04 -5.81877306e-04 -5.38971253e-05 -2.31014754e-04\n",
      "  4.26205588e-05 -3.42558167e-04 -1.07591550e-04 -1.99040209e-04\n",
      "  1.74620523e-04 -2.60780856e-04 -2.24466974e-04  1.96161636e-04\n",
      " -1.12692316e-04  1.49996107e-04 -6.62798411e-05 -1.18948046e-04\n",
      " -2.66176012e-05 -2.48398628e-05 -2.48614699e-04 -4.79904993e-04\n",
      " -1.42277000e-04  2.73568701e-04 -1.35783193e-04  2.67904670e-05\n",
      "  8.34333914e-05 -3.04325455e-04  2.38116809e-05 -7.98485562e-05\n",
      " -2.86235707e-04  2.73558035e-05 -5.31395257e-04  4.27513383e-04\n",
      " -5.30052785e-05  5.49928300e-05 -8.59511420e-05  1.53251385e-04\n",
      " -1.24276208e-04  9.12109854e-08  1.26142204e-05  4.97499423e-04\n",
      "  2.94850644e-04  1.09590746e-05 -3.58258287e-04  1.51498185e-04\n",
      "  1.07703425e-04 -2.66658812e-04 -2.65695235e-05 -4.03569371e-04\n",
      " -7.96764143e-05  6.44011656e-04 -1.39388358e-04  1.99647082e-04\n",
      " -1.49055428e-04  3.58885118e-05 -1.29408858e-04  1.62478493e-04\n",
      " -1.57996561e-04 -2.01272182e-04 -8.58993226e-05 -1.97962563e-05\n",
      "  5.22956616e-05  6.05588313e-04  1.87286187e-05 -1.13999056e-04]\n",
      "discriminator_11/conv_block_140/batch_normalization_216/gamma:0 [0.99986565 0.9888199  1.0158179  0.914697   0.9681966  1.0104493\n",
      " 1.0100098  0.936618   1.0670217  0.9760867  0.92769873 1.096132\n",
      " 1.084286   1.1433325  0.9738655  1.0138588  0.98652506 0.987301\n",
      " 1.0295187  0.9327513  0.9827751  0.96818435 1.0181458  0.98178095\n",
      " 0.9431832  0.93325365 1.0236409  0.9022174  1.1732359  0.9986467\n",
      " 1.0204251  1.1466962  0.96022516 0.9834316  0.9496364  0.9171895\n",
      " 1.0391668  0.96021616 0.9639696  0.9589176  1.0326627  0.9861083\n",
      " 0.9758916  1.0143442  0.92479765 0.9980101  1.0246631  0.9620636\n",
      " 1.1548057  0.92100084 1.0192636  1.01728    0.96920556 0.9400716\n",
      " 0.97849864 0.9598593  0.98284936 1.0607984  1.0377116  1.0105339\n",
      " 0.9817077  0.9931621  0.9941831  1.015183   0.99184966 1.2319146\n",
      " 1.021318   0.937179   0.9199248  1.0236174  0.95296705 0.9781933\n",
      " 1.1747113  0.9533615  1.0225976  1.0020465  1.0032007  0.9411627\n",
      " 0.9650579  0.9668233  0.95908374 1.019494   0.96291053 0.97836024\n",
      " 0.93349403 1.1078826  1.0588558  1.0368962  0.9327829  0.94716316\n",
      " 1.0553658  0.9897226  1.0572952  1.0007701  0.9998715  1.1489116\n",
      " 0.9585939  0.965034   0.96643466 0.99679023 0.9827348  0.92440104\n",
      " 1.1743261  1.0042117  0.91151154 0.98736197 0.9168652  0.9372149\n",
      " 1.0045472  1.0376216  0.9697527  1.2169724  1.001757   1.0719424\n",
      " 0.9183654  0.9449747  0.9861074  0.9253115  0.8843411  1.0801262\n",
      " 1.0043765  1.1225693  0.9856826  0.9750747  0.92233384 1.2191403\n",
      " 1.0835376  0.9938091 ]\n",
      "discriminator_11/conv_block_140/batch_normalization_216/beta:0 [ 0.00148698 -0.01770195  0.01706592 -0.0370936   0.01362949 -0.03542023\n",
      " -0.05889761  0.00486082 -0.04829882 -0.02956495  0.01385389  0.01338484\n",
      "  0.06395848  0.06610326 -0.0020555  -0.03088805 -0.01797986  0.01230681\n",
      "  0.00170798 -0.05774881 -0.04327711 -0.01180147 -0.02264217 -0.0116823\n",
      " -0.04173662 -0.00314691  0.08798951 -0.03849497  0.05267514 -0.01610751\n",
      "  0.01185301  0.07086124 -0.02589525  0.07651496  0.01947688 -0.01528103\n",
      "  0.02447824 -0.0124765   0.03529938 -0.00429334  0.06573658  0.04986044\n",
      " -0.05455996  0.02298638 -0.03538132  0.03448697  0.05736731  0.00893968\n",
      " -0.06904685 -0.09212881  0.00299397  0.05283408 -0.09918681 -0.01197736\n",
      " -0.00252159  0.01633717  0.02879307  0.0112987  -0.00826022  0.03121683\n",
      " -0.07865318  0.04780189 -0.00250404  0.05276415 -0.00616941  0.10141256\n",
      " -0.00353366 -0.04950845 -0.00919416  0.01255039  0.04936164  0.01504601\n",
      "  0.07740763  0.01806379 -0.04146771 -0.04546262 -0.0065556  -0.0270574\n",
      "  0.01119057  0.01429499 -0.0299523   0.01465837  0.04761619  0.00931618\n",
      " -0.068726    0.0303772   0.00395346  0.08130234 -0.02949017  0.0150481\n",
      "  0.02174666  0.01259479 -0.05971568 -0.00925209  0.01041201  0.10103877\n",
      "  0.01098463 -0.00523335 -0.00646479 -0.1027441  -0.08937395 -0.01838113\n",
      "  0.07680298 -0.03338559  0.00263918 -0.00367288 -0.04381322 -0.05567449\n",
      "  0.0561033   0.02190529 -0.0144384   0.02295934  0.00831961 -0.1729084\n",
      " -0.04557731 -0.00304004 -0.01917558 -0.03692082 -0.05968702 -0.04998736\n",
      " -0.07191752 -0.0129779   0.02177589  0.0216962  -0.04379731  0.08423597\n",
      "  0.04482306  0.05637058]\n",
      "discriminator_11/conv_block_141/conv2d_141/kernel:0 [[[[ 6.69737207e-03  8.04534182e-03  5.47847077e-02 ...  6.53645247e-02\n",
      "    -1.17923301e-02 -7.35666305e-02]\n",
      "   [-4.41554151e-02  8.61828029e-02 -6.50830269e-02 ... -6.69611171e-02\n",
      "     3.61502394e-02 -3.22151035e-02]\n",
      "   [ 1.96262985e-03  6.37972355e-02  6.72644079e-02 ... -3.64050008e-02\n",
      "    -6.71623554e-03  6.54465938e-03]\n",
      "   ...\n",
      "   [-6.46961555e-02  8.31592828e-03  3.62772867e-02 ...  3.81554700e-02\n",
      "    -4.96262573e-02  1.63901914e-02]\n",
      "   [ 1.10037014e-01  3.26275341e-02  1.06473053e-02 ...  3.99871245e-02\n",
      "    -5.13043106e-02  4.43548299e-02]\n",
      "   [-5.20152263e-02 -1.59585532e-02 -3.20814662e-02 ... -5.81078418e-03\n",
      "     1.69779565e-02  2.20277831e-02]]\n",
      "\n",
      "  [[ 3.93131748e-02  9.91339143e-03 -5.93836419e-02 ... -5.84327765e-02\n",
      "     1.02945007e-01 -4.00043055e-02]\n",
      "   [ 7.71425068e-02  3.25419977e-02 -4.22364771e-02 ... -4.37049083e-02\n",
      "     7.29550049e-03 -1.76637862e-02]\n",
      "   [ 3.49475555e-02  2.02324707e-02  2.26591788e-02 ... -7.18759373e-03\n",
      "    -4.42070775e-02  1.33082429e-02]\n",
      "   ...\n",
      "   [-9.94004235e-02  9.38429385e-02 -1.10608019e-01 ... -4.45197150e-02\n",
      "    -8.44830498e-02  1.04822457e-01]\n",
      "   [ 3.74872945e-02  4.36906032e-02 -2.75076162e-02 ...  2.52936371e-02\n",
      "    -2.05532443e-02 -5.08798063e-02]\n",
      "   [ 3.03521771e-02 -6.77668154e-02 -6.78049847e-02 ... -5.91765083e-02\n",
      "     2.63820179e-02 -3.68486857e-03]]\n",
      "\n",
      "  [[ 2.22858489e-02  2.59596333e-02 -1.72252916e-02 ... -1.62543077e-02\n",
      "    -3.64127085e-02 -3.98583785e-02]\n",
      "   [ 5.19507118e-02  3.60648073e-02 -7.18584284e-03 ... -9.46264714e-03\n",
      "    -5.58019429e-03  4.82999608e-02]\n",
      "   [ 3.87045257e-02  3.93443555e-02  1.17411837e-01 ... -9.20870993e-03\n",
      "    -7.33268633e-02  5.01266867e-02]\n",
      "   ...\n",
      "   [-7.17549548e-02  2.30333656e-02  1.87716540e-02 ... -2.81933546e-02\n",
      "     1.06351390e-01  4.84225433e-03]\n",
      "   [-9.66317300e-03  5.26309982e-02 -8.85690562e-03 ...  9.29720758e-04\n",
      "     5.08499667e-02 -8.01864937e-02]\n",
      "   [ 9.73125473e-02 -3.14237997e-02 -7.44218454e-02 ...  6.55933022e-02\n",
      "     2.47504078e-02 -7.62791857e-02]]]\n",
      "\n",
      "\n",
      " [[[-2.40628910e-03  4.27820198e-02  5.50338663e-02 ...  4.05899063e-02\n",
      "    -6.18175254e-04 -6.73440052e-03]\n",
      "   [-6.32436946e-02  4.71891724e-02  1.09328344e-01 ... -7.17739686e-02\n",
      "     5.17962947e-02  4.31804061e-02]\n",
      "   [-7.83633348e-03  2.88253985e-02 -3.16165201e-02 ...  9.67851933e-03\n",
      "     3.23159769e-02  4.18913811e-02]\n",
      "   ...\n",
      "   [ 2.32632719e-02 -5.03765047e-02  7.68256858e-02 ... -6.20684996e-02\n",
      "    -5.56682535e-02  8.94559175e-02]\n",
      "   [ 1.08754449e-01 -2.47132921e-05  2.62118839e-02 ... -3.87396142e-02\n",
      "     1.74733400e-02  1.17085958e-02]\n",
      "   [ 6.63639605e-02 -4.57893796e-02  8.44930485e-02 ... -4.60653231e-02\n",
      "    -6.04305565e-02  1.25994242e-03]]\n",
      "\n",
      "  [[-1.20138563e-02 -6.26352131e-02  8.90487246e-03 ...  5.37794642e-03\n",
      "     7.57123753e-02 -2.45006606e-02]\n",
      "   [-5.80276782e-03  1.52786495e-02  2.16000080e-02 ...  1.76284928e-02\n",
      "     5.40747829e-02 -3.14509682e-02]\n",
      "   [-2.20722035e-02 -8.26846063e-03  5.88042811e-02 ... -3.26890163e-02\n",
      "    -6.02529161e-02 -8.09003562e-02]\n",
      "   ...\n",
      "   [-9.58003998e-02  5.84824830e-02  1.76612735e-02 ... -4.27831858e-02\n",
      "    -8.80778730e-02  1.43003553e-01]\n",
      "   [ 8.19930881e-02  4.21809927e-02  3.17193940e-02 ... -1.89793191e-03\n",
      "    -6.12420477e-02  6.81261241e-04]\n",
      "   [ 4.23627421e-02 -6.72790706e-02  3.72337736e-02 ...  2.74056513e-02\n",
      "    -3.47426273e-02  1.34851066e-02]]\n",
      "\n",
      "  [[ 1.05233617e-01  8.11035931e-02  4.75119660e-03 ...  1.05381124e-02\n",
      "    -3.81041728e-02 -1.34266280e-02]\n",
      "   [-1.09462105e-02  2.24592611e-02 -6.81144372e-02 ... -5.23665827e-03\n",
      "    -5.47858402e-02 -2.01563127e-02]\n",
      "   [ 9.01691325e-04 -2.31186282e-02 -2.02557407e-02 ... -1.58749595e-02\n",
      "    -5.23289517e-02 -3.55075672e-02]\n",
      "   ...\n",
      "   [-9.29205790e-02  1.98670253e-02  5.35435714e-02 ... -3.29466886e-03\n",
      "     1.42054006e-01  7.61619732e-02]\n",
      "   [ 1.78278442e-02  2.16422454e-02  2.99853925e-02 ...  5.50839007e-02\n",
      "    -1.96340084e-02  1.85894482e-02]\n",
      "   [ 2.97888108e-02 -6.42152876e-02  6.59624487e-02 ... -4.03144397e-02\n",
      "    -7.15268478e-02 -9.07456949e-02]]]\n",
      "\n",
      "\n",
      " [[[ 8.70991871e-02  2.68133841e-02 -7.50935674e-02 ...  3.24297473e-02\n",
      "     4.53526303e-02  6.27594739e-02]\n",
      "   [ 7.58551434e-02 -4.16536108e-02 -6.22587129e-02 ... -1.60225015e-02\n",
      "     5.94488867e-02  9.95749328e-03]\n",
      "   [ 4.54050787e-02  1.63672697e-02 -7.22073019e-02 ... -3.99010815e-02\n",
      "     1.25055769e-02  8.71040393e-03]\n",
      "   ...\n",
      "   [ 5.29324673e-02 -6.82285130e-02  8.04697052e-02 ...  2.32542008e-02\n",
      "    -7.61190057e-02  1.01789936e-01]\n",
      "   [-2.36241184e-02  5.03135063e-02  2.71081217e-02 ...  2.59499787e-03\n",
      "     7.68892886e-03  8.99198726e-02]\n",
      "   [-3.52912433e-02 -2.57822480e-02 -4.86598760e-02 ... -2.64108498e-02\n",
      "     2.68805568e-04 -5.12764342e-02]]\n",
      "\n",
      "  [[ 7.86772147e-02 -5.37085161e-02 -1.14682898e-01 ... -5.49430586e-02\n",
      "     3.12010068e-02 -1.58363860e-02]\n",
      "   [ 5.08712381e-02 -9.56073217e-03 -3.03587765e-02 ... -1.38358958e-03\n",
      "     2.51094922e-02  6.47685751e-02]\n",
      "   [-8.38673860e-03  5.71808033e-02 -9.24097653e-03 ... -7.29252622e-02\n",
      "    -2.66987178e-02  5.48218153e-02]\n",
      "   ...\n",
      "   [ 3.20812464e-02  1.07032858e-01 -1.60209239e-02 ...  4.37127203e-02\n",
      "     8.15489423e-03  1.83723554e-01]\n",
      "   [ 4.27910164e-02 -6.33660406e-02  3.25630046e-02 ... -1.60862561e-02\n",
      "     3.44542712e-02  2.51105540e-02]\n",
      "   [ 5.37294429e-03 -5.21698818e-02 -3.84502001e-02 ...  5.97189181e-02\n",
      "     1.44801466e-02 -5.64746372e-02]]\n",
      "\n",
      "  [[-5.23708500e-02 -4.16131020e-02 -5.35465144e-02 ... -7.38158524e-02\n",
      "     9.62783620e-02 -8.36846158e-02]\n",
      "   [ 4.91287410e-02  4.96902689e-02 -7.03358203e-02 ... -5.88288642e-02\n",
      "     1.00094257e-02  7.20610004e-03]\n",
      "   [ 4.79031578e-02 -4.02675830e-02  7.50843063e-02 ... -4.08428498e-02\n",
      "     4.09001112e-02  6.57045916e-02]\n",
      "   ...\n",
      "   [ 5.55785522e-02 -6.00172393e-02  1.17300889e-02 ...  9.51591227e-03\n",
      "     5.64228520e-02  1.73368044e-02]\n",
      "   [ 7.91826695e-02  2.57859994e-02 -3.21870297e-02 ... -6.13679402e-02\n",
      "    -2.61532068e-02  6.91489056e-02]\n",
      "   [ 1.12592742e-01 -5.86162470e-02 -7.73055851e-02 ... -6.47594425e-05\n",
      "     7.61998743e-02 -4.30187322e-02]]]]\n",
      "discriminator_11/conv_block_141/conv2d_141/bias:0 [ 4.55118679e-05 -2.17035515e-04  5.09852776e-04 -6.58024685e-04\n",
      "  3.15395941e-04 -1.14821378e-04 -2.04355863e-04  1.77249865e-04\n",
      " -1.63647099e-04 -2.07744830e-04  3.88326938e-04 -1.03136197e-04\n",
      " -4.89185855e-04 -8.10941929e-05 -1.67153077e-04  5.17165790e-05\n",
      " -4.93592815e-05  1.28293963e-04  2.67828409e-06 -9.21607425e-04\n",
      " -4.47047612e-04 -1.52110122e-04 -1.75662164e-04  7.08853477e-05\n",
      "  2.33540573e-04  5.43533247e-07  5.89866715e-04  2.30822712e-04\n",
      "  1.67699018e-05  1.15874130e-03 -1.21744371e-04  2.32865708e-03\n",
      " -1.12156500e-04 -4.11976071e-04  4.87620564e-05  2.48509896e-04\n",
      " -1.96998240e-04  8.99400766e-05 -1.22904443e-04 -3.54397896e-04\n",
      " -4.45216312e-04  6.83188628e-05  9.91378256e-05  4.84173826e-04\n",
      "  4.46721504e-04 -1.65373727e-04  4.38336574e-04  4.05928731e-05\n",
      " -4.24037949e-04  1.16525458e-04  3.75616539e-04  2.30755075e-04\n",
      " -1.32046000e-03 -1.85819474e-04 -1.22653146e-04 -3.93652736e-04\n",
      "  1.96437104e-04 -9.53759227e-05  1.04588347e-04  1.60362601e-04\n",
      " -1.26328829e-04  6.04618923e-04 -6.57386699e-05  4.11035544e-05\n",
      " -3.29135510e-05  7.69826525e-04  4.16956842e-04 -5.75671904e-04\n",
      "  1.70286967e-05  1.13089533e-04  2.69592536e-04 -1.91373692e-04\n",
      "  3.82492261e-04  3.74287483e-04  4.70437772e-05  1.90187609e-04\n",
      "  2.17764071e-04  2.82414170e-04  9.12438009e-06  3.52605130e-04\n",
      " -5.50703902e-04  1.50697335e-04 -1.23756894e-04 -2.71698285e-04\n",
      "  3.39895487e-04  1.71075924e-04  1.51940680e-04 -5.41690446e-04\n",
      "  3.46407352e-04  1.06836138e-04 -1.45128055e-04  3.09569034e-04\n",
      "  2.91597622e-04  1.67006074e-05 -2.36521941e-04 -1.02173035e-04\n",
      " -2.44780618e-04  3.63710220e-04 -3.33428528e-04 -1.34073271e-04\n",
      "  6.96430681e-04  4.47451835e-04 -4.39477735e-04 -1.28563595e-04\n",
      " -2.40838810e-04  3.13842727e-04 -8.55855105e-05  3.83795938e-04\n",
      "  3.87651060e-04  1.61262287e-04  5.63194335e-04  9.02939501e-05\n",
      " -4.56931652e-04 -2.26867633e-04  1.60016920e-04  4.21376753e-04\n",
      "  2.97415700e-05  3.80673999e-04 -3.67252418e-04  3.81373829e-04\n",
      " -2.90848489e-04 -1.68265658e-04  4.56181820e-04  5.48780663e-04\n",
      "  8.66490009e-05  3.07353039e-04  1.95346031e-04  1.65367455e-04]\n",
      "discriminator_11/conv_block_141/batch_normalization_217/gamma:0 [0.9367187  1.0552937  1.1514482  0.9924225  1.0976793  1.0091566\n",
      " 1.0002472  0.92361873 1.009741   0.96683884 0.95551616 1.0024762\n",
      " 0.9512368  0.9500059  0.948843   0.9839546  1.054266   0.98747975\n",
      " 0.93366355 1.1964917  0.9793944  0.9384408  0.88929456 0.96830773\n",
      " 0.90796655 0.9811921  1.1231935  0.96645164 0.9937172  1.2191613\n",
      " 0.97075933 1.0410095  1.050372   0.876394   1.0311514  0.9833507\n",
      " 0.9869602  1.1702745  1.0081514  1.00225    0.93952996 0.89296883\n",
      " 0.98405564 0.9351414  0.97025794 0.9602594  1.0153584  0.9920888\n",
      " 0.9930927  0.9124203  1.0233155  1.1564406  1.0002182  0.9888493\n",
      " 0.9225122  1.0633576  1.18758    0.92539835 0.9898714  0.94866\n",
      " 1.0160998  1.066654   0.9650653  0.9330603  1.0405279  1.041851\n",
      " 0.966299   0.9514486  0.9912514  1.0292939  1.0152942  1.0106196\n",
      " 1.1161565  1.0091327  1.0006192  1.0403996  0.95715666 0.9901675\n",
      " 0.9480753  0.9816831  0.9978869  0.9939765  0.9305338  1.0369992\n",
      " 0.9911199  1.0693811  0.97112894 1.1716968  1.1259205  0.98214304\n",
      " 0.9379625  0.9582389  1.0106959  1.0119212  0.96432996 0.9686901\n",
      " 0.9883801  1.0100265  0.9972754  1.0189583  1.102105   1.0235069\n",
      " 0.9417231  1.0280333  0.9259306  0.94665736 0.91912484 0.9778915\n",
      " 0.9194252  0.9908463  0.96300197 1.0018796  0.9842397  1.1333113\n",
      " 0.90626574 0.9695183  0.96037304 1.145941   0.9696719  1.0348155\n",
      " 0.9418997  0.9755003  0.971596   0.9913595  1.0034755  1.0332077\n",
      " 1.037117   1.0559571 ]\n",
      "discriminator_11/conv_block_141/batch_normalization_217/beta:0 [-0.01228226  0.05734232  0.08000062  0.02378686  0.00946158  0.0081582\n",
      "  0.02397964 -0.04649993  0.03497106 -0.03757542 -0.03022524  0.00717371\n",
      "  0.00956727  0.00938579 -0.0214677  -0.00062023 -0.01361859  0.03484317\n",
      " -0.02799858  0.08938678  0.01639436  0.00985823 -0.04087112 -0.0032416\n",
      " -0.02595745 -0.01291013  0.03948653  0.01183391  0.01154406  0.09743278\n",
      "  0.01183029  0.05022285  0.02445625 -0.06797794  0.05964745  0.011305\n",
      "  0.02560562  0.05729729  0.00029443  0.02706373 -0.01183077 -0.02638325\n",
      "  0.01548717 -0.02000455  0.00215657 -0.00354202  0.0099146   0.04962897\n",
      " -0.03485226 -0.02630047  0.03037548 -0.03775387  0.02764499  0.00402153\n",
      " -0.00973755  0.00017961  0.08991188 -0.0026333   0.03564615  0.00586637\n",
      " -0.00997178  0.05194205 -0.0214369  -0.04839969 -0.01949914  0.03312823\n",
      "  0.02155837  0.01769724  0.02374243  0.03479188  0.02889436 -0.00609566\n",
      "  0.02501601  0.0050432   0.00514288  0.0103028  -0.01078393  0.01179439\n",
      "  0.00335553  0.03306136 -0.04242863  0.04661851 -0.00897496  0.02948236\n",
      "  0.04312978 -0.00916646 -0.02600203  0.06631849  0.00953049  0.01894326\n",
      " -0.02758681 -0.00266226  0.01718559 -0.00210226  0.02237377 -0.01582981\n",
      "  0.00023596 -0.00982315  0.03912985  0.03934287  0.05050427  0.01802002\n",
      " -0.04587265 -0.01799735 -0.03347776  0.01284481 -0.01641976 -0.03919464\n",
      "  0.00727571 -0.02451329 -0.00638813 -0.00248987 -0.00222578  0.0309518\n",
      " -0.0255591   0.0014017  -0.0010894   0.14123331  0.02361775  0.01516115\n",
      " -0.01986868  0.00603109  0.00061407 -0.0061217   0.01577408  0.02393825\n",
      "  0.0177689  -0.02087008]\n",
      "discriminator_11/conv_block_142/conv2d_142/kernel:0 [[[[-0.04604021 -0.00691818 -0.1179385  ...  0.18664345 -0.1789343\n",
      "    -0.14704436]\n",
      "   [ 0.1414698  -0.13283704  0.04349517 ... -0.13876177  0.11669847\n",
      "     0.07246712]\n",
      "   [ 0.2738918  -0.21837357  0.10295194 ... -0.07366852 -0.09332989\n",
      "    -0.13031156]\n",
      "   ...\n",
      "   [ 0.06864464 -0.07457137 -0.06830757 ... -0.18760224  0.03687429\n",
      "    -0.29607433]\n",
      "   [-0.0948886   0.04492226  0.12986499 ...  0.18385921  0.20613466\n",
      "    -0.14960057]\n",
      "   [ 0.13717754  0.15363435 -0.06287877 ... -0.04448768  0.03249956\n",
      "     0.02385273]]]]\n",
      "discriminator_11/conv_block_142/conv2d_142/bias:0 [-8.3167775e-05  1.5664246e-04  1.1521935e-03 -7.5329741e-04\n",
      " -5.4682670e-05  3.9013117e-04  7.6198875e-04 -3.5416801e-04\n",
      "  4.0344225e-04 -2.5052403e-04  1.9586114e-04 -5.3056481e-04\n",
      " -4.6897494e-05  5.1051833e-05  3.3396477e-04 -4.5225676e-04\n",
      "  3.8233853e-04  8.3116081e-04 -3.8721936e-04  1.0250957e-03\n",
      " -1.1775681e-04  4.0492396e-05  1.4569482e-04 -2.4165294e-05\n",
      " -1.6230284e-04 -1.2735213e-04  6.0021610e-04  4.9849012e-04\n",
      "  8.2568586e-04 -2.9250165e-04  8.7706430e-05  6.2960287e-04\n",
      " -3.1177246e-04 -1.1983957e-03  2.7297667e-04 -7.8218203e-05\n",
      " -4.3901725e-04 -4.7402291e-04  1.0434793e-03 -8.9837704e-04\n",
      "  4.0776572e-06  7.9538487e-04 -8.9778285e-04  1.5678175e-03\n",
      "  4.1216638e-04 -7.7133613e-05 -3.0882453e-04  5.0036341e-04\n",
      "  5.2753538e-05  5.5946210e-05  7.0262970e-05  4.6464589e-05\n",
      " -9.6672814e-04  4.4066142e-04  3.7886982e-04  4.3568338e-04\n",
      " -1.0146191e-03 -1.8135154e-04  1.2961106e-03  9.0273315e-05\n",
      " -5.1832508e-04  1.0580507e-03 -2.0514309e-04 -4.5505146e-04\n",
      " -1.8958261e-04  2.4327401e-04 -4.0210524e-04  5.1054300e-04\n",
      "  1.1374857e-03  4.0252399e-04  6.3969794e-04  1.9572679e-05\n",
      "  1.3839216e-03 -6.4062874e-04  4.6215355e-04  1.2781977e-04\n",
      " -1.4708571e-04  4.7978060e-04 -6.1919977e-04  3.8890910e-04\n",
      " -4.8049405e-05 -2.1455091e-05  3.5183635e-04 -7.8082387e-04\n",
      "  4.2741525e-04  6.2781444e-05  1.3077403e-04 -2.1698714e-04\n",
      "  3.2072185e-04 -2.0057823e-04  1.3308454e-03 -1.6845259e-04\n",
      "  6.2661152e-04  4.6048555e-04  2.1895710e-04 -6.8611972e-04\n",
      "  7.0353656e-04  2.7998954e-05  2.1961720e-04 -2.9811988e-04\n",
      " -2.1523207e-04  3.3448261e-05 -5.3205778e-04  7.5764826e-04\n",
      " -9.0500844e-06  3.1325134e-04 -2.6597240e-04  1.5281112e-04\n",
      "  1.8468477e-04  1.0474728e-03  3.2126743e-04  1.0828814e-04\n",
      "  5.0192251e-04 -1.4496174e-04  3.2880151e-04 -1.4938888e-04\n",
      " -1.1981610e-03  4.6174537e-04  3.1150031e-04 -2.4724301e-04\n",
      "  3.5528908e-04  3.5227882e-04 -2.5134603e-04 -1.4346373e-05\n",
      "  2.9564294e-06 -7.4625399e-04  2.9675033e-05  5.0274271e-04]\n",
      "discriminator_11/conv_block_142/batch_normalization_218/gamma:0 [1.0336374  1.0167675  1.0572252  1.0005995  0.9456005  1.0531778\n",
      " 0.99630225 1.0208275  1.015678   1.0655175  0.98057467 1.0530472\n",
      " 1.0353353  0.94733083 1.005824   0.9962366  1.0111809  1.0019957\n",
      " 1.0773735  0.96278    1.0333204  0.9984306  1.0026288  0.92319447\n",
      " 1.0739447  0.99591315 0.9603368  0.9757793  1.0094725  1.1042101\n",
      " 0.9857531  0.9913604  1.008601   0.9911809  1.0805418  0.9228244\n",
      " 1.0100484  1.0079252  1.0085648  1.0363415  1.0262382  0.98277473\n",
      " 0.99928576 0.97874427 1.0085053  0.9805218  1.0083934  1.0016204\n",
      " 0.99037844 1.0363781  1.0064399  0.9816597  1.1310991  1.0144717\n",
      " 1.11222    1.0525706  0.97161305 1.0394639  0.9796494  0.97930515\n",
      " 0.948202   1.0953016  0.96018916 1.1851041  0.9811084  1.0303558\n",
      " 1.0296634  0.99410236 1.1002339  1.0576596  1.0411112  1.0258518\n",
      " 0.9973456  0.964581   1.0090843  0.9956899  0.97827625 1.1474264\n",
      " 1.0365441  0.9456404  1.0081736  1.1509705  1.0053761  1.0197847\n",
      " 1.0434545  0.9792206  1.0380871  1.0972527  0.9980841  1.0120264\n",
      " 0.96793616 0.9946132  0.99266344 1.0275563  0.9035506  1.1803099\n",
      " 0.9664086  0.9807308  0.9715958  1.018464   1.0006032  1.0014825\n",
      " 0.92511654 1.0005022  1.0055405  1.0065304  0.99805963 0.9926394\n",
      " 0.9617223  1.0426497  1.0105442  1.0306575  0.9769169  0.974801\n",
      " 0.9708112  1.0060934  0.99345237 1.0350633  0.9975593  1.0142796\n",
      " 0.9805145  1.0140208  0.9531961  0.95875275 1.0486296  0.9956382\n",
      " 0.99938506 0.99838436]\n",
      "discriminator_11/conv_block_142/batch_normalization_218/beta:0 [-0.07431196 -0.03690346 -0.07128251 -0.07777938  0.0375021   0.02269742\n",
      "  0.02870778 -0.00728266  0.05606298  0.10910666 -0.04028432 -0.0434785\n",
      "  0.05782561 -0.02225056  0.02567896  0.01289476  0.0390577   0.01018695\n",
      "  0.05925049 -0.03772369  0.02727441 -0.03608985  0.0160536  -0.03337448\n",
      " -0.00879839 -0.09373143 -0.0192527  -0.02044325  0.05073625  0.08299862\n",
      "  0.00514611  0.07047844  0.04656187 -0.00150956  0.0768379  -0.01515285\n",
      " -0.0268558   0.06063307 -0.04755199 -0.01323303  0.03913446  0.01409952\n",
      " -0.00133114 -0.02272551  0.06366138  0.0187326  -0.03666621 -0.00947548\n",
      " -0.04493263  0.07301592  0.00821641 -0.00615073  0.09142631  0.02841927\n",
      " -0.05036953 -0.03348723 -0.04917002  0.02700473 -0.02089586 -0.04766096\n",
      "  0.01530614  0.03491399 -0.00787184  0.10582473 -0.0054034   0.00703788\n",
      " -0.04470037  0.01720795  0.02384477  0.05746667  0.04912513  0.00012582\n",
      " -0.06158321  0.00115747  0.03034255 -0.03699848 -0.00846191 -0.05643139\n",
      " -0.01970887 -0.05440334 -0.01530954  0.01666719  0.04226531 -0.01692402\n",
      "  0.05832759 -0.07034726  0.00991421  0.06703218  0.01069102 -0.01167597\n",
      " -0.03721416  0.01922749 -0.00991017  0.00062666 -0.05432856  0.1030997\n",
      " -0.04043156  0.03388136  0.05113934  0.0302254  -0.03761728  0.04661863\n",
      " -0.04394645  0.04569087  0.02206085  0.02468164  0.01048582  0.0910651\n",
      " -0.01449385  0.05966152  0.01090863  0.07804619  0.00553842 -0.01074279\n",
      " -0.00821178  0.00642403  0.0459895   0.04310095 -0.01905121 -0.02016898\n",
      " -0.03030221  0.01574985  0.00238725 -0.0234853  -0.00784265 -0.00021406\n",
      "  0.03625476 -0.00318418]\n",
      "discriminator_11/conv_block_143/conv2d_143/kernel:0 [[[[ 0.04804629  0.02126581 -0.03410098 ... -0.01194346  0.03172104\n",
      "    -0.09266701]\n",
      "   [ 0.00491682  0.0544504   0.10281128 ...  0.075032    0.00864698\n",
      "    -0.04274181]\n",
      "   [-0.04765932 -0.04936465 -0.02629962 ...  0.0098403  -0.05236741\n",
      "    -0.0185558 ]\n",
      "   ...\n",
      "   [-0.0243862   0.06443199  0.01466506 ...  0.02326505  0.0545496\n",
      "     0.01986737]\n",
      "   [-0.04844528 -0.00886212 -0.03501173 ... -0.05621401 -0.06367177\n",
      "    -0.02095317]\n",
      "   [-0.04199561  0.02083531  0.04556011 ... -0.03694227  0.03139344\n",
      "    -0.0133766 ]]\n",
      "\n",
      "  [[-0.02679829 -0.04020437 -0.01790823 ... -0.01526971  0.02343938\n",
      "    -0.09198628]\n",
      "   [ 0.11611512  0.02792672  0.01731725 ... -0.06167131 -0.0169308\n",
      "    -0.06261934]\n",
      "   [-0.02292418 -0.06602591  0.01417325 ... -0.07561555  0.11516695\n",
      "     0.01144502]\n",
      "   ...\n",
      "   [ 0.06303611  0.09718283 -0.043664   ...  0.05600729  0.00145495\n",
      "     0.06549796]\n",
      "   [-0.106416    0.00802663 -0.11011799 ...  0.01278154 -0.0474452\n",
      "    -0.12798461]\n",
      "   [ 0.01087279  0.06743944  0.08517    ...  0.07333145 -0.03350883\n",
      "    -0.06742094]]\n",
      "\n",
      "  [[-0.03789116 -0.06715395 -0.01769702 ...  0.02501561  0.01985783\n",
      "     0.00479721]\n",
      "   [ 0.02533481  0.07061867  0.02550541 ...  0.06246686  0.00399143\n",
      "    -0.01021677]\n",
      "   [-0.07230195  0.05651358  0.07094406 ...  0.02499409  0.01388967\n",
      "    -0.02343493]\n",
      "   ...\n",
      "   [-0.01133677  0.08445124  0.03023499 ... -0.0408943   0.00723592\n",
      "    -0.10561937]\n",
      "   [-0.02926148  0.00026087 -0.06054606 ...  0.07863067  0.03152709\n",
      "    -0.05017055]\n",
      "   [-0.00923008 -0.00592517  0.11821092 ... -0.07250196  0.03638372\n",
      "    -0.06679875]]]\n",
      "\n",
      "\n",
      " [[[ 0.01770564  0.0014967   0.11534837 ... -0.0652045  -0.01184596\n",
      "    -0.02896573]\n",
      "   [-0.0316794  -0.07124979  0.04254312 ...  0.04520517 -0.00384441\n",
      "     0.01357481]\n",
      "   [-0.07322069  0.00702642  0.01427034 ...  0.00425124  0.05949913\n",
      "     0.02388135]\n",
      "   ...\n",
      "   [ 0.02656796 -0.00854045 -0.05855444 ...  0.01942403  0.00040624\n",
      "     0.03609539]\n",
      "   [-0.04388281 -0.05248608  0.05563756 ...  0.03855523  0.05040948\n",
      "    -0.04646087]\n",
      "   [-0.03431717  0.00168688 -0.03272004 ...  0.04065853 -0.02976872\n",
      "    -0.03041625]]\n",
      "\n",
      "  [[-0.04864523 -0.0708499   0.05353248 ... -0.02146513  0.03401661\n",
      "    -0.08802256]\n",
      "   [ 0.01864416  0.03554776 -0.00748853 ... -0.05895755  0.04890431\n",
      "     0.07757062]\n",
      "   [-0.00999216  0.04537876  0.01330417 ... -0.08861494  0.06860314\n",
      "    -0.03774597]\n",
      "   ...\n",
      "   [ 0.00291504  0.04215593  0.0083794  ...  0.04933009 -0.03433907\n",
      "    -0.00085967]\n",
      "   [-0.00483645  0.04816347 -0.01506126 ...  0.03800135  0.02518572\n",
      "     0.01890539]\n",
      "   [-0.05521407  0.04597244  0.02731026 ...  0.06128113  0.04759515\n",
      "    -0.05328241]]\n",
      "\n",
      "  [[ 0.02523479 -0.00655756 -0.07437541 ... -0.03754552  0.07093512\n",
      "     0.04732252]\n",
      "   [-0.05412906  0.03365011  0.04274988 ... -0.00072193  0.03762648\n",
      "    -0.0620922 ]\n",
      "   [ 0.02547031  0.05312987 -0.05289742 ... -0.04214497  0.06069741\n",
      "    -0.02418781]\n",
      "   ...\n",
      "   [-0.02480256 -0.02177702  0.04622563 ... -0.0168793   0.0201364\n",
      "    -0.038173  ]\n",
      "   [-0.04436693  0.0764104  -0.04475455 ... -0.07269853  0.06681635\n",
      "    -0.05056543]\n",
      "   [-0.00697276  0.05343127 -0.03686746 ... -0.04231343  0.01326499\n",
      "    -0.04679612]]]\n",
      "\n",
      "\n",
      " [[[-0.0821544  -0.01481751 -0.04108481 ... -0.07415283 -0.02778234\n",
      "     0.02475762]\n",
      "   [ 0.00800921 -0.03619137  0.06794664 ... -0.02825251 -0.0254302\n",
      "     0.04117294]\n",
      "   [-0.00247425 -0.03751582  0.03049911 ... -0.06049565  0.04857274\n",
      "     0.00495239]\n",
      "   ...\n",
      "   [ 0.02265896 -0.00120943  0.00865363 ... -0.00104058  0.05144702\n",
      "     0.09339705]\n",
      "   [ 0.00442284  0.03987522  0.01377684 ... -0.05108544 -0.00267861\n",
      "    -0.02805901]\n",
      "   [-0.00564411 -0.02248698  0.02768556 ...  0.03867572  0.01534487\n",
      "     0.03178263]]\n",
      "\n",
      "  [[-0.04219652  0.03749192 -0.07028081 ... -0.0105332   0.03515611\n",
      "    -0.07040889]\n",
      "   [ 0.01501611 -0.03870139 -0.08631033 ...  0.02836791  0.03056349\n",
      "    -0.049293  ]\n",
      "   [-0.0900839   0.08624177  0.02575066 ... -0.03543882  0.01497295\n",
      "    -0.08686292]\n",
      "   ...\n",
      "   [-0.00016825 -0.08979341 -0.06329903 ... -0.03102062  0.00692517\n",
      "    -0.02362794]\n",
      "   [-0.07176899  0.02161784 -0.02927322 ... -0.02074959 -0.02422757\n",
      "    -0.05765505]\n",
      "   [-0.09144204  0.04734251 -0.0744032  ...  0.04202469  0.07548007\n",
      "     0.02200264]]\n",
      "\n",
      "  [[-0.0634802   0.06286854  0.09061297 ...  0.10408555 -0.04043389\n",
      "    -0.02458095]\n",
      "   [-0.08434615  0.05435165 -0.10814324 ... -0.0091967  -0.0244135\n",
      "    -0.03882354]\n",
      "   [-0.0382932   0.07072259  0.09295438 ... -0.06248975  0.056484\n",
      "     0.05304453]\n",
      "   ...\n",
      "   [-0.06186678  0.01704654  0.05663701 ... -0.00603925  0.01809541\n",
      "     0.03352913]\n",
      "   [-0.0515864   0.05923769 -0.06272845 ...  0.07211944  0.06527203\n",
      "    -0.06089551]\n",
      "   [ 0.0017518  -0.03759377  0.04320838 ...  0.06275319  0.03171287\n",
      "     0.05120395]]]]\n",
      "discriminator_11/conv_block_143/conv2d_143/bias:0 [ 3.2564663e-04  1.2410649e-03  3.3369460e-04 -9.2582595e-06\n",
      " -3.3060191e-04 -6.1012612e-04  4.1804035e-04  6.7285378e-05\n",
      " -2.4280295e-04  3.9602144e-04 -1.7163728e-04  3.7181098e-04\n",
      "  6.6126441e-04 -5.2087079e-04  1.1199423e-03 -3.9749741e-04\n",
      "  1.0146013e-04 -3.3969272e-04  5.4214121e-04  6.2948751e-04\n",
      "  3.0223551e-04  4.9344631e-04 -1.2651658e-04  3.7766295e-04\n",
      "  3.7390040e-04  7.7714577e-07 -1.1164815e-03 -2.9846415e-04\n",
      " -9.9249752e-05 -3.6552493e-04 -1.2743539e-05  4.6478052e-04\n",
      "  1.8116531e-04  9.1200712e-04  5.0787388e-05 -7.2951626e-04\n",
      " -3.1385006e-04  2.0583945e-04 -3.2317569e-04  1.8822814e-04\n",
      "  1.5976065e-03 -4.6810627e-04 -4.6684483e-05  3.1973689e-04\n",
      " -7.9347385e-04  4.8588600e-04 -5.0192839e-04 -1.8083280e-03\n",
      "  1.0229868e-03  1.0356486e-03 -7.0694652e-05  1.6237686e-04\n",
      " -4.0258202e-04  3.5474473e-04 -6.8205199e-04  1.1682671e-03\n",
      "  9.5971691e-04 -2.3897487e-04 -1.7767647e-04  2.4339039e-04\n",
      " -1.5422526e-04  2.9162897e-04 -9.0693496e-04 -1.4649262e-04]\n",
      "discriminator_11/conv_block_143/batch_normalization_219/gamma:0 [0.9709259  0.8659306  0.9545353  0.98513854 1.0434779  0.8783111\n",
      " 0.8762198  0.9476653  0.95704025 1.1651132  0.96096313 1.1415825\n",
      " 0.82503176 0.9372808  1.0897987  0.97047216 1.031331   0.8681692\n",
      " 1.1976293  1.0686367  1.047785   1.0284922  0.95094746 0.9615032\n",
      " 1.1205723  0.89011586 0.9083303  0.8986228  0.9758138  0.8682154\n",
      " 1.0259516  0.96440023 0.9532096  1.1522622  0.88795054 0.96318865\n",
      " 1.0105346  0.9193155  0.90306944 1.0000483  0.980141   1.0056161\n",
      " 1.0035065  1.0571167  0.9362053  0.93105596 0.91490847 0.8565431\n",
      " 1.1857653  1.0188575  0.9113375  1.1506262  1.2218992  0.98506266\n",
      " 1.0333306  0.9540502  0.87821585 0.977674   1.0331765  0.94471055\n",
      " 1.2295316  0.88065267 1.0149574  1.0526888 ]\n",
      "discriminator_11/conv_block_143/batch_normalization_219/beta:0 [-0.04899851 -0.08781096 -0.01722291  0.00596221 -0.0177175  -0.08701618\n",
      " -0.06065022 -0.1099543   0.0169668  -0.01665341  0.01214355 -0.01026892\n",
      " -0.14080891 -0.08375085 -0.08773687 -0.02323922  0.00619637 -0.05588292\n",
      "  0.0752926   0.00804046  0.04927452  0.01247945  0.00038298  0.00859974\n",
      "  0.0151733  -0.01786645 -0.07863142 -0.07606251 -0.02936046 -0.11402068\n",
      "  0.04707807 -0.03479277 -0.03703394  0.09734922 -0.05347124  0.04285779\n",
      "  0.00601172  0.03294441 -0.05369638  0.04546883  0.06263039  0.03580921\n",
      " -0.0559718   0.05311191 -0.02574555 -0.0270245  -0.04963362 -0.06745281\n",
      "  0.04424707 -0.02316392 -0.0489119   0.09211203  0.14655194 -0.00222608\n",
      "  0.00241676 -0.03041091 -0.04533208 -0.06579033 -0.01017466  0.040634\n",
      "  0.07381766 -0.04568823 -0.05786792  0.04406213]\n",
      "discriminator_11/conv_block_144/conv2d_144/kernel:0 [[[[ 0.340388    0.07627428 -0.1560576  ... -0.05248933 -0.18522702\n",
      "    -0.27364394]\n",
      "   [ 0.04566991  0.08300785 -0.02224474 ... -0.2676368   0.09641377\n",
      "     0.07703039]\n",
      "   [ 0.24761355  0.08923205  0.11310614 ...  0.14469336  0.06547843\n",
      "     0.00862913]\n",
      "   ...\n",
      "   [-0.07022431  0.20948426  0.14087382 ...  0.33204654 -0.01529896\n",
      "    -0.03907786]\n",
      "   [-0.2594057   0.00791087  0.33750933 ... -0.23368597  0.16272801\n",
      "    -0.01421074]\n",
      "   [ 0.1333515   0.06585411 -0.1068828  ...  0.06359069  0.25254965\n",
      "    -0.20071454]]]]\n",
      "discriminator_11/conv_block_144/conv2d_144/bias:0 [-4.7452131e-04 -1.1831473e-03  8.5711607e-04 -1.3750169e-03\n",
      " -1.2836235e-03  5.4567156e-04  2.8601149e-04 -3.0022178e-05\n",
      " -2.8037429e-03  1.1650417e-03 -1.5353541e-03  9.2282722e-04\n",
      " -1.2425977e-03  4.4216562e-04 -1.3118639e-04  1.0746690e-03\n",
      " -2.0414847e-04 -2.8555517e-04  1.6857979e-03  2.3655008e-04\n",
      "  5.6471827e-04  2.7860861e-04  6.0291693e-04  2.8467173e-04\n",
      "  1.2148797e-03  6.0999719e-04  1.0280373e-03  1.4474990e-03\n",
      " -1.1188176e-03  1.0308647e-03 -2.5368158e-03 -1.8393331e-03\n",
      " -9.5048518e-04 -1.2898076e-04  6.6346792e-04 -7.8820146e-04\n",
      "  2.0695184e-03 -3.8006972e-04  1.9187572e-03 -1.9418792e-04\n",
      " -5.5500411e-04  1.5700140e-04  1.0014386e-03 -9.5765985e-04\n",
      "  6.9367199e-04 -2.6599143e-04 -4.7791976e-04 -8.8474917e-05\n",
      " -6.1707408e-04 -1.7614041e-06  9.7438472e-04 -2.5268356e-04\n",
      " -1.8458308e-04 -2.7732123e-04 -8.0444623e-04  6.9701957e-04\n",
      "  1.3527659e-03 -6.0214102e-04  9.4761876e-05 -3.1426302e-04\n",
      "  2.2698347e-03 -1.2050539e-03 -8.1070559e-04  5.0108961e-04]\n",
      "discriminator_11/conv_block_144/batch_normalization_220/gamma:0 [0.9483532  0.8769353  1.0360074  1.3096406  0.8305185  0.821069\n",
      " 1.0684259  1.2589538  0.82070744 0.892953   0.9083839  0.9166188\n",
      " 0.7993267  1.080396   0.8194586  0.9162106  1.0830457  1.1035606\n",
      " 0.92880034 1.0463707  1.2639607  0.8773632  0.96021086 0.935016\n",
      " 1.0444084  0.8365416  1.2764366  0.798589   1.2390747  1.1539116\n",
      " 1.0492054  1.2629069  0.8957129  1.0526717  1.1579512  0.90896994\n",
      " 0.8220444  1.255167   1.2947891  0.84529155 0.80287856 1.2258799\n",
      " 0.9718999  1.2431264  0.9817474  0.8550926  0.80310565 1.0104415\n",
      " 0.8310745  1.1608588  0.8401079  0.87489885 1.1592027  1.2233638\n",
      " 0.85452765 1.0575652  1.0072825  1.0777996  1.2926639  1.0224549\n",
      " 1.2352581  0.80675775 0.8252526  1.236436  ]\n",
      "discriminator_11/conv_block_144/batch_normalization_220/beta:0 [-0.07646607 -0.13434152 -0.10518036  0.18765138 -0.15780152 -0.16272229\n",
      "  0.02092675  0.1585213  -0.19703035 -0.12906949 -0.11155277 -0.11198666\n",
      " -0.20565428  0.05793808 -0.19820626 -0.16251403  0.09658313  0.02888494\n",
      " -0.06027533  0.0216896   0.04943508 -0.09424224 -0.01370584 -0.10982114\n",
      "  0.03577711 -0.18226576  0.00022491 -0.19230247  0.09963628  0.04968499\n",
      " -0.10346722  0.06233095 -0.13110869 -0.02217704  0.12307445 -0.08338515\n",
      " -0.1587786   0.14551203  0.17893979 -0.16482024 -0.16953915  0.16846287\n",
      " -0.0008711   0.1724383  -0.05177871 -0.11629615 -0.20645729 -0.02269171\n",
      " -0.10682305  0.10567112 -0.18174729 -0.10715083  0.07380759  0.07092419\n",
      " -0.14657624 -0.04638625 -0.02304034  0.01444419  0.16030805  0.00199791\n",
      "  0.16049017 -0.20821285 -0.18502945  0.08244171]\n",
      "discriminator_11/conv_block_136/batch_normalization_212/moving_mean:0 [ 8.25820342e-02 -1.30216375e-01  1.09528756e+00  3.29913534e-02\n",
      "  2.52356548e-02  2.85148174e-01  8.68700668e-02 -2.40081996e-01\n",
      " -1.62348196e-01 -2.61946529e-01  5.13713658e-01  3.48173708e-01\n",
      " -8.57100487e-02 -2.39314251e-02 -3.13752979e-01 -5.38684726e-01\n",
      "  5.09322226e-01 -1.16632569e+00  6.63325071e-01 -4.97219205e-01\n",
      "  7.23094344e-01 -2.48418480e-01  1.99469980e-02 -3.00225496e-01\n",
      " -1.69006959e-01  1.90795008e-02  8.09662819e-01 -7.27010658e-03\n",
      "  1.06094964e-01  3.35219085e-01 -1.73528679e-02 -3.83172780e-01\n",
      "  8.82864475e-01  6.29192650e-01  2.85050184e-01  5.66803038e-01\n",
      "  1.20809603e+00 -3.39075364e-02 -4.26521897e-01 -2.16084123e-02\n",
      " -6.74020350e-01 -9.39366315e-03  5.52863657e-01  8.55434775e-01\n",
      " -8.86516809e-01 -9.92084201e-03  4.59541380e-01  2.27380782e-01\n",
      " -3.29714686e-01 -1.27515629e-01  7.13945031e-01  1.11424506e+00\n",
      " -4.36646432e-01  4.75435466e-01 -2.10338876e-01  1.15151092e-01\n",
      " -1.59932720e-03 -2.82509834e-01 -1.61754024e+00  1.86238289e-01\n",
      "  4.03326780e-01  7.05497086e-01  7.62410820e-01  6.73216403e-01\n",
      " -5.37334144e-01  5.90593457e-01 -5.18164150e-02  1.97183266e-01\n",
      " -9.57215205e-02 -6.02968156e-01 -6.01947904e-02 -8.91545117e-02\n",
      "  3.19807231e-03 -8.92484002e-03 -1.83576375e-01 -2.47677818e-01\n",
      "  1.49116948e-01 -7.89321437e-02 -8.94098058e-02 -1.22423045e-01\n",
      "  7.73637474e-01 -1.90268233e-02 -2.17835218e-01 -1.98805705e-01\n",
      "  2.88814962e-01  9.72569525e-01  4.30380374e-01  2.02476270e-02\n",
      "  3.31340469e-02  7.43707120e-02  2.37898797e-01 -5.47572039e-02\n",
      "  5.69195375e-02 -2.85147689e-02  1.52745172e-01 -6.89412057e-01\n",
      " -5.11194766e-02  2.49286234e-01 -1.38172880e-01 -4.13521519e-03\n",
      "  1.86872840e-01  7.13313162e-01  9.08343852e-01  2.55128860e-01\n",
      "  1.69536829e-01 -4.65854943e-01 -6.01584554e-01 -9.73757636e-03\n",
      "  1.99456394e-01 -6.51622787e-02  6.06856108e-01 -6.14519827e-02\n",
      "  8.80407467e-02  3.05064470e-01  4.50820848e-02  6.40882730e-01\n",
      " -1.25022626e+00 -3.45378846e-01 -5.40837288e-01 -3.72215807e-02\n",
      "  2.18457729e-01  4.92379934e-01 -2.68882334e-01 -5.51961623e-02\n",
      "  2.70041406e-01 -2.20422707e-02  4.85525072e-01 -1.94280833e-01\n",
      " -2.21653476e-01  4.69849378e-01 -3.31590623e-01 -5.72648756e-02\n",
      "  5.19652605e-01 -5.38576357e-02 -9.30441141e-01 -1.84522441e-03\n",
      "  5.51969945e-01 -1.72305346e-01  1.18227935e+00 -7.53827453e-01\n",
      " -1.33053258e-01  4.60592300e-01  2.90289044e-01 -2.05885246e-01\n",
      " -3.50692123e-02  2.23378420e-01 -1.88317642e-01 -5.46293080e-01\n",
      "  1.31173924e-01  7.14889765e-02  1.05315924e-01 -9.37096681e-03\n",
      " -9.18252885e-01  3.97100955e-01  2.18156433e+00  2.47816592e-01\n",
      "  5.42766273e-01 -1.34199572e+00 -1.08530927e+00  3.97979319e-01\n",
      " -1.64321855e-01  8.95444274e-01  4.09037173e-01  3.87021869e-01\n",
      "  9.32450294e-01  3.36638510e-01  6.59414291e-01 -1.53573990e-01\n",
      " -1.92594633e-01 -3.55614312e-02 -1.17873204e+00 -3.17941904e-01\n",
      "  3.88677627e-01  1.05539560e+00 -1.45841971e-01  4.53089118e-01\n",
      "  1.31049603e-02  2.66713947e-01 -1.91841386e-02  5.47979632e-03\n",
      "  6.25081062e-01 -2.46579554e-02  7.70554662e-01  6.04222476e-01\n",
      " -2.95490444e-01 -9.90291983e-02 -6.13843184e-03 -2.23595798e-01\n",
      "  2.76736587e-01  7.83379853e-01 -4.90354467e-03 -6.36161685e-01\n",
      "  1.28574014e-01 -3.82991165e-01  2.05050871e-01 -1.71010301e-01\n",
      "  3.92131776e-01 -2.59420037e-01  3.14870596e-01 -2.92422503e-01\n",
      "  1.56693712e-01 -6.09086752e-01  1.53693140e-01  5.97116113e-01\n",
      " -8.25267017e-01 -2.27109030e-01 -2.70928559e-03  1.32661414e+00\n",
      " -2.50381142e-01  2.37878814e-01  2.00323761e-02  9.04505700e-02\n",
      "  6.69950694e-02 -1.97498068e-01 -3.69430095e-01  8.40177476e-01\n",
      " -7.03014970e-01  7.00800240e-01 -8.71382207e-02  3.94144893e-01\n",
      " -5.26128232e-01 -3.32376957e-01 -8.96763861e-01 -2.49395698e-01\n",
      " -1.80119529e-01 -1.47898889e+00  2.51191169e-01 -8.56046498e-01\n",
      "  2.36289650e-02 -7.72150308e-02  6.55578971e-01  8.57275426e-01\n",
      "  3.14574093e-01  7.18208432e-01  1.27307460e-01 -5.04753768e-01\n",
      "  5.73241770e-01 -7.47902021e-02  5.22562027e-01 -1.24126053e+00\n",
      " -1.47993445e-01 -7.62902319e-01 -9.54149723e-01  6.91470325e-01\n",
      "  1.22435331e-01 -8.59923959e-01  3.35315466e-01 -4.07404974e-02\n",
      "  2.54590452e-01 -5.37068963e-01 -3.85726541e-01 -1.49660945e-01\n",
      "  7.66880751e-01 -4.75337833e-01  1.23195406e-02 -1.52904898e-01\n",
      "  2.91777968e-01  3.96770656e-01  4.83110100e-01 -1.10784695e-01\n",
      " -2.94786662e-01 -5.42199351e-02  2.31731653e-01 -7.87870109e-01\n",
      " -1.25642765e+00 -6.31234527e-01  2.34075524e-02  1.17647707e-01\n",
      " -6.30745590e-02  6.95503056e-01 -7.85004199e-02 -6.99434519e-01\n",
      " -3.83736849e-01 -1.23225316e-01  4.97210830e-01 -6.14453137e-01\n",
      "  3.95380825e-01 -1.16825268e-01 -3.37363839e-01  1.56270444e-01\n",
      " -3.50109898e-02 -7.92827070e-01 -1.60949230e-01  1.90548897e-01\n",
      "  8.66726860e-02 -6.69067860e-01  3.78950745e-01 -1.32412171e+00\n",
      "  9.70996320e-01  8.10080707e-01  2.48922542e-01 -1.12228185e-01\n",
      " -4.44401614e-02  4.16018158e-01 -7.58950353e-01 -8.13201368e-01\n",
      "  1.83924645e-01  1.00695527e+00 -2.29640529e-01  1.06682464e-01\n",
      "  3.63646984e-01  3.79669040e-01 -1.38003640e-02  7.54093975e-02\n",
      " -3.12083840e-01  3.75081837e-01  1.79873765e-01 -1.63063735e-01\n",
      "  1.35308996e-01  9.00060058e-01 -7.08064064e-02 -2.49124721e-01\n",
      "  6.27192616e-01 -3.49907070e-01 -6.48747563e-01 -1.87573522e-01\n",
      " -3.94112349e-01 -2.88350880e-01 -3.96133572e-01  3.57903019e-02\n",
      " -7.18310833e-01 -6.59161434e-02  2.15026081e-01  1.52881024e-02\n",
      "  3.23113263e-01 -8.45534503e-01 -5.53945780e-01 -7.44585276e-01\n",
      "  5.18297791e-01  7.50051141e-02 -2.66109198e-01  4.32008535e-01\n",
      " -1.79309756e-01  2.18430459e-02 -3.46691281e-01  8.67083669e-02\n",
      " -1.44767308e+00  1.13578129e-03 -7.15970516e-01  1.25169709e-01\n",
      "  4.89349524e-03 -1.20827928e-01 -7.42975891e-01  3.30879092e-01\n",
      "  5.47165517e-03 -1.54732872e-04  4.38494951e-01 -2.66923755e-02\n",
      "  3.73179883e-01 -1.44735435e-02  8.77733946e-01 -7.85890460e-01\n",
      "  7.32094422e-02  4.72455919e-02 -1.23166684e-02 -1.01211262e+00\n",
      "  1.33725211e-01  2.97946274e-01  7.69392550e-02 -1.27431667e+00\n",
      "  5.58924258e-01 -2.47186810e-01  3.22807044e-01 -7.76090384e-01\n",
      "  2.50323951e-01  4.18276079e-02 -2.23368015e-02  4.32491988e-01\n",
      "  1.95744168e-02  7.20993876e-01 -2.28283200e-02 -2.63961434e-01\n",
      "  1.77901328e-01  8.66029024e-01 -7.30687737e-01 -3.54700148e-01\n",
      " -2.66786478e-02 -2.72403075e-03  1.02026153e+00  5.53663135e-01\n",
      " -3.50300610e-01 -9.47853401e-02  5.04438728e-02 -1.02510500e+00\n",
      " -1.06252648e-01  5.94783127e-01 -8.37581933e-01 -2.66780406e-01\n",
      " -3.60162824e-01 -8.46802890e-01  5.74987829e-01 -7.82831535e-02\n",
      " -6.62450433e-01  6.33078367e-02 -5.35113573e-01  7.17218399e-01\n",
      " -1.37244657e-01  3.40275913e-01  7.44801641e-01 -1.10870624e+00\n",
      " -4.74283367e-01 -2.27073412e-02 -5.67772150e-01 -1.54882833e-01\n",
      "  2.19728008e-01  1.52019471e-01  5.75742185e-01  2.51737654e-01\n",
      "  2.80012816e-01 -4.51862156e-01 -1.37726098e-01  4.32788193e-01\n",
      " -1.14174843e+00 -7.11109163e-03  6.45048320e-02  1.32275606e-02\n",
      "  1.33090639e+00  1.92490909e-02 -7.34323740e-01  3.71949524e-01\n",
      " -2.94274479e-01 -1.07118320e+00 -1.28069026e-02 -4.11491930e-01\n",
      "  6.61745742e-02  4.85342890e-01 -3.55370969e-01 -4.40113135e-02\n",
      "  4.39596176e-01 -3.27501118e-01 -1.13489878e+00 -1.12068784e+00\n",
      " -4.55653574e-03 -8.57814729e-01  3.06268513e-01  1.10296592e-01\n",
      "  1.09221763e-03  4.70882982e-01  9.30897743e-02 -1.37663949e+00\n",
      " -6.83231771e-01  1.60385922e-01 -1.17763579e+00  5.43210745e-01\n",
      " -4.13481891e-03 -2.46154144e-01  4.29177999e-01  4.84125942e-01\n",
      "  7.72757828e-02 -1.60242870e-01 -6.00472391e-01  1.88122004e-01\n",
      " -3.54275674e-01  5.42126829e-03 -4.30909812e-01 -9.38255727e-01\n",
      " -3.54615360e-01  5.99554718e-01 -1.08357735e-01  8.25553775e-01\n",
      " -4.55835372e-01  7.58556664e-01 -1.42383063e-02  1.11515057e+00\n",
      " -3.64102006e-01  1.55221045e-01  1.78516164e-01 -6.28398776e-01\n",
      "  7.31570423e-02 -9.25171468e-03 -3.57284099e-01  7.38296986e-01\n",
      "  4.01615985e-02 -2.63241947e-01  1.79942891e-01 -2.99228013e-01\n",
      " -1.09277785e-01  1.98765159e-01  1.04845273e+00 -7.23438784e-02\n",
      " -5.14570415e-01 -3.59267324e-01  1.67371444e-02  2.26085812e-01\n",
      "  4.72369999e-01  6.90498501e-02 -2.67489310e-02  9.20098498e-02\n",
      "  7.08393229e-04  6.19715035e-01  2.83352554e-01 -1.55204251e-01\n",
      "  4.33644503e-01 -4.06146467e-01  9.25406277e-01  6.20048679e-02\n",
      "  1.96513265e-01  2.80622184e-01  8.54084969e-01 -3.03483516e-01\n",
      "  1.29916227e+00 -5.35971224e-02 -6.11849010e-01  4.00236636e-01\n",
      " -3.76916885e-01  4.77683723e-01 -3.17601562e-01 -6.21677414e-02\n",
      " -3.02744716e-01 -1.23894654e-01  6.73282087e-01  4.10932034e-01]\n",
      "discriminator_11/conv_block_136/batch_normalization_212/moving_variance:0 [0.09994875 0.04299077 0.4318074  0.03196031 0.0507202  0.13006593\n",
      " 0.07701474 0.13523553 0.04665323 0.0334423  0.17217463 0.13633467\n",
      " 0.03709577 0.03377625 0.08243579 0.3331058  0.21557823 0.42356488\n",
      " 0.18226674 0.19775265 0.23250782 0.12145805 0.11294148 0.050069\n",
      " 0.03993576 0.05394094 0.31665125 0.0262332  0.07253224 0.09221695\n",
      " 0.01964276 0.1015268  0.28033206 0.17283477 0.08905198 0.15032516\n",
      " 0.43424317 0.01329293 0.10448258 0.03491943 0.24965207 0.03375575\n",
      " 0.1666665  0.3711442  0.3100513  0.01181122 0.09321193 0.0584106\n",
      " 0.06489144 0.02554587 0.20403674 0.41111156 0.10562863 0.10569745\n",
      " 0.06936906 0.06948861 0.01904025 0.18775575 0.96394616 0.02535515\n",
      " 0.09275901 0.16304189 0.21536514 0.21558665 0.18892981 0.13886821\n",
      " 0.04796162 0.0531573  0.0564906  0.1487127  0.08033329 0.09067075\n",
      " 0.01689605 0.0096141  0.03323123 0.05956181 0.06237004 0.06666755\n",
      " 0.03219687 0.06675472 0.2004504  0.04490891 0.08071154 0.03851646\n",
      " 0.08111396 0.28072214 0.17087443 0.00760617 0.1080614  0.08323563\n",
      " 0.08532602 0.06146478 0.04126902 0.06762763 0.05216845 0.17570645\n",
      " 0.03023661 0.05002288 0.05639573 0.03135918 0.04427299 0.16586596\n",
      " 0.4715944  0.04805429 0.13962846 0.11546238 0.33585957 0.07890621\n",
      " 0.06025052 0.02315096 0.13966502 0.04767383 0.02785391 0.06766084\n",
      " 0.07191026 0.20971444 0.71771383 0.11462072 0.13439809 0.06070504\n",
      " 0.09120851 0.12661864 0.10259832 0.06904211 0.11473443 0.04565102\n",
      " 0.07602486 0.09311666 0.16952322 0.08630984 0.12491    0.0513184\n",
      " 0.17964561 0.02443019 0.410188   0.01544492 0.1277479  0.12642238\n",
      " 0.44662958 0.21791905 0.06102608 0.09903762 0.06061888 0.04116074\n",
      " 0.03580821 0.03290225 0.05650717 0.22987844 0.02422395 0.05385516\n",
      " 0.03434813 0.03043711 0.345509   0.08094933 1.6039141  0.10266246\n",
      " 0.12973864 0.62524956 0.6064121  0.2228951  0.05464401 0.3093868\n",
      " 0.09430193 0.07940261 0.34533286 0.08705193 0.1801953  0.04620839\n",
      " 0.05823625 0.04000402 0.52722263 0.06105949 0.13405113 0.40996975\n",
      " 0.04010339 0.07531488 0.02104896 0.04044778 0.06575697 0.00730071\n",
      " 0.14893371 0.01379431 0.24914858 0.15963414 0.08685746 0.07257944\n",
      " 0.03544038 0.10716484 0.03687295 0.2070894  0.03363577 0.24498206\n",
      " 0.01833917 0.08254758 0.08345111 0.07152217 0.09462538 0.05922925\n",
      " 0.04257202 0.09223986 0.11285943 0.23214866 0.05483585 0.16389455\n",
      " 0.28605914 0.05391758 0.02137649 0.5026676  0.03881228 0.14750163\n",
      " 0.10712969 0.07536258 0.0762457  0.07953852 0.13417989 0.30042621\n",
      " 0.34922168 0.16467056 0.02213321 0.13389707 0.10811363 0.05545645\n",
      " 0.3963728  0.04261493 0.09669939 0.7765734  0.0480763  0.290441\n",
      " 0.0671165  0.01939185 0.20994858 0.24968596 0.07686077 0.17641264\n",
      " 0.05553641 0.22378866 0.12553674 0.03495292 0.13358423 0.5250375\n",
      " 0.04014921 0.21801312 0.41641715 0.32848194 0.10879167 0.25292668\n",
      " 0.10692264 0.01156615 0.06319287 0.28941244 0.1837766  0.04625058\n",
      " 0.33274123 0.07762849 0.02510476 0.14214459 0.19813886 0.08365417\n",
      " 0.09249514 0.03443911 0.12701443 0.05212913 0.08255431 0.34421682\n",
      " 0.4608836  0.25024432 0.05124593 0.03110299 0.0399013  0.16792129\n",
      " 0.02159313 0.19484444 0.15218595 0.07804234 0.27405038 0.31492463\n",
      " 0.07829195 0.02987521 0.1709106  0.05839061 0.01361819 0.32226372\n",
      " 0.07881935 0.05328595 0.13433465 0.24331726 0.05928713 0.5387371\n",
      " 0.290966   0.32178253 0.05732134 0.07559517 0.01606543 0.07026479\n",
      " 0.26548266 0.20955174 0.03330289 0.44529703 0.06708845 0.05600268\n",
      " 0.06538796 0.0563623  0.01560715 0.02266837 0.06112398 0.07524912\n",
      " 0.14024375 0.0947855  0.02152198 0.4251987  0.1005547  0.09137604\n",
      " 0.259185   0.08793698 0.18065389 0.04993355 0.0957851  0.11160319\n",
      " 0.09573545 0.04420391 0.3427055  0.03530067 0.06011929 0.01502879\n",
      " 0.06121339 0.22597829 0.15175563 0.20647736 0.2570217  0.02479463\n",
      " 0.07541988 0.12358661 0.06756211 0.06837042 0.09570258 0.09690006\n",
      " 0.8560113  0.04155895 0.17136174 0.15972869 0.0144107  0.05798284\n",
      " 0.49472255 0.16643351 0.05502108 0.0560207  0.0831297  0.02123889\n",
      " 0.09361754 0.07885245 0.32359236 0.29574805 0.0343082  0.06857866\n",
      " 0.02362917 0.39018667 0.11335044 0.10289298 0.04126354 0.7396934\n",
      " 0.18442492 0.07633386 0.05803377 0.2047708  0.15855514 0.0287067\n",
      " 0.01691557 0.12846754 0.04225107 0.27889884 0.01013835 0.06564795\n",
      " 0.05731593 0.23900624 0.18239254 0.12985678 0.08277644 0.00547832\n",
      " 0.39175206 0.12174347 0.09087262 0.06551752 0.04127585 0.35087973\n",
      " 0.0681734  0.23605742 0.3141409  0.06173705 0.19354998 0.22573021\n",
      " 0.21996088 0.09273443 0.23083976 0.06799433 0.17665018 0.15967387\n",
      " 0.06530844 0.05430207 0.47251183 0.39979067 0.11842071 0.03494202\n",
      " 0.2087207  0.04395028 0.03078662 0.02965034 0.13856764 0.1486492\n",
      " 0.0615574  0.09716206 0.06500065 0.08906224 0.5104369  0.03665556\n",
      " 0.04340416 0.0806879  0.5828844  0.03388804 0.20121725 0.08695208\n",
      " 0.1116346  0.4733247  0.02982776 0.13502847 0.06364702 0.12610757\n",
      " 0.07895387 0.02692773 0.15259506 0.08232895 0.47894672 0.49812448\n",
      " 0.00797453 0.31237906 0.10285988 0.1069363  0.04939554 0.11052962\n",
      " 0.0458412  0.7120783  0.3007077  0.12007321 0.5108347  0.20460269\n",
      " 0.01471199 0.07797133 0.09630782 0.14567624 0.08274223 0.09798355\n",
      " 0.1422706  0.05591548 0.10478549 0.07109345 0.09282631 0.37563333\n",
      " 0.0668653  0.17716457 0.08471844 0.33710328 0.1267611  0.20679237\n",
      " 0.04108414 0.43450227 0.07069121 0.0547542  0.11326602 0.28500205\n",
      " 0.07632001 0.04640449 0.07063225 0.28183833 0.0693999  0.10482735\n",
      " 0.03446173 0.04892128 0.02488594 0.02665802 0.37631208 0.0310631\n",
      " 0.13400346 0.07419714 0.05313431 0.04796078 0.10330939 0.15635817\n",
      " 0.01026653 0.03901562 0.01157405 0.24870661 0.05837526 0.10891237\n",
      " 0.20680176 0.08865286 0.38337907 0.02471609 0.05622898 0.06777801\n",
      " 0.26525158 0.09230343 0.5525079  0.02029201 0.3138481  0.09068528\n",
      " 0.07058405 0.15135941 0.05708981 0.0587767  0.05317435 0.03814109\n",
      " 0.1656103  0.08429531]\n",
      "discriminator_11/conv_block_137/batch_normalization_213/moving_mean:0 [ 8.47509503e-01 -7.58227468e-01  7.86140263e-01 -1.11953139e+00\n",
      " -3.75064403e-01  2.07073689e-01 -5.63727140e-01 -3.09039950e-01\n",
      "  4.33515996e-01  1.33332455e+00 -5.33626974e-01  4.08981562e-01\n",
      "  6.89221472e-02  8.69635761e-01 -1.17959967e-02  9.57780600e-01\n",
      " -1.23544089e-01 -1.89147353e+00  1.36561596e+00  4.12457764e-01\n",
      " -9.67823714e-02  5.88946640e-01  8.12522471e-01 -1.49631882e+00\n",
      "  1.85301185e-01  5.64897060e-02  1.07888448e+00  1.62391436e+00\n",
      "  4.09251064e-01  1.38344932e+00 -1.29209653e-01  4.73112255e-01\n",
      " -6.67729318e-01 -4.42704082e-01  8.06220829e-01  1.51144549e-01\n",
      " -1.25857338e-01  6.98526025e-01  2.93143559e+00 -1.02227736e+00\n",
      " -1.22853398e-01 -3.55666190e-01 -4.77136552e-01  1.07539743e-01\n",
      " -3.82433861e-01 -2.85176516e-01  3.64597380e-01 -3.74309093e-01\n",
      "  2.62725770e-01  3.52651887e-02  8.71319950e-01  5.28789401e-01\n",
      "  9.35796559e-01  2.02602088e-01  3.94798934e-01  4.45295990e-01\n",
      "  7.36971974e-01  1.01035726e+00 -3.13212425e-01  9.48676229e-01\n",
      "  1.31234729e+00 -6.62379146e-01  1.29791677e-01  6.70461655e-01\n",
      "  1.46544918e-01  9.23137367e-02 -3.88026506e-01 -2.05901170e+00\n",
      " -3.71825278e-01 -3.15770864e-01  5.87013841e-01 -6.92633271e-01\n",
      "  1.24926418e-01  1.00762939e+00 -5.95076621e-01  8.95121321e-02\n",
      " -1.85327157e-02 -1.23351431e+00 -9.27750230e-01  1.85616896e-01\n",
      " -5.55083513e-01  1.99451789e-01  4.48211059e-02  7.49906013e-03\n",
      "  1.80143404e+00 -1.18570305e-01 -2.07678042e-02  1.13425934e+00\n",
      "  2.57413340e+00 -3.89409438e-02 -5.97613037e-01  6.09461546e-01\n",
      " -4.22275901e-01  8.53939533e-01 -7.53786325e-01 -1.37355840e+00\n",
      "  9.52202678e-02  4.87483740e-01  3.96341622e-01 -2.29187399e-01\n",
      "  2.69798338e-01  9.61133599e-01  3.33401769e-01 -1.14866209e+00\n",
      " -6.69492006e-01 -1.64051995e-01 -5.63406110e-01 -2.22237408e-01\n",
      " -9.14499342e-01 -1.11515749e+00  1.71177015e-01 -5.99339128e-01\n",
      " -3.93594913e-02 -8.15167308e-01  6.31407022e-01  4.35568213e-01\n",
      " -1.07846893e-01  2.07161605e-01  5.35533689e-02  2.58812934e-01\n",
      " -4.09256488e-01  2.06879234e+00 -2.04619676e-01 -9.82891917e-01\n",
      " -5.08425772e-01  1.45573211e+00  1.13466002e-01 -1.60077646e-01\n",
      " -1.09968758e+00  2.48504832e-01  1.63338810e-01 -6.23336852e-01\n",
      "  2.65508860e-01  4.90720034e-01 -1.61690962e+00  9.94975120e-02\n",
      " -8.36651623e-01  2.16175675e-01 -7.65460312e-01 -4.20309752e-01\n",
      " -2.94866227e-02 -1.54857826e+00  7.13191032e-02 -8.70038211e-01\n",
      " -1.24956727e+00 -1.13483407e-01  9.20727253e-01 -3.05518359e-01\n",
      "  2.14438128e+00  1.13946438e+00  3.80339354e-01 -3.53451133e-01\n",
      "  2.03017533e-01  7.65907049e-01  7.15846360e-01  1.52280295e+00\n",
      "  5.90294227e-03 -1.66018978e-01  1.76973403e+00  2.78745532e-01\n",
      " -1.78406549e+00  9.10989165e-01 -5.30835092e-01  8.14552307e-02\n",
      "  1.67103127e-01  2.76164144e-01 -6.58031762e-01  2.19651535e-01\n",
      "  1.25906765e+00 -1.17209330e-02 -1.92241538e-02  1.60540259e+00\n",
      "  1.62534082e+00 -7.21955240e-01 -1.23594575e-01 -6.33837879e-01\n",
      " -2.17584655e-01  4.99845706e-02  1.52980208e+00 -1.84465751e-01\n",
      "  1.10378158e+00  3.50256488e-02 -1.80664217e+00  3.14483464e-01\n",
      " -4.99234468e-01 -1.10946310e+00 -4.63070005e-01 -9.28900421e-01\n",
      " -8.89224052e-01  3.63428414e-01 -3.15929145e-01 -1.55869961e+00\n",
      " -1.45511734e+00 -2.22500324e+00  8.35499167e-02 -1.43698812e+00\n",
      "  6.00362659e-01 -8.82858634e-01 -6.85218692e-01 -3.46209586e-01\n",
      " -1.73439905e-01  2.95858651e-01  3.31921488e-01 -3.24505240e-01\n",
      " -1.38023651e+00  2.99147964e-01 -1.14674020e+00  1.73476160e+00\n",
      " -3.10115904e-01 -3.52232039e-01 -1.65983677e-01 -6.14490271e-01\n",
      "  3.29258233e-01 -6.41502857e-01  5.65606892e-01 -1.02810049e+00\n",
      " -1.45112717e+00  6.02919310e-02 -6.86563412e-03  9.43632662e-01\n",
      " -1.02269959e+00  6.24210835e-01  4.51331705e-01  2.59426832e-01\n",
      " -5.35018086e-01  1.62130654e-01  2.43568704e-01 -8.99282157e-01\n",
      "  1.81840873e+00 -2.83714924e-02 -5.50626576e-01  7.56244361e-01\n",
      "  3.36490184e-01 -2.80287325e-01  7.83854544e-01 -5.85656047e-01\n",
      "  4.20416713e-01 -9.36569929e-01 -2.06237674e-01  9.65407267e-02\n",
      "  2.10092211e+00  3.92661989e-01 -1.87748909e+00  8.78993198e-02\n",
      " -5.18127903e-02 -9.27634239e-01 -4.95079964e-01  4.83412981e-01\n",
      " -7.31271088e-01 -9.98472095e-01  4.14442062e-01 -6.17841519e-02\n",
      " -6.77753687e-01 -3.44128788e-01 -4.74524170e-01 -2.65404493e-01\n",
      "  1.61930211e-02  1.39376327e-01 -2.53477663e-01  5.09833395e-01\n",
      "  1.42715037e+00  2.28343576e-01 -9.89346266e-01 -1.41942108e+00\n",
      " -4.89900321e-01  1.32148424e-02 -5.89610934e-01  2.32643470e-01\n",
      " -9.59674120e-02  6.26744211e-01 -5.01086354e-01 -6.87062144e-01\n",
      " -1.51828518e-02  6.00720644e-01  3.79818201e-01 -5.14213204e-01\n",
      " -1.16512787e+00 -7.37034440e-01 -1.49910003e-01  8.00804257e-01\n",
      " -1.35415041e+00  2.35407382e-01  4.37711403e-02 -5.31192780e-01\n",
      " -7.45628536e-01  6.14384227e-02 -3.71600956e-01  8.40867937e-01\n",
      " -9.84485373e-02  7.37472415e-01 -8.63426864e-01  3.31390470e-01\n",
      " -2.09409937e-01  1.02202393e-01  7.04522252e-01 -1.89732480e+00\n",
      "  3.31476569e-01  7.17295647e-01 -2.31354445e-01  2.28575379e-01\n",
      " -2.89378583e-01 -1.24800158e+00  3.07539314e-01  2.46874630e-01\n",
      "  5.99419832e-01  4.25715111e-02  1.49108991e-02  6.15022421e-01\n",
      "  3.11150342e-01  1.32320011e+00 -7.78629959e-01 -1.80607095e-01\n",
      "  3.96272123e-01 -2.99833268e-01  1.28845930e+00 -1.42215550e-01\n",
      " -1.34229988e-01  4.53182131e-01  9.78715122e-01  1.77484378e-01\n",
      "  2.98367667e+00 -2.38179207e-01  1.40363932e+00 -3.20133001e-01\n",
      " -4.58683878e-01  1.49954736e-01 -1.02051266e-01 -9.49715436e-01\n",
      "  9.38799560e-01 -1.19047558e+00 -1.34524936e-03  5.34779251e-01\n",
      "  1.77888250e+00  3.51559669e-01 -2.94661433e-01  1.43974447e+00\n",
      "  1.57408893e-01  8.84155869e-01  9.39901054e-01 -3.96839947e-01\n",
      "  2.49309435e-01 -1.19537838e-01 -4.38398749e-01  8.33009481e-01\n",
      "  8.48156512e-01 -1.54795069e-02  2.30176330e+00 -5.29389858e-01\n",
      " -2.96915829e-01 -1.65709645e-01 -7.61346519e-02  9.11694109e-01\n",
      " -2.07445696e-01 -6.52743936e-01 -2.60496408e-01  1.90181121e-01\n",
      " -2.82388687e-01  1.14773087e-01 -7.06034720e-01  3.63127530e-01\n",
      "  2.43942335e-01 -1.58239913e+00 -5.48681557e-01 -1.29504359e+00\n",
      "  1.07713096e-01  1.19624150e+00  5.29067814e-01  3.91427070e-01\n",
      " -7.45178685e-02 -7.52857327e-01 -4.81840372e-01 -1.32660592e+00\n",
      "  1.26896226e+00  1.07666600e+00  9.90381122e-01 -3.37212682e-01\n",
      "  8.82793590e-02  8.59640837e-02 -2.94111874e-02  7.21767604e-01\n",
      "  3.08665782e-01  2.95489579e-01  3.48362446e-01  2.73956824e-02\n",
      " -2.84855306e-01 -1.82985321e-01  6.77802712e-02 -8.35349977e-01\n",
      "  1.06852818e+00 -1.57327607e-01  5.24313152e-02  1.54532504e+00\n",
      "  3.23516160e-01  4.29746568e-01 -1.84596944e+00  3.17522317e-01\n",
      " -2.24514648e-01 -3.62647831e-01 -1.66219604e+00 -1.25148678e+00\n",
      "  2.14917183e-01 -8.81128013e-02  1.35616139e-01  1.95605528e+00\n",
      "  4.50369507e-01 -3.53413612e-01 -2.93694973e-01  1.95992634e-01\n",
      " -9.15427983e-01 -9.55688894e-01  2.75440127e-01 -1.05057038e-01\n",
      " -3.29899371e-01  5.07340312e-01 -1.38213587e+00  5.90551309e-02\n",
      " -1.04841627e-01  1.17396295e+00  2.41159514e-01  1.04163468e+00\n",
      " -1.51371658e-01  4.78169590e-01 -4.36514318e-01 -1.29667580e+00\n",
      " -1.92615879e+00 -1.41205266e-01 -1.02035785e+00  6.26402140e-01\n",
      " -6.03829980e-01  3.82774323e-01  1.32863700e+00 -3.53754073e-01\n",
      " -5.72941564e-02 -3.03896666e-01  1.27246583e+00 -1.11555398e+00\n",
      " -1.38543442e-01  1.49269521e+00  1.76538384e+00  9.80883718e-01\n",
      "  2.25753212e+00 -2.15357855e-01  2.85597801e-01  7.20456764e-02\n",
      "  1.63865829e+00  2.63840079e-01  9.28239524e-02  1.10337114e+00\n",
      " -5.64288259e-01  1.00229360e-01 -4.10314113e-01  1.18897252e-01\n",
      " -2.27272391e-01  9.95047748e-01 -4.38922420e-02 -6.41176254e-02\n",
      "  5.86441755e-01  2.57216487e-02  1.67259295e-02 -5.69295466e-01\n",
      " -1.56017113e+00 -6.16884291e-01 -9.69875097e-01  2.13627124e+00\n",
      "  1.71124533e-01  1.53887236e+00 -7.54976571e-01  8.75216201e-02\n",
      "  2.54738116e+00  1.34488952e+00  1.81058988e-01 -3.14637534e-02\n",
      " -1.41249812e+00 -3.46003830e-01 -6.18791699e-01 -3.72488528e-01\n",
      "  1.38011873e+00 -4.22528118e-01 -2.71547854e-01  3.30002844e-01\n",
      "  8.22998658e-02 -3.22738290e-01  5.99550188e-01  1.46233010e+00\n",
      "  1.17904730e-01  1.24521875e+00 -5.39413512e-01 -5.96023500e-01\n",
      "  7.70398855e-01 -8.15437138e-01 -1.11575774e-03  1.90182462e-01\n",
      "  1.58540285e+00  9.30069506e-01 -4.05054212e-01  1.46744223e-02\n",
      " -4.73345183e-02 -1.21635541e-01 -5.91271162e-01 -7.53979683e-01\n",
      " -1.47607410e+00 -6.48359656e-01 -1.58290792e+00 -1.68921876e+00\n",
      " -3.19426060e-01  6.22759759e-01  1.43210441e-01 -1.10126905e-01\n",
      "  4.25881326e-01  5.16350627e-01 -9.48593974e-01 -1.24612220e-01]\n",
      "discriminator_11/conv_block_137/batch_normalization_213/moving_variance:0 [0.48067895 1.0459875  0.5701529  1.7086262  1.4983377  0.4549888\n",
      " 0.7298556  0.7344     0.6070381  0.41416654 0.26159734 2.641474\n",
      " 0.19425529 1.086142   0.27913347 0.95165175 0.43621555 0.6974284\n",
      " 0.6322741  0.6987112  0.38480383 0.60679185 0.50443435 0.755107\n",
      " 0.3207264  0.47785667 0.38204372 2.703926   2.2446702  0.7798966\n",
      " 0.2812122  0.74795854 0.425667   1.2341232  0.6243116  0.2673899\n",
      " 0.45869094 0.38554567 0.9880269  1.1113361  0.3750576  0.81485504\n",
      " 0.6218796  0.48291764 1.2400585  0.74988955 0.44627032 1.1632022\n",
      " 1.6855398  0.3126665  0.77068114 0.6236992  0.74504375 0.31816304\n",
      " 0.63243365 0.26634496 0.52526975 0.56837916 1.826659   0.37170073\n",
      " 0.7044262  0.7343207  0.94003093 0.23358406 0.4017239  0.37314737\n",
      " 0.60889864 1.7599248  0.30846843 0.63979286 0.36027223 0.94947296\n",
      " 1.2502248  0.44498396 0.377817   0.47273573 1.6344066  1.574831\n",
      " 0.6490804  0.666089   0.47752404 0.44642764 0.362125   0.3019154\n",
      " 1.1044953  0.44592306 0.862894   0.84766424 1.0949408  0.29152012\n",
      " 0.7776072  1.3428823  0.35097295 0.97030425 0.67672473 1.2197692\n",
      " 0.33639556 0.7158396  0.5731366  0.61266094 1.9185991  0.73177177\n",
      " 0.9157284  0.8180889  0.9981501  0.66037047 1.096182   0.3627427\n",
      " 0.96781665 1.510097   0.39938265 0.7582762  0.50799966 1.3668276\n",
      " 0.73567075 0.5289991  1.5184245  0.52277166 1.1630008  0.53304625\n",
      " 0.39412752 1.6730087  0.31509593 0.67331356 0.4564411  0.7779263\n",
      " 0.47908992 0.24797823 0.93231255 0.85492885 1.0289137  1.2205327\n",
      " 0.6590933  0.33760288 0.7146197  0.67326325 0.4342865  0.39571407\n",
      " 0.6688821  1.2925262  0.39133203 0.9369533  0.29900593 0.6968945\n",
      " 1.9316384  1.6169016  0.93058676 0.6539011  2.5602143  1.1962925\n",
      " 0.24742435 0.5839035  0.5444261  2.2163951  0.5558989  0.892012\n",
      " 1.1602901  0.32636723 0.7999063  0.38581786 1.2355664  2.7423944\n",
      " 0.8293857  0.39089033 1.3873761  0.31423694 1.4487289  0.59100306\n",
      " 0.44966602 0.40372336 0.5201197  0.6356426  0.81504107 1.0079848\n",
      " 0.44804603 0.51572883 0.9312878  0.33524978 0.99937165 0.29474503\n",
      " 0.6291786  0.31058297 0.6525662  0.49468318 1.0715978  1.1746486\n",
      " 0.3184415  0.2943535  1.2349925  0.8004872  0.5567301  0.7427059\n",
      " 0.7037579  0.77541    0.31383282 1.0725952  1.6536921  0.5810571\n",
      " 1.5259908  0.89246565 0.7913687  0.65381783 0.46986583 0.3725744\n",
      " 3.1034582  0.7845473  0.5274523  1.0422689  1.0546641  0.51899874\n",
      " 0.7732063  0.5107178  0.8294639  0.46180847 0.30568573 0.71968645\n",
      " 1.5466766  0.25820753 0.50905585 0.28935835 0.6140557  0.50743765\n",
      " 0.6921987  1.0312911  0.9076786  0.6589951  0.39821357 1.1845372\n",
      " 0.81138426 0.25719994 0.85636985 0.56022817 0.4626766  0.37394682\n",
      " 0.64254916 0.9990493  0.28727472 0.36279368 0.46975803 0.3776664\n",
      " 0.7270728  0.7902695  1.0989085  0.48963568 0.30985123 1.073871\n",
      " 0.6212856  0.33536243 2.215416   0.655954   0.79073834 1.0160325\n",
      " 1.5093886  0.4758078  1.8958386  0.571992   0.3352729  0.49550456\n",
      " 0.52865624 0.73604983 1.521766   1.7243593  0.7642293  0.55456984\n",
      " 0.64664    1.3255485  0.4309413  1.4031477  1.218911   0.43569946\n",
      " 0.24408029 1.0042946  0.43324855 0.7190262  0.41125786 0.53444505\n",
      " 0.96089417 0.66739565 0.27617183 0.361463   1.1403769  0.4895863\n",
      " 0.48463723 0.8745635  0.821858   0.35256717 0.72197545 0.79930377\n",
      " 0.3316127  0.4557922  0.7928613  0.32015595 0.36369953 0.48471737\n",
      " 0.66435647 0.46218905 0.33569598 0.28719503 0.5021234  0.5120729\n",
      " 0.7767594  0.6382665  0.30023384 0.29289898 3.2732062  0.33406404\n",
      " 0.35209885 0.7195387  1.3161606  1.4313922  0.36136648 0.21691588\n",
      " 0.4364402  0.4520353  0.53566    0.6149759  0.6071936  0.5781716\n",
      " 0.5529477  1.4796435  1.276126   0.39181924 1.3854604  0.49273542\n",
      " 1.6342839  1.1303018  0.257926   0.41802543 0.38318023 0.4573988\n",
      " 0.9888665  0.30431157 0.7712948  0.37714592 0.7456091  1.4603704\n",
      " 0.36656344 1.2922939  0.8664344  0.8103943  0.41832805 0.53975475\n",
      " 1.0011299  0.79649407 0.6659798  0.37457642 1.1162276  0.3813886\n",
      " 0.39697567 1.8238233  0.6834053  0.46640587 0.70629305 0.4815877\n",
      " 1.0850402  0.34145227 0.43515953 0.3253693  1.4128625  0.8576768\n",
      " 0.5229294  0.5264704  0.70125616 1.426313   0.22780187 1.424916\n",
      " 0.79610986 1.9028623  0.20079328 2.3271213  1.2286742  2.3275547\n",
      " 1.3042533  1.3103842  0.37186295 0.41153714 0.4711076  0.38164076\n",
      " 2.1339254  0.3518214  0.5373725  0.37542954 0.839968   1.7443033\n",
      " 0.5783612  0.23971464 0.641051   0.5705384  0.55653125 0.9961206\n",
      " 0.91522753 1.4905872  0.65036064 0.3324458  1.0984732  0.3556299\n",
      " 0.7174369  0.6962943  1.4816976  0.93734396 0.90894973 0.44835377\n",
      " 0.4499976  0.98711103 0.82480013 0.23972672 0.40933886 0.83644474\n",
      " 0.6156073  0.5860952  0.37927094 0.44642746 0.7572591  1.1546369\n",
      " 1.3184464  0.29306152 0.22587061 0.613414   0.4192783  1.4934367\n",
      " 0.48756993 0.30713835 0.93360823 0.52373344 8.878307   0.5058904\n",
      " 1.8404223  0.46859926 1.267249   0.30171216 0.5454311  1.0185896\n",
      " 0.3076862  0.2972098  0.9621481  0.48013544 0.68701166 0.8012658\n",
      " 0.9930916  0.6016273  0.9581414  0.7443104  0.34967974 0.23343098\n",
      " 0.71183366 0.78291935 0.47390246 2.1507266  0.48847404 0.33596015\n",
      " 3.997547   1.3999718  0.3551954  0.63213897 0.6547651  2.288969\n",
      " 0.4530664  0.46998233 0.41151136 0.37574315 1.0921439  2.2511907\n",
      " 0.46821472 1.2423956  0.25857955 0.6027761  0.96406746 0.47617564\n",
      " 1.0195868  0.7100323  0.3997038  0.4282397  1.688384   0.5325014\n",
      " 0.531388   0.53764194 0.7735386  1.1176581  0.41523626 0.42203736\n",
      " 0.27850497 0.3126685  0.5956356  0.68687856 0.7871368  1.2321779\n",
      " 0.51999843 0.37225285 0.55097294 3.5667632  0.6215758  0.60248107\n",
      " 0.6866873  0.8973053  2.1387491  0.48684296 0.29262882 0.2198604\n",
      " 0.38425457 0.441786   1.3144906  0.4349707  1.0270153  1.2253009\n",
      " 2.0799975  1.0602788  0.4293862  0.4332415  0.779693   0.60576576\n",
      " 1.8813081  0.7585779 ]\n",
      "discriminator_11/conv_block_138/batch_normalization_214/moving_mean:0 [-1.3694441   0.23266771  0.327802    4.0181656   5.4556336   0.37471256\n",
      "  1.5437913   5.074823    0.1780816   2.9205475  -2.0934594  -0.10535144\n",
      "  1.1609561   2.2029269   0.36658105 -0.23682006  0.27060628  2.5613618\n",
      " -0.96908474  1.1676207  -4.3876595  -0.51623297  1.7231785  -1.2559234\n",
      "  1.1117274  -2.1417189   1.5921015   6.1387725   6.361413    2.52233\n",
      "  6.731011   -3.5842159   3.267815    0.77283216 -2.3532083   0.78343123\n",
      "  0.35032207 -2.9212298   1.9774377  -1.6923518  -0.7226205  -0.07258801\n",
      " -0.781324    8.513328    4.293818    3.3299391   2.3553069   1.6842461\n",
      "  3.8521209   5.0818124   1.571644    4.6294947  -1.7750876  -2.4164007\n",
      "  8.733092    2.3825586  -0.31200704  3.9968429   0.4125294   5.4742436\n",
      " -2.1052067   2.9738631  -0.15560456  5.935211    6.3024554   1.2252202\n",
      " -1.1208079   1.0326833   0.87663716 -2.4757285  -1.0993755   4.3216023\n",
      " -1.1716298   0.0125532  -1.7130809   5.9763007   0.26095712  1.1777749\n",
      " -1.9172541   0.6010774  -0.30855265 -1.2901759   3.1001184  -3.4791017\n",
      "  0.5475594  -3.8913593   3.8135004  -1.2431816   3.3841991  -0.09058903\n",
      "  6.810375   -1.4905154   1.5567919   7.5752087   3.9960527   1.4460572\n",
      "  4.243751    4.4536586   0.45043576  7.769753    1.8467993   3.1384807\n",
      "  4.8005757   1.883323    0.07285545 -2.1660705   2.5908997   1.7785429\n",
      " -7.4206104   2.253659    0.04123504  0.5033773   3.9933388   0.78014946\n",
      "  7.4670715   4.110842   -2.4457836   0.0638743  -0.5222959  -2.0171723\n",
      " -3.0072544   4.016559    0.93397284  3.7219715  -1.1569543  -1.4659935\n",
      "  0.8204815   4.9497075   0.39783898  0.3138045   0.9631894   4.6854844\n",
      " -0.61703676  2.0343604   8.269104   -0.2927712  -1.1961777  -2.5601404\n",
      "  6.7011275  -0.36249512 -3.1092463   5.0472846   2.4901216  -2.2735791\n",
      "  2.6651397   0.9523097   1.0610607   0.64636594 -1.4011998  -0.22009143\n",
      "  0.5772687  -2.3565936   2.161522    2.1730926  -0.2616728   0.42585537\n",
      "  3.3317895  -1.7862556  10.465267    6.451243   -1.9779717   4.268759\n",
      "  0.8752299  -0.6509137   0.7917221  -0.43836954  0.27625555 -2.8798535\n",
      " -0.68818027  0.92805433  1.5766435  -5.2382617   1.7781243   3.0576932\n",
      "  0.7538128   0.09042841 -5.3846436   2.6942108  -3.0414033   2.0028539\n",
      "  0.11856775 -0.15632641  2.8615644   0.24431936  1.0031263   1.6496894\n",
      " -1.2099686   0.7115541  -2.6992679   2.2934387   0.02547935  5.185327\n",
      "  0.29657924 -0.5078041   4.8489695  -1.3209697  -2.1736248   1.9774548\n",
      " -3.3105688  -4.7295923  -0.3221892   1.9386418   6.94119     1.7553627\n",
      "  1.5147388  -0.5472831  -0.05117723  5.6429586  -0.9139015   5.6931133\n",
      "  3.9663036   2.0946994  -0.9204585  -2.348457   -2.4575636  -2.4644012\n",
      "  5.3930936  -0.87736815  8.591843    0.7685035   3.9674397  -0.9848665\n",
      "  2.1418042  -1.1086229   6.6637845  -0.5796695   0.5181758  -0.04893043\n",
      "  1.9487282   5.74067     1.7324778  -1.6188986   1.0874094   1.2511579\n",
      "  2.1756644   2.3136697   3.4380875  -4.1510167  -2.3823805  -3.0037434\n",
      " -2.1463385  -5.3670797  -2.1133456  -0.10054924  2.2035327   3.2973154\n",
      "  4.0419717  -3.1211908   1.0890344   0.15075998  2.7831285  -2.0904963\n",
      "  0.40628785  0.7620545   2.0325074   1.5142274 ]\n",
      "discriminator_11/conv_block_138/batch_normalization_214/moving_variance:0 [ 8.559653   6.3745003  6.3971734  5.8882556  7.504963  11.410615\n",
      " 14.750793  10.430529   6.9530954 15.496782   9.602228  10.100701\n",
      " 10.352411  14.199628   7.1595373  6.4524517  7.065443   6.9375\n",
      "  7.731434   8.651353   7.9588675  5.96849   11.031529   7.3500977\n",
      "  2.7509747  5.7717676  2.6454914  5.3255215  6.8701086  7.671629\n",
      "  6.031009   9.123677   5.9902377 10.32461    3.2825508  7.1862326\n",
      "  5.5464206  5.5285087  6.791337   4.5147357  7.714382   6.459699\n",
      "  5.14033   10.754605  10.432972   6.2405334  5.6420903  5.119407\n",
      "  7.750943   6.1805935  5.3947706  8.181229   6.740888  21.35496\n",
      "  6.904201   5.1493955 10.439737   4.7906847  2.3166168 14.333618\n",
      " 12.8413315  7.3108845  2.6992934  3.401899  13.394837   5.8065906\n",
      "  8.109925   7.305354   8.401364  17.986805   5.1059427  9.772138\n",
      "  9.672472   7.185581   7.0945616  5.772552  16.29665    6.5259376\n",
      " 10.221065  10.357487  11.707422   9.733759  11.514705   6.129151\n",
      "  6.5571356  5.3491087  7.4924126  2.5548594  7.067673   4.2163916\n",
      "  8.505396   4.894662   7.891033   8.517238   5.7501     7.2516894\n",
      "  4.772368   5.9984     9.620965   8.794722   5.3634357  7.771155\n",
      " 10.255754   7.111794   4.3914857  4.615948   9.655242   6.0447927\n",
      "  9.493278   8.5870495  5.7147255  6.11213    5.150969   3.9039514\n",
      "  5.775871   5.929799   4.3212504  4.9729133  4.285593  13.955564\n",
      "  7.139853   4.720086   4.3753796  6.7187557  3.6195383  5.0168114\n",
      "  5.9041924 11.245693   5.594263   6.093472   9.902049   8.169371\n",
      "  8.001234   6.490818  14.599572   5.6858215  7.380479   5.9941044\n",
      "  5.7683043  7.6454835  7.823148   8.974559   5.584268   7.168414\n",
      "  9.431884  12.6936035  5.7357726 11.227138   4.9109097  4.6995864\n",
      "  9.595746  13.528244   5.2669525 11.1225605  6.052107   5.6766877\n",
      "  5.4824123  6.535751   7.5806346  7.9291105 11.6736765  4.8103395\n",
      "  4.310776   3.0529926  7.5052323 10.83291   13.272753  19.910683\n",
      "  8.998787   6.033609   4.7584057 44.614723   6.0786166  8.92244\n",
      " 11.690633   9.883054   5.80848    6.4875894  6.128829   4.661049\n",
      "  3.4421356  5.697692   8.414429   3.976616   6.5395174 11.875311\n",
      "  6.0768905 14.313303   6.2462363  8.438792   7.643767  11.373829\n",
      " 10.541384   6.956274   6.707909   3.3695862  4.18474    7.571393\n",
      " 11.028728   5.209822   5.1645904  3.354207   5.4298005 10.92286\n",
      " 10.56055    9.795643  10.756591   7.940839   5.4598722  5.95505\n",
      "  8.906832  10.315118   8.412887   4.983094   4.080462   5.9978714\n",
      "  7.982831   4.7637467 13.473675   9.352429  10.885715   4.601305\n",
      "  4.812589   5.308268  12.629498   6.4238467  2.4681406  5.326802\n",
      "  8.907287   8.672897   5.8906984  3.90647    6.7408614  6.685324\n",
      "  7.063443   8.915592   5.8134427 20.706642   3.448729   6.709045\n",
      "  4.4495454  3.5527515 11.202981   2.7037582  4.979322   6.1030793\n",
      "  9.189027   8.533973   7.8720527  2.6067553 11.471531   4.752657\n",
      "  7.2766986  8.686044   8.496923   6.7943454]\n",
      "discriminator_11/conv_block_139/batch_normalization_215/moving_mean:0 [ 3.12452197e-01  5.91128945e-01 -1.01842158e-01 -1.23421097e+00\n",
      "  1.24814190e-01 -5.13144508e-02  5.92814624e-01  1.21706855e+00\n",
      "  5.72599828e-01 -1.49086908e-01  1.13096774e+00  2.11610243e-01\n",
      "  1.91773176e-01  7.18463659e-02 -5.34626842e-01 -1.24426842e+00\n",
      "  1.09299338e+00  4.91895676e-01 -1.51737309e+00 -3.55702601e-02\n",
      "  1.47612357e+00  6.21697128e-01  1.58598758e-02  1.60857868e+00\n",
      "  2.20448270e-01 -1.37429088e-01 -1.32405949e+00 -6.47548676e-01\n",
      "  7.88604796e-01  2.20040753e-01  4.18496698e-01  7.54080296e-01\n",
      "  4.60159749e-01  4.42966193e-01 -2.92262852e-01 -7.41948962e-01\n",
      "  3.81205916e-01 -1.98142564e+00 -2.81734616e-01 -1.24901623e-01\n",
      " -1.04390883e+00 -6.59119248e-01  1.41643763e+00 -1.84439316e-01\n",
      "  2.72342891e-01 -1.01084363e+00  1.59121335e+00  5.06742656e-01\n",
      "  5.37309647e-01 -3.46651286e-01  4.02431309e-01  1.02591366e-01\n",
      "  4.23180014e-01 -5.37310064e-01  1.35855842e+00  3.82431418e-01\n",
      " -9.48147833e-01  1.06238949e+00  1.50200069e-01  8.45228374e-01\n",
      "  2.71277338e-01  1.20878112e+00  2.88221866e-01  2.66077995e-01\n",
      " -1.47923231e-01  1.03213513e+00  6.43913746e-01  3.83414835e-01\n",
      " -3.49521667e-01 -1.14259791e+00  5.31674683e-01  4.35265779e-01\n",
      "  2.13262677e-01  5.46457708e-01 -2.59916282e+00  4.81400967e-01\n",
      "  2.36035019e-01  2.65534580e-01  1.03977990e+00  3.79014492e-01\n",
      "  3.46838802e-01 -9.97976065e-01  2.01955900e-01 -9.40802455e-01\n",
      "  4.22456622e-01 -9.65639710e-01 -4.15264040e-01 -1.32279074e+00\n",
      "  6.01772547e-01 -1.57214940e-01  1.30191040e+00  1.31198466e+00\n",
      "  5.77370040e-02  1.14069271e+00 -1.44707632e+00 -6.21953681e-02\n",
      " -1.73659098e+00  1.68572354e+00  1.12819743e+00  2.03244805e-01\n",
      "  2.80693084e-01  5.46268113e-02  1.03544995e-01 -7.56222010e-02\n",
      "  5.87206185e-01  7.84627616e-01  7.59172142e-02  4.46560830e-01\n",
      " -6.99527711e-02  8.48373055e-01 -6.15544498e-01 -1.02193201e+00\n",
      " -1.37563550e+00  3.60273451e-01 -4.06317592e-01  1.80229455e-01\n",
      "  8.61659229e-01  7.14573145e-01  1.53334141e-01  3.12667340e-01\n",
      "  6.77050889e-01 -6.32226229e-01 -8.13864589e-01  7.29353905e-01\n",
      " -5.60669780e-01  5.90631664e-01  1.60616279e-01 -7.22190738e-01\n",
      "  5.58642507e-01 -4.55287308e-01 -6.50347710e-01 -1.53564751e-01\n",
      " -1.13217030e-02 -4.08201158e-01 -9.07796100e-02  5.09276688e-02\n",
      "  5.48121892e-03  5.50818801e-01 -2.65353560e-01 -3.96449298e-01\n",
      " -8.31398606e-01 -1.81508124e+00  8.70257139e-01 -6.82833433e-01\n",
      "  6.17572606e-01 -3.34044904e-01  5.46988428e-01  1.76769674e+00\n",
      "  8.06823850e-01  6.87550485e-01  2.68157572e-01 -1.63409770e+00\n",
      "  1.41353622e-01  1.03986263e+00  7.56368339e-01  1.41945273e-01\n",
      " -1.29571748e+00  2.08573759e-01  5.13606071e-01  1.76984608e-01\n",
      " -1.63706875e+00  3.74261856e-01 -5.17272651e-01  8.36098120e-02\n",
      "  1.17578566e-01 -5.91117859e-01  7.63179958e-02 -4.04571295e-01\n",
      "  6.65190101e-01  4.44369167e-01 -8.14106286e-01  1.85364521e+00\n",
      "  2.98076004e-01  7.19124258e-01 -9.97595191e-01  4.04382348e-01\n",
      "  8.12617898e-01  4.12631422e-01 -4.70161229e-01  6.50803566e-01\n",
      "  8.95178258e-01 -1.51034284e+00  3.53692472e-01  4.61588688e-02\n",
      " -1.32813334e+00  6.21746778e-01 -7.48710752e-01  7.49067307e-01\n",
      "  5.53402126e-01  1.20259166e+00 -4.01144683e-01  9.89487290e-01\n",
      " -8.91495883e-01 -1.06182730e+00 -3.62503529e-03  1.30237687e+00\n",
      " -3.03077936e-01 -7.19699204e-01 -7.08379298e-02  6.28702700e-01\n",
      "  1.11813354e+00  6.32996023e-01 -3.30468714e-01 -6.09287560e-01\n",
      " -1.03619194e+00  6.68103546e-02 -1.90743732e+00  4.29028630e-01\n",
      " -7.15378761e-01 -3.90694797e-01  1.59263229e+00 -5.89491546e-01\n",
      " -1.23136109e-04 -2.31966332e-01 -2.87104219e-01  1.04323216e-01\n",
      " -2.18626237e+00  5.99139571e-01  4.10464972e-01  6.75265968e-01\n",
      " -8.59911323e-01 -1.22135831e-02  5.22229731e-01 -4.84573454e-01\n",
      "  5.76763511e-01  4.89797175e-01 -9.74767447e-01  8.12710941e-01\n",
      "  1.44438875e+00  6.61386073e-01  1.26590714e-01  1.01595514e-01\n",
      " -3.38371783e-01  6.67659700e-01  1.91956353e+00  1.26847577e+00\n",
      " -9.47678268e-01 -5.60269058e-01  5.93043745e-01  6.29874468e-01\n",
      "  1.19723105e+00 -9.79855478e-01 -1.61772266e-01  3.28495383e-01\n",
      "  2.24877857e-02 -5.28626442e-01  1.19238937e+00  3.18740457e-01\n",
      "  4.14131641e-01 -1.20508265e+00  1.02475178e+00 -1.10907936e+00\n",
      "  1.37244761e+00 -3.94574076e-01 -5.79855323e-01 -1.05658278e-01]\n",
      "discriminator_11/conv_block_139/batch_normalization_215/moving_variance:0 [0.93879807 0.503179   1.3129898  1.2783577  0.86208826 1.4343904\n",
      " 1.1255883  0.75763625 1.1839867  0.60372525 1.2877555  2.0835803\n",
      " 0.54423106 0.6452883  1.5808659  0.38855815 2.5011168  0.5927626\n",
      " 0.54889643 0.5379918  1.8809203  0.5752645  0.6285147  2.024892\n",
      " 2.0774512  1.0868295  1.1006792  2.0700376  1.8760912  0.9356616\n",
      " 1.2509906  1.4066126  0.78052235 1.5853647  0.49944788 0.6556666\n",
      " 2.1420221  0.5271223  0.35285276 1.4343038  1.0862831  0.7300999\n",
      " 1.7348539  1.358309   0.88677776 1.9011264  1.0594884  1.0441893\n",
      " 0.9187043  1.268389   1.1759442  1.1358854  1.6490895  0.26368713\n",
      " 1.4382367  2.9599113  1.1405512  0.93930215 1.60818    1.3149701\n",
      " 0.5394076  1.0483254  1.937281   2.2709827  0.8399264  1.9457202\n",
      " 0.5121294  1.0890335  0.52837974 0.8404375  0.896476   0.35847872\n",
      " 0.8431188  0.87456757 0.6357837  1.1751148  0.47540015 1.0386978\n",
      " 1.3730793  0.4792997  1.7099627  0.4007503  1.2481654  0.56108135\n",
      " 0.69400764 0.6913356  1.9183694  0.8521602  2.3878899  1.6409588\n",
      " 1.6011233  1.3531383  0.40027368 2.2417865  3.6962543  1.4590899\n",
      " 1.6331618  1.8560927  1.5692568  0.6246148  0.9432288  0.7738942\n",
      " 1.9621053  0.75958484 1.4330949  1.8342211  2.0413303  0.6521227\n",
      " 0.60869473 1.5753237  1.2669187  2.222986   0.52427244 3.4143689\n",
      " 1.2405722  0.8437885  0.9683033  1.0021263  1.7199519  0.6321875\n",
      " 1.0856445  0.73837054 1.497563   1.3709289  0.52294207 2.2332134\n",
      " 0.48450083 1.3477626  0.6312526  0.8563919  0.90960217 0.3919701\n",
      " 1.357622   0.9948364  1.0318655  0.47777456 0.6131676  1.7327807\n",
      " 1.0240012  0.515069   1.3701905  0.6948272  1.6274418  0.8694793\n",
      " 1.1137435  0.7979532  0.28382832 1.4215409  0.69720054 1.0397385\n",
      " 1.3308865  0.6675754  2.080973   1.2262537  0.7964389  0.69799405\n",
      " 0.37043065 0.58097106 0.958224   0.5846161  2.4021916  0.6689497\n",
      " 0.71921414 1.0817755  0.7838135  0.6499528  1.888069   1.464859\n",
      " 1.688931   0.78561395 0.69635457 1.5983248  1.0932903  0.8753972\n",
      " 0.846233   1.4846524  1.8456252  1.0487789  0.66246706 2.4273436\n",
      " 1.0422748  2.2352002  1.1622695  2.2168598  1.321701   1.0156496\n",
      " 2.047777   1.4182391  0.46476358 1.4687835  0.99953204 1.070678\n",
      " 0.6018687  0.7350333  3.4691563  1.139446   1.1743902  0.32369435\n",
      " 1.2030472  1.3303769  1.7066606  1.7048666  1.0943669  0.6008641\n",
      " 1.5148137  1.554503   1.0634347  1.1084732  1.7086915  1.5487345\n",
      " 0.86325794 1.872729   0.53074175 0.40886587 0.40146366 0.8677948\n",
      " 0.9154506  1.8009561  1.2278401  0.97759193 0.4964992  2.4874473\n",
      " 0.88671696 0.87872577 1.8004211  0.3463263  0.7999663  1.9682877\n",
      " 2.4297676  0.8960467  0.37657815 0.534486   1.3419899  1.6681584\n",
      " 1.9732612  1.7610499  1.8221323  0.54162335 2.4444246  1.525711\n",
      " 2.6784415  1.2640787  1.0665307  0.4156644  1.4666945  0.54863316\n",
      " 1.1686212  1.5596327  0.5023405  0.43186435 0.9808532  0.80030924\n",
      " 0.88912207 1.6629252  0.8249521  0.8458631 ]\n",
      "discriminator_11/conv_block_140/batch_normalization_216/moving_mean:0 [-0.12391584 -0.8680479  -2.2573812   0.21365945  1.0530701   4.7562594\n",
      "  1.7016674   2.9815502  -1.851815    1.4950669   4.560767   -1.4210249\n",
      "  0.5692597   4.43391     3.1549294   2.8804483  -2.0122278   0.21888554\n",
      "  1.2557591  -1.3816506  -0.70845544  1.2031403   2.0305245   0.0225435\n",
      " -0.8802508   1.4922994  -1.1791097   1.3004262  -3.3888862   4.0464497\n",
      "  0.3385165  -0.8806852  -5.449436    3.3016849  -0.7391675   2.8677962\n",
      " -1.5346767   2.8164055   0.1285763  -0.38832918  2.1662383   2.049397\n",
      " -4.741045    2.731523    2.8937044  -0.33774468  3.7508216   0.80411905\n",
      " -0.5613488   2.72171    -1.019861   -2.396704    1.8201237   1.0914696\n",
      "  1.779498   -0.584555    0.9403922  -2.8762388   4.060303    3.7910578\n",
      "  3.8126347  -0.52877444  2.6768773  -0.28924236  3.8493745  -0.76651436\n",
      "  3.1811116   2.75777     2.8034272  -0.79789203  2.950948    1.2114646\n",
      "  5.763338    1.1141263   2.5444412   3.8251264  -0.49166104  3.858828\n",
      "  0.35035756 -0.7936489   0.05782188 -1.5409056   3.085306   -5.678175\n",
      "  3.5622478   0.25612196  4.834601   -2.017716    0.24181281  0.5725831\n",
      "  3.0280206   0.15798105 -0.5032782   2.9611216  -3.1812656   2.7137833\n",
      "  0.2300293   1.7211872   1.8940384   1.1190572   1.1367472   0.10650155\n",
      "  3.0779366   0.4952186   0.4870888   0.8209129   2.7000473   4.5337834\n",
      "  0.41065553  1.2848303   1.794503   -5.3142514   3.7671344  -0.446806\n",
      "  2.3827598  -1.9878025   3.2915487   1.8238037   1.9055238   5.4894276\n",
      "  2.4770665   7.326915   -0.28350124  1.6744534   1.711226    4.112348\n",
      "  0.7864067   0.03170304]\n",
      "discriminator_11/conv_block_140/batch_normalization_216/moving_variance:0 [ 6.0953493  6.7505    10.748052   8.055739   4.369324   9.794775\n",
      " 10.115925   4.3509884 30.5637     6.2995915  4.6081643 19.101204\n",
      " 14.800394  14.181456  11.543099  11.709285   5.8558354  5.7095118\n",
      "  7.8955426  4.701215   8.550659  10.250052   9.411124   6.96383\n",
      "  6.947795   3.2571225  7.6107316  9.1771965 31.976809   5.4427624\n",
      "  8.192885  27.798021   9.751719   5.8089943  4.8153243 10.749643\n",
      "  7.1661263  9.804586   5.5794473  5.2579436 11.751299  10.442737\n",
      "  9.027355   6.983486   9.06223    6.6430902  8.802604   6.383315\n",
      " 25.01438    7.485836   6.7808685  5.115668   9.712606   8.149437\n",
      "  8.338652   3.1246052  9.110267  13.5663185 10.100362  11.781302\n",
      " 13.41462   10.476018   6.411946   4.1141467 15.161541  38.05013\n",
      " 19.355112   6.6172767  5.6327176  3.999227   7.5561767  7.533882\n",
      " 17.824749  10.447174   9.4634285  8.838066   5.7266674  9.22049\n",
      "  5.246421   5.2773857  4.9002614 12.447733   6.5965195 10.942673\n",
      " 12.288862  21.05754   22.305311   9.005218   9.790036   6.5780473\n",
      " 13.039051   9.112694   8.75275   10.526412   4.6481905 12.092517\n",
      "  8.043852   7.700081   6.756031  10.758975   3.322847   8.132696\n",
      " 22.701094   4.032894   3.763881   7.0815477  6.802119   6.14547\n",
      "  5.740359   8.068218   8.32054   48.62836    4.4281044  8.949227\n",
      "  7.348638  10.045438   7.6528106  7.2720513  5.593495  23.6228\n",
      "  4.895329  23.91683   11.784784   6.6833596  7.354962  15.816632\n",
      " 11.585986  10.062996 ]\n",
      "discriminator_11/conv_block_141/batch_normalization_217/moving_mean:0 [ 0.49398166  0.8771343   0.11989194 -0.37684757  0.69927615  0.17486836\n",
      " -0.0245577   0.22064437  0.36413714  1.4329114   0.5932451   0.13030683\n",
      "  0.618714   -0.8810081   2.1533022   2.5762575   0.58946943  0.24198928\n",
      "  0.9310987   0.67952204  1.4018557   1.8474474   0.28470242 -0.7563018\n",
      "  1.5066413  -1.2000184   1.4191236   0.98747325  1.8671802   0.05183671\n",
      "  0.65204555  0.9422177   0.54910576  1.2508675   1.0046349  -0.45998073\n",
      "  0.8882748   0.4489124  -0.6716611   0.78802603  0.9464369   1.3288652\n",
      "  0.7700456   0.04981049  0.30677232  0.5711901  -0.8217092   0.83157873\n",
      "  0.3610632   2.0007493   1.476185    0.88494027 -1.0204983  -0.655416\n",
      "  1.4196161   3.093334    0.39989853  1.211903    0.25961104  0.83652\n",
      "  0.08495033  0.13661095 -1.5704942   1.2073076  -0.84205097  2.134971\n",
      "  0.24995105  1.0417823   0.9896257   0.7816903   0.8112496   0.52936614\n",
      "  1.3295858  -0.68717766  3.1482453   1.1318583   1.2552626  -0.404992\n",
      "  1.0791111   2.0054526  -1.6871873   0.1776741   0.62474906  0.55446833\n",
      "  0.29040003  0.62273085 -0.02835388  1.9204537   2.1011672   0.96299356\n",
      "  0.34090936  0.3662277   1.457973    2.5384574  -0.03936286  0.55658865\n",
      " -0.3538841  -1.0864103  -1.3233141   0.01780383 -0.15086542 -0.30522078\n",
      "  1.5580667   0.40921247  1.2785587  -0.49479744  0.4345411  -0.37233365\n",
      "  0.9470983  -0.74648446  0.9642678   0.79613453  0.8988169   1.0918208\n",
      "  0.7634922  -0.47675994  0.65025234 -0.13517879  1.3122809   0.24859335\n",
      "  1.5585804   1.8893118  -0.15314277  0.68786436  1.0883017  -0.63137966\n",
      "  2.1787899   2.910695  ]\n",
      "discriminator_11/conv_block_141/batch_normalization_217/moving_variance:0 [ 1.4348135   5.495977   14.479328    2.3117328   6.0525126   4.1340847\n",
      "  2.4619765   1.61892     5.0854692   3.9564722   2.2233248   3.1488574\n",
      "  1.8551447   2.0751066   6.085065    7.9772296   6.512209    3.0549552\n",
      "  1.7290021   7.089979    1.8411275   3.1488295   2.4968245   3.1651933\n",
      "  2.6260762   2.13732     6.044474    2.3074882   2.6098132   8.178783\n",
      "  1.6543528   3.598741    5.4644613   2.3093865   1.7905413   1.7276459\n",
      "  2.963364    9.705205    4.0424285   4.44904     3.8003871   3.2680502\n",
      "  2.4129212   3.0625482   2.7146928   2.5044029   2.9492188   3.0818727\n",
      "  2.5207548   5.155791    2.3721797   3.3657234   1.5573888   2.446737\n",
      "  2.347136    7.289563    6.500708    3.2113876   3.3558507   1.6538571\n",
      "  3.812268    5.635857    3.8158424   2.6132946   6.2284393   4.614557\n",
      "  2.3825147   2.231781    2.1150117   3.5194225   2.1374607   5.761018\n",
      "  5.8742003   3.0352147   4.830003    6.122223    2.8918774   1.3010519\n",
      "  3.3052397   5.4232597   2.5374997   5.518228    1.8873262   2.3836243\n",
      "  2.699926    5.450098    0.92094105  7.527913   10.750551    3.2632577\n",
      "  4.9008546   2.95091     3.5201144   5.5179653   3.180966    1.4807652\n",
      "  4.639066    2.1281216   2.7091212   2.0841923   6.173884    3.5049596\n",
      "  2.6200213   3.896667    2.1983855   3.2355535   1.8717481   3.252264\n",
      "  2.8607426   2.2704046   3.1271267   4.168281    2.6047854   4.4512177\n",
      "  3.227654    3.3366284   1.6383766   9.298205    2.6272078   5.2172146\n",
      "  2.900232    4.595127    7.5148163   3.9854243   2.9896739   3.02555\n",
      "  6.167371    6.071581  ]\n",
      "discriminator_11/conv_block_142/batch_normalization_218/moving_mean:0 [ 1.78511724e-01  5.71210146e-01  4.48907286e-01  1.06005646e-01\n",
      "  5.63158751e-01 -7.67487586e-02 -3.48490506e-01  9.42030609e-01\n",
      " -8.16089194e-03 -1.02016151e+00 -6.80092990e-01 -5.03108501e-01\n",
      " -2.53316760e-01  1.73404440e-01 -6.80348396e-01  8.36525142e-01\n",
      " -2.81252056e-01  3.56225789e-01  3.79180282e-01 -1.09981501e+00\n",
      "  1.85188204e-01  8.38678002e-01  5.39649129e-01  7.99729954e-03\n",
      "  2.61553586e-01  6.49494648e-01 -2.41776779e-02  5.51641166e-01\n",
      " -7.48666823e-01 -1.11353517e+00  3.64116549e-01 -5.88451684e-01\n",
      " -1.01199400e+00  2.92122811e-01 -8.53743374e-01  3.32413375e-01\n",
      "  5.85930526e-01 -2.26620749e-01  1.35784864e-01  3.16598862e-01\n",
      " -3.54892462e-02 -5.35191715e-01  1.02727902e+00  6.48777723e-01\n",
      "  6.16817037e-03 -4.25164681e-03  6.24963403e-01  3.17843914e-01\n",
      "  1.21903670e+00 -2.89090186e-01  4.85968024e-01 -1.28687397e-01\n",
      "  2.09063247e-01 -3.42101842e-01  4.43419367e-01  1.52945352e+00\n",
      " -2.77161211e-01 -1.01521105e-01 -5.98371103e-02  2.53784567e-01\n",
      "  1.65489409e-02  3.70408185e-02 -5.48923314e-01  2.13069275e-01\n",
      "  9.74804759e-02 -2.16399282e-01  1.12499249e+00 -3.88053030e-01\n",
      "  3.12157124e-01 -1.06601167e+00  1.22402675e-01  4.69690770e-01\n",
      "  2.48887166e-01  3.55493456e-01 -6.30524337e-01  7.56204844e-01\n",
      "  4.48610261e-02  5.37653208e-01 -2.59118050e-01 -4.14466225e-02\n",
      "  3.62875462e-01 -1.90735936e-01 -2.04084609e-02  5.09801209e-01\n",
      "  3.91664475e-01  3.55812162e-01 -3.32078427e-01  2.72572078e-02\n",
      "  4.46198851e-01  1.97757244e-01 -3.39312971e-01 -3.91687602e-01\n",
      " -8.88060629e-02  7.03295290e-01  4.67867329e-04  5.74252427e-01\n",
      "  6.00154340e-01 -1.63532957e-01  5.64763919e-02  3.40139687e-01\n",
      "  3.16154510e-01 -2.58826226e-01 -1.43518642e-01 -2.52999723e-01\n",
      "  1.87643275e-01  2.98517615e-01  2.88628321e-02  2.14223310e-01\n",
      " -1.68507829e-01 -6.67597413e-01 -1.58743843e-01 -6.37985229e-01\n",
      "  1.94419503e-01 -2.36808807e-01  3.44306648e-01 -3.34785581e-01\n",
      "  4.04852271e-01  4.68243867e-01  1.65295944e-01  7.04898536e-01\n",
      "  5.06563127e-01 -2.31514886e-01  2.35476911e-01 -1.25154942e-01\n",
      "  1.88033730e-01  1.56032160e-01  7.98670709e-01  5.74138165e-01]\n",
      "discriminator_11/conv_block_142/batch_normalization_218/moving_variance:0 [2.0413318  1.1765734  1.7266804  0.8605751  1.1203955  1.4505097\n",
      " 1.0164366  1.3620855  1.2242913  1.3836608  0.81862706 1.8290814\n",
      " 0.5380134  1.15655    1.4476587  0.8195059  0.6114806  0.8321563\n",
      " 0.9029619  0.61599797 0.98746276 1.3228241  0.54876727 0.8795846\n",
      " 1.5465127  1.091898   1.2281181  0.58857125 0.8630424  2.922682\n",
      " 1.0912513  0.5534507  1.075163   0.78559095 0.6299115  1.3083987\n",
      " 0.8927812  0.56804734 1.0086854  1.0083836  1.8141901  0.4572053\n",
      " 1.2193897  1.1462538  0.80017465 0.47649643 1.2982001  0.7719954\n",
      " 2.3596194  0.9512232  0.7480279  1.0719149  1.6952033  0.9145738\n",
      " 1.2489294  2.3848639  0.93907696 0.93142873 1.139782   1.3142515\n",
      " 0.8301925  1.5907986  1.2413309  1.6314387  0.6842041  0.61426777\n",
      " 1.4378035  0.7098432  2.6391227  1.9793651  0.96628314 0.85403913\n",
      " 1.6488582  1.045338   1.0285958  0.850181   0.871787   2.242944\n",
      " 1.152899   0.77729166 1.379989   1.4101063  0.6459021  0.43895793\n",
      " 2.8440735  1.2253891  1.4290525  2.300186   0.72136366 0.77387035\n",
      " 0.8006456  0.67744493 1.2187377  1.0054482  0.4954713  2.8697364\n",
      " 1.0723944  1.1498631  1.1870092  0.6731633  0.4752993  0.61092156\n",
      " 1.1284922  1.7720449  0.9036527  1.1110741  2.1354206  0.82435733\n",
      " 0.5891551  1.0518312  1.106718   1.2410097  0.87877804 0.6144151\n",
      " 0.77776176 0.48358387 0.7577084  0.87196314 0.64653915 1.0507274\n",
      " 0.7900969  1.3036282  1.2322621  1.4478353  0.79936296 1.9321455\n",
      " 1.3113712  0.7862747 ]\n",
      "discriminator_11/conv_block_143/batch_normalization_219/moving_mean:0 [ 3.6588794e-01 -2.5650728e-01  1.4287250e+00  1.1348385e+00\n",
      "  4.3405824e+00  1.6898618e+00  8.0924833e-01  1.1953375e+00\n",
      "  2.8285282e+00  1.6267262e+00 -8.3516610e-01  1.0811157e+00\n",
      "  7.6396003e-02 -1.5542849e+00  2.7124298e+00 -2.7107367e-01\n",
      "  2.8474212e-01 -2.2843499e-01  2.0079252e-01  2.6459002e+00\n",
      "  1.8951628e-02  2.8752542e+00 -7.9071216e-02  4.5058990e+00\n",
      "  1.1033003e+00 -2.8482136e-01  1.5079219e+00  1.9814707e+00\n",
      " -1.5426544e+00  1.2270821e+00  5.6370407e-01  3.2118707e+00\n",
      "  8.8777250e-01  1.9247246e+00 -5.3978145e-01  8.8855994e-01\n",
      "  1.3050989e+00 -1.0384382e+00 -2.5570604e-01  1.4616746e-01\n",
      "  1.8694557e+00  7.9748207e-01  3.7844768e+00  1.4546500e+00\n",
      " -9.0421420e-01  2.8054955e+00  1.1050084e-01  1.0395846e+00\n",
      "  9.6463358e-01  1.8423932e+00 -8.8122034e-01  7.2582281e-01\n",
      " -9.5476335e-01 -5.2879703e-01  1.3876656e+00  6.4488792e-01\n",
      "  1.1750517e+00 -3.3021017e-03  2.0608089e+00  9.3995780e-01\n",
      " -1.6144653e-01 -1.2422342e+00  4.4995613e+00  1.1517044e+00]\n",
      "discriminator_11/conv_block_143/batch_normalization_219/moving_variance:0 [ 4.040187    2.586696    3.0106134   2.8262715   6.335824    2.4968767\n",
      "  1.3998597   3.834176    3.1173086   4.686208    7.150721    4.8141007\n",
      "  1.6633263   2.6634727   3.5264823   2.6919234   3.8928914   3.3316264\n",
      " 12.075441    5.324307    8.089372    5.1599603   3.1443264   4.8911495\n",
      "  4.242235    2.1754527   3.174476    2.653822    3.6649005   0.97096217\n",
      "  2.7692595   4.417306    1.9490818   5.661311    1.9788489   1.8514086\n",
      "  3.8357904   1.3948069   2.9868822   1.947193    4.278787    4.0919056\n",
      "  4.2770348   2.9459345   1.5419278   5.9924684   1.8181713   1.4572482\n",
      "  9.296301    1.9212763   2.0019617   4.885772    8.271191    2.1781394\n",
      "  2.928003    2.156098    2.060424    3.485162    4.7481284   3.1313858\n",
      " 12.107642    2.653796    4.829681    2.72398   ]\n",
      "discriminator_11/conv_block_144/batch_normalization_220/moving_mean:0 [-0.0654228  -0.10706684 -0.1536465   0.20622958 -0.22926253 -0.22338215\n",
      " -0.25582266  0.5892224  -0.31358957 -0.12805028 -0.4193147  -0.7569166\n",
      " -0.30596718  0.64388406  0.2352359   0.59314346  0.13351347 -0.573232\n",
      " -0.7529755   0.11739665  0.6724879  -0.06744145 -0.00974863 -0.76819384\n",
      " -0.09121271  0.09916268  0.20092514  0.6038903   0.37429094  0.30812767\n",
      "  0.49111736  1.0091426  -0.8592712   0.53793293  1.1864456   0.09532798\n",
      "  0.05561198  0.6162348   0.21806006 -0.3615857  -0.91381615  0.76822317\n",
      " -0.39319474  0.22731924 -0.54741496 -0.20283653 -1.338523   -0.08901945\n",
      " -0.4452337   0.20379224 -0.44217506  0.38104528  0.12112084  0.48480666\n",
      " -1.1077123  -0.0121717   0.08072245  0.84141576  0.562651    0.10482565\n",
      "  0.5328591  -0.32797378  0.12435532  0.3800761 ]\n",
      "discriminator_11/conv_block_144/batch_normalization_220/moving_variance:0 [0.38849226 0.37213483 1.1258028  0.7254986  0.8225067  0.9232241\n",
      " 1.9524782  1.9631394  0.38812187 0.6452396  1.2026346  1.6719453\n",
      " 0.5205225  2.346663   0.50194085 1.4116169  0.88709855 0.84835553\n",
      " 0.66226983 0.58766186 1.6535563  0.64221907 0.5026857  1.6865007\n",
      " 0.7802048  0.682321   1.8098912  1.0216167  2.611031   0.8083357\n",
      " 2.2014585  1.8197225  1.0452366  1.4194422  1.5257758  0.3174295\n",
      " 0.4753038  2.3216085  0.47237456 0.59722036 1.3072649  1.9140043\n",
      " 1.0254594  1.1490538  0.92338485 0.58897406 2.8313024  1.3283656\n",
      " 0.60684836 0.609942   1.5365872  0.55823207 2.6957595  1.4943312\n",
      " 1.6500043  0.9616249  0.26816663 1.463914   1.2392418  0.72122383\n",
      " 0.9704289  1.1273389  0.43133673 1.6958743 ]\n",
      "discriminator_11/dense_69/kernel:0 [[ 0.01518272 -0.01727357  0.11547078 ...  0.07859822  0.10121811\n",
      "   0.01500937]\n",
      " [-0.1081837   0.00226737 -0.09239859 ...  0.03333235 -0.02641039\n",
      "   0.12300227]\n",
      " [-0.0458055  -0.06925458 -0.09768202 ...  0.1012485  -0.08165339\n",
      "   0.01406488]\n",
      " ...\n",
      " [-0.04226872  0.1155743   0.13008112 ...  0.01284929 -0.05410586\n",
      "  -0.11754826]\n",
      " [ 0.00921893 -0.00106989  0.10532468 ... -0.04272209  0.01816027\n",
      "  -0.12181904]\n",
      " [ 0.0115134  -0.02404218 -0.05011182 ... -0.0368406  -0.09197309\n",
      "  -0.0032262 ]]\n",
      "discriminator_11/dense_69/bias:0 [-0.07350182 -0.07526473 -0.07375455  0.07368562 -0.0757471   0.07424285\n",
      " -0.07040896 -0.07374797  0.07194711 -0.07525538  0.07337766  0.07265133\n",
      "  0.06583241 -0.07368301  0.07223575 -0.07518894  0.0750161   0.06586203\n",
      " -0.06975871 -0.06967147 -0.07246754  0.07530891 -0.0750502   0.06563289\n",
      " -0.07484963  0.07520811 -0.0751895  -0.07367189  0.07004579  0.0729407\n",
      "  0.07328855  0.07435577  0.06292762 -0.07167968 -0.0735578  -0.07258124\n",
      "  0.01314723 -0.07100781 -0.07217528  0.07395615 -0.0737434   0.06576177\n",
      " -0.07080357 -0.07227127 -0.07420304 -0.07454128  0.04444939  0.07182634\n",
      "  0.07228395 -0.07382028 -0.07269339  0.02904039 -0.07537382 -0.07591969\n",
      " -0.07612059 -0.07201968 -0.07726963 -0.07444273 -0.0732421   0.07263912\n",
      "  0.05925925  0.07154527  0.06797816  0.02721802  0.07163122  0.07109223\n",
      "  0.02743102 -0.07340943  0.06090736 -0.07530143 -0.07214187  0.06916205\n",
      "  0.02302516  0.06225395 -0.07525709 -0.06833608 -0.07177019  0.07011063\n",
      "  0.07025283  0.07240203  0.07087809 -0.07455212 -0.07602048 -0.07477711\n",
      "  0.06977603  0.06894641 -0.06958076 -0.07325188 -0.07367159  0.07462069\n",
      " -0.07436933  0.0739181  -0.07379961  0.07425161 -0.07506562  0.07075563\n",
      " -0.07511623  0.07044606  0.0755979  -0.07532955  0.07661462  0.0711583\n",
      " -0.07522201  0.07287918 -0.07554634 -0.07573824 -0.07066029 -0.07212662\n",
      " -0.06942558 -0.07541857 -0.07539168 -0.07570067  0.06753383  0.06125573\n",
      "  0.07098693 -0.07482471 -0.07421374  0.06923989 -0.07354745  0.07004645\n",
      " -0.07301243  0.06304002  0.07592295  0.02763776  0.03038713  0.02617279\n",
      " -0.07403078  0.07524021]\n",
      "discriminator_11/dense_70/kernel:0 [[-0.01260295 -0.0360019   0.00274348 ... -0.06015816 -0.01983648\n",
      "  -0.06917039]\n",
      " [ 0.04979632  0.04106643  0.06438632 ...  0.07204305  0.03293379\n",
      "  -0.02959825]\n",
      " [ 0.02387493  0.03480427 -0.02358927 ... -0.04279147 -0.06232278\n",
      "  -0.06944368]\n",
      " ...\n",
      " [-0.01571499  0.00807373  0.07861849 ... -0.11283948  0.04184562\n",
      "  -0.0244557 ]\n",
      " [ 0.00998909 -0.0605019   0.0451996  ...  0.0558242  -0.04772153\n",
      "   0.01792759]\n",
      " [-0.00135872 -0.02604351  0.18874909 ... -0.06723353  0.04573063\n",
      "   0.04903269]]\n",
      "discriminator_11/dense_70/bias:0 [-0.02898659  0.00881194  0.01649876  0.01917099 -0.07771794  0.03709239\n",
      "  0.06762773 -0.02594209 -0.05784395  0.02501685  0.06474752  0.04563813\n",
      " -0.06585898 -0.01367186  0.05181465  0.0720035   0.07577035  0.01270673\n",
      " -0.04540788 -0.07330969  0.00256635  0.05974418  0.06608797  0.05653384\n",
      "  0.0244372   0.0124967  -0.06445204  0.03535903 -0.00344254  0.01158193\n",
      "  0.05635472  0.06897667 -0.07027385  0.02187661 -0.00988474 -0.05861076\n",
      "  0.00963541  0.0652376   0.07281623  0.0158767  -0.06636699  0.05264181\n",
      " -0.01443172  0.03079933  0.03346333  0.04694433 -0.00924557 -0.0469489\n",
      "  0.06825171 -0.03904559 -0.01139204 -0.01482449  0.02188088 -0.07163152\n",
      "  0.05252714 -0.07258503  0.00381953 -0.048797   -0.00612938  0.04374274\n",
      " -0.03296473  0.0712494  -0.06005494  0.02212177  0.00627941  0.00918667\n",
      " -0.05739871  0.02160567  0.06043379 -0.04958758 -0.0212654   0.06690672\n",
      " -0.00912637  0.07351466  0.05002981 -0.07106894 -0.00990433 -0.06414114\n",
      " -0.01591945 -0.01192915 -0.06166679 -0.00114676  0.02380489 -0.02334803\n",
      "  0.04111605  0.01942012  0.00021066  0.02593165 -0.04977881 -0.06631602\n",
      "  0.06676751 -0.06304969  0.03652704  0.02739116  0.00448106  0.00624961\n",
      "  0.07607747 -0.07180965  0.05461966  0.06044603  0.01048573  0.03043198\n",
      "  0.01649195 -0.01641673  0.05528197 -0.0029024  -0.06265925  0.03565315\n",
      "  0.02707907 -0.00909306  0.05537207  0.05643907  0.00823609  0.07508315\n",
      " -0.04645766 -0.00922362  0.00186145 -0.06123634  0.04431253  0.0364442\n",
      " -0.0218824   0.07746761  0.04450009  0.0233806  -0.0321527   0.04568727\n",
      " -0.04956071 -0.02885092]\n",
      "discriminator_11/dense_71/kernel:0 [[-2.00049251e-01]\n",
      " [-1.13089688e-01]\n",
      " [-8.43300819e-02]\n",
      " [ 8.10393319e-03]\n",
      " [-1.65900245e-01]\n",
      " [ 1.64352115e-02]\n",
      " [-9.97219309e-02]\n",
      " [-2.08630189e-01]\n",
      " [ 6.36934415e-02]\n",
      " [-1.96848020e-01]\n",
      " [ 7.17291832e-02]\n",
      " [ 3.15498263e-02]\n",
      " [ 1.07931018e-01]\n",
      " [-1.91803783e-01]\n",
      " [ 1.12319291e-02]\n",
      " [-8.10252652e-02]\n",
      " [ 2.45598946e-02]\n",
      " [ 1.28165841e-01]\n",
      " [-6.90241009e-02]\n",
      " [-9.66902822e-02]\n",
      " [-1.67949989e-01]\n",
      " [ 1.08229481e-02]\n",
      " [-2.04899311e-01]\n",
      " [-1.49844366e-03]\n",
      " [-2.01877370e-01]\n",
      " [ 5.91045544e-02]\n",
      " [-9.80510116e-02]\n",
      " [-1.28224760e-01]\n",
      " [ 8.28072312e-04]\n",
      " [ 9.47013050e-02]\n",
      " [ 4.11457829e-02]\n",
      " [ 7.69867282e-03]\n",
      " [ 1.46222219e-01]\n",
      " [-7.12282434e-02]\n",
      " [-1.09041847e-01]\n",
      " [-8.18045288e-02]\n",
      " [-6.01847749e-03]\n",
      " [-1.27400041e-01]\n",
      " [-1.88046649e-01]\n",
      " [ 7.53896832e-02]\n",
      " [-6.20675571e-02]\n",
      " [ 1.13118246e-01]\n",
      " [-1.23982400e-01]\n",
      " [-1.12752140e-01]\n",
      " [-1.61352605e-01]\n",
      " [-8.71741101e-02]\n",
      " [-1.20104263e-02]\n",
      " [ 7.79769868e-02]\n",
      " [ 8.75901431e-02]\n",
      " [-1.39571711e-01]\n",
      " [-1.04173407e-01]\n",
      " [-1.28773153e-02]\n",
      " [-9.20094699e-02]\n",
      " [-1.58871725e-01]\n",
      " [-1.91372231e-01]\n",
      " [-1.98959649e-01]\n",
      " [-9.22900066e-02]\n",
      " [-9.84273255e-02]\n",
      " [-1.08410500e-01]\n",
      " [ 5.43407314e-02]\n",
      " [ 2.20352970e-03]\n",
      " [ 5.12849875e-02]\n",
      " [ 1.10748179e-01]\n",
      " [-9.12438799e-03]\n",
      " [ 4.75801378e-02]\n",
      " [ 3.46209034e-02]\n",
      " [-9.42401681e-03]\n",
      " [-1.85910940e-01]\n",
      " [ 1.26890302e-01]\n",
      " [-1.71522617e-01]\n",
      " [-9.44106951e-02]\n",
      " [ 9.01385471e-02]\n",
      " [-1.06139388e-02]\n",
      " [ 1.24964923e-01]\n",
      " [-7.03006163e-02]\n",
      " [-5.36123477e-02]\n",
      " [-2.01098740e-01]\n",
      " [ 2.18866877e-02]\n",
      " [ 9.11562666e-02]\n",
      " [ 7.58952945e-02]\n",
      " [ 5.98315038e-02]\n",
      " [-1.98945209e-01]\n",
      " [-8.97352621e-02]\n",
      " [-1.92978516e-01]\n",
      " [ 1.67774654e-03]\n",
      " [ 2.33461019e-02]\n",
      " [-7.74273723e-02]\n",
      " [-1.92512050e-01]\n",
      " [-1.05071329e-01]\n",
      " [ 2.16613282e-02]\n",
      " [-8.77542347e-02]\n",
      " [ 6.82613626e-02]\n",
      " [-1.46605954e-01]\n",
      " [ 3.74736786e-02]\n",
      " [-1.22759163e-01]\n",
      " [ 8.40895250e-02]\n",
      " [-1.93945169e-01]\n",
      " [ 7.59672299e-02]\n",
      " [ 1.50366556e-02]\n",
      " [-1.34727731e-01]\n",
      " [ 2.69109122e-02]\n",
      " [ 1.07975397e-02]\n",
      " [-1.19163126e-01]\n",
      " [ 2.01713461e-02]\n",
      " [-9.08184946e-02]\n",
      " [-1.39205232e-01]\n",
      " [-7.18400851e-02]\n",
      " [-6.17420226e-02]\n",
      " [-1.50616691e-01]\n",
      " [-1.65345460e-01]\n",
      " [-1.18893221e-01]\n",
      " [-1.75811365e-01]\n",
      " [ 7.81173958e-03]\n",
      " [ 1.41812921e-01]\n",
      " [ 4.75866273e-02]\n",
      " [-8.26979429e-02]\n",
      " [-1.82031378e-01]\n",
      " [ 2.92799855e-03]\n",
      " [-1.02997147e-01]\n",
      " [ 2.01427732e-02]\n",
      " [-1.30380511e-01]\n",
      " [ 1.31168067e-01]\n",
      " [ 3.59750129e-02]\n",
      " [-8.64463113e-03]\n",
      " [-8.25771783e-03]\n",
      " [-8.85879621e-03]\n",
      " [-9.70158949e-02]\n",
      " [ 4.88670543e-02]\n",
      " [-2.15532407e-01]\n",
      " [-8.66849422e-02]\n",
      " [-4.59857285e-01]\n",
      " [-3.69750001e-02]\n",
      " [-1.54622301e-01]\n",
      " [-2.21206062e-02]\n",
      " [-7.47223524e-03]\n",
      " [-2.14483082e-01]\n",
      " [-1.33664265e-01]\n",
      " [-1.70348492e-02]\n",
      " [ 7.85136297e-02]\n",
      " [-3.32981423e-02]\n",
      " [-1.99059293e-01]\n",
      " [-3.74704421e-01]\n",
      " [ 7.97599554e-02]\n",
      " [ 4.20440882e-02]\n",
      " [-8.97132501e-04]\n",
      " [-4.55860227e-01]\n",
      " [-2.09031209e-01]\n",
      " [-9.92530142e-04]\n",
      " [-4.23474282e-01]\n",
      " [ 1.60734966e-01]\n",
      " [ 9.61957127e-03]\n",
      " [ 1.41798213e-01]\n",
      " [-4.12101075e-02]\n",
      " [-4.26047184e-02]\n",
      " [-1.09170042e-01]\n",
      " [-3.79341915e-02]\n",
      " [-4.11253601e-01]\n",
      " [-1.40377566e-01]\n",
      " [ 1.61017612e-01]\n",
      " [ 7.92615041e-02]\n",
      " [-7.29486123e-02]\n",
      " [-2.70876903e-02]\n",
      " [-2.23071367e-01]\n",
      " [-1.75307497e-01]\n",
      " [-1.07569266e-02]\n",
      " [ 5.28233722e-02]\n",
      " [ 1.87637340e-02]\n",
      " [ 1.54128605e-02]\n",
      " [-2.03691438e-01]\n",
      " [-1.87120978e-02]\n",
      " [-2.12456942e-01]\n",
      " [ 1.00846577e-03]\n",
      " [ 1.49048576e-02]\n",
      " [ 1.37869328e-01]\n",
      " [-3.98159564e-01]\n",
      " [-1.83897674e-01]\n",
      " [ 8.65538642e-02]\n",
      " [-1.32702351e-01]\n",
      " [-1.99741721e-01]\n",
      " [-1.40076270e-02]\n",
      " [ 1.19712120e-02]\n",
      " [-9.20927078e-02]\n",
      " [ 1.30816668e-01]\n",
      " [-7.22525939e-02]\n",
      " [ 1.04758488e-02]\n",
      " [-1.06540836e-01]\n",
      " [-4.07566011e-01]\n",
      " [ 1.13688521e-01]\n",
      " [-1.74582392e-01]\n",
      " [ 6.47261217e-02]\n",
      " [-8.20649490e-02]\n",
      " [-2.81582698e-02]\n",
      " [-1.10234499e-01]\n",
      " [-8.99050105e-03]\n",
      " [-2.11590324e-02]\n",
      " [-3.84460366e-03]\n",
      " [ 7.47354329e-02]\n",
      " [-1.02366112e-01]\n",
      " [-2.44759157e-01]\n",
      " [-6.46248506e-03]\n",
      " [-3.73380065e-01]\n",
      " [ 2.55827736e-02]\n",
      " [ 1.50462300e-01]\n",
      " [-4.77407947e-02]\n",
      " [-3.82925689e-01]\n",
      " [-4.43385690e-02]\n",
      " [ 2.55039334e-02]\n",
      " [-3.71520132e-01]\n",
      " [-1.96631074e-01]\n",
      " [-9.84281208e-03]\n",
      " [-3.29353139e-02]\n",
      " [-3.58032078e-01]\n",
      " [ 2.22598940e-01]\n",
      " [-1.81519333e-02]\n",
      " [-2.92544607e-02]\n",
      " [ 7.01580849e-03]\n",
      " [-1.11077644e-01]\n",
      " [-1.12687245e-01]\n",
      " [-4.24311915e-03]\n",
      " [-1.84872940e-01]\n",
      " [-3.73881161e-02]\n",
      " [-3.81486565e-02]\n",
      " [ 1.31378137e-02]\n",
      " [-9.79562923e-02]\n",
      " [-2.95435137e-04]\n",
      " [-1.14460841e-01]\n",
      " [ 1.41710490e-01]\n",
      " [ 1.26687095e-01]\n",
      " [-1.84000451e-02]\n",
      " [ 1.25402212e-02]\n",
      " [-4.57977682e-01]\n",
      " [-1.69797875e-02]\n",
      " [ 1.54977828e-01]\n",
      " [ 1.50171341e-02]\n",
      " [-4.35296781e-02]\n",
      " [ 1.53018406e-03]\n",
      " [ 1.03639446e-01]\n",
      " [-2.06685126e-01]\n",
      " [-8.38697702e-03]\n",
      " [ 1.85360163e-01]\n",
      " [-4.39356714e-01]\n",
      " [ 5.93775064e-02]\n",
      " [ 1.34638641e-02]\n",
      " [-3.88173342e-01]\n",
      " [-4.39858109e-01]\n",
      " [-1.64330810e-01]\n",
      " [-2.13010982e-02]\n",
      " [-3.39664370e-02]\n",
      " [-2.04054013e-01]\n",
      " [ 5.89199476e-02]\n",
      " [ 2.07270384e-01]\n",
      " [-3.77446115e-02]\n",
      " [-2.35952213e-01]\n",
      " [-3.25874537e-02]\n",
      " [-1.37929454e-01]\n",
      " [-2.13808492e-01]]\n",
      "discriminator_11/dense_71/bias:0 [-0.1668692]\n"
     ]
    }
   ],
   "source": [
    "for var in discriminator.variables:\n",
    "    print(var.name, var.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "1ca7c064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Courses\\24aut_deep_learning\\24aut-deep-learning\\deep-learning-comp3\\testing\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "--------------Evaluation Success-----------------\n",
      "C:\\Users\\User\\Courses\\24aut_deep_learning\\24aut-deep-learning\\deep-learning-comp3\n"
     ]
    }
   ],
   "source": [
    "%cd ./testing\n",
    "!python inception_score.py ../inference/demo output.csv 21\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "fa35e068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_encoder_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    multiple                  0 (unused)\n",
      "                                                                 \n",
      " gru_11 (GRU)                multiple                  0 (unused)\n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "efcd9b89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_22 (Flatten)        multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_66 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_67 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_block_11 (dense_block  multiple                 2107392   \n",
      " )                                                               \n",
      "                                                                 \n",
      " deconv_block_58 (deconv_blo  multiple                 4196864   \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " deconv_block_59 (deconv_blo  multiple                 2098432   \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " deconv_block_60 (deconv_blo  multiple                 524928    \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " deconv_block_61 (deconv_blo  multiple                 131392    \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " deconv_block_62 (deconv_blo  multiple                 32928     \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " conv_block_134 (conv_block)  multiple                 1184      \n",
      "                                                                 \n",
      " deconv_block_63 (deconv_blo  multiple                 8272      \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " conv_block_135 (conv_block)  multiple                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,101,455\n",
      "Trainable params: 9,095,273\n",
      "Non-trainable params: 6,182\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "7d6f6c25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_block_136 (conv_block)  multiple                 16384     \n",
      "                                                                 \n",
      " conv_block_137 (conv_block)  multiple                 264704    \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " conv_block_138 (conv_block)  multiple                 1180928   \n",
      "                                                                 \n",
      " conv_block_139 (conv_block)  multiple                 66816     \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " conv_block_140 (conv_block)  multiple                 295552    \n",
      "                                                                 \n",
      " conv_block_141 (conv_block)  multiple                 148096    \n",
      "                                                                 \n",
      " conv_block_142 (conv_block)  multiple                 17024     \n",
      "                                                                 \n",
      " conv_block_143 (conv_block)  multiple                 74048     \n",
      "                                                                 \n",
      " conv_block_144 (conv_block)  multiple                 4416      \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        multiple                  0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            multiple                  65664     \n",
      "                                                                 \n",
      " dense_70 (Dense)            multiple                  131200    \n",
      "                                                                 \n",
      " dense_71 (Dense)            multiple                  257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,265,089\n",
      "Trainable params: 2,260,993\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00f10b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b128e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a11e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865cbfa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba08b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b304dd53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a7d6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
